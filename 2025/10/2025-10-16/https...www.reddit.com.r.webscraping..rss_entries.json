[
    {
        "age": null,
        "album": "",
        "author": "/u/ChocolateMilk71",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-16T20:38:34.413884+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-16T18:01:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello all, I&#39;m very new to web scraping, so forgive me for any concepts I may be wrong about or that are otherwise common sense. I am trying to scrape a decent-sized amount of posts (and comments, ideally) off Reddit, not entirely sure how many I am looking for, but am looking to do it for free or very cheap. </p> <p>I&#39;ve been made aware of Reddit&#39;s controversial 2023 plan to charge users for using its API, but have also done some more digging and it seems like people are still scraping Reddit for free. So I suppose I want to just get some clarification on all that. Thanks y&#39;all.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ChocolateMilk71\"> /u/ChocolateMilk71 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o8ddr3/mixed_info_on_web_scraping_reddit/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o8ddr3/mixed_info_on_web_scraping_re",
        "id": 3832280,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o8ddr3/mixed_info_on_web_scraping_reddit",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Mixed info on web scraping reddit",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Dankk911",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-16T16:52:48.591114+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-16T15:44:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys, just wanted to share what&#39;s been working for me after months of terrible reply rates.</p> <p>I&#39;m a freelance web developer and needed to find my own clients. Tried all the fancy tools but either couldn&#39;t afford them or they were too complicated.</p> <p>Here&#39;s my stupid-simple process:</p> <p>Google Search for my ideal clients: &quot;digital agency&quot; &quot;New York&quot; email or &quot;marketing director&quot; &quot;tech startup&quot;</p> <p>Scrape emails right from search results using the <a href=\"https://chromewebstore.google.com/detail/emailscout-email-finder-s/cimcplcgdnbakbpdjbdiehmjlfpemofo\">Email Scout</a> Chrome extension. No more manual copying - just click and get 50-100 emails in minutes.</p> <p>Verify &amp; send through a cold email platform with a warmed-up domain.</p> <p>The Email Scout free plan has been perfect for my volume. It&#39;s crazy how much time I wasted before on manual searching.</p> <p>What&#39",
        "id": 3830403,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o89nv0/my_simple_3step_cold_email_process_that_finally",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "My simple 3-step cold email process that finally works",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TellusChaosovich",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-16T16:52:48.340126+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-16T15:42:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Google Shopping took down product-specific results pages last month. Example: shopping.google.com/product/############</p> <p>How are people getting all the Google Shopping prices for a specific product now? I can&#39;t just search the product name or upc, the results have all kinds of related items.</p> <p>There is one results page that still works for now, but it requires a ton of manual effort to get each product&#39;s Feed ID. The Feed IDs are no longer available in Google Ad Manager in a nice list.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TellusChaosovich\"> /u/TellusChaosovich </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o89lfg/google_shopping_changes/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o89lfg/google_shopping_changes/\">[comments]</a></span>",
        "id": 3830402,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o89lfg/google_shopping_changes",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Google Shopping changes",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Shot-Needleworker298",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-16T14:22:50.607040+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-16T13:41:34+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1o86h23/nevermiss_ai_powered_concert_and_festival_curator/\"> <img src=\"https://preview.redd.it/55tc863d9hvf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d59bd18f8e53f85609a913196bbacbc23c7cfd18\" alt=\"NeverMiss: AI Powered Concert and Festival Curator\" title=\"NeverMiss: AI Powered Concert and Festival Curator\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Two years ago I quit social media altogether. Although I feel happier with more free time I also started missing live music concerts and festivals I would\u2019ve loved to see.</p> <p>So I built NeverMiss: a tiny AI-powered app that turns my Spotify favorites into a clean, personalized weekly newsletter of local concerts &amp; festivals based on what I listen on my way to work! </p> <p>No feeds, no FOMO. Just the shows that matter to me. It\u2019s open source and any feedback or suggestions are welcome!</p> <p>GitHub: <a href=\"https://github.com/ManosMrgk/NeverMi",
        "id": 3828950,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o86h23/nevermiss_ai_powered_concert_and_festival_curator",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/55tc863d9hvf1.png?width=640&crop=smart&auto=webp&s=d59bd18f8e53f85609a913196bbacbc23c7cfd18",
        "title": "NeverMiss: AI Powered Concert and Festival Curator",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/gormayfood",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-16T13:10:58.232145+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-16T12:38:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a pretty basic Python scraper for a website but it has a rate limiter. </p> <p>Proxies don\u2019t work as it\u2019s a gov website. Any workarounds or methods?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/gormayfood\"> /u/gormayfood </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o850uc/ip_rate_limiter_workaround/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o850uc/ip_rate_limiter_workaround/\">[comments]</a></span>",
        "id": 3828351,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o850uc/ip_rate_limiter_workaround",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "IP rate limiter workaround",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Hot_Box_9170",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-16T14:22:50.707276+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-16T12:36:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>E-commerce site don&#39;t show all the products at a time, you have to scroll down to load all the products.</p> <p>How you guys deal with such issues.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hot_Box_9170\"> /u/Hot_Box_9170 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o84z35/how_you_guys_deal_with_infinite_page/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o84z35/how_you_guys_deal_with_infinite_page/\">[comments]</a></span>",
        "id": 3828951,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o84z35/how_you_guys_deal_with_infinite_page",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How you guys deal with infinite page?",
        "vote": 0
    }
]