[
    {
        "age": null,
        "album": "",
        "author": "/u/yousephx",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-01T23:55:42.734408+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-01T23:00:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>With <a href=\"https://github.com/yousephzidan/gsvp-dl\">gsvp-dl</a>, an open source solution written in Python, you are able to download millions of panorama images off Google Maps Street View.</p> <p>Unlike other existing solutions (which fail to address major edge cases), <a href=\"https://github.com/yousephzidan/gsvp-dl\">gsvp-dl</a> downloads panoramas in their correct form and size with unmatched accuracy. Using Python Asyncio and Aiohttp, it can handle bulk downloads, scaling to millions of panoramas per day.</p> <p>It was a fun project to work on, as there was no documentation whatsoever, whether by Google or other existing solutions. So, I documented the key points that explain why a panorama image looks the way it does based on the given inputs (mainly zoom levels).</p> <p>Other solutions don\u2019t match up because they ignore edge cases, especially pre-2016 images with different resolutions. They used fixed width and height that only worked for pos",
        "id": 3714452,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nvndre/built_an_open_source_google_maps_street_view",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Built an open source Google Maps Street View Panorama Scraper.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Grigoris_Revenge",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-01T23:55:42.811503+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-01T22:44:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I built a small web scraper to pick up upc and title information for movies (dvd, bluray, etc). I&#39;m currently being very conservative in my scans. 5 workers each on one domain (with a queue of domains waiting). I scan for 1 hour a day and only 1 connection at a time per domain. Built in url history with no revisit rules. Just learning mostly while I build my database of upc codes. </p> <p>I&#39;m currently tracking bandwidth and trying to get an idea on how much I&#39;ll need if I decide to crank things up and add proxy support. </p> <p>I&#39;m going to add cpu and memory tracking next and try to get an idea on scalability for a single workstation.</p> <p>Are any of you running a python based scraper at home? Using proxies? How does it scale on a single system? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Grigoris_Revenge\"> /u/Grigoris_Revenge </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 3714453,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nvn0ir/home_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Home scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MastodonFunny5180",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-01T18:34:02.510107+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-01T18:32:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i am trying to build the scrapper, but failing in getting the element to get the content,<br/> can anyone help me with that.</p> <p>i have try to understand the network tab, windows apollo state and other stuff but nothing works</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MastodonFunny5180\"> /u/MastodonFunny5180 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nvgecr/how_to_scrape_the_medium/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nvgecr/how_to_scrape_the_medium/\">[comments]</a></span>",
        "id": 3712059,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nvgecr/how_to_scrape_the_medium",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "how to scrape the medium",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/brewpub_skulls",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-01T11:25:48.556789+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-01T10:00:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>Any suggestions how can I scrape an aspx site that fetches record form backend. The record can only be fetched when you go to home page -&gt; enter details -&gt; fill captcha then it directs you to next aspx page which has the required data.</p> <p>If I directly go to this page it is blank. Data doesn\u2019t show up in network calls just the final page with the data.</p> <p>Would appreciate any help.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/brewpub_skulls\"> /u/brewpub_skulls </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nv42zc/scraping_aspx_site/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nv42zc/scraping_aspx_site/\">[comments]</a></span>",
        "id": 3707568,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nv42zc/scraping_aspx_site",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping aspx site",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Eliterocky07",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-01T08:36:12.246398+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-01T07:46:32+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1nv22me/web_scraping_techniques_for_static_sites/\"> <img src=\"https://b.thumbs.redditmedia.com/hjGmuAUhY_911jJP6fjOZ98nRIJ4Z4dkuGci8IeyMTc.jpg\" alt=\"Web scraping techniques for static sites.\" title=\"Web scraping techniques for static sites.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Eliterocky07\"> /u/Eliterocky07 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1nv22me\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nv22me/web_scraping_techniques_for_static_sites/\">[comments]</a></span> </td></tr></table>",
        "id": 3706488,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nv22me/web_scraping_techniques_for_static_sites",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/hjGmuAUhY_911jJP6fjOZ98nRIJ4Z4dkuGci8IeyMTc.jpg",
        "title": "Web scraping techniques for static sites.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-01T04:29:38.392160+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-01T03:00:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello and howdy, digital miners of r/webscraping!</p> <p>The moment you&#39;ve all been waiting for has arrived - it&#39;s our once-a-month, no-holds-barred, show-and-tell thread!</p> <ul> <li>Are you bursting with pride over that supercharged, brand-new scraper SaaS or shiny proxy service you&#39;ve just unleashed on the world?</li> <li>Maybe you&#39;ve got a ground-breaking product in need of some intrepid testers?</li> <li>Got a secret discount code burning a hole in your pocket that you&#39;re just itching to share with our talented tribe of data extractors?</li> <li>Looking to make sure your post doesn&#39;t fall foul of the community rules and get ousted by the spam filter?</li> </ul> <p>Well, this is your time to shine and shout from the digital rooftops - Welcome to your haven!</p> <p>Just a friendly reminder, we like to keep all our self-promotion in one handy place, so any promotional posts will be kindly redirected here. Now, let&#39;s get ",
        "id": 3704935,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nux535/monthly_selfpromotion_october_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Monthly Self-Promotion - October 2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/shravana14",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-01T02:42:29.412087+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-01T01:23:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I would like to get the product videos of 1080 pixels or 4k quality from aliexpress site. How to get them?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/shravana14\"> /u/shravana14 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nuv4kw/how_to_scrape_the_aliexpress_site_based_on_the/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nuv4kw/how_to_scrape_the_aliexpress_site_based_on_the/\">[comments]</a></span>",
        "id": 3704666,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nuv4kw/how_to_scrape_the_aliexpress_site_based_on_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape the aliexpress site based on the video availability?",
        "vote": 0
    }
]