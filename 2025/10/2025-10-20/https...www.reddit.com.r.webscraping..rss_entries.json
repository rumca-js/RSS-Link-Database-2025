[
    {
        "age": null,
        "album": "",
        "author": "/u/jaster_ba",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-20T19:48:44.391519+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-20T19:17:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to scrape data from website with browser extension, so it&#39;s basically nothing bad - the content is loaded and viewed by actual user, but with the extension the server returns 403 with message to contact the provider for data access, which is ridiculous. What would be the best approach? From what I can tell, there&#39;s this akamai BS.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jaster_ba\"> /u/jaster_ba </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1obqvw5/akamai_blocks_chrome_extension/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1obqvw5/akamai_blocks_chrome_extension/\">[comments]</a></span>",
        "id": 3859635,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1obqvw5/akamai_blocks_chrome_extension",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Akamai blocks chrome extension",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Open-Journalist6052",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-20T22:33:16.179863+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-20T19:14:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>hello guys, so as the title said, i made a simple api that fetches data from piratebay, and i wanted to know if there are things to consider or to add, and thanks for advance .<br/> written with django, and i used beautifulSoup for scraping.<br/> <a href=\"https://github.com/Charaf3334/Torrent-API\">https://github.com/Charaf3334/Torrent-API</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Open-Journalist6052\"> /u/Open-Journalist6052 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1obqskl/piratebay_api/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1obqskl/piratebay_api/\">[comments]</a></span>",
        "id": 3860822,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1obqskl/piratebay_api",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Piratebay API",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/imormonn",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-20T18:24:44.554607+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-20T17:17:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is there a way to automate blazeR to signalR binary dynamic requests or it\u2019s impossible unless you hack it? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/imormonn\"> /u/imormonn </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1obo0oy/blazer_to_signalr_question/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1obo0oy/blazer_to_signalr_question/\">[comments]</a></span>",
        "id": 3858920,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1obo0oy/blazer_to_signalr_question",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "BlazeR to SignalR question",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Upstairs-Public-21",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-20T08:58:45.385940+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-20T08:26:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>With anti-scraping tools becoming more sophisticated, platforms are detecting and blocking scrapers more effectively. How are you overcoming these advanced systems?</p> <p>Here are a few things I\u2019ve been thinking about:</p> <ol> <li><strong>AI &amp; Machine Learning</strong>: How are you using AI to simulate human behavior and avoid detection by scraping defenses?</li> <li><strong>IP Rotation</strong>: What strategies do you use to manage IP rotation and avoid detection?</li> <li><strong>Device Fingerprinting</strong>: How do you bypass device fingerprinting? Any tools that help?</li> <li><strong>Human Interaction Simulation</strong>: What methods or tools have you used to simulate realistic user behavior (e.g., mouse movements, clicks)?</li> <li><strong>Browser Fingerprinting</strong>: Are you using any tools to simulate complex browser behaviors for better success rates?</li> </ol> <p>Looking forward to hearing your thoughts and",
        "id": 3855056,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1obel3d/overcoming_advanced_antiscraping_algorithms_whats",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 2,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Overcoming Advanced Anti-Scraping Algorithms: What\u2019s Working for You?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Background-Basket854",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-20T07:25:09.796389+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-20T06:09:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey folks -- lurker been wanting to dive deeper in automations. Anyone have experience with these challenges:</p> <ul> <li>Gigya login UI hidden &amp; injected iframes as it hydrates the real form inside an iframe after Arkose checks pass (I believe Arkose is used for fingerprinting the browser). </li> <li>Web workers (SPA?) used to generate some nonce to prevent replay, and are added to the API endpoints.</li> </ul> <p>I have given up hope that I would be able to automate the login portion, but would at least like to the API used for querying can be automated. Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Background-Basket854\"> /u/Background-Basket854 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1obcco8/bypassing_hidden_iframes_spa_arkose/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1obcco8/bypassing_hidden_iframes_spa_arkose/\">[comme",
        "id": 3854704,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1obcco8/bypassing_hidden_iframes_spa_arkose",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Bypassing hidden iframes, SPA, Arkose",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BWJackal",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-20T03:12:12.485984+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-20T03:04:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Not sure if this is a dumb question, but is webscraping not really allowed anymore? I tried to scrape data from zillow using beautifulsoup, not sure of theres a better way to obtain listing data; I got a response 400.</p> <p>I webscraped a little quite a few years back and dont remember running into too many issues.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BWJackal\"> /u/BWJackal </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ob8ylv/is_web_scraping_not_really_allowed_anymore/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ob8ylv/is_web_scraping_not_really_allowed_anymore/\">[comments]</a></span>",
        "id": 3853792,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ob8ylv/is_web_scraping_not_really_allowed_anymore",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is Web Scraping Not Really Allowed Anymore?",
        "vote": 0
    }
]