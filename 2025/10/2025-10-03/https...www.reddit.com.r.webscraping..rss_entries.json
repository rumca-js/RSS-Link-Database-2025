[
    {
        "age": null,
        "album": "",
        "author": "/u/devdkz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-03T21:11:33.686947+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-03T19:30:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I made a node js and puppeteer project that opens a checkout link and fills in the information with my card and I try to make the purchase and it says declined but in my browser on my cell phone or normal computer the purchase is normally approved, does anyone know or have any idea what it could be?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/devdkz\"> /u/devdkz </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nx8r0d/scrapping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nx8r0d/scrapping/\">[comments]</a></span>",
        "id": 3729910,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nx8r0d/scrapping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scrapping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Proper_Gap_1252",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-03T16:02:21.686427+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-03T14:52:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been trying to scrape the gymshark website for a while and I haven&#39;t had any luck with that so I&#39;d like to ask for help, what software should I use ? if anyone had experience with their website, maybe recommend scraping tools to get a full scrape of the whole website and get that scraper to run every 12hrs or every 6 hours to get full updates of sizes colors and names of all the items then get that connected to a google sheet for the results. if anyone has tips please lmk</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Proper_Gap_1252\"> /u/Proper_Gap_1252 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nx1aq8/gymshark_website_full_scrape/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nx1aq8/gymshark_website_full_scrape/\">[comments]</a></span>",
        "id": 3727500,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nx1aq8/gymshark_website_full_scrape",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Gymshark website Full scrape",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Atronem",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-03T14:41:50.199287+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-03T14:15:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Budget: $550</p> <p>We seek an operator to extract one million book titles from <a href=\"http://Abebooks.com\">Abebooks.com</a>, using filtering parameters that will be provided.</p> <p>After obtaining this dataset, the corresponding PDF for each title should be retrieved from the Wayback Machine or Anna\u2019s Archive if available.</p> <p>Estimated raw storage requirement: approximately 20 TB; the required disk capacity will be supplied.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Atronem\"> /u/Atronem </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nx0cbs/hiring_download_1_million_pdfs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nx0cbs/hiring_download_1_million_pdfs/\">[comments]</a></span>",
        "id": 3726605,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nx0cbs/hiring_download_1_million_pdfs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "HIRING - Download 1 million PDFs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/UnhappyRecognition91",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-03T06:14:42.002965+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-03T05:34:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I\u2019ve been trying to learn how to web scrape for the last month and I got the basic down however I\u2019m having trouble trying to gain the data table of per 100 possessions stats from WNBA players. I was wonder if anyone could help me. Also idk if this is like illegal or something, but is there a header or any other way to avoid the 429 errors. Thank you and if you have any other tips that you would like to share please do I really want to learn everything I can about web scraping. This is a link to use to experiment: <a href=\"https://www.basketball-reference.com/wnba/players/c/collina01w.html\">https://www.basketball-reference.com/wnba/players/c/collina01w.html</a> my project includes multiple pages so just use this one. I\u2019m also doing it in python using beautifulsoups</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/UnhappyRecognition91\"> /u/UnhappyRecognition91 </a> <br/> <span><a href=\"https://www.reddit.com/r/w",
        "id": 3722755,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nwqrby/scraping_bball_reference",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping BBall Reference",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Silly_Cause5064",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-03T06:14:42.099244+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-03T01:26:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve used nodriver for a while but recent chrome version doesn\u2019t allow chrome to load extensions.</p> <p>I tried chromium/camoufox/playwright/stealth e.t.c, none are close to actual chrome with a mix of extensions I use/used.</p> <p>Do you know any lesser known alternatives that still works?</p> <p>I\u2019m looking for something deployable and easy to scale that uses regular chrome like nodriver.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Silly_Cause5064\"> /u/Silly_Cause5064 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nwm0vd/are_there_any_chrome_automations_that_allows/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nwm0vd/are_there_any_chrome_automations_that_allows/\">[comments]</a></span>",
        "id": 3722756,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nwm0vd/are_there_any_chrome_automations_that_allows",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are there any chrome automations that allows loading extensions?",
        "vote": 0
    }
]