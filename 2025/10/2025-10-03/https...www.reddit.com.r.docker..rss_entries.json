[
    {
        "age": null,
        "album": "",
        "author": "/u/Proof-Locksmith-3424",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-03T22:26:32.784210+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-03T22:26:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have several containers running on the same host built from a few different compose files. Over the weekend I was working on something else, and also pulled new images for some containers. After that I have been having errors (rolling back did not help). Specifically, it seems that containers could no longer talk to one another using the host&#39;s IP, whether or not they were on the same network (this had been working before). I am only using default networks for now. This is not an exhaustive list, but for example one compose file has Plex and Nginx Proxy Manager (NPM, using the <a href=\"https://hub.docker.com/r/jc21/nginx-proxy-manager\">jc21 container</a>); another has a Kiwix server; and a third has Immich.</p> <p>I use NPM and a domain I own to redirect friendly URLs to my internal IP/port (192.168.x.x:xxxx). I understand this isn&#39;t necessary or the optimal way to accomplish the goal, but it works. Before this issue came up, all my containe",
        "id": 3730380,
        "language": "en",
        "link": "https://www.reddit.com/r/docker/comments/1nxd4vk/help_with_container_networking_issue",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help with container networking issue",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Equivalent-Cable989",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-03T21:11:09.366233+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-03T20:16:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a jenkins container running inside docker, jenkins checks out source code as UID 1000 (&#39;jenkins&#39;) then on the host where I run a windows VM to perform the build they end up owned by &#39;ubuntu&#39; (UID 1000 on the host).</p> <p>The vm runs as &#39;john&#39;, and john doesn&#39;t have write access to the source code owned by &#39;ubuntu&#39;.</p> <p>I&#39;ve seen various different answers for this, like using bindfs, or using a shared group on the host which contains both &#39;ubuntu&#39; and &#39;john&#39; then chmod+chown&#39;ing the files after checkout to be group writable.</p> <p>What is the proper way to solve this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Equivalent-Cable989\"> /u/Equivalent-Cable989 </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1nx9y4a/proper_way_to_share_files_from_a_jenkins/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docke",
        "id": 3729909,
        "language": "en",
        "link": "https://www.reddit.com/r/docker/comments/1nx9y4a/proper_way_to_share_files_from_a_jenkins",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Proper way to share files from a jenkins container to host without UID mismatch?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/abhishekkumar333",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-03T19:58:56.048006+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-03T18:55:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Big thanks to the mods for letting me share this! \ud83d\ude4c you guys are OG!!!</p> <p>Most tutorials show you how to use Docker\u2026 but very few explain what happens behind the scenes when you type docker run.</p> <p>In this tutorial I break it down step by step: \u2022How regular binaries turn into images \u2022How Docker delegates to containerd &amp; then to runc \u2022How namespaces &amp; cgroups actually isolate processes</p> <p>If you\u2019ve always used Docker but never peeked under the hood, this will connect the dots.</p> <p>Docker Containers Are Just Linux? <a href=\"https://youtu.be/l7BjhysbXf8\">https://youtu.be/l7BjhysbXf8</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/abhishekkumar333\"> /u/abhishekkumar333 </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1nx7u37/docker_isnt_magic_its_just_linux_i_traced_how/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1nx7u37/docker_isnt_ma",
        "id": 3729371,
        "language": "en",
        "link": "https://www.reddit.com/r/docker/comments/1nx7u37/docker_isnt_magic_its_just_linux_i_traced_how",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Docker isn\u2019t magic \u2014 it\u2019s just Linux. I traced how containerd, runc, namespaces & cgroups make it all work",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/derekoh",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-03T12:48:16.629649+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-03T11:34:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have several containers that use the docker socket (portainer, autoheal, watchtower, ...). I had a situation where docker-ce got updated and it seemed that these containers lost their connection to the docker socket, but didn&#39;t fail - they just sat there doing nothing.</p> <p>So, I&#39;ve setup another container called docker-watchdog that does nothing but have a healthcheck doing a docker PS every minute - if this docker PS fails/stalls, then the docker container goes unhealthy.</p> <p>How can I automatically restart these other contains if the docker-watchdog container goes unhealthy? Using depends_on only affects startup, whereas what I want is to mark these contains as unhealthy depending on the state of the docker-watchdog container.</p> <p>Make sense?</p> <p>ta</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/derekoh\"> /u/derekoh </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1nwwmc",
        "id": 3725926,
        "language": "en",
        "link": "https://www.reddit.com/r/docker/comments/1nwwmc8/restart_associated_containers_if_container_goes",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Restart associated containers if container goes unhealthy?",
        "vote": 0
    }
]