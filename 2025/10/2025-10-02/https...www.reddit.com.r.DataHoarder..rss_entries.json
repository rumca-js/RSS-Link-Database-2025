[
    {
        "age": null,
        "album": "",
        "author": "/u/Select-Marionberry33",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T23:55:59.652593+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T23:52:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello! Looking for recommendations for a photo scanner. So far, I&#39;ve been looking at the Plustek ePhoto Z300 but wanted some other opinions before I get too far down the road!</p> <p>My father recently passed away and I found a stack of old photos in his home I&#39;d love to scan and create digital copies of. They&#39;re primarily 4x6 or 5x7 prints like you&#39;d get when having a disposable camera developed. Most appear to be from the 90&#39;s, although there are some older and more recent, too.</p> <p>I have no knowledge of photography or scanning in general, but here are my thoughts/assumptions:</p> <p>* I&#39;d like to capture as much detail as possible, so I have been looking for something that does ~1200dpi. But after looking further into it, it seems like 600dpi is the real sweet spot for photos, as 1200 is usually just interpolated and only make a larger image, not a more detailed one?</p> <p>* Looking for something with an ADF or slot-fed",
        "id": 3722561,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwk0l2/looking_to_purchase_a_photo_scanner",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking to purchase a photo scanner",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Appropriate-Bend3332",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T22:21:24.270343+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T21:46:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looks like NASA NTRS is no longer going to be funded/updated. I\u2019m hoping that this is only tied to the government shutdown but would anyone have any advice on how to download the papers from it? I\u2019m willing to go get an external hard drive to store it. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Appropriate-Bend3332\"> /u/Appropriate-Bend3332 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwh38q/nasa_ntrs_no_longer_funded/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwh38q/nasa_ntrs_no_longer_funded/\">[comments]</a></span>",
        "id": 3722080,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwh38q/nasa_ntrs_no_longer_funded",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "NASA NTRS no longer funded",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Cowmootoe",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T22:21:24.432728+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T21:42:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey so im not the most tech savy person but I cant find any other solutions, I have a 4tbWD passport and I cant connect it to my Veon tv It gets recognized but cant be accessed. Now for things I have checked </p> <ol> <li><p>I have reformatted and patritoned it ive attempted a exfat and fat32 partrition and then a fat 32 and fat 32 partrition </p></li> <li><p>I have also bought a powered usb hub cause I read online that power supply may be an issue</p></li> <li><p>The tv does accept fat32 Usb&#39;s ive got a 128gb and a 500gb in the flat that is compatible </p></li> <li><p>Ive put the same exact movies on all 3 usbs they all can be read except the WD passport </p></li> </ol> <p>Im going to move in a few months to work on the boats (which means limited internet) so just hoping to have my media on an external and I opened the box like a cave man so I sadly cant even return the drive</p> <p>Im open to any adivce please and thank you \ud83d\ude4f</p> </div><!-- SC_O",
        "id": 3722081,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwgz68/compatibility",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Compatibility",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/feral_poodles",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T22:21:24.096861+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T21:09:01+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwg4ty/this_data_copy_appears_to_have_stalled_out_with/\"> <img src=\"https://preview.redd.it/qo22q4f6krsf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b76f57a3e97ab701188d4522d1061e9a27f748b8\" alt=\"This data copy appears to have stalled out with 16gb left.\" title=\"This data copy appears to have stalled out with 16gb left.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;m copying from an SSD to a 5tb HDD. After the copy is complete I am going to format the 2tb SSD (FAT?) and use it to store the stuff that feels &quot;essential.&quot; I am doing this primarily to feel some control over life.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/feral_poodles\"> /u/feral_poodles </a> <br/> <span><a href=\"https://i.redd.it/qo22q4f6krsf1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwg4ty/this_data_copy_appears_to_have_stalled",
        "id": 3722078,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwg4ty/this_data_copy_appears_to_have_stalled_out_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/qo22q4f6krsf1.png?width=640&crop=smart&auto=webp&s=b76f57a3e97ab701188d4522d1061e9a27f748b8",
        "title": "This data copy appears to have stalled out with 16gb left.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dedlop",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T20:56:34.882934+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T20:26:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>In datasheet it is stated that 15tb kioxia drives consume 5w in idle and 20w while active.</p> <p>My question is, if a drive would get 10-100 mb/s read 24/7, would the power consumption be closer to 5w or 20w ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dedlop\"> /u/dedlop </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwey6a/how_much_power_enterprise_ssds_would_consume_in_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwey6a/how_much_power_enterprise_ssds_would_consume_in_a/\">[comments]</a></span>",
        "id": 3721514,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwey6a/how_much_power_enterprise_ssds_would_consume_in_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How much power enterprise ssd's would consume in a low intensity environment?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/FarPotential95",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T20:56:34.981268+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T20:04:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I have a Qnap TS-664 with 6 x Seagate Exo 20TB Enterprise (ST20000NM007D). I purchased everything about 3 years ago and stopped using it soon after because it was way too loud for my apt.</p> <p>The drive seeking and banging is insane, I realize this might be my mistake as I purchased enterprise drives and they aren&#39;t meant to be quiet. So can I get some recommendations for 20TB HDDS for my NAS? I live in a small 800sqft apt and I can currently hear my drives outside and my neighbors have complained before as the walls are super thin.</p> <p>My drives will be configured in a raid 5. Also use my NAS to stream 4K Blu-ray UHD via plex or infuse so I mean the drives would have to support that.</p> <p>Would appreciate the help and advice.</p> <p>Also want to add I have a 2TB SSD for Cache (with expansion card)</p> <p>The NAS itself isn&#39;t loud the fan is fairly quiet even under heavy loads but still I&#39;ve ordered some sound pads for the bottom",
        "id": 3721515,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwedzm/can_i_get_your_opinions_on_what_new_drives_to_get",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can I get your opinions on what new drives to get current ones are way to loud with my NAS.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Informal_Fly_9142",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T20:56:34.739466+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T19:52:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have just noticed as well that every freshly installed program I&#39;m launching on this newly installed SSD prompt me the &quot;unknown publisher&quot; pop up, I tried installing the program on Windows&#39;s drive and it works fine with no pop-up showing up, any idea what&#39;s causing all of this ? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Informal_Fly_9142\"> /u/Informal_Fly_9142 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwe1qf/i_installed_a_new_ssd_on_my_laptop_moved_1tb_of/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwe1qf/i_installed_a_new_ssd_on_my_laptop_moved_1tb_of/\">[comments]</a></span>",
        "id": 3721513,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwe1qf/i_installed_a_new_ssd_on_my_laptop_moved_1tb_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I installed a new SSD on my laptop, moved 1TB of file through Teracopy with an external SSD, now all of my .Exes files are missing their signatures (despite running fine)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/yousephx",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T22:21:24.184091+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T19:52:19+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/yousephx\"> /u/yousephx </a> <br/> <span><a href=\"/r/opensource/comments/1nvq258/built_an_open_source_google_maps_street_view/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwe1gc/built_an_open_source_google_maps_street_view/\">[comments]</a></span>",
        "id": 3722079,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwe1gc/built_an_open_source_google_maps_street_view",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Built an open source Google Maps Street View Panorama Scraper.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/pillsandpotionz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T19:31:29.016228+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T19:14:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello. It turns out an SSD I bought, a Sandisk portable TB SSD which allows reading/writing from devices so it&#39;s useful for watching shows while travelling. </p> <p>It turns out that&#39;s had a firmware issue where blocks become corrupted and unusable. </p> <p>Now suddenly getting worried it&#39;ll fail me when I&#39;m not expecting it, what external drives do you recommend?</p> <p>I liked that one as it has both type C and type A so I can put movies on from my PC and watch on a tablet on a coach, but it DOESN&#39;T HAVE to be compatible with phones as I can just shove what I&#39;d wanna watch onto a micro SD. Thanks, it was like \u00a380 so I&#39;m getting worried about it failing so I wanna get a back up that I make sure holds all the same items the Sandisk one has, I&#39;ll probably take a look each month and port onto the back up what the Sandisk has and the new one yet doesn&#39;t so I&#39;ve not lost a whole lot when I does fail and j have a 2nd",
        "id": 3720874,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwd15a/looking_for_best_external_ssd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for best external SSD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/pillsandpotionz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T19:31:28.448554+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T19:10:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwcx5y/any_way_to_mass_dl_snapchat_memories/\"> <img src=\"https://preview.redd.it/ideit5u9zqsf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=405b6946c910fa14122a59723c509b549053f97c\" alt=\"Any way to mass DL Snapchat memories?\" title=\"Any way to mass DL Snapchat memories?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi, looking to masse export all of my snapchat memories due to this coming change </p> <p>I&#39;ve got a few years of images I&#39;d like to keep</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/pillsandpotionz\"> /u/pillsandpotionz </a> <br/> <span><a href=\"https://i.redd.it/ideit5u9zqsf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwcx5y/any_way_to_mass_dl_snapchat_memories/\">[comments]</a></span> </td></tr></table>",
        "id": 3720872,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwcx5y/any_way_to_mass_dl_snapchat_memories",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ideit5u9zqsf1.jpeg?width=640&crop=smart&auto=webp&s=405b6946c910fa14122a59723c509b549053f97c",
        "title": "Any way to mass DL Snapchat memories?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dissected_gossamer",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T19:31:29.276237+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T19:06:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I&#39;ve read through many posts and watched many YouTube videos, trying to figure out the best way to digitize my VHS tapes. But every time I believe I&#39;ve finally found a worthy solution, it turns out its Windows only.</p> <p>Are there any good external video capture devices that:</p> <ol> <li>Work on Mac?</li> <li>Handle the interlaced video signal from a VCR&#39;s composite output properly?</li> <li>Have decent/good video quality?</li> </ol> <p>I know there are dozens of affordable external devices out there, but when I dig into the reviews I find out supposedly they skip every other field and have junky video quality.</p> <p>I&#39;m not looking for absolute pixel perfect quality...just something better than crap, that works on a Mac and doesn&#39;t involve opening up VCRs and soldering.</p> <p>Thank you very much.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dissected_gossamer\"> /u/dissected_gossam",
        "id": 3720875,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwcto4/best_way_to_digitize_vhs_tapes_on_a_mac",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best way to digitize VHS tapes on a Mac?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/someonestupid12",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T19:31:29.498461+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T18:44:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have this drive that I&#39;ve got connected to my pc and I need to transfer a lot of old videos to it. Thats fine and all its just that the cable maxone gave with the drive is extremely short and my pc is under my desk. I&#39;m worried about it heating up too much and potentially causing issues. For now I have left it on top of my pc right on top of 2 fans which are exhaust and blowing air directly into it. It would be more ideal to have a longer cable but I don&#39;t recognise the connection type on my maxone drive. Any help would be appreciated</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/someonestupid12\"> /u/someonestupid12 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwc8lm/25_external_drive_from_maxone_worried_about_heat/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwc8lm/25_external_drive_from_maxone_worried_about_heat/\">[comments]<",
        "id": 3720876,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwc8lm/25_external_drive_from_maxone_worried_about_heat",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "2.5\" external drive from maxone. worried about heat etc. please read desc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheReturnOfAnAbort",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T19:31:29.687817+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T18:30:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Currently I have a 48TB RAID 10, that I am looking to upgrade. I have been eyeballing the Seagate X24 Exos 24TB hard drives so that then I\u2019m essentially doubling my storage and the \u201cold\u201d 48TB will become a backup for crucial files in the new 96TB RAID 10 serverpartdeals has a pretty decent price for manufacturer refurbished drives considering all the demand ($320 per drive roughly). I haven\u2019t bought any manufacturer refurbished drives before, am worried since they have a 2 year warranty vs 5 year when new and since they\u2019re fairly new releases that there already such a large supply of refurbished drives. Are they recommended? Should I steer clear and looked for used instead? Or entirely different drives?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheReturnOfAnAbort\"> /u/TheReturnOfAnAbort </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nwbuhf/seagate_exos_x24_refurb_reliablility/\">[li",
        "id": 3720877,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nwbuhf/seagate_exos_x24_refurb_reliablility",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seagate Exos X24 Refurb Reliablility",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LegendOfDave88",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T16:29:37.779390+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T15:51:52+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw7k1c/the_before_times/\"> <img src=\"https://preview.redd.it/x7x9464tzpsf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d57ef8371e1aefdd9eded5836f7da8b001034ff6\" alt=\"The Before Times\" title=\"The Before Times\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Current price is $229.99. Should have bought 10 last year.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LegendOfDave88\"> /u/LegendOfDave88 </a> <br/> <span><a href=\"https://i.redd.it/x7x9464tzpsf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw7k1c/the_before_times/\">[comments]</a></span> </td></tr></table>",
        "id": 3719246,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw7k1c/the_before_times",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/x7x9464tzpsf1.jpeg?width=320&crop=smart&auto=webp&s=d57ef8371e1aefdd9eded5836f7da8b001034ff6",
        "title": "The Before Times",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ne_nenene--",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T19:31:28.792196+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T15:50:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I wanted to get an external hard drive to back up my files but i know almost nothing about this so I&#39;m not sure which one to get. Is it ok to get used or should i just get a brand new one? There are also a ton of brands our there and I&#39;m not sure which ones are good/reliable. </p> <p>I&#39;ve read a lot of people saying that they lost everything because their hard disk just stopped working for whatever reason, how do i prevent this or know if it starts deteriorating? I don&#39;t plan to move around with the hdd and I&#39;ll keep it in a safe place but should i make sure to connect it every now and then to see that it&#39;s still working or is this not necessary? </p> <p>I&#39;ll have the most important files backed up in Google drive just in case too but is this enough. I&#39;ve seen discussions about storing data in blueray discs because apparently they&#39;re reliable but I&#39;ve also seen a lot of scepticism so I&#39;m not sure. I can only",
        "id": 3720873,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw7if1/backing_up_pc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Backing up pc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Gianfilippo96",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T16:29:38.247966+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T15:14:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My 5-bay Y-Pioneer case doesn&#39;t sleep, I even reduced the timer to 1 minute (via the downloadable software) but it still uses 38 W constantly. Now, I understand that having the drives active can reduce latency, but I don&#39;t care much about it, while I want to keep the case powered up all the time, without wasting power or disk life. Any ideas? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Gianfilippo96\"> /u/Gianfilippo96 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw6jcy/yottamaster_case_doesnt_sleep/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw6jcy/yottamaster_case_doesnt_sleep/\">[comments]</a></span>",
        "id": 3719247,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw6jcy/yottamaster_case_doesnt_sleep",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Yottamaster case doesn't sleep",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/sweetSweets4",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T16:29:38.341431+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T15:00:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Not sure where to Post so maybe the ones with the Most Data know.</p> <p>The Orico D35M2 12-1 Docking Station, saw that thing the other day and i don&#39;t know what to think of it. I mean i read the name but what the hell ist that thing, cuz it&#39;s rather unique in it&#39;s existance, at least for Sure in Europe. But also on eBay and Amazon.</p> <p>But i think i missunderstand it&#39;s use, it has an HDD with a bunch of ports and an Ethernet Port.</p> <p>Sooo, does that mean If i Plug it into an Router or Switch it will act Like an Network Drive ? (Manual says yes ?) And to escalate it further, what about all the stuff attached to this thing over USB, is it also then seeable over the Network?</p> <p>Reading the manual the USBc is an upstream, So all connected devices should show.? And Ethernet always has to be both directions right ?</p> <p>I cant wrap my head around it.</p> <p>Why is no one else offering that kinde of thing? Is it just a stupid Th",
        "id": 3719248,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw65sa/the_orico_d35m2_121_docking_station",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The Orico D35M2 12-1 Docking Station",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/JeddyH",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:27.584737+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T14:29:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve written a python script that finds 5 songs of a particular genre, scrapes all relevant information then creates a video with those songs/information. That video is then added to a MPV player playlist maintaining a buffer of around 30 minutes. </p> <p>This continues in a loop until it hits 10,000 songs, I&#39;m livestreaming this process in realtime, as a way to monitor what its doing and find any AI generated content (theres a bit now...), the script has the ability to exclude any artists from being scraped via URL.</p> <p>I want to be able to bundle up all these songs into a torrent, a snapshot of what was happening in Australian music at this point in time. All songs downloaded are free to listen to on Bandcamp, I just see it as a more efficient way of finding bands I might actually like.</p> <p>I&#39;ve tried to include as much of the Bandcamp info into the ID3 tags of each MP3 file.</p> <p>It&#39;s currently scraping the following genres:",
        "id": 3717562,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw5ca9/im_downloading_10000_australian_songs_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I'm downloading 10,000 Australian songs from Bandcamp",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/counterfeit_coin",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:28.402131+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T14:19:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I acquired a new 20TB external HDD yesterday. It will serve as my back-up drive. I want to simply copy and paste all 15TB onto it right away. Is that a bad idea? Should I break it in somehow such as copying small batches of 50GB, for example? Should I do half today, half tomorrow with the intention of turning it off between two large jobs?</p> <p>Or, am I unnecessarily worrying?</p> <p>EDIT: Ok, thank you for all the responses. Here I go!</p> <p>exit</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/counterfeit_coin\"> /u/counterfeit_coin </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw5360/how_do_you_breakin_a_new_hdd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw5360/how_do_you_breakin_a_new_hdd/\">[comments]</a></span>",
        "id": 3717567,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw5360/how_do_you_breakin_a_new_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you \"break-in\" a new HDD?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/redditunderground1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:27.325141+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T13:35:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://cinematography.com/index.php?/forums/topic/103854-dont-overcomplicate-things-with-your-film-databasesunless-you-have-to/\">Don&#39;t overcomplicate things with your film databases...unless you have to. - Off Topic - Cinematography.com</a></p> <p>I see lots of overcomplication here. If stressed out...try simplicity in your archival work Hoarders!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/redditunderground1\"> /u/redditunderground1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw3yus/dont_overcomplicate_things_with_your_film/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw3yus/dont_overcomplicate_things_with_your_film/\">[comments]</a></span>",
        "id": 3717560,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw3yus/dont_overcomplicate_things_with_your_film",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Don't overcomplicate things with your film databases...unless you have to.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/scene_missing",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:27.171241+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T12:49:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Every Goharddrive and Serverpartdeals link I have saved is between 10 and 20 dollars higher this morning. Looks like the bad times are firmly here.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/scene_missing\"> /u/scene_missing </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw2v2d/used_drives_just_went_up_another_20_ugh/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw2v2d/used_drives_just_went_up_another_20_ugh/\">[comments]</a></span>",
        "id": 3717559,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw2v2d/used_drives_just_went_up_another_20_ugh",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Used drives just went up another $20. Ugh.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MeTuLHeD",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:27.813060+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T12:30:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been using the cheap external toasters in my home setup now for years. But I&#39;ve noticed with the larger capacity hard drives that they are giving me problems. Corrupted one drive so I had to reformat. Had a folder just disappear on another. Fortunately I was able to recover the data. But it was a hassle.</p> <p>So I am seriously considering looking at something a little bit more reliable. I don&#39;t need RAID or any other fancy stuff. JBOD is perfectly sufficient for my needs. Also I would prefer not have to fiddle with proprietary software. I just want to plug it into a Windows machine and be able to access the drives through Windows interface. Any recommendations? Units to avoid like the plague? Eyeballing a TerraMaster box. Any feedback you can give me would be greatly appreciated. Thanks in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MeTuLHeD\"> /u/MeTuLHeD </a> <br/> <span><a href=\"",
        "id": 3717563,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw2gbm/so_just_a_quick_question_for_all_my_fellow",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "So just a quick question for all my fellow DataHoarders...",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LinuxIsFree",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:27.066984+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T12:18:38+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw26jf/affordable_way_to_scan_aperture_microfilm_cards/\"> <img src=\"https://b.thumbs.redditmedia.com/kJME7wrsFQJbycLm9IrvFgyzYhdkgseSITfd9ACBNVY.jpg\" alt=\"Affordable way to scan aperture microfilm cards?\" title=\"Affordable way to scan aperture microfilm cards?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Im trying to scan the microfilm on these cards for some art projects. I got useable photos of one, but many like this one are too tiny to get anything readable. I have a macro lense that lets me read it in tiny sections, but I cant stitch the photos together due to didtortion.</p> <p>Aperture scanners are upwards of $400-$12,000 which I cant afford. All the standard film scanners / microfilm scanners I can find would require me to remove the film from the punch card.</p> <p>Any methods?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LinuxIsFree\"> /u/LinuxIsFree </a>",
        "id": 3717558,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw26jf/affordable_way_to_scan_aperture_microfilm_cards",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/kJME7wrsFQJbycLm9IrvFgyzYhdkgseSITfd9ACBNVY.jpg",
        "title": "Affordable way to scan aperture microfilm cards?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GruMaestro",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T19:31:30.342597+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T11:55:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, i have situation where i share data with my coleagues over Onedrive, its not perfect but back when we started it worked well enough, now i am thinking about creating simple storage that would replace one drive since we are going bit over 5tb now, what i am thinking about: </p> <p>two same systems:<br/> a) is daily upload and download server, no pool, just individual disks so everything does not spin all the time (i ll have this in my flat, and it should save bit of energy??)<br/> b) one of coleagues will have identical that would thate snapshots 2x times a day of new data as backup</p> <p>is this line of thinking alright or better yet what do i miss?<br/> also what software would you recommend for working ideally dirtectly inside that server folder (having repo in my pc) and being able to preferably like onedrive autosync to that server or some version cotnroll? </p> <p>thanks in advance</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"h",
        "id": 3720878,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw1pd2/simple_solution_to_one_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "simple solution to one drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BulkySquirrel1492",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:28.080938+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T10:53:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everybody!</p> <p>I want to download/archive all posts and comments from a very helpful user on X/Twitter who has shared his knowledge about medical science and the burden of chronic illness for several years. This user is leaving X/Twitter for personal reasons and we are brainstorming how we can keep the helpful information for some selected followers available. Windows or Linux doesn&#39;t matter.</p> <p>Any ideas?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BulkySquirrel1492\"> /u/BulkySquirrel1492 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw0j34/xtwitter_archiver/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nw0j34/xtwitter_archiver/\">[comments]</a></span>",
        "id": 3717565,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nw0j34/xtwitter_archiver",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "X/Twitter Archiver",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HaiseKaneki12",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:28.795016+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T09:14:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Been curious if it&#39;s okay to just delete HD Sentinel Portable folder cause I don&#39;t see an uninstaller. So is it fine to delete the folder it is in directly? Thank you to who will answer</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HaiseKaneki12\"> /u/HaiseKaneki12 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvyw3l/does_hd_sentinel_portable_not_have_an_uninstaller/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvyw3l/does_hd_sentinel_portable_not_have_an_uninstaller/\">[comments]</a></span>",
        "id": 3717569,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nvyw3l/does_hd_sentinel_portable_not_have_an_uninstaller",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does HD Sentinel Portable not have an uninstaller?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/341255",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:28.217618+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T08:27:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I use gallery-dl to download images from deviantart. But it only downloads the first image, the rest of the images in the post will be skipped. Does anyone know how to download all the images in the post?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/341255\"> /u/341255 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvy5ip/gallerydl_can_only_download_1_image_from/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvy5ip/gallerydl_can_only_download_1_image_from/\">[comments]</a></span>",
        "id": 3717566,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nvy5ip/gallerydl_can_only_download_1_image_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "gallery-dl can only download 1 image from deviantart.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/herculeon6",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:27.448989+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T08:17:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to start simple - finding and storing DRM free versions of my favourite games. I\u2019m thinking 2-4 TB, as I know nothing about proper storage and archiving and have lots to learn.</p> <p>For now, purely focusing on PC games that can run on Windows 10 or 11.</p> <p>This database would be for private use and future use by the kids, etc., so I assume I\u2019d need to use a medium that enables relatively hassle-free access.</p> <p>Actually, is this even a datahoarder question? </p> <p>Sorry if I\u2019m in the wrong sub. I\u2019m just looking for some advice on how to proceed with this to make sure I have easy and reliable access to my favourite games these days when real ownership is ephemeral. </p> <p>Main question marks for me: - proper storage medium for this use case? - anything I\u2019d need to consider?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/herculeon6\"> /u/herculeon6 </a> <br/> <span><a href=\"https://www.reddit.com/r",
        "id": 3717561,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nvy0b7/new_here_i_want_to_start_archiving_games",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New here. I want to start archiving games.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/counterfeit_coin",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:27.958997+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T08:09:19+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvxvvr/seagate_expansion_hdd_makes_thumping_sounds/\"> <img src=\"https://external-preview.redd.it/0Ji0FEzUjc9paP7RjM3ofQ1oiQPKUFJEiDS84Iq7e34.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e0ddd7b5825660f2a20bbd07149d6e54439fc4ed\" alt=\"Seagate Expansion HDD makes thumping sounds during write cycles. Can you determine whether this is normal?\" title=\"Seagate Expansion HDD makes thumping sounds during write cycles. Can you determine whether this is normal?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/counterfeit_coin\"> /u/counterfeit_coin </a> <br/> <span><a href=\"https://imgur.com/a/ttn6E7K\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvxvvr/seagate_expansion_hdd_makes_thumping_sounds/\">[comments]</a></span> </td></tr></table>",
        "id": 3717564,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nvxvvr/seagate_expansion_hdd_makes_thumping_sounds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/0Ji0FEzUjc9paP7RjM3ofQ1oiQPKUFJEiDS84Iq7e34.jpg?width=640&crop=smart&auto=webp&s=e0ddd7b5825660f2a20bbd07149d6e54439fc4ed",
        "title": "Seagate Expansion HDD makes thumping sounds during write cycles. Can you determine whether this is normal?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/UnlikelyAdventurer",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T05:13:55.662394+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T05:00:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Need a new NAS. Currently in the Qnap ecosystem and generally like the power/dollar, but would consider another brand, just preferably Taiwan, Europe, US, or non mainland China.<br/> For business storage, self-hosting, and Plex/Jellyfin. 10 GBE is essential, two SSD for software so one can fail without losing the system.<br/> Where are the great deals on HDs? Is 26TB for $250.00 still around? Is that the current sweet spot?<br/> Looking at the QNAP TS-832PX-4G 8 Bay High-Capacity NAS with 10GbE SFP+ and 2.5GbE. Is that a good price/performance model right now? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/UnlikelyAdventurer\"> /u/UnlikelyAdventurer </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvut1i/advice_sought_whats_best_in_qnap_8_bay_and_sweet/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvut1i/advice_sought_whats_best_in_qnap_8_bay_and_",
        "id": 3715681,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nvut1i/advice_sought_whats_best_in_qnap_8_bay_and_sweet",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Advice sought: what's best in Qnap 8 bay and sweet spot in 20tb+ drives price/TB?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Character-Figure-311",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T14:50:28.622962+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T04:27:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I am waiting for the arrival of my NAS, which I will be installing TrueNAS on. I thought I can install CopyParty on my windows machine and get used to using the tool.<br/> Unfortunately there are minimal videos explaining simple processes available online and any videos I do find are poorly explained or just heavy breathers frothing over all the features without actually showcasing HOW to do things.<br/> My experience is as follows: (I am aware that thousands of others had no problem, but this is from the perspective of someone with ZERO coding or python experience) </p> <p>I went to the Github and downloaded the latest .py file. </p> <p>The quick start guide states:</p> <p>&quot;just run <a href=\"https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py\"><strong>copyparty-sfx.py</strong></a> -- that&#39;s it! \ud83c\udf89\u2139\ufe0f the sfx is a <a href=\"https://github.com/9001/copyparty/issues/270\">self-extractor</a> which unpacks an embedded <code",
        "id": 3717568,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nvu7y4/copy_party_is_not_fun_to_setup_on_windows",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Copy Party is NOT fun to setup on Windows",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/OracleDBA",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T02:18:21.259612+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T02:08:23+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/OracleDBA\"> /u/OracleDBA </a> <br/> <span><a href=\"https://si.inc/posts/the-heap/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvrhdp/how_we_spent_under_half_a_million_dollars_to/\">[comments]</a></span>",
        "id": 3715097,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nvrhdp/how_we_spent_under_half_a_million_dollars_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How we spent under half a million dollars to build a 30 petabyte data storage cluster in downtown San Francisco. So many Linux ISOs\u2026",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ShavedDesk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T00:55:04.045078+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T00:23:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>When I just export directly to camera roll, it saves with the export date instead of the original capture date. Ideally, I want everything downloaded in bulk with the right timestamps in the files themselves. Has anyone found a reliable way to do this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ShavedDesk\"> /u/ShavedDesk </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvp8ur/has_anyone_here_exported_their_snapchat_memories/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvp8ur/has_anyone_here_exported_their_snapchat_memories/\">[comments]</a></span>",
        "id": 3714747,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nvp8ur/has_anyone_here_exported_their_snapchat_memories",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Has anyone here exported their Snapchat Memories and managed to keep the original dates?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sad_Ad_3169",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-02T00:55:04.121707+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-02T00:03:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Having a hard time finding a free way to download the streams. Can download everything else (video, audio, pdf, other files). </p> <p>Anyone had any luck?</p> <p>Be nice to have a backup of what I paid for. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sad_Ad_3169\"> /u/Sad_Ad_3169 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvotk2/patreon_streams/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nvotk2/patreon_streams/\">[comments]</a></span>",
        "id": 3714748,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nvotk2/patreon_streams",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Patreon Streams",
        "vote": 0
    }
]