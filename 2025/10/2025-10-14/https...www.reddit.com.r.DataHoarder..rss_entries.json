[
    {
        "age": null,
        "album": "",
        "author": "/u/adeptus_chronus",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T23:29:54.140518+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T23:22:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, my 4To external drive from 2019 is getting old and disk health softwares are starting to scream at me, so it&#39;s time for an upgrade, but getting a NAS seems like overkill since I don&#39;t need any sort of accessibility over network nor am I looking for a home multimedia server, I just need a big (~10To) external drive that won&#39;t fail on me in one go.</p> <p>I realize that this is kind of like asking if there is something between a bike and a car and that the answer will probably be &quot;lol no, get a NAS&quot;, but I figured that I&#39;d at least ask some peoples that are actually knowledgeable on the subject before I spend a thousand bucks on NAS.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/adeptus_chronus\"> /u/adeptus_chronus </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6v5ji/i_need_redundant_storage_but_using_a_nas_as_a/\">[link]</a></span> &#32; <span><a href=\"h",
        "id": 3814800,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6v5ji/i_need_redundant_storage_but_using_a_nas_as_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I need redundant storage but using a NAS as a glorified external drive seems overkill, any other options ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lucky_peic",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T23:29:54.418452+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T22:56:00+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6uj2g/brand_new_wd_red_plus_4tb_making_clicking_and/\"> <img src=\"https://external-preview.redd.it/cHJ2bXp0aDRwNXZmMfZkXFi_IhFl9Myrx6ZHFeesKZ8ycTgFO1g-howRc7Rb.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e6b57f7a9071ded8b5c4c24ee1051460c04df222\" alt=\"Brand new WD Red Plus 4TB making clicking and beeping noises when downloading files in browser.\" title=\"Brand new WD Red Plus 4TB making clicking and beeping noises when downloading files in browser.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>So I already had two 4TB WD Red Plus drives but since Im hoarding lots of data I decided to get another one cause other two were getting full.</p> <p>Right away I ran HD Sentinel surface test (write and read) which took about 14 hours and everything looked fine, no bad blocks or other issues.</p> <p>After the test I finished setting everything up and proceeded to download some files from my cloud back onto the dri",
        "id": 3814801,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6uj2g/brand_new_wd_red_plus_4tb_making_clicking_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/cHJ2bXp0aDRwNXZmMfZkXFi_IhFl9Myrx6ZHFeesKZ8ycTgFO1g-howRc7Rb.png?width=640&crop=smart&auto=webp&s=e6b57f7a9071ded8b5c4c24ee1051460c04df222",
        "title": "Brand new WD Red Plus 4TB making clicking and beeping noises when downloading files in browser.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BikemeAway",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T23:29:54.522768+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T22:44:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I wanted to use an external NVMe as temporary disk while for video editing on the go, so I wouldn&#39;t say is heavy task use (heating not an issue) but I still require things to be available while I&#39;m working. I tried the UGREEN 10G and Sabrent 10G enclosures. They seem to work fine for transfering files in one take but they are not reliable cause sometimes, for no reason, even when you&#39;re not doing anything special they disconnect. And that&#39;s really a problem. Are these enclosures supposed to be usable or i should just stick to use them internally?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BikemeAway\"> /u/BikemeAway </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6u9hp/nvme_enclosures_that_are_reliable/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6u9hp/nvme_enclosures_that_are_reliable/\">[comments]</a></span>",
        "id": 3814802,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6u9hp/nvme_enclosures_that_are_reliable",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "NVMe enclosures that are reliable?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/searcher92_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T23:29:53.761674+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T22:00:30+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6t6yy/youtube_either_by_human_error_or_otherwise_seems/\"> <img src=\"https://preview.redd.it/ccfmgm6sf5vf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e60be9b6cc7b766b2a5339082811d300780c7970\" alt=\"YouTube, either by human error or otherwise, seems to be making some old videos with low views inaccessible: &quot;We're processing this video. Check back later.&quot;\" title=\"YouTube, either by human error or otherwise, seems to be making some old videos with low views inaccessible: &quot;We're processing this video. Check back later.&quot;\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/searcher92_\"> /u/searcher92_ </a> <br/> <span><a href=\"https://i.redd.it/ccfmgm6sf5vf1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6t6yy/youtube_either_by_human_error_or_otherwise_seems/\">[comments]</a></span> </td></tr></table>",
        "id": 3814798,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6t6yy/youtube_either_by_human_error_or_otherwise_seems",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ccfmgm6sf5vf1.png?width=640&crop=smart&auto=webp&s=e60be9b6cc7b766b2a5339082811d300780c7970",
        "title": "YouTube, either by human error or otherwise, seems to be making some old videos with low views inaccessible: \"We're processing this video. Check back later.\"",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Capitan_Indus",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T21:56:36.266695+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T21:05:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello Datahoarders, I am searching the Reuters Morning News Call U.S. Edition of the last five years. I&#39;d like to know, if by chance, anyone of you has it and would share it with me.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Capitan_Indus\"> /u/Capitan_Indus </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6rrpx/has_anyone_archived_the_reuters_morning_news_call/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6rrpx/has_anyone_archived_the_reuters_morning_news_call/\">[comments]</a></span>",
        "id": 3814093,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6rrpx/has_anyone_archived_the_reuters_morning_news_call",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Has anyone Archived the Reuters Morning News Call",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LeoWitt",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T21:56:36.403689+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T20:26:33+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6qqds/t7_ssd_default_accessing_updating_the_samsung/\"> <img src=\"https://b.thumbs.redditmedia.com/nJsg5Au_KnUqCgtqgwz_TfDjx6ryIUNbPKRoRkHq5VM.jpg\" alt=\"T7 SSD, Default Accessing &amp; updating the Samsung Software?\" title=\"T7 SSD, Default Accessing &amp; updating the Samsung Software?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>When I plug in the T7 SSD, what is the proper way to access the encryption software each time, and set that up?</p> <p>Do you need to install the app on the COMPUTER your using, or does it just launch from the SSD? The folder just has that .exe file and everytime i doube click it, it runs the installer, it does not open just the app itself?<br/> Also, I can not get it to update, it says failed to communicate? I have no VPN enabled. </p> <p><a href=\"https://preview.redd.it/r52dt7uqz4vf1.png?width=1948&amp;format=png&amp;auto=webp&amp;s=1927c147286b5f2ebf4b857a02ab918c04ad1fed\">htt",
        "id": 3814094,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6qqds/t7_ssd_default_accessing_updating_the_samsung",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/nJsg5Au_KnUqCgtqgwz_TfDjx6ryIUNbPKRoRkHq5VM.jpg",
        "title": "T7 SSD, Default Accessing & updating the Samsung Software?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GroundbreakingOwl186",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T20:20:47.086631+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T20:15:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I&#39;m new at this. I finally decided that I have a lot of things I don&#39;t want to lose, but I have so many miscellaneous size hard drives over the years that are all getting pretty full. I&#39;d like something so that if a hard drive fails I can just plug a new one in and it can get that data back. </p> <p>I currently have 1 of each: 8tb 4tb 1tb 640bg 500gb 300gb</p> <p>I&#39;m not opposed to buying another hard drive if it helps. Like maybe a 16tb? I&#39;m just not really sure which raid number would suit me so I&#39;m having trouble figuring out which one to research. </p> <p>I&#39;ve just recently setup a proxmox server, if that helps. All this is new. But it&#39;s pretty fun!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GroundbreakingOwl186\"> /u/GroundbreakingOwl186 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6qfoz/is_there_a_raid_that_would_work_with_my_current/\">[lin",
        "id": 3813545,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6qfoz/is_there_a_raid_that_would_work_with_my_current",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a raid that would work with my current hard srives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/keremdev",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T20:20:47.234468+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T20:14:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Are there any tools available for scraping an entire blogger feed (including all subpages and images) to create a mirror? I tried using wget for this but Blogger seems to have a weird resolving thing going on with images, making them point to 404s.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/keremdev\"> /u/keremdev </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6qemk/archiving_blogger_feed/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6qemk/archiving_blogger_feed/\">[comments]</a></span>",
        "id": 3813546,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6qemk/archiving_blogger_feed",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Archiving Blogger feed",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/flearhcp97",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T20:20:46.819322+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T19:44:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So this drive I bought was giving me tons of errors, so I copied whatever I could back off of it, and am planning to exchange it. Problem is I&#39;m paranoid and doing a full reformat (Windows) will apparently take well over a week. Is it worth it? Is there a faster way? Am I just being paranoid? Thanks! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/flearhcp97\"> /u/flearhcp97 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6pltk/have_you_ever_had_to_returnexchange_a_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6pltk/have_you_ever_had_to_returnexchange_a_drive/\">[comments]</a></span>",
        "id": 3813544,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6pltk/have_you_ever_had_to_returnexchange_a_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Have you ever had to return/exchange a drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GladDragonfly5709",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T21:56:36.688022+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T19:21:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey! so a while ago I downloaded Rule 34 downloader and it&#39;s been working up until now, every time I try and download something I get an error code saying &quot;The index being passed in is out of range&quot; </p> <p>coul anybody follow me through how to fix this please and thank you :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GladDragonfly5709\"> /u/GladDragonfly5709 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6oz8a/rule_34_downloader_github_error_need_help/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6oz8a/rule_34_downloader_github_error_need_help/\">[comments]</a></span>",
        "id": 3814095,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6oz8a/rule_34_downloader_github_error_need_help",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Rule 34 downloader github error? NEED HELP",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/00headbob00",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T21:56:35.775034+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T19:01:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Legislation is being created that will force companies to use facial recognition to identify users.</p> <p>ANY ACCOUNTS THAT DO NOT COMPLY IN 30 DAYS, AND HAVE BRAZIL AS THEIR ORIGIN, SHOULD, BY LAW, BE DELETED.</p> <p>This is going to be a massive data loss if it does pass, specially considering all the abandoned channels laying around.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/00headbob00\"> /u/00headbob00 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6og9x/start_hoarding_brazilian_media_specially_youtube/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6og9x/start_hoarding_brazilian_media_specially_youtube/\">[comments]</a></span>",
        "id": 3814091,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6og9x/start_hoarding_brazilian_media_specially_youtube",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Start hoarding brazilian media, specially youtube.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/divyraval",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T18:41:43.857846+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T18:05:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello there, I am looking to get about 1 to 2 TB of storage for cheaper price and I found that there is some kind of SSD enclosure. I do not know how it works. Should I go for external SSD or SSD with enclosure? Do They both work the same? , my main purpose is to Store photos and videos accumulated over time and maybe some documents. What do you guys suggest and if you have any links, please share them with me.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/divyraval\"> /u/divyraval </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6mymw/external_ssd_or_ssd_with_enclosure/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6mymw/external_ssd_or_ssd_with_enclosure/\">[comments]</a></span>",
        "id": 3812742,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6mymw/external_ssd_or_ssd_with_enclosure",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "External ssd or ssd with enclosure",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cruisercut",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T21:56:35.882598+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T18:00:04+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6msop/wall_of_dead_media_collection/\"> <img src=\"https://preview.redd.it/fobn2wrn94vf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=14bd639ace2be70d633b7d44a659285a9a2ee3cd\" alt=\"Wall of dead media collection\" title=\"Wall of dead media collection\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Kind of a hoarder setup, any suggestions of what I need next, looking for normal size record, 8 track, and 10 in floppies rn</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cruisercut\"> /u/cruisercut </a> <br/> <span><a href=\"https://i.redd.it/fobn2wrn94vf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6msop/wall_of_dead_media_collection/\">[comments]</a></span> </td></tr></table>",
        "id": 3814092,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6msop/wall_of_dead_media_collection",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/fobn2wrn94vf1.jpeg?width=640&crop=smart&auto=webp&s=14bd639ace2be70d633b7d44a659285a9a2ee3cd",
        "title": "Wall of dead media collection",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/404-no-fund",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T18:41:45.415762+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T17:50:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I only have less than 1TB of data to store atm. Which one is faster and easier to use?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/404-no-fund\"> /u/404-no-fund </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6mjhd/dad_gifted_me_two_nas_systems_which_one_would_you/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6mjhd/dad_gifted_me_two_nas_systems_which_one_would_you/\">[comments]</a></span>",
        "id": 3812745,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6mjhd/dad_gifted_me_two_nas_systems_which_one_would_you",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dad gifted me two NAS systems. Which one would you keep? TERRAMASTER F4 SSD (2x2TB WD Black SSD) or UGREEN DH4300 Plus (2x4TB WD Red HDD).",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/-Roby-",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T21:56:36.852248+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T17:42:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So recently I bought a NAS and started searching for HDD and which kind of configuration I would like to use. I&#39;m tempted to choose the maximum security and have RAID6 but I&#39;m wondering if on a practical way it would be overkill.</p> <p>My need is to create a family server with every pictures we own and maybe some other stuff. Right now everything is on a google drive storage and I want to close it. </p> <p>Is RAID6 not to overkill? There will be no other backup and I wonder if a disk die I will have time to react and is it common of having 2 hdd dying without having time to prevent that. I want to buy from a known brand and good one.</p> <p>Thanks for you help! Hope my English isn&#39;t too broken lol</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/-Roby-\"> /u/-Roby- </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6mb66/hey_noob_here_which_one_i_shall_use_between_raid5/\">[link]<",
        "id": 3814096,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6mb66/hey_noob_here_which_one_i_shall_use_between_raid5",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hey noob here. Which one I shall use between RAID5 and RAID6?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Loud_Ride_1122",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T23:29:53.839666+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T17:33:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Yeah, it was my dumbest mistake ever in my life probably, there are some personal data on it, maybe even a crypto wallet seed phrase on it. I sold it and thought it was bitlocker encrypted anyways (but it wasn\u2019t) to a friend of my friend and I am not sure if they\u2019ve already seen the data, they claimed that they \u201cformatted\u201c the drive but should I ask them to give it back? and even if I get it back, is it even worth it since they could already just copy the file off the drive.</p> <p>Also yes, I\u2019ve created a new wallet and moved the funds to the new one, enabled 2FA, changed password etc etc just in case. And in case of any identity theft I could just locate him by asking my friend.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Loud_Ride_1122\"> /u/Loud_Ride_1122 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6m1ev/i_forgot_to_wipe_my_drive_before_i_sold_it_roast/\">[link]</a></span> &#32",
        "id": 3814799,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6m1ev/i_forgot_to_wipe_my_drive_before_i_sold_it_roast",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I forgot to wipe my drive before I sold it, roast me",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Red-Hot_Snot",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T18:41:44.292037+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T17:09:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a few dozen older DVD rips I accidentally encoded at a non-standard resolution that I&#39;ve since fixed, but that means I have multiple copies of these movies in separate directories and I&#39;d like to find some way to compare file names and <em>control</em> which version I delete without merging the contents of these folders (cause they on two different HDDs).</p> <p>I&#39;ve tried DupeGuru, and it seems to work well at file name matching, but infuriatingly, doesn&#39;t allow me to pick the version to get rid of, and often tags the incorrectly encoded versions of these files as &quot;the originals&quot; so they can&#39;t be deleted.</p> <p>Is there a utility that can do a simple filename comparison between two directories but removes the training wheels and allows more granular control over files marked for batch deletion? I don&#39;t need content comparison, just an app that can find two files named the same way that may have different file",
        "id": 3812743,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6ldzx/duplicate_video_files_of_different_sizes_best",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "\"Duplicate\" video files of different sizes; Best approach?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ScarredCorn",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T18:41:44.497541+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T17:08:40+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6lczl/hard_drive_keeps_beeping/\"> <img src=\"https://external-preview.redd.it/cDVvbnp0amowNHZmMWygeOUE_6NoEEkPd5s_moZ71K_WdascuDWuB18t5Iyz.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ecddb424f4b0c4023204da161b6c5fb4b4eab0d5\" alt=\"Hard drive keeps beeping\" title=\"Hard drive keeps beeping\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>It only does this when i open games that are downloaded onto it, then it will either stop, or if it doesn&#39;t, it keeps going until the game closes itself, this is the second hard drive I&#39;ve bought after returning the first one for the same reason, it this a me issue or is my store just scamming me?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ScarredCorn\"> /u/ScarredCorn </a> <br/> <span><a href=\"https://v.redd.it/wb6zorej04vf1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6lczl/hard_",
        "id": 3812744,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6lczl/hard_drive_keeps_beeping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/cDVvbnp0amowNHZmMWygeOUE_6NoEEkPd5s_moZ71K_WdascuDWuB18t5Iyz.png?width=640&crop=smart&auto=webp&s=ecddb424f4b0c4023204da161b6c5fb4b4eab0d5",
        "title": "Hard drive keeps beeping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Jakethefanofturbo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T17:06:41.356243+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T16:40:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.youtube.com/watch?v=6mz-8fqKDho\">https://www.youtube.com/watch?v=6mz-8fqKDho</a></p> <p>This is said video, it has an <a href=\"http://archive.org\">archive.org</a> snapshot but it keeps showing an error.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Jakethefanofturbo\"> /u/Jakethefanofturbo </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6kkw9/any_way_to_archive_a_deletedprivated_youtube_video/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6kkw9/any_way_to_archive_a_deletedprivated_youtube_video/\">[comments]</a></span>",
        "id": 3811998,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6kkw9/any_way_to_archive_a_deletedprivated_youtube_video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any way to archive a deleted/privated youtube video?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LexisMikaya",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T17:06:41.463128+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T16:30:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This feels like the best place to ask as I&#39;ve been moving the same drive across setups over the course of 10-ish years.</p> <p>Is software better for cloning by plugging in the drive to the computer and letting it sit overnight, or should I use those hard drive cloners that do not require plugging into a computer? What is a good recommendation.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LexisMikaya\"> /u/LexisMikaya </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6kbs9/recommendations_for_cloning_a_boot_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6kbs9/recommendations_for_cloning_a_boot_drive/\">[comments]</a></span>",
        "id": 3811999,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6kbs9/recommendations_for_cloning_a_boot_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Recommendations for Cloning a boot drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/specd-tech",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T17:06:41.684270+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T16:03:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>With the price of individual drives being what they are I\u2019m looking for a new less janky case then what I have been using. From my research Sliger and Rosewill fit what I\u2019m looking for but with the price difference being roughly $100 Sliger seemed like a better choice. I\u2019m looking at the CX4712 but it is a big purchase for me so I was looking for other peoples opinions.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/specd-tech\"> /u/specd-tech </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6jlh9/thoughts_on_sliger_hot_swap_cases/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6jlh9/thoughts_on_sliger_hot_swap_cases/\">[comments]</a></span>",
        "id": 3812000,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6jlh9/thoughts_on_sliger_hot_swap_cases",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Thoughts On Sliger Hot Swap Cases?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jabberwockxeno",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T15:53:57.939534+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T15:35:36+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6its5/my_26tb_seagate_external_hdd_arrived_is_the/\"> <img src=\"https://external-preview.redd.it/cp-NJfC4CV6Iw27M1QSrLz5jxryKs27Cd0ZkwLKE-Uw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b0d726350c9723d50b9eead676a67e2f01133d3d\" alt=\"My 26tb Seagate External HDD arrived... is the inside of the chasis supposed to look crumpled like this?\" title=\"My 26tb Seagate External HDD arrived... is the inside of the chasis supposed to look crumpled like this?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jabberwockxeno\"> /u/jabberwockxeno </a> <br/> <span><a href=\"https://i.imgur.com/7enUBaJ.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6its5/my_26tb_seagate_external_hdd_arrived_is_the/\">[comments]</a></span> </td></tr></table>",
        "id": 3811296,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6its5/my_26tb_seagate_external_hdd_arrived_is_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/cp-NJfC4CV6Iw27M1QSrLz5jxryKs27Cd0ZkwLKE-Uw.png?width=640&crop=smart&auto=webp&s=b0d726350c9723d50b9eead676a67e2f01133d3d",
        "title": "My 26tb Seagate External HDD arrived... is the inside of the chasis supposed to look crumpled like this?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/manzurfahim",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T15:53:58.197097+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T15:16:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am finding myself being obsessed with collecting remuxes as well as full BD/UHD discs for the movies that I really like, and it is taking a toll on the storage capacity. Not sure if anyone else do this. I often find myself relentlessly looking for full discs that I can&#39;t seem to find anywhere and requesting them in tracker forums for BON points even though I have a perfectly good remux.</p> <p>It is getting crazy, GoT discs are like over 2TB, lost is over 1.4TB, Friends is close to 2TB and so on.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/manzurfahim\"> /u/manzurfahim </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6ibd7/do_you_hoard_remuxes_as_well_as_discs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6ibd7/do_you_hoard_remuxes_as_well_as_discs/\">[comments]</a></span>",
        "id": 3811297,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6ibd7/do_you_hoard_remuxes_as_well_as_discs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Do you hoard remuxes as well as discs?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Viperer",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T15:53:57.839640+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T14:42:24+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Viperer\"> /u/Viperer </a> <br/> <span><a href=\"/r/lostmedia/comments/1o63u1r/partially_lost_paleoworld_paleontologydinosaur/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6he8f/partially_lost_paleoworld_paleontologydinosaur/\">[comments]</a></span>",
        "id": 3811295,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6he8f/partially_lost_paleoworld_paleontologydinosaur",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[Partially Lost] PaleoWorld - Paleontology/Dinosaur Documentary Series",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lewzealandlover",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T14:42:08.142867+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T14:34:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Am I missing something here:</p> <p><a href=\"https://www.onbuy.com/gb/p/external-hard-drive-portable-shockproof-mobile-ssd-20tb-blue%7Ep76616152/\">https://www.onbuy.com/gb/p/external-hard-drive-portable-shockproof-mobile-ssd-20tb-blue~p76616152/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lewzealandlover\"> /u/lewzealandlover </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6h73z/scam/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6h73z/scam/\">[comments]</a></span>",
        "id": 3810710,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6h73z/scam",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scam?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cosacee88",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T13:30:52.785648+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T12:27:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Long story short, i was about to buy from robertelectronics who sells recerts shipped from singapoore, however iv been reading horror stories about relabelled drives and dubious practices in other threads and online news articles.</p> <p>Where would be my next best bet buying recert drives in the UK for decent prices. Happy to import from the EU if shipping allows... thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cosacee88\"> /u/cosacee88 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6e3qq/uk_hd_refurbcert_reputable_sellers/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6e3qq/uk_hd_refurbcert_reputable_sellers/\">[comments]</a></span>",
        "id": 3810045,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6e3qq/uk_hd_refurbcert_reputable_sellers",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "UK HD Refurb/cert Reputable sellers?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/shellshock321",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T13:30:52.874005+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T12:22:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I find two nvme enclosures that are small and compact. But I can&#39;t seem to find quad bay nvme enclsoures.</p> <p>Is there a reason why?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/shellshock321\"> /u/shellshock321 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6e001/is_there_a_quad_bay_nvme_enclosure_that_is_small/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6e001/is_there_a_quad_bay_nvme_enclosure_that_is_small/\">[comments]</a></span>",
        "id": 3810046,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6e001/is_there_a_quad_bay_nvme_enclosure_that_is_small",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a quad bay nvme enclosure? that is small and compact?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/sideshowbob01",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T12:13:25.859041+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T11:47:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Someone is selling this in my local FB marketplace for \u00a360.</p> <p>I am in the market for a Blu-ray burner for long term secondary backup for my RAW photos. </p> <p>Found that these <strong>LG N2B1DD2</strong> also comes with a blu-ray burner.</p> <p>It still has its original Hitachi 1tb x 2 drives as well.</p> <p>Does the WebUI still work?</p> <p>Specifically a review says that:</p> <p><strong><em>&#39;&#39;Remote Access</em></strong> <em>\u2013 The N2B1 NAS supports only LG\u2019s own DDNS (Dynamic Domain Name Service) so you can\u2019t really configure the device to be a remote resource on your own domain \u2013 at least not easily. To set up remote access, you enable the DDNS feature and enter in a user name and password. This creates a sub-domain on lgnas.com.&#39;&#39;</em></p> <p>I can&#39;t seem to access <a href=\"http://lgnas.com\">lgnas.com</a> , does it mean that these NAS are obsolete?</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"h",
        "id": 3809487,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6da6e/is_this_15yo_nas_still_usable_lg_n2b1dd2",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is this 15yo NAS still usable? LG N2B1DD2?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/WinFuk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T12:13:26.113210+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T11:33:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, <em>(TLDR; read the last two paragraphs)</em></p> <p>For the past week I have been searching online and in this sub for informations related to storing archival storage inside my car. I&#39;m currently changing the way I do my backups to be more resilient.</p> <p>I currently only having one principale drive (M.2) and two backup drivers, one of which is always plugged into my system (HDD) and the other one directly disconnected after the backup (SSD).</p> <p>My goal is to add a new layer of redundancy by having one off-site backup, sadly I cannot make exchanges of drives with anyone I know of, and bank safe cost too much in the long term. My only reliable option right now would be storing it inside my car.</p> <p>As such, I have read a lot about how SSD and HDD behave in cars and belive a HDD would be more appropriate. SSD need to be powered fairly often and react badly to high temperature change, such as when inside a car. HDD on another hand supp",
        "id": 3809488,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6d07t/question_on_storage_durability_in_car",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Question on storage durability in car",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Anto19891",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T12:13:26.365171+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T11:30:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone. Is there a script/tool/software in 2025 that can bulk download files (in my case, zip and rar) from a Telegram channel? I&#39;ve tried everything I found here on Reddit, and nothing works. Only a Chrome script worked the first time, but then it stopped working. Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Anto19891\"> /u/Anto19891 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6cy7g/bulk_download_in_telegram/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6cy7g/bulk_download_in_telegram/\">[comments]</a></span>",
        "id": 3809489,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6cy7g/bulk_download_in_telegram",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "bulk download in telegram",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Consistent-Camel-499",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T11:04:28.910357+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T10:46:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m trying to put a video onto dvd which is an NRG file but it\u2019s too big for 4.7gb (dvd\u2019s which shows as 4.6 for all of the dvds) I tried turning it to an ISO file and burning it their but that didn\u2019t work either.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Consistent-Camel-499\"> /u/Consistent-Camel-499 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6c4su/how_do_a_shrink_nrg_files/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6c4su/how_do_a_shrink_nrg_files/\">[comments]</a></span>",
        "id": 3808968,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6c4su/how_do_a_shrink_nrg_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do a shrink NRG files",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ac_shooter",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T11:04:29.062497+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T10:30:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anybody used a RipBox DVD robot (25-disc capacity) to get their and DVDs onto SSDs? I have a few hundred of each which I&#39;d love to get onto a couple of SSDs. </p> <p>The priority is the CDs, as some of those would be very hard to replace. My plan is to buy a refurbished a RipBox DVD robot and then try both dBpoweramp Batch Ripper and dBpoweramp CD Ripper before ripping all the CDs, 25 at a time, using whichever program works best. Has anybody here done that? If so, what do you wish you&#39;d known before you started?</p> <p>For the DVDs I&#39;ve done less research but am thinking maybe dBpoweramp Video Converter would be a decent choice (and it can come bundled with the above software). Again, if anybody has any relevant experience (especially when using the RipBox DVD robot), I&#39;d love to hear your thoughts.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ac_shooter\"> /u/ac_shooter </a> <br/> <span><a",
        "id": 3808969,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6bugc/using_ripbox_dvd_robot_to_get_1000_cds_and_dvds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Using RipBox DVD robot to get 1,000 CDs and DVDs onto SSDs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Alphabethur",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T11:04:28.457109+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T09:46:39+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6b3fb/instagram_deleted_massive_archive_of_journalist/\"> <img src=\"https://preview.redd.it/93gpj7ncszuf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=efc570a4109c85d81328e4c69fefee528698335c\" alt=\"Instagram deleted massive archive of journalist, Saleh who was murdered in Gaza almost immediately after he was confirmed dead. Any instagram hoarders?\" title=\"Instagram deleted massive archive of journalist, Saleh who was murdered in Gaza almost immediately after he was confirmed dead. Any instagram hoarders?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Alphabethur\"> /u/Alphabethur </a> <br/> <span><a href=\"https://i.redd.it/93gpj7ncszuf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6b3fb/instagram_deleted_massive_archive_of_journalist/\">[comments]</a></span> </td></tr></table>",
        "id": 3808967,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6b3fb/instagram_deleted_massive_archive_of_journalist",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/93gpj7ncszuf1.jpeg?width=640&crop=smart&auto=webp&s=efc570a4109c85d81328e4c69fefee528698335c",
        "title": "Instagram deleted massive archive of journalist, Saleh who was murdered in Gaza almost immediately after he was confirmed dead. Any instagram hoarders?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ObviousCoconut5849",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T12:13:26.987353+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T09:03:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Good morning everyone, I hope you\u2019re doing well. </p> <p>How would you design and index a searchable database of 200,000 PDF books stored on Verbatim 128 GB optical discs?</p> <p>Which software tools or programs should be integrated to manage and query the database prior to disc burning? What data structure and search architecture would you recommend for efficient offline retrieval?</p> <p>The objective is to ensure that, within 20 years, the entire archive can be accessed and searched locally using a standard PC with disc reader, without any internet connectivity.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ObviousCoconut5849\"> /u/ObviousCoconut5849 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6af3c/how_to_design_a_searchable_pdf_database_archived/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6af3c/how_to_design_a_searchable_pdf_database",
        "id": 3809490,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6af3c/how_to_design_a_searchable_pdf_database_archived",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to Design a Searchable PDF Database Archived on Verbatim 128 GB Discs?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fantastic-Hair1554",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T09:39:08.746884+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T08:50:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I take a lot of photos and videos based on the railways in my area. And I know in a few years I\u2019m gonna have a lot of bytes worth of storage and possibly a professional camera. I for now have a USB for transferring data, a SanDisk SSD for fast access and overall usage, a SeaGate HDD to backup my SSD and archive important things, and might buy another HDD to put in a different location or do Cloud storage as another backup.</p> <p>But eventually I\u2019ll need more because my work will expand, and I\u2019m kinda starting to get into this data hoarding thing.</p> <p>So, what is the best HDD or even setup/station to keep my work for a very long time or possibly forever?</p> <p>(Money isn\u2019t really an issue for me, but it can\u2019t be thousands expensive lol)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Fantastic-Hair1554\"> /u/Fantastic-Hair1554 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o6a7mv/i",
        "id": 3808456,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o6a7mv/im_a_phone_photographervideographer_what_is_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I\u2019m a phone photographer/videographer, what is the best HDD setup?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Elephant-comb",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T08:23:21.896901+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T08:08:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Thanks </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Elephant-comb\"> /u/Elephant-comb </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o69l4y/if_i_burn_some_music_on_cdr_disks_down_the_track/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o69l4y/if_i_burn_some_music_on_cdr_disks_down_the_track/\">[comments]</a></span>",
        "id": 3808044,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o69l4y/if_i_burn_some_music_on_cdr_disks_down_the_track",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "If I burn some music on CD-R disks, down the track when they stop working from age can I just reburn the the music to the disk",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/firedrakes",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T04:07:50.706503+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T03:44:49+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1o656h8/rosewill_thor_nas_pc_case/\"> <img src=\"https://preview.redd.it/dg4oqt0v00vf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=752d6c4f659bbdc3fac3c6e64f0d935f99ea9595\" alt=\"Rosewill Thor NAS pc case\" title=\"Rosewill Thor NAS pc case\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>anyone use this case????</p> <p>is it good,ok or crap?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/firedrakes\"> /u/firedrakes </a> <br/> <span><a href=\"https://i.redd.it/dg4oqt0v00vf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o656h8/rosewill_thor_nas_pc_case/\">[comments]</a></span> </td></tr></table>",
        "id": 3807008,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o656h8/rosewill_thor_nas_pc_case",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/dg4oqt0v00vf1.jpeg?width=640&crop=smart&auto=webp&s=752d6c4f659bbdc3fac3c6e64f0d935f99ea9595",
        "title": "Rosewill Thor NAS pc case",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Basher5155",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T04:07:50.411909+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T03:13:14+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1o64jhh/two_months_ago_amazon_shipped_me_my_hard_drives/\"> <img src=\"https://b.thumbs.redditmedia.com/TmTxDfqfP_x2L11KMAb6mwmCc4HOzubu0Y3NJX4HCTA.jpg\" alt=\"Two months ago, Amazon shipped me my hard drives without any protection. Bought the same drives in Newegg instead.\" title=\"Two months ago, Amazon shipped me my hard drives without any protection. Bought the same drives in Newegg instead.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Back-ordered the same 12TB Ironwolf Pros on Newegg weeks ago. Received the package today in a big box. The box contains a lot of air pillows and two smaller boxes. The smaller boxes contain the hard drive wrapped around a thick bubble wrap. </p> <p>Checked the warranty for both drives and confirmed that they have it. Great!</p> <p>While I had to pay for shipping on this purchase, at least I appreciate the fact that Newegg handled the shipment of these hard drives well, unlike",
        "id": 3807007,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o64jhh/two_months_ago_amazon_shipped_me_my_hard_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/TmTxDfqfP_x2L11KMAb6mwmCc4HOzubu0Y3NJX4HCTA.jpg",
        "title": "Two months ago, Amazon shipped me my hard drives without any protection. Bought the same drives in Newegg instead.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LobsterTooButtery",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T02:40:40.020840+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T01:43:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>so there is a now deleted youtube channel that has almost all videos on internet archive, the problem is that the channel has hundreds of videos, and i would like to know how can i download every video easily, from the oldest archive if possisble </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LobsterTooButtery\"> /u/LobsterTooButtery </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o62ol1/how_to_download_every_video_on_a_deleted_youtube/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o62ol1/how_to_download_every_video_on_a_deleted_youtube/\">[comments]</a></span>",
        "id": 3806688,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o62ol1/how_to_download_every_video_on_a_deleted_youtube",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "how to download every video on a deleted youtube channel?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/YulpGULP12",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T01:12:36.024694+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T01:09:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Thinking of opening my local data with movies , shows , etc </p> <p>Should I get a SSD or HDD? Jellyfin, emby or plex?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/YulpGULP12\"> /u/YulpGULP12 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o61y3o/12tb_of_media_ssd_or_hdd_external_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o61y3o/12tb_of_media_ssd_or_hdd_external_drive/\">[comments]</a></span>",
        "id": 3806419,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o61y3o/12tb_of_media_ssd_or_hdd_external_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "12TB of media SSD OR HDD? External drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/blakkheartt12",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T02:40:40.345810+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T00:49:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have about 160 TB of data I need to back up. I&#39;m trying to figure out the most cost effective way to backup the data. I currently do not have any RAID setups. I know RAID is not a backup, so please don&#39;t tell me that. I was looking into Blu-ray, but they only burn at max 100 GB, LTO tape drives, but they are crazy expensive. And the cost of hdd are skyrocketing. I literally bought a refurbished 16TB hdd on Saturday for 199.99. Today I went to buy another one, and the price was increased to 219.00. I was like WTF. In the course of 1 day it increased $20. I have the most important stuff backed up to multiple cloud sources. Looking at the Seagate exos 30 TB, I would need about 6 drives, which would be about 3600. Even the 24 TB would be a bit over 3000. I&#39;m almost prone to just say F-it and if I lose the data, I will just try to recover what I can and what I don&#39;t, I&#39;ll just be sad about it. Data storage is just getting so expensive",
        "id": 3806689,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o61j4d/best_cost_effective_way_to_backup_my_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best cost effective way to backup my data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Neros_Cromwell",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T01:12:35.543695+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T00:41:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m thinking about starting a home media library for Books, Movies, Music, etc. In the future I may use something like Jelly Fin, but for now as a college kid it seems over the top, I was just thinking about getting a hard drive and just start out putting everything on there (is 1 TB a good amount?). I have CD&#39;s and at home there&#39;s some DVD&#39;s, how would I get all of these into a hard drive? Also is this a good way to go about things or is there a way better way to start making a media library?</p> <p>Also there&#39;s no way to free yourself entirely from subscription services if you want to watch the new shows or movies they&#39;re releasing right?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Neros_Cromwell\"> /u/Neros_Cromwell </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o61cya/how_to_start_a_media_library/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.c",
        "id": 3806418,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1o61cya/how_to_start_a_media_library",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to start a Media Library",
        "vote": 0
    }
]