[
    {
        "age": null,
        "album": "",
        "author": "/u/Relative-Pace-2923",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T23:46:37.474738+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T22:24:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, everything seems to be based on JS or Python. I would like to use browser text rendering in a C++ program. So the workflow is like this:</p> <p>- Initialize my C++ library, as well as the browser(s)</p> <p>- Call a C++ function that gets image data of screenshot of web page</p> <p>So it&#39;s not as simple as calling `node index.js` from C++.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Relative-Pace-2923\"> /u/Relative-Pace-2923 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o6ts0r/browser_automation_of_chrome_and_firefox_from_c/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o6ts0r/browser_automation_of_chrome_and_firefox_from_c/\">[comments]</a></span>",
        "id": 3814835,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o6ts0r/browser_automation_of_chrome_and_firefox_from_c",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Browser automation of Chrome and Firefox from C++?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/burai1992",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T22:14:02.966935+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T22:13:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is there any way to rip unblurred images from SubscribeStar? The only closest thing I can find is this (It&#39;s a web scrapping app built on MERN stack. To run it, you will have to download the code to your computer, open it in vscode): <a href=\"https://github.com/Alessandro-Gobbetti/IR\">https://github.com/Alessandro-Gobbetti/IR</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/burai1992\"> /u/burai1992 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o6tick/ripping_unblurred_images_from_subscribestar/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o6tick/ripping_unblurred_images_from_subscribestar/\">[comments]</a></span>",
        "id": 3814160,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o6tick/ripping_unblurred_images_from_subscribestar",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ripping unblurred images from SubscribeStar",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/erdethan",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T20:37:35.774973+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T19:40:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>The code below works great as it repairs the HTML as a browser, however it is quite slow. Do you know about a more effective way to repair a broken HTML without using a browser via Playwright or anything similar? Mainly the issues I&#39;ve been stumbling upon are for instance &lt;p&gt; tags not being closed.</p> <pre><code>from playwright.sync_api import sync_playwright # Read the raw, broken HTML with open(&quot;broken.html&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f: html = f.read() with sync_playwright() as p: browser = p.chromium.launch(headless=True) page = browser.new_page() # Load the HTML string as a real page page.set_content(html, wait_until=&quot;domcontentloaded&quot;) # Get the fully parsed DOM (browser-fixed HTML) cleaned_html = page.content() browser.close() # Save the cleaned HTML to a new file with open(&quot;cleaned.html&quot;, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f: f.write(cleaned_html) </code></pre> ",
        "id": 3813590,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o6phhm/browser_parsed_dom_without_browser_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Browser parsed DOM without browser scraping?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/2H3seveN",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T20:37:35.926020+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T19:15:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello. Anybody here have shareable data on posts about generative AI? Data that lists posting dates and content. Can be X, Reddit, or ... Thanks. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/2H3seveN\"> /u/2H3seveN </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o6ot3s/genai_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o6ot3s/genai_data/\">[comments]</a></span>",
        "id": 3813591,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o6ot3s/genai_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "GenAI data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/VillageHomeF",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T14:54:25.878578+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T14:50:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I run an ecom business and have about 50 suppliers and 9k skus. for about a dozen of them I manually login and enter sku to check pricing and inventory. for 90% of the products the inventory doesn&#39;t change in a meaningful way. but the other 10% cause me problems when products are out of stock or get discontinued. as well as the out of the blue wholesale price changes </p> <p>obviously this is laborious and we need to figure out a longer term solution. debating the possibility of scraping the sites once a month but have some concerns.</p> <p>anyone tackle this and have some ideas? the sites are all password protected and require me to log in</p> <p>thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/VillageHomeF\"> /u/VillageHomeF </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o6hlwd/need_to_pull_inventory_price_from_my_wholesale/\">[link]</a></span> &#32; <span><a href=\"https://www",
        "id": 3810756,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o6hlwd/need_to_pull_inventory_price_from_my_wholesale",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need to Pull Inventory & Price from my Wholesale Suppliers Sites",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T13:42:52.825102+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T13:01:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels\u2014whether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>If you&#39;re new to web scraping, make sure to check out the <a href=\"https://webscraping.fyi\">Beginners Guide</a> \ud83c\udf31</p> <p>Commercial products may be mentioned in replies. If you want to promote your own products and services, continue to use the <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">monthly thread</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 3810084,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o6ever/weekly_webscrapers_hiring_faqs_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weekly Webscrapers - Hiring, FAQs, etc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/umen",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-14T07:12:06.816628+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-14T06:43:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello all,</p> <p>I&#39;m a developer, so feel free to offer programming solutions.</p> <p>I need a tool for personal use to monitor a ticket website. When a ticket becomes available, it should:</p> <ol> <li>Capture the event</li> <li>Click on the ticket offer link, which will go to another page</li> <li>Select tickets only if there are 2 or 3 available (not 1, and not more than 3)</li> <li>Move to the purchase page, where I will manually complete the payment </li> </ol> <p>all this will run on my provate computer . </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/umen\"> /u/umen </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o68a7i/how_automatically_order_tickets_online_when_they/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o68a7i/how_automatically_order_tickets_online_when_they/\">[comments]</a></span>",
        "id": 3807754,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o68a7i/how_automatically_order_tickets_online_when_they",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How automatically order tickets online when they appear?",
        "vote": 0
    }
]