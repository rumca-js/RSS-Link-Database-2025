[
    {
        "age": null,
        "album": "",
        "author": "/u/Meaveready",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-18T22:43:50.155226+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-18T22:12:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Since Google was never known for providing its search as a service (at least I couldn&#39;t find anything official), and only has a very limited API (maxed at 10k searches per day, for $50), then are proxy search engines like Mullvad leta, Startpage, ... really just scraping SERP on demand (+ cache ofc)? </p> <p>it doesn&#39;t sound very likely since Google could just legally give them the axe.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Meaveready\"> /u/Meaveready </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1oa9008/how_do_proxyengines_have_access_to_google_results/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1oa9008/how_do_proxyengines_have_access_to_google_results/\">[comments]</a></span>",
        "id": 3847203,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1oa9008/how_do_proxyengines_have_access_to_google_results",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do proxy-engines have access to Google results?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/armanfixing",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-18T14:57:11.943396+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-18T13:54:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey r/webscraping, Just shipped my first PyPI package as a side project and wanted to share here.</p> <p>What it is: httpmorph - a drop-in replacement for requests that mimics real browser TLS/HTTP fingerprints. It&#39;s written in C with Python bindings, making your Python script look like Chrome from a fingerprinting perspective. [or at least that was the plan..]</p> <p>Why I built it: Honestly? I kept thinking &quot;I should learn this&quot; and &quot;I&#39;ll do it when I&#39;m ready.&quot; Classic procrastination. Finally, I just said screw it and started, even though the code was messy and I had no idea what I was doing half the time. It took about 3-4 days of real work. Burned through 2000+ GitHub Actions minutes trying to get it to build across Python 3.8-3.14 on Linux, Windows, and macOS. Uses BoringSSL (the same as Chrome) for the TLS stack, with a few late nights debugging weird platform-specific build issues. Claude Code and Copilot saved ",
        "id": 3845014,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o9wgkv/made_my_first_pypi_package_learned_a_lot_would",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 1,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Made my first PyPI package - learned a lot, would love your thoughts",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sajys",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-18T14:57:12.158616+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-18T13:11:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all, I&#39;m trying to scrape Truth Social in near\u2013real-time (millisecond delay max) but there\u2019s no API and the site needs JS, so I\u2019m using a browser simulation python library to simulate real sessions.</p> <p>Problem: aggressive rate limiting (~3\u20135 requests then a ~30s timeout, plus randomness) and I need to see new posts the instant they\u2019re published. My current brute-force prototype is to rotate a very large residential proxy pool (thousands of IPs), run browser sessions with device/profile simulation, and poll every 1\u20132s while rotating IPs, but that feels wasteful, fragile, and expensive...</p> <p>Is massive IP rotation and polling the pattern to follow for real-time updates? Any better approaches? I&#39;ve thought about long-lived authenticated sessions, listening to in-browser network/websocket events, DOM mutation observers, smarter backoff, etc.. but since they don&#39;t offer API it looks impossible to pursue that path. Appreciate any fre",
        "id": 3845015,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o9vf3r/is_rotating_thousands_of_ips_practical_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is rotating thousands of IPs practical for near-real-time scraping?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/uncletee96",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-18T14:57:12.317451+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-18T12:28:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How can I bypass bot detection through navigator Hey good afternoon members.. Iam having problem to bypass bot detection on browserscan.net through navigator... The issue is that when I use the default chromium hardware and it&#39;s not configured to my liking... I bypass it... The problem comes when I modify it... Cause I don&#39;t want all my bots to be having the same hardware even if I mimic android, iPhone, Mac and windows... They are all the same... So I need help Maybe someone can know how to bypass it... Cause imagine you have like 10 profiles(users) and they are having the same hardware It&#39;s a red flag</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/uncletee96\"> /u/uncletee96 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o9uh3f/how_can_i_bypass_bot_detection_through_navigator/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o9uh3f/how_",
        "id": 3845016,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o9uh3f/how_can_i_bypass_bot_detection_through_navigator",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can I bypass bot detection through navigator using puppeteer?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/irrisolto",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-18T14:57:11.728439+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-18T11:46:27+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1o9tmm3/open_source_requestsbased_skyscanner_scraper/\"> <img src=\"https://external-preview.redd.it/9hVvsGPTpQlzU4-cFrQnKOJg4Cs9BT-wE2XrJjOuLOc.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1e8874bb5fddd9f0503fedcb8f45fa1468f5b75\" alt=\"Open source requests-based Skyscanner scraper\" title=\"Open source requests-based Skyscanner scraper\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi everyone, I made a Skyscanner scraper using the Skyscanner android app endpoints and published it on GitHub. Let me know if you have suggestions or bugs</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/irrisolto\"> /u/irrisolto </a> <br/> <span><a href=\"https://github.com/irrisolto/skyscanner\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o9tmm3/open_source_requestsbased_skyscanner_scraper/\">[comments]</a></span> </td></tr></table>",
        "id": 3845013,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o9tmm3/open_source_requestsbased_skyscanner_scraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/9hVvsGPTpQlzU4-cFrQnKOJg4Cs9BT-wE2XrJjOuLOc.png?width=640&crop=smart&auto=webp&s=c1e8874bb5fddd9f0503fedcb8f45fa1468f5b75",
        "title": "Open source requests-based Skyscanner scraper",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/abrazilianinreddit",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-18T04:14:03.131314+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-18T02:48:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Steam requires multiple media files when developers upload a game to Steam, as seen here:</p> <p><a href=\"https://partner.steamgames.com/doc/store/assets\">https://partner.steamgames.com/doc/store/assets</a></p> <p>In particular, I&#39;m trying to fetch the <strong>Library</strong>-type images: Capsule (Vertical Boxart), Hero (Horizontal banner), Logo and Header. </p> <p>Previously, these images had a static, predictable URL. You only had to insert the AppID in a url template, like this:</p> <p>- <a href=\"https://steamcdn-a.akamaihd.net/steam/apps/%7BAPP_ID%7D/library_600x900_2x.jpg\">https://steamcdn-a.akamaihd.net/steam/apps/{APP_ID}/library_600x900_2x.jpg</a></p> <p>- <a href=\"https://steamcdn-a.akamaihd.net/steam/apps/%7BAPP_ID%7D/logo.png\">https://steamcdn-a.akamaihd.net/steam/apps/{APP_ID}/logo.png</a></p> <p>This still works for old games (e.g.: <a href=\"https://steamcdn-a.akamaihd.net/steam/apps/502500/library_600x900_2x.jpg\">https://steamcdn-a.",
        "id": 3842161,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o9klhp/trying_to_figure_out_how_to_scrape_images_for_new",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to figure out how to scrape images for new games on Steam...",
        "vote": 0
    }
]