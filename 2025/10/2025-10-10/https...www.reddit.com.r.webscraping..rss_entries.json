[
    {
        "age": null,
        "album": "",
        "author": "/u/bulletsyt",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-10T21:35:44.282938+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-10T20:59:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Beginner here, I am trying to scrape a website by the API endpoint in the Network . The problem is that<br/> a. the website requires a login b. the API endpoint is quite protected, </p> <p>so I can&#39;t just copy-paste to extract information. Instead, I have to use and Cookies to get the data, but after a specific point, the API just blocks you and stops giving you data. In such case, </p> <p>how do I find my way to bypass this? Since im logged in i cant rotate accounts or proxies as that would make no difference and since im logged in i dont get it how i would be able to bypass the endpoint but there are people who have successfully done it in the past? Any help would be appreciated. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/bulletsyt\"> /u/bulletsyt </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o3cusb/tapping_api_endpoints_via_python_requests/\">[link]</a></span> &#32; <span><a ",
        "id": 3786179,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o3cusb/tapping_api_endpoints_via_python_requests",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "tapping api endpoints via python requests",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheFruitfulBooty",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-10T21:35:44.195636+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-10T20:25:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been trying to scrape some Amazon product info for a small project, but everything I\u2019ve tested keeps getting blocked or messy after a few pages.<br/> I\u2019d like to know if there is any simple or reliable approach that\u2019s worked for you guys lately, most stuff I find online feels outdated. appreciate any recs.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheFruitfulBooty\"> /u/TheFruitfulBooty </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o3bywa/reliable_way_to_extract_amazon_product_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o3bywa/reliable_way_to_extract_amazon_product_data/\">[comments]</a></span>",
        "id": 3786178,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o3bywa/reliable_way_to_extract_amazon_product_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Reliable way to extract Amazon product data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Longjumping-Scar5636",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-10T14:45:24.338219+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-10T08:48:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi i have a project related to checking the updates from the website on weekly or monthly basis like what data have been updated there or not </p> <p>This website is food platform where restro menu items, pricing, description Are there and we need to check on weekly basis for the new updates if so or not.</p> <p>Hashlib, difflib I&#39;m currently working on through scrapy spider </p> <p>Tell me some better approach if any one has ever done ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Longjumping-Scar5636\"> /u/Longjumping-Scar5636 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o2vltk/update_web_scraper_pipelines/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o2vltk/update_web_scraper_pipelines/\">[comments]</a></span>",
        "id": 3780931,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o2vltk/update_web_scraper_pipelines",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Update web scraper pipelines",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Due_Construction5400",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-10T14:45:24.096789+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-10T07:27:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m trying to scrape data from websites that update their content frequently. A lot of tools I\u2019ve tried either break or miss new updates.</p> <p>Which web scraping tools or libraries do you recommend that handle dynamic content well? Any tips or best practices are also welcome!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Due_Construction5400\"> /u/Due_Construction5400 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o2uedq/fastchanging_sites_whats_the_best_web_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1o2uedq/fastchanging_sites_whats_the_best_web_scraping/\">[comments]</a></span>",
        "id": 3780930,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o2uedq/fastchanging_sites_whats_the_best_web_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Fast-changing sites: what\u2019s the best web scraping tool?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Tall-Explanation-476",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-10T04:20:56.621845+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-10T03:23:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey. I have a project in production where I am using Selenium to gather some data in the backend. I am using the railway for my backend, and i am getting into this issue.<br/> I have configured it like this and also have a buildpacks.yml file where i mention installing the chromium package.</p> <p>Full Error: chromedriver unexpectedly exited. Status code was: 127</p> <pre><code> options = webdriver.ChromeOptions() # Run the browser in the background without a GUI options.add_argument(&quot;--headless&quot;) # Mandatory for running in a restricted container environment options.add_argument(&quot;--no-sandbox&quot;) options.add_argument(&quot;--disable-dev-shm-usage&quot;) options.add_argument(&quot;--disable-gpu&quot;) # Use the driver with the specified options driver = webdriver.Chrome(options=options) </code></pre> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tall-Explanation-476\"> /u/Tall-Explanation-476 </a> <",
        "id": 3780098,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1o2q600/chromedriver_unexpectedly_exited_railway",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "chromedriver unexpectedly exited (Railway production)",
        "vote": 0
    }
]