[
    {
        "age": null,
        "album": "",
        "author": "Unreal Engine",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-08T18:48:45.789638+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-08T18:01:02+00:00",
        "description": "In this session recorded at Unreal Fest Orlando 2025, we explore how studios that don't use MetaHumans can use the MetaHuman ecosystem to quickly produce facial animation on any character, using only a voice track.\n\nThis session shows how to convert a voice file to a lip-synced character and apply its animation to any character, just by following a few simple rigging design rules. \n\nLearn about tools like the new Character Retargeter in Unreal Engine 5.6 for applying motion capture to any character, and get the knowledge to create a flexible, modular animation pipeline for ideation or as a base for animation en route to final pixel. \n\nLearn more about the MetaHuman framework here: metahuman.com\n\n#CharacterRetargeter, #UnrealEngine5.6, #MotionCapture, #MetaHuman, #DigitalHumans, #MetaHumanCreator, #UnrealFestOrlando",
        "id": 3767380,
        "language": "en",
        "link": "https://www.youtube.com/watch?v=zghbv9yiigo",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 685,
        "source_url": "https://youtube.com/channel/UCBobmJyzsJ6Ll7UbfhI4iwQ",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://i3.ytimg.com/vi/zghbv9yiigo/hqdefault.jpg",
        "title": "Using the MetaHuman Ecosystem for Non-MetaHuman Animation | Unreal Fest Orlando 2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "Unreal Engine",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-08T17:19:55.073221+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-08T16:00:27+00:00",
        "description": "In this session recorded at Unreal Fest Orlando 2025, Hyunggoo Kim (Michaelk) of Netmarble Monster dives into the visual rendering techniques used to bring Mongil: Star Dive\u2019s subcultural environments to life.\n\nWatch as he shares insights from the development process, focusing on shader optimization, GPU-based performance enhancements, and the architecture of the visual system, and explore how complex mathematical principles were applied to balance artistic fidelity with real-time performance\u2014pushing boundaries and setting new benchmarks for visual quality in gaming. \n\nThe session also highlights the unique challenges of rendering culturally rich, stylized visuals and the innovative solutions that enabled their success.\n\nFind out more about creating games in Unreal Engine here: unrealengine.com/uses/games\n\n#MongilStarDive, #NetmarbleMonster, #GameDevelopment, #ShaderOptimization, #UnrealEngine, #UE5, #UnrealFestOrlando",
        "id": 3766334,
        "language": "en",
        "link": "https://www.youtube.com/watch?v=EKM0_7c8-_E",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 685,
        "source_url": "https://youtube.com/channel/UCBobmJyzsJ6Ll7UbfhI4iwQ",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://i2.ytimg.com/vi/EKM0_7c8-_E/hqdefault.jpg",
        "title": "Subculture Rendering and Calculations in Mongil: Star Dive | Unreal Fest Orlando 2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "Unreal Engine",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-08T14:12:42.805169+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-08T14:00:28+00:00",
        "description": "In this session recorded at Unreal Fest Orlando 2025, MetaHuman veteran Cory Strassburger (Xanadu) showcases a new workflow for creating and bringing to life engaging MetaHumans in Unreal Engine. \n\nCory covers everything from using AI-driven tools and the MeshMorpher plugin to help conceptualize and model unique digital personas, to capturing human performances and enhancing them with AI tools.\n\nThis session will equip you with a bleeding-edge toolkit for creating larger than life MetaHuman characters.\n\nLearn more about the MetaHuman framework here: MetaHuman.com\n\n#CoryStrassburger, #Xanadu, #AI, #MeshMorpher, #MetaHuman, #DigitalHumans, #MetaHumanCreator, #UnrealFestOrlando",
        "id": 3764421,
        "language": "en",
        "link": "https://www.youtube.com/watch?v=ITPXDJ1FTHk",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 1,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 685,
        "source_url": "https://youtube.com/channel/UCBobmJyzsJ6Ll7UbfhI4iwQ",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://i2.ytimg.com/vi/ITPXDJ1FTHk/hqdefault.jpg",
        "title": "Crafting Larger-than-Life Personas with MetaHumans & AI Tools | Unreal Fest Orlando 2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "Unreal Engine",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-10-08T10:45:58.517955+00:00",
        "date_dead_since": null,
        "date_published": "2025-10-08T09:36:02+00:00",
        "description": "Not in love with your current cinematics workflow? We get it, it's hard to find that perfect spark when building a cinematics pipeline that scales in Unreal Engine. So, it is time we change that! Whether you are creating a feature length animated film or cinematics for your indie game, you can up your game with the new Cinematic Assembly Toolset (CAT), a suite of new tools designed to help you escape the tedium of managing a cinematic pipeline and get back to what really matters: making something unreal. Come chat with Senior Technical Product Manager Thomas Kilkenny and Tools Programmer Geoffrey Douglas to learn about new developments in Shot Management, and how CAT can transform your cinematic workflows (and save you from heartache).",
        "id": 3762959,
        "language": "en",
        "link": "https://www.youtube.com/watch?v=S4Iyzbl-oaE",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 685,
        "source_url": "https://youtube.com/channel/UCBobmJyzsJ6Ll7UbfhI4iwQ",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://i4.ytimg.com/vi/S4Iyzbl-oaE/hqdefault.jpg",
        "title": "Shoot Your Shot: Cinematic Pipeline Dating Advice | Unreal Fest Orlando 2025",
        "vote": 0
    }
]