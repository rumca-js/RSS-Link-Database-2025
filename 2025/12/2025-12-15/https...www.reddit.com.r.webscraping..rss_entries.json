[
    {
        "age": null,
        "album": "",
        "author": "/u/OtherwiseAnalysis99",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-15T23:56:39.551913+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-15T22:21:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>is it better to use zendriver or patchright for scale?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/OtherwiseAnalysis99\"> /u/OtherwiseAnalysis99 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pnkvks/which_is_better_for_automation_and_stealth/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pnkvks/which_is_better_for_automation_and_stealth/\">[comments]</a></span>",
        "id": 4329418,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pnkvks/which_is_better_for_automation_and_stealth",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "which is better for automation and stealth?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/vfreefly",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-15T17:21:46.814850+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-15T16:51:53+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1pncddb/github_vifreeflyec2_proxies_create_on_demand_free/\"> <img src=\"https://external-preview.redd.it/FndEwiQb_a4qGwV3ABIXQWi0jkqjOXcfKFLPQkBDBLI.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=94c7bdb44fcd181e383a8ac94d9c63eac3ac5f61\" alt=\"GitHub - vifreefly/ec2_proxies: Create on demand FREE HTTPS/SOCKS5 proxy servers using AWS Free EC2 instances automatically with Terraform\" title=\"GitHub - vifreefly/ec2_proxies: Create on demand FREE HTTPS/SOCKS5 proxy servers using AWS Free EC2 instances automatically with Terraform\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/vfreefly\"> /u/vfreefly </a> <br/> <span><a href=\"https://github.com/vifreefly/ec2_proxies\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pncddb/github_vifreeflyec2_proxies_create_on_demand_free/\">[comments]</a></span> </td></tr></table>",
        "id": 4326426,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pncddb/github_vifreeflyec2_proxies_create_on_demand_free",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/FndEwiQb_a4qGwV3ABIXQWi0jkqjOXcfKFLPQkBDBLI.png?width=640&crop=smart&auto=webp&s=94c7bdb44fcd181e383a8ac94d9c63eac3ac5f61",
        "title": "GitHub - vifreefly/ec2_proxies: Create on demand FREE HTTPS/SOCKS5 proxy servers using AWS Free EC2 instances automatically with Terraform",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/OtherwiseGroup3162",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-15T17:21:47.063000+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-15T16:44:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a simple script that runs a HTTP to login and get the cookie (GET Login page using -u parameter)... Then I have another GET request that downloads a file. Everything works great.</p> <p>However, in the near future, they will be adding MFA. They will have a couple of options to choose from, either authentication app (Okta, Microsoft, etc...), or text message.</p> <p>Is there any way to use these HTTP cURL requests and get past the MFA, or somehow incorporate the MFA into these scripts? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/OtherwiseGroup3162\"> /u/OtherwiseGroup3162 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pnc5x0/website_adding_mfa/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pnc5x0/website_adding_mfa/\">[comments]</a></span>",
        "id": 4326427,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pnc5x0/website_adding_mfa",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Website adding MFA",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Peace_Soul",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-15T12:55:26.790868+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-15T12:50:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need help to bypayss a site, I am unable to do that need professionals.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Peace_Soul\"> /u/Peace_Soul </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pn6k7o/any_professional_web_scrapper/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pn6k7o/any_professional_web_scrapper/\">[comments]</a></span>",
        "id": 4324032,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pn6k7o/any_professional_web_scrapper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any professional web scrapper?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HackerArgento",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-15T10:27:40.434126+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-15T10:24:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, yesterday i was tasked with a job that required reverse engineering the http requests of a certain app, as i usually do i hooked frida into it and as you might&#39;ve guessed from the title, it did not work since the app uses flutter, so i thought, no big deal and hooked up some frida flutter scripts to it, but still no results, did static analysis for a few hours only to discover they had a custom implementation that was a pain in the ass to deal with because hooking into the dart VM was way harder than normal flutter apps, i was about to give up when it ocurred to me, since ssl pinning and flutter ssl pinning just validates the certificate validity beetween a client and a server, if i installed a certificate in the system, it&#39;d bypass normal ssl pinning (this has been out for a long time) but flutter is not proxy aware, so it&#39;d just straight up ignore my proxy!, so by modifying the iptables via adb i rerouted the port connection the a",
        "id": 4323043,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pn42ad/using_ip_tables_to_defeat_custom_ssl_and_flutter",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Using IP tables to defeat custom ssl and flutter pinning (writeup)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/qwertysoupcode",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-15T11:43:40.002682+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-15T08:39:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m scraping Eventim seatmaps and I can extract two things separately:</p> <ol> <li>available seats per block (row + seat number), and</li> <li>price categories (PK1, PK2, colors, prices).</li> </ol> <p>The problem is there\u2019s no frontend data that links seats to categories.</p> <p>The availability JSON has no price/category info, and the canvas JSON defines categories but never assigns them to seats, rows, or blocks.</p> <p>The UI suggests users choose a category and quantity, and the backend assigns seats at purchase time.</p> <p>Is this mapping intentionally not exposed, or am I missing some frontend-accessible source?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/qwertysoupcode\"> /u/qwertysoupcode </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pn2jcv/struggling_on_eventim_scraper/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pn2jcv/strugglin",
        "id": 4323490,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pn2jcv/struggling_on_eventim_scraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Struggling on Eventim scraper",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/qwertysoupcode",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-15T09:17:29.355782+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-15T08:03:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m working on a scraper for Eventim events that use the interactive seatmap, and I\u2019ve hit a conceptual wall.</p> <p>I can successfully extract the seatmap canvas configuration (blocks, layout, category definitions with colors) and also the block-level availability JSON that lists available seats with row and seat number.</p> <p>However, these two data sources are completely disconnected when it comes to pricing.</p> <p>The availability JSON tells me which seats are free, but contains no price or category information.</p> <p>The canvas JSON defines the price categories (PK1, PK2, etc.) and their colors, but does not assign them to seats, rows, or blocks in any structured way.</p> <p>I\u2019ve also inspected the full HTML and all related seatmap JavaScript files.</p> <p>They clearly show that users select a category and quantity, not a block or specific seats, and the backend assigns seats during the purchase flow.</p> <p>There is no exposed mapping like \u201cr",
        "id": 4322709,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pn210v/struggling_to_map_available_seats_to_price",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Struggling to map available seats to price categories",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Artistic_Warning_298",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-15T07:07:27.417347+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-15T06:30:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Good morning ladies and gentlemen,</p> <p>I have an idea that is currently under process, i am looking for partners that are enthusiastic and passionate with some background of international trade and online marketplaces.</p> <p>Even if you do not have the correct background it is normal (im a doctor), but at least have some work ethics and willingness to participate correctly.</p> <p>Thanks and good luck.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Artistic_Warning_298\"> /u/Artistic_Warning_298 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pn0ks3/international_trade/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pn0ks3/international_trade/\">[comments]</a></span>",
        "id": 4322173,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pn0ks3/international_trade",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "International Trade",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Striking_Most_5111",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-15T06:03:59.823012+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-15T05:36:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I run a job portal that ingests job listings from external professional/job platforms (via links we provide) and publishes them on our site.</p> <p>The current system works, but has two big issues:</p> <ol> <li>Breaks when source UIs change (frontend-dependent logic)</li> <li>Slow runs (takes hours, so we can only run it once a day; want 2\u20133+ runs/day)</li> </ol> <p>We\u2019re open to either fixing the existing setup or rebuilding it properly.</p> <p>Core needs: Ingest job data from external links Auto-categorize jobs (fresher/experienced, domain, etc.) Auto-publish via internal API/form Strong deduplication Filter out third-party/aggregator spam</p> <p>What we\u2019re really looking for is architecture guidance: how to make ingestion resilient to UI changes, fast and incremental, modular and scalable.</p> <p>We currently handle ~1,000 jobs/day, but want something that can scale much further.</p> <p>Open to paid consulting/help from people ",
        "id": 4321907,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pmznmj/traumatized_building_a_job_scraper_open_to_paid",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Traumatized building a Job Scraper (Open to Paid)",
        "vote": 0
    }
]