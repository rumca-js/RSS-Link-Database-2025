[
    {
        "age": null,
        "album": "",
        "author": "/u/eternviking",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-20T20:35:07.982197+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-20T18:47:30+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1prll1z/google_is_taking_legal_action_against_serpapi/\"> <img src=\"https://preview.redd.it/kr0s6zh3ne8g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c52d38c409ee859b20d1e35af8ce87bae57960ef\" alt=\"Google is taking legal action against SerpApi\" title=\"Google is taking legal action against SerpApi\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/eternviking\"> /u/eternviking </a> <br/> <span><a href=\"https://i.redd.it/kr0s6zh3ne8g1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1prll1z/google_is_taking_legal_action_against_serpapi/\">[comments]</a></span> </td></tr></table>",
        "id": 4371264,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1prll1z/google_is_taking_legal_action_against_serpapi",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/kr0s6zh3ne8g1.png?width=640&crop=smart&auto=webp&s=c52d38c409ee859b20d1e35af8ce87bae57960ef",
        "title": "Google is taking legal action against SerpApi",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/scrape-dot-page",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-20T22:38:09.342639+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-20T17:19:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Pardon me if this has been discussed before, but I simply don&#39;t see it. When pricing your own web scraper or choosing a service to use, there doesn&#39;t seem to be any pricing differentiator for...&quot;last crawled&quot; data.</p> <p>Images are a challenge to scrape of course, but I&#39;m sure that not every client will need their image scrapes from say, time of commission or from the past hour.</p> <p>What possible benefits or repercussions do you forsee from giving two paths to the user:</p> <ul> <li><p>Prioritise Recency: Always check for latest content by generating a new scrape for all requests.</p></li> <li><p>Prioritise Cost-Savings: Get me the most recent data without activating new crawls, if the site has been crawled at least once. </p></li> </ul> <p>Given that its usually the same popular sites that are being crawled, why the redundancy? Or...is this being done already, priced at #1 but sold at #2?</p> </div><!-- SC_ON --> &#32; submi",
        "id": 4371781,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1prjja0/why_has_no_one_considered_this_pricing_issue",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Why has no one considered this pricing issue?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HackerArgento",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-20T05:00:30.765022+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-20T04:24:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello guys, this is the token decoder i made to build my local api, if you want to build your own, take a look at it, it has the reversed encryption algorithm straight from their VM!, just build a token generator for the endpoint of your choice and you are free to scrape</p> <p><a href=\"https://github.com/Movster77/x-net-sync-term-decoder-Bet365\">https://github.com/Movster77/x-net-sync-term-decoder-Bet365</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HackerArgento\"> /u/HackerArgento </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pr5f83/bet365_xnetsyncterm_decoder/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pr5f83/bet365_xnetsyncterm_decoder/\">[comments]</a></span>",
        "id": 4367115,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pr5f83/bet365_xnetsyncterm_decoder",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Bet365 x-net-sync-term decoder!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Rude_Ride_268",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-20T04:00:00.537474+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-20T03:05:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Yoooooo,</p> <p>I\u2019m currently a freshman in Uni and I\u2019ve spent the last few days in the trenches trying to automate a Game Pass master list for a project. I have a list of 717 games, and I needed to get the official Microsoft Store Product IDs (those 12-character strings like 9NBLGGH4R02V) for every single one. There are included in all the links so I thought I could grab that and then use a regex function to only get the ID at the end </p> <p>I would love to know if anyone figured knows of a way to do this that does involve me searching these links and then copying and pasting</p> <p>Here is what I have tried so far!</p> <ol> <li><p>I started with the =AI() functions in Sheets. It worked for like 5 games, then it started hallucinating fake URLs or just timing out. 0/10 do not recommend for 700+ rows.</p></li> <li><p>I moved to Python to try and scrape Bing/Google. Even using Playwright with headless=False (so I could see the browser), Bing immediatel",
        "id": 4366953,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pr3wpi/getting_microsoft_store_product_ids",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Getting Microsoft Store Product IDs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NoBlackberry8611",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-20T02:59:35.792279+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-20T02:42:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anyone built a webscraper for an internet forum? Essentially, I want to make a &quot;feed&quot; of every post on specific topics on the internet forum HotCopper. </p> <p>What is the best way to do this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NoBlackberry8611\"> /u/NoBlackberry8611 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pr3gmr/web_scraping_on_an_internet_forum/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pr3gmr/web_scraping_on_an_internet_forum/\">[comments]</a></span>",
        "id": 4366783,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pr3gmr/web_scraping_on_an_internet_forum",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Web scraping on an Internet forum",
        "vote": 0
    }
]