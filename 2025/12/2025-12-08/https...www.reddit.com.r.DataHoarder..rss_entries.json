[
    {
        "age": null,
        "album": "",
        "author": "/u/OverloadedTech",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T22:04:19.248860+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T21:57:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, i have a quick question.</p> <p>I found a folder containing an old copy of my WhatsApp folder from a while back (2019-2020 circa) from a phone no longer accessible and i was wondering if i could decrypt them. The DB&#39;s as we all know are encrypted but they can be copied and restored as long as the same number is used, i tried placing them in the appropriate directory on a phone and configure the app with them. It all proceeded but the restore failed probably due to the app version and the DB mismatch, also i cannot use an older version of the app as it won&#39;t connect with WhatsApp anymore and wouldn&#39;t let me configure it as it won&#39;t be able to send out the OTP</p> <p>I could technically extract my key from a rooted device by setting my account there on a modern app version just to get the key but would it work on those older databases by extracting it externally with the key? Do keys work between versions? Is the data lost?</p> <p>Wh",
        "id": 4269683,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phpngs/extract_old_whatsapp_db_using_new_extracted_key",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Extract Old WhatsApp DB using new Extracted Key",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/nricotorres",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T22:04:19.510783+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T21:36:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have 2x NTSC 28TB JBODs inside CENMATE dual drive systems. I&#39;m using each in JBOD mode and using SyncBackPro to sync JBOD A &gt; JBOD B. When I want to make updates, i do them on A, then SyncBackPro takes care of getting everything sorted with B. For some reason the other day when I powered both, I noticed A was in RAW format. My only recourse was to disable SBP, format A back to NTSC, then copy everything back to A from B, which took an entire day. </p> <p>What would cause a drive in a Cenmate to be listed as RAW file format and was there a way to recover without reformatting/recopying?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nricotorres\"> /u/nricotorres </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1php4dy/why_would_my_jbod_suddenly_become_raw/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1php4dy/why_would_my_jbod_suddenly_become_r",
        "id": 4269684,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1php4dy/why_would_my_jbod_suddenly_become_raw",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Why would my JBOD suddenly become RAW?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/arpciu",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T22:04:19.744217+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T21:06:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Been fighting split libraries for months. Upgraded my existing account to a 2TB-backed setup today and everything unified \u2014 backups, Photos, Drive. It even fixed device-only folders and duplicate chaos. If anyone\u2019s curious what I changed, ask and I\u2019ll explain the steps I followed</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/arpciu\"> /u/arpciu </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phoco2/how_i_finally_stopped_losing_files_across_devices/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phoco2/how_i_finally_stopped_losing_files_across_devices/\">[comments]</a></span>",
        "id": 4269685,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phoco2/how_i_finally_stopped_losing_files_across_devices",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How I finally stopped losing files across devices \u2014 a 2TB change that made Drive + Photos stop fighting",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dugadugaboost",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T21:03:13.672564+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T20:29:24+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1phncw1/how_do_you_guys_hoard_your_music/\"> <img src=\"https://preview.redd.it/a0jexansh16g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bff0f6fd9d63904444494a4a28324bd2f69a266d\" alt=\"How do you guys hoard your music?\" title=\"How do you guys hoard your music?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Or do you just use streaming services? I&#39;m an avid collector of physical copies and like to convert lossless audio to lossy audio. I&#39;ve been using this program for like 15 years now.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dugadugaboost\"> /u/dugadugaboost </a> <br/> <span><a href=\"https://i.redd.it/a0jexansh16g1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phncw1/how_do_you_guys_hoard_your_music/\">[comments]</a></span> </td></tr></table>",
        "id": 4269199,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phncw1/how_do_you_guys_hoard_your_music",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/a0jexansh16g1.png?width=640&crop=smart&auto=webp&s=bff0f6fd9d63904444494a4a28324bd2f69a266d",
        "title": "How do you guys hoard your music?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Hostile_18",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T21:03:13.897997+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T20:24:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just wondering for anyone that downloads direct to a ssd before it goes to the array, how seriously should you take the TBW limit? Has anyone gone past theirs? I&#39;m on 375tbw on a 4000tbw limit at the moment. I don&#39;t like the health counter going down! :P</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hostile_18\"> /u/Hostile_18 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phn8cu/how_seriously_should_you_take_the_tbw_value_for_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phn8cu/how_seriously_should_you_take_the_tbw_value_for_a/\">[comments]</a></span>",
        "id": 4269200,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phn8cu/how_seriously_should_you_take_the_tbw_value_for_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How seriously should you take the TBW value for a SSD download drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DryRepresentative985",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T22:04:19.957632+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T20:12:24+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1phmwii/samsung_magician_not_recognizing_my_samsung_t9/\"> <img src=\"https://b.thumbs.redditmedia.com/hafSfB6HVfsMpK5Xzh8DUg6jLagB6veJUZUKPXxwsTs.jpg\" alt=\"Samsung Magician not Recognizing my Samsung T9 SSD External Drive\" title=\"Samsung Magician not Recognizing my Samsung T9 SSD External Drive\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>New to this community. Just trying to find someone who can help me out. Hope this is the right place to ask. I have a Samsung T9 SSD 4 Terabytes. </p> <p>I wanted to use the Samsung Magician software, to track the \u201chealth of my drive\u201d so to speak. I\u2019m new to this whole world of data storage, and have basically all my most important files stored on this drive. If this drive goes kaput, all my data is lost. </p> <p>Is there any idea how long the T9 can be expected to last? </p> <p>I wanted use the Samsung Magician software, to monitor the health of my drive. I ",
        "id": 4269686,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phmwii/samsung_magician_not_recognizing_my_samsung_t9",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/hafSfB6HVfsMpK5Xzh8DUg6jLagB6veJUZUKPXxwsTs.jpg",
        "title": "Samsung Magician not Recognizing my Samsung T9 SSD External Drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/diastom",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T22:04:20.178129+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T20:03:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve just released version <strong>1.0.14</strong> of <strong>RedLightDL</strong> (installable via <code>ph-shorts</code>). This update focuses heavily on stability and network management.</p> <h1>What My Project Does</h1> <p>RedLightDL is a CLI tool designed to download videos from various adult content websites. While the initial versions focused on simple scraping, <strong>v1.0.14</strong> introduces a more robust download engine. <strong>Key updates in this version include:</strong></p> <ul> <li><strong>Stop/Resume Support:</strong> You can now interrupt downloads and resume them later without starting over.</li> <li><strong>Smart Retry:</strong> The tool monitors download speed; if it drops significantly, it automatically retries the chunk/segment to ensure the download doesn&#39;t hang.</li> <li><strong>Config System:</strong> Added a configuration file system so you don&#39;t have to pass arguments every time.</li> <li><strong>Notifications",
        "id": 4269687,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phmnr0/update_redlightdl_v1014_resume_support_autoretry",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[Update] RedLightDL v1.0.14: Resume support, Auto-retry logic, and CLI Config added",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/excludehk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T19:41:01.797375+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T18:39:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>just bought a ugreen dxp4800 plus nas, and was wondering which one would be better. i know it&#39;s subjective and based on how you feel but i&#39;m wondering what are other people&#39;s opinions about it</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/excludehk\"> /u/excludehk </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phkehu/8tb_x4_raid_5_or_16tb_x4_raid_10/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phkehu/8tb_x4_raid_5_or_16tb_x4_raid_10/\">[comments]</a></span>",
        "id": 4268689,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phkehu/8tb_x4_raid_5_or_16tb_x4_raid_10",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "8tb x4 raid 5 or 16tb x4 raid 10",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/KuronePhoenix",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T18:32:45.328728+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T18:06:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So i&#39;m trying to rip my first CD on Linux with abcde, and i encounter some troubles.</p> <p>The first one it&#39;s that when i finish to do it with the command <code>abcde -o flac</code> when i reproduce it with mpv, vlc and on my phone on the highs (i don&#39;t know if it&#39;s called this way sorry i&#39;m not native) i hear like a buzzing, i tried headphones and speakers, different ones but no lucky.</p> <p>And if i rip it with vlc it sounds good in flac format, i don&#39;t know the difference, for what i understand abcde rips it with cdparanoia.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/KuronePhoenix\"> /u/KuronePhoenix </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phjj2d/help_me_ripping_my_first_cd_with_abcde_on_linux/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phjj2d/help_me_ripping_my_first_cd_with_abcde_on_linux/\">[comments]</",
        "id": 4268167,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phjj2d/help_me_ripping_my_first_cd_with_abcde_on_linux",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help me ripping my first CD with abcde on Linux",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/loweexclamationpoint",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T17:26:59.864533+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T16:08:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Newbie to data hoarding (although an old hand with PCs), on a fairly tight budget and I&#39;m looking for permanent storage for:</p> <p>1a. a bunch of old photos, videos &amp; scans (50-100GB)</p> <p>1b. permanent records like prior years&#39; tax and insurance forms (&lt;10GB)</p> <ol> <li>documents where I update versions, like recipes (2GBish)</li> </ol> <p>I&#39;m thinking M-Disc is a good way to go but not sure if DVD or Blu Ray is the right size. The writer for DVD is a lot cheaper ($30 vs $120+) but the M-Disc DVDs seem to be harder to get plus a lot more $ per GB. On the other hand, the granularity of DVD seems handier - I could write a disc of new photos and videos once or twice per year, and a disc of recipes every few years, and have them reasonably full - even though I&#39;d have to initially do like a couple dozen discs.</p> <p>Advice from the experts here?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/",
        "id": 4267350,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phgckc/mdisc_advice",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "M-Disc advice?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/oqwnM",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T17:27:00.055181+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T15:28:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I ordered 24 TB WD Reds over Black Friday from the website and my order is still stuck on Processing Order for over a week. Not even &quot;Preparing to Ship&quot;, so I assume the order isn&#39;t even confirmed yet. Has anyone ordered from WD over Black Friday, and if you did, did you receive your drives yet?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/oqwnM\"> /u/oqwnM </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phfalx/wd_black_friday_order/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phfalx/wd_black_friday_order/\">[comments]</a></span>",
        "id": 4267351,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phfalx/wd_black_friday_order",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WD Black Friday Order",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/JeremiahCLynn",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T17:26:59.234241+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T15:26:02+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1phf811/terramaster_d5310_supports_wd_red_pro_26tb/\"> <img src=\"https://b.thumbs.redditmedia.com/9gMkjtZFlhO0y6yshsvYQCQlpj-jd0u-1URCXdG1RDM.jpg\" alt=\"TerraMaster D5-310 Supports WD Red Pro 26TB\" title=\"TerraMaster D5-310 Supports WD Red Pro 26TB\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JeremiahCLynn\"> /u/JeremiahCLynn </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1phf811\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phf811/terramaster_d5310_supports_wd_red_pro_26tb/\">[comments]</a></span> </td></tr></table>",
        "id": 4267348,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phf811/terramaster_d5310_supports_wd_red_pro_26tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/9gMkjtZFlhO0y6yshsvYQCQlpj-jd0u-1URCXdG1RDM.jpg",
        "title": "TerraMaster D5-310 Supports WD Red Pro 26TB",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ShittyMillennial",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T17:26:58.785890+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T15:01:47+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pheks2/finally_replaced_my_externals_drives_with_a/\"> <img src=\"https://b.thumbs.redditmedia.com/yjB2cKl35fShfYz1VF7LMmAVDeET8q4CJRTS3cV89Ug.jpg\" alt=\"Finally replaced my externals drives with a proper storage system!!\" title=\"Finally replaced my externals drives with a proper storage system!!\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>About a year ago I shared the picture of my 12x external HDD storage setup here and got a ton of tips on how to transition to a proper system. After a ton of research and countless mistakes, I&#39;ve finally got my first server up and running!!</p> <p>I picked up a used Dell T640 with the 18-bay chassis and it&#39;s running a 9x16tb and 8x14tb raidz2 vdev for a total of ~172TB usable storage! The 8x14tb is actually 4x16tb + 4x14tb so once I replace the 4x14tb I&#39;ll be much closer to my 200tb goal.</p> <p>I was originally going to start with the 9-bay HP Z820 that I got",
        "id": 4267347,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pheks2/finally_replaced_my_externals_drives_with_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/yjB2cKl35fShfYz1VF7LMmAVDeET8q4CJRTS3cV89Ug.jpg",
        "title": "Finally replaced my externals drives with a proper storage system!!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Valuable-Speaker-312",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T17:26:59.566789+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T14:56:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>With the price of hard drives going up, I am trying to find the most economical way to get 20TB or larger drives. I know re-certified drives price ranges right now. Just curious if any of the current crop of USB external drives have an enterprise-class drive in it these days. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Valuable-Speaker-312\"> /u/Valuable-Speaker-312 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phefim/20tb_or_larger_usb_shucking_enterpriseclass_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1phefim/20tb_or_larger_usb_shucking_enterpriseclass_drives/\">[comments]</a></span>",
        "id": 4267349,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phefim/20tb_or_larger_usb_shucking_enterpriseclass_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "20tb or larger USB shucking - Enterprise-class drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fit-Foundation746",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T14:30:39.400295+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T14:25:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Soooo this is just a speculative post, a dream or twinkle in the engineers eye so to speak. </p> <p>Before I was born, hard drives were measured in megabytes and capacities were small... then an order of magnitude or two later, drives were 1 Gigabyte... or so. When I was old enough to use a PC... our home PC had a nice 20GB drive in it on an IDE interface., this was 2001 ish time frame. Fast forward to 2008 we had an iMac and it had a whopping 1TB HDD on a SATA interface... I remember specifically when I was with my parents at the store buying it, the salesman saying &quot;youll never fill this 1TB HDD, its the biggest one we offer.&quot; Now today in 2025, 1TB is almost comically small. But we havent broken into the PB level yet. </p> <p>Here comes rhe speculation, a 1PB drive, in the 3.5&quot; form factor... when would we actually see this. My guess is probably 2035, maybe 2040 at the latest. I am aware that a 100TB drive exists, its called the exad",
        "id": 4265949,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phdp65/data_density",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Data Density!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Cool-Reveal-3864",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T14:30:39.771080+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T13:49:56+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1phcv3h/help_me_choose_between_these_7_external_hdds_2tb/\"> <img src=\"https://b.thumbs.redditmedia.com/FO0G_b0V16I7vVZEj3-C3phXSryOnKOpgpPxY3G-fbY.jpg\" alt=\"Help me choose between these 7 External HDDs (2TB) ?\" title=\"Help me choose between these 7 External HDDs (2TB) ?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I\u2019m trying to pick a 2TB external HDD and I\u2019m torn between these 7 models:</p> <ol> <li><strong>WD Elements 2TB</strong></li> <li><strong>WD My Passport 2TB</strong></li> <li><strong>Toshiba Canvio Basics 2TB</strong></li> <li><strong>Toshiba Canvio Advance 2TB</strong></li> <li><strong>Toshiba Canvio Gaming 2TB</strong></li> <li><strong>Toshiba Canvio Ready 2TB</strong></li> <li><strong>Toshiba Canvio Flex 2TB</strong></li> </ol> <p>I just need suggestions on which one is the most reliable long-term.</p> <p><strong>My needs:</strong></p> <ul> <li>Mainly for storing <strong>movies and TV series</",
        "id": 4265950,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phcv3h/help_me_choose_between_these_7_external_hdds_2tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/FO0G_b0V16I7vVZEj3-C3phXSryOnKOpgpPxY3G-fbY.jpg",
        "title": "Help me choose between these 7 External HDDs (2TB) ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/adammo666",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T13:29:43.764570+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T12:39:18+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1phbd0g/i_for_once_snagged_pretty_sweet_deal/\"> <img src=\"https://preview.redd.it/ruqtq7ol6z5g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5c366776f7f7da18bf8b82f30a84019b98f16d55\" alt=\"I for once snagged pretty sweet deal\" title=\"I for once snagged pretty sweet deal\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I was looking for new HDDs for my ever-growing movie collection and an offer from pepper (polish hotukdeals/mydealz equivalent) popped up.</p> <p>26TB for 800z\u0142 is about 189 eur or 220 usd (after tax, given 23% here it would be something like 178 usd without). I know these aren&#39;t NAS dedicated drives (barracuda inside) but it&#39;s just for plex movies that are easily redownloadable so not that much of a problem anyway.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/adammo666\"> /u/adammo666 </a> <br/> <span><a href=\"https://i.redd.it/ruqtq7ol6z5g1.pn",
        "id": 4265324,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1phbd0g/i_for_once_snagged_pretty_sweet_deal",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ruqtq7ol6z5g1.png?width=640&crop=smart&auto=webp&s=5c366776f7f7da18bf8b82f30a84019b98f16d55",
        "title": "I for once snagged pretty sweet deal",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/duandenonym",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:26.247823+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T10:40:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Greetings from Germany I just starting out to do backups of my old phones that I have lying around and also my current phone. Im guessing around 2 TB</p> <p>How do I manage to move all that data around? Everytime I want to copy something on my 5TB HDD there are errors that either Data can&#39;t be found or can&#39;t be moved. </p> <p>Is this common? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/duandenonym\"> /u/duandenonym </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph9a4n/starting_out/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph9a4n/starting_out/\">[comments]</a></span>",
        "id": 4262512,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ph9a4n/starting_out",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Starting out",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Hydrozy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:28.467209+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T06:12:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello together,</p> <p>are you sure that I can easily restore bitrot errors when I make a 1:1 copy (not the best backup method compared to nas or others I know) of the file? I think there are programs out there for Windows/Mac to restore bitrot easily if it is on two different places but is it relatively easy and functional? Actually I would have to make two copys so the program could differentiate if one is of, otherwise it couldn&#39;t tell wich one has bitrot right?</p> <p>So is this possible? Simply copying files to drastically reduce bitrot problems? Do you have easier solutions like checksums? What do you guys do?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hydrozy\"> /u/Hydrozy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph545z/i_just_want_to_be_sure_about_bitrot/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph545z/i_just_want_to_be_",
        "id": 4262522,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ph545z/i_just_want_to_be_sure_about_bitrot",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I just want to be sure about bitrot",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/data_cat",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:26.572370+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T04:17:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Most of my DVD\u2019s were ripped to folders (VIDEO_TS). I\u2019ve recently decided to switch to ISO. Is there any reason to go back and re-rip the older ones to ISO? I haven\u2019t played all of the VIDEO_TS copies, but have never had any problems with the ones I\u2019ve played.</p> <p>In case it\u2019s relevant, I\u2019m on a Mac.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/data_cat\"> /u/data_cat </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph2ytt/iso_vs_ts_for_dvd_backup/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph2ytt/iso_vs_ts_for_dvd_backup/\">[comments]</a></span>",
        "id": 4262514,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ph2ytt/iso_vs_ts_for_dvd_backup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "ISO vs. TS for DVD backup",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LimCW1223",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:26.379147+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T03:59:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I hoard Pixiv and Twitter artist images on my phone and backup in a seasgate HDD as sometimes they would just nuke them without prior notification. Most online piracy site doesnt store them in HD.</p> <p>I was wondering what medium should i use to hoard them as they are slowly approching 2tb. Should i run a NAS or just keep buying and upsizing my HDD?</p> <p>Granted i still have time and not in a rush as images take from 1-25mb.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LimCW1223\"> /u/LimCW1223 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph2m77/ways_to_view_and_store_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph2m77/ways_to_view_and_store_data/\">[comments]</a></span>",
        "id": 4262513,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ph2m77/ways_to_view_and_store_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ways to view and store data?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/msg7086",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:27.233998+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T03:28:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This is a PSA like post, as I didn&#39;t find any post talking about this.</p> <p>Many of us use XFS for file storage, like our Linux ISO collections. Some recent change to XFS has changed how much reserved space the filesystem is going to take. So I did some quick test and I&#39;m sharing the results. You should choose format options that fit you the best.</p> <p>Unit of numbers below are all <code>1M-blocks</code> in <code>df -BM</code>.</p> <table><thead> <tr> <th align=\"left\">Object</th> <th align=\"left\">Formatted size</th> <th align=\"left\">Metadata Use (Base)</th> <th align=\"left\">finobt=1</th> <th align=\"left\">reflink=1</th> <th align=\"left\">rmapbt=1</th> </tr> </thead><tbody> <tr> <td align=\"left\">26TB HDD</td> <td align=\"left\">24794120</td> <td align=\"left\">34</td> <td align=\"left\">+24696</td> <td align=\"left\">+148172</td> <td align=\"left\">+301877</td> </tr> <tr> <td align=\"left\">100GiB file</td> <td align=\"left\">102336</td> <td align=\"left\">3",
        "id": 4262518,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ph20ji/xfs_filesystem_metadata_reserved_space_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "XFS Filesystem metadata reserved space for different format options",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Capt-Kirk31",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:25.986809+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T02:48:06+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph17ma/fake_wd_red/\"> <img src=\"https://b.thumbs.redditmedia.com/P5-x9_6fBzfAGciwbHloNIiclw1JtVIhwZyfLcNzIZk.jpg\" alt=\"Fake WD red?\" title=\"Fake WD red?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I bought two hard drives from nellis for $200 each. The 18tb was fine and worked and is registered now. The 26 TB was sealed in the bag but there was a lot of slack in the bag. Then the faded poor quality label and the 2 big dents. Plus the chug chug brreapp chug chug sounds. And WD has no record for the serial number.</p> <p>What do y&#39;all think \ud83e\udd14 </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Capt-Kirk31\"> /u/Capt-Kirk31 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1ph17ma\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph17ma/fake_wd_red/\">[comments]</a></span> </td></tr></table>",
        "id": 4262511,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ph17ma/fake_wd_red",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/P5-x9_6fBzfAGciwbHloNIiclw1JtVIhwZyfLcNzIZk.jpg",
        "title": "Fake WD red?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/six_artillery",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:28.172307+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T02:47:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>is it possible to use those nvme m.2 usb adapters / enclosures to update an SSD&#39;s firmware? only PC i have access to right now predates nvme&#39;s so it has no such slot (ivy bridge mobo)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/six_artillery\"> /u/six_artillery </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph17a1/ssd_firmware_updating_via_usb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph17a1/ssd_firmware_updating_via_usb/\">[comments]</a></span>",
        "id": 4262521,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ph17a1/ssd_firmware_updating_via_usb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SSD firmware updating via usb?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/givemeanappple",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:26.727973+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T02:12:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have 7 year old Samsung T external SSD, it seems to work fine, but should I transfer every to a new one since it&#39;s pretty old at this point? Not sure how long they actually last. Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/givemeanappple\"> /u/givemeanappple </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph0hb3/should_i_replace_a_7_year_old_ssd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ph0hb3/should_i_replace_a_7_year_old_ssd/\">[comments]</a></span>",
        "id": 4262515,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ph0hb3/should_i_replace_a_7_year_old_ssd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Should I replace a 7 year old SSD?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CyberSimon",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:25.770557+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T01:42:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Seagate direct has their <a href=\"https://www.seagate.com/products/external-hard-drives/expansion-desktop-hard-drive/?sku=STKP22000400\">22TB Expansion Desktop Hard Drive</a> on sale again for $229. A great deal!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CyberSimon\"> /u/CyberSimon </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pgzuj7/229_22tb_seagate_expansion_desktop_hard_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pgzuj7/229_22tb_seagate_expansion_desktop_hard_drive/\">[comments]</a></span>",
        "id": 4262510,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pgzuj7/229_22tb_seagate_expansion_desktop_hard_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "$229 - 22TB Seagate Expansion Desktop Hard Drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Muted_Delivery4655",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:27.008303+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T01:37:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Have a fairly ancient TD340 Thinkserver with the following base specs: - 8 HS bays but only one backplane and one cage - Dual 1356 socket with 1x e2400v2 currently installed. - 1x HS 800w PSU with the option to add a second.</p> <p>I&#39;ll be turning this into a bare metal truenas box for personal photo/media backup as well as an *arr stack with jellyfin or plex for playback. Would love to also be able to access this securely from my phone when I travel in the event I need any Linux ISO&#39;s on the go as well.</p> <p>Based on power consumption, the dual 1356 socket xeon board is getting ripped out and I&#39;m slapping in an either an old h110-d3a or a z170a gaming m7 that I have laying around paired with a dell h310 hba flashed to a 9211-8i in IT mode.</p> <p>For processor choice, have a g4400 in the h110-d3a right now but I did purchase a 7400t from a user in the F/S subreddit to hopefully have a little more compute power at a lower tdp.</p> <p>I f",
        "id": 4262517,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pgzqwq/gathering_parts_for_a_storagemedia_server",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Gathering parts for a storage/media server",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Development-Feisty",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:25.574779+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T01:33:26+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pgznub/scanning_onion_skin_memo_paper_from_the_1960s/\"> <img src=\"https://a.thumbs.redditmedia.com/EaIdYhb-H664iC93wFLlH4YCEnLKv9EXgXkTCb2HLz4.jpg\" alt=\"Scanning Onion Skin Memo Paper from the 1960\u2019s advice (Space Technology Labs MORL project)\" title=\"Scanning Onion Skin Memo Paper from the 1960\u2019s advice (Space Technology Labs MORL project)\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I have a box of documents from the early 1960s MORL program (Manned Orbiting Research Laboratory) and I\u2019d like to scan them into PDF form before putting them up for sale so that I can add them to Internet archives and make sure that they don\u2019t get lost to time. </p> <p>The best I can tell these are documents that should not have been brought home by the person who brought them home but have been declassified as of the late 1990s. </p> <p>I\u2019m looking at an old Fujitsu scanner, since there are so many hundreds of pages it need",
        "id": 4262509,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pgznub/scanning_onion_skin_memo_paper_from_the_1960s",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/EaIdYhb-H664iC93wFLlH4YCEnLKv9EXgXkTCb2HLz4.jpg",
        "title": "Scanning Onion Skin Memo Paper from the 1960\u2019s advice (Space Technology Labs MORL project)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/clovercolor",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-08T12:25:27.485260+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-08T01:00:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently got a ugreen 4 bay nas and four 12 tb hard drives. I also have an old computer that I thought about selling or reusing. Would be it be better to put two drives in the ugreen nas and two in the pc as a backup or should i just put all four in the ugreen nas? This is my first time dealing with nas stuff so i&#39;m not quite sure. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/clovercolor\"> /u/clovercolor </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pgyzb2/what_should_i_do_with_these_hard_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pgyzb2/what_should_i_do_with_these_hard_drives/\">[comments]</a></span>",
        "id": 4262519,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pgyzb2/what_should_i_do_with_these_hard_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What should I do with these hard drives?",
        "vote": 0
    }
]