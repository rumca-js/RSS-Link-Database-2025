[
    {
        "age": null,
        "album": "",
        "author": "/u/Ok-Exit1876",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-03T22:20:33.305200+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-03T21:18:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am a bit new to this scraping thing, want to build a solution for that I require to scrape 10000 youtube channels along with their videos view count every single hour. Please tell me some solutions to do that.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok-Exit1876\"> /u/Ok-Exit1876 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pdgtor/need_help/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pdgtor/need_help/\">[comments]</a></span>",
        "id": 4231646,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pdgtor/need_help",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/bellsrings",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-03T20:17:08.637253+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-03T20:12:26+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1pdf2yf/i_refactored_our_reddit_scraper_to_kill_the_n1/\"> <img src=\"https://preview.redd.it/n5gc18fjq15g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=741a239676f2e718ecfc28c2ee73a4feae2f3044\" alt=\"I refactored our Reddit scraper to kill the &quot;N+1&quot; request loop. Here is how we fetch full context in 1 call instead of 50.\" title=\"I refactored our Reddit scraper to kill the &quot;N+1&quot; request loop. Here is how we fetch full context in 1 call instead of 50.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><strong>TL;DR:</strong> We moved from a &quot;Search -&gt; Loop IDs -&gt; Fetch Content&quot; model to a &quot;Hydrated&quot; model. This reduces API calls by ~90%, saves massive amounts of proxy bandwidth, and avoids rate-limit buckets.</p> <p><strong>The N+1 Nightmare</strong> If you build scrapers for Reddit, you know the specific pain of getting search results. usually, the flow looks like t",
        "id": 4230723,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pdf2yf/i_refactored_our_reddit_scraper_to_kill_the_n1",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/n5gc18fjq15g1.png?width=640&crop=smart&auto=webp&s=741a239676f2e718ecfc28c2ee73a4feae2f3044",
        "title": "I refactored our Reddit scraper to kill the \"N+1\" request loop. Here is how we fetch full context in 1 call instead of 50.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/R3dAt0mz3",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-03T19:15:48.684100+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-03T19:03:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Saw a reddit ad about germanproxy(dot)io<br/> And want to know more details about same ? </p> <p>How it works, what it is.. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/R3dAt0mz3\"> /u/R3dAt0mz3 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pdd7lp/what_are_dolphin_anty_or_bitbrowser_used_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pdd7lp/what_are_dolphin_anty_or_bitbrowser_used_for/\">[comments]</a></span>",
        "id": 4230256,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pdd7lp/what_are_dolphin_anty_or_bitbrowser_used_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What are Dolphin Anty or BitBrowser used for ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HackerArgento",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-03T12:30:36.804859+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-03T11:50:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://github.com/Movster77/Bet365-Reversed-VM\">https://github.com/Movster77/Bet365-Reversed-VM</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HackerArgento\"> /u/HackerArgento </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pd24c1/technical_analysis_of_bet365_vm_aes_system/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pd24c1/technical_analysis_of_bet365_vm_aes_system/\">[comments]</a></span>",
        "id": 4226510,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pd24c1/technical_analysis_of_bet365_vm_aes_system",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Technical analysis of Bet365 VM AES system",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/theeoddduck",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-03T10:23:44.285772+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-03T10:07:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Using n8n Browserless Node to Scrap using community node but can&#39;t seem to bypass the CAPCHA Challenge Any Solution ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/theeoddduck\"> /u/theeoddduck </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pd0dlu/aws_waf_captcha_challenge/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pd0dlu/aws_waf_captcha_challenge/\">[comments]</a></span>",
        "id": 4225648,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pd0dlu/aws_waf_captcha_challenge",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AWS WAF CAPTCHA challenge",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/postytocaster",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-03T00:35:37.046494+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-03T00:03:45+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1pcoy7s/what_would_be_the_best_way_to_solve_this_type_of/\"> <img src=\"https://b.thumbs.redditmedia.com/f7XTf6_K8_VUxLuJlemNT3SGvUfUOd0wwzo1707B-RU.jpg\" alt=\"What would be the best way to solve this type of text captcha?\" title=\"What would be the best way to solve this type of text captcha?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/qzvw8yt6rv4g1.jpg?width=250&amp;format=pjpg&amp;auto=webp&amp;s=9421d980ce9474dbe3e4227c81fa213667b5b430\">https://preview.redd.it/qzvw8yt6rv4g1.jpg?width=250&amp;format=pjpg&amp;auto=webp&amp;s=9421d980ce9474dbe3e4227c81fa213667b5b430</a></p> <p>I&#39;ve used Capsolver in a previous project with a different and easier type of text captcha and it did work well. However, it can&#39;t answer a single image correctly from this different type of text captcha. What way do you guys think would be the best to have correct answers for it?</p> </div><!--",
        "id": 4223019,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pcoy7s/what_would_be_the_best_way_to_solve_this_type_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/f7XTf6_K8_VUxLuJlemNT3SGvUfUOd0wwzo1707B-RU.jpg",
        "title": "What would be the best way to solve this type of text captcha?",
        "vote": 0
    }
]