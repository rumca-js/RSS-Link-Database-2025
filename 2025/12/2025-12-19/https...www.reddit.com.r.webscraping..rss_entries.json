[
    {
        "age": null,
        "album": "",
        "author": "/u/Pop317",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-19T23:52:15.804804+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-19T23:25:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a project such that for Part 1 I want to find 1000 basketball websites, scrape the url, website name, phone number on the main page if it exists, and place it into a google sheet. Obviously I can ask AI to do this, but my experience with AI is that it&#39;s going to find like 5-10 sites, and that&#39;s it. I would like something which can methodically keep checking the internet via google or bing or whatever, to find 1000 such sites. </p> <p>For Part 2, once the URLs are found, I&#39;d use a second AI / AI Agent to go check the sites and find out the main topics, type of site (blog vs news site vs mock draft site, etc.) and get more detailed information for the google sheet. </p> <p>What would be the best approach for Part 1? Open to any and all suggestions. Thank you in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Pop317\"> /u/Pop317 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscrapin",
        "id": 4365971,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pqzbrc/best_way_to_find_1000_basketball_websites",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best way to find 1000 basketball websites??",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/albert_in_vine",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-19T19:44:24.428194+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-19T18:47:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello scrapers, I&#39;m having a difficult time retrieving the product descriptions from this<a href=\"https://www.trendyol.com/luis-bien/kas-sekillendirici-wax-50-ml-trichogen-hint-yagi-destekli-dogal-sabitleyici-uzun-sure-kalici-p-87220000?boutiqueId=61&amp;merchantId=786475\"> website</a> without using browser automation tools. Is there a way to find the word <strong>\u00dcr\u00fcn A\u00e7\u0131klamas\u0131</strong>&quot;(product description)? There are two descriptions I need, and using a headless browser would take too long. I would appreciate any guidance on how to approach this more efficiently. Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/albert_in_vine\"> /u/albert_in_vine </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pqszg3/get_product_description/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pqszg3/get_product_description/\">[comments]</a></span>",
        "id": 4364239,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pqszg3/get_product_description",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Get product description",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Elliot6262",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-19T16:37:51.267597+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-19T15:45:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>We are seeking a Full-Time Data Scraper to extract business information from bbb.org.</p> <p>Responsibilities:</p> <p>Scrape business profiles for data accuracy.</p> <p>Requirements:</p> <p>Experience with web scraping tools (e.g., Python, BeautifulSoup).</p> <p>Detail-oriented and self-motivated.</p> <p>Please comment if you\u2019re interested!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Elliot6262\"> /u/Elliot6262 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pqoc3v/hiring_full_time_data_scraper/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pqoc3v/hiring_full_time_data_scraper/\">[comments]</a></span>",
        "id": 4362619,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pqoc3v/hiring_full_time_data_scraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[Hiring] Full time data scraper",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/JGRussell",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-19T15:13:19.842241+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-19T15:09:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Title says it all. My ultimate goal is to find a scraper that will scan all pages associated with the home website address provided and pull phone numbers and email address. I&#39;ll only do this once to continue to build out my contact database. Any recommendations on a program that provides this service?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JGRussell\"> /u/JGRussell </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pqnfsk/import_list_of_websites_looking_to_scrape_email/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pqnfsk/import_list_of_websites_looking_to_scrape_email/\">[comments]</a></span>",
        "id": 4361913,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pqnfsk/import_list_of_websites_looking_to_scrape_email",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Import List of websites, looking to scrape email and phone numbers",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sea-Curve1871",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-19T15:13:20.335101+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-19T14:07:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How do I get discord invite links like a huge list</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sea-Curve1871\"> /u/Sea-Curve1871 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pqlyxf/discord_links/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pqlyxf/discord_links/\">[comments]</a></span>",
        "id": 4361914,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pqlyxf/discord_links",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Discord links",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/eren_yeager04",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-19T12:26:52.514368+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-19T11:30:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>When I first started doing web scraping, I only had a few accounts to manage, so some free tools seemed fine. But as my projects grew and I had to handle more accounts at the same time, those tools started slowing down and sometimes even caused profiles to mix up or break.</p> <p>I realized I needed something that could stay stable when working at scale. That\u2019s when I started experimenting with professional setups. I&#39;ve tried a lot of anti detect browsers and which I found useful, Incogniton, handled multiple profiles much more smoothly. It also made it easier to automate repetitive tasks across accounts, which saved a lot of time when my projects grew bigger.</p> <p>Now, I use simpler tools for small projects, but for bigger scraping setups, having something stable and fast really makes a difference. I\u2019m curious how others handle multiple accounts without things breaking.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.redd",
        "id": 4360653,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pqiuos/managing_multiple_web_scraping_accounts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Managing Multiple Web Scraping Accounts",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HackerArgento",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-19T04:49:55.833530+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-19T03:56:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello guys, you might&#39;ve seen my post about the reversal of the security header of bet365, i wanted to know if more stuff should be added to the live play api, currently the data it gets is shown like this, it&#39;s gotten in ms continously, let me know of any improvement you might want to see in it!</p> <p><code>&quot;id&quot;:&quot;186133997&quot;,&quot;name&quot;:&quot;Pato Basquete vs Franca&quot;,&quot;home&quot;:&quot;Pato Basquete&quot;,&quot;away&quot;:&quot;Franca&quot;,&quot;league&quot;:&quot;Brasile - NBB&quot;,&quot;sport&quot;:&quot;basketball&quot;,&quot;score&quot;:{&quot;display&quot;:&quot;50-68&quot;,&quot;home&quot;:50,&quot;away&quot;:68},&quot;time&quot;:&quot;0&quot;,&quot;period&quot;:&quot;4\u00b0 Q&quot;,&quot;status&quot;:&quot;prematch&quot;,&quot;stats&quot;:{&quot;home&quot;:{&quot;name&quot;:&quot;Pato Basquete&quot;,&quot;score&quot;:37,&quot;three_pointers&quot;:6,&quot;two_pointers&quot;:8,&quot;free_throws&quot;:3,&qu",
        "id": 4358438,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pqbaio/showcasing_my_bet365_live_scraping_api",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Showcasing my bet365 live scraping api!",
        "vote": 0
    }
]