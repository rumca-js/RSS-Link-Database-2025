[
    {
        "age": null,
        "album": "",
        "author": "/u/Neither-Director5658",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T23:42:51.151495+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T23:07:18+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvpaoh/monthly_internet_usage/\"> <img src=\"https://preview.redd.it/ba9fyqbmlf9g1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8331745aa742236da95058e7f9fd7d5f7c5811e2\" alt=\"Monthly Internet Usage\" title=\"Monthly Internet Usage\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Ok end of the year, who&#39;s got me beat. And this is no internet storage backups, just pure surfing, streaming, and downloads. Might include online gaming, not sure how that is counted.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Neither-Director5658\"> /u/Neither-Director5658 </a> <br/> <span><a href=\"https://i.redd.it/ba9fyqbmlf9g1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvpaoh/monthly_internet_usage/\">[comments]</a></span> </td></tr></table>",
        "id": 4406697,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvpaoh/monthly_internet_usage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ba9fyqbmlf9g1.jpeg?width=320&crop=smart&auto=webp&s=8331745aa742236da95058e7f9fd7d5f7c5811e2",
        "title": "Monthly Internet Usage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Avalon_CherryApple",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T22:29:59.504813+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T21:36:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I read through the rules and the wiki, as well as searching online. I am not a big technical person, but I\u2019m trying to learn enough so that I can do what I need for my personal situation. </p> <p>Same story as a lot of people I\u2019m sure: I have years of family photos I would like to store on hard drives, to help clear up digital storage space and to make sure I have \u201cphysical\u201d access to them long term. </p> <p>I was planning to get two 1TB Samsung T7 shields, uploading and organizing all of my photos onto them, then putting one away as a backup and the other for more regular/as needed use. I would still use online cloud storage (I have an Apple ecosystem), but I would like to mass delete things that would be stored on the hard drives. I also know I have under 1TB of photos that I\u2019d like to store so that\u2019s why I\u2019m choosing that low storage space. I\u2019m also hoping to immediately start this process next week or so, and I\u2019m trying to purchase more affordable",
        "id": 4406442,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvnhm2/asking_for_opinions_on_samsung_t7_shield_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Asking for opinions on Samsung T7 shield for family photo storage (and timeline)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Envoyager",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T21:03:24.126861+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T20:12:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I thought I did everything &quot;write&quot;. </p> <ul> <li>DD to zero out whole drive since it&#39;s used (Linux Debian 13)</li> <li>Sent ATA Secure Erase commands</li> <li>Formatted to NTFS using large block size of 64K</li> <li>Mounting it in Linux using the &quot;noatime&quot; option to minimize constant updates to file access time</li> <li>Turned on caching in Linux drive settings in Disk utility</li> <li>Sent <strong>fstrim</strong> command for good measure</li> </ul> <p>And the thing CRAWLS to 0.6x (lowest I&#39;ve seen so far). Usually the first 10GB is pretty fast, starting off around 70 MB/s. My understanding is that this is where the CMR &quot;cache&quot; portion of the drive is filled until it&#39;s forced to start &quot;tear apart&quot; every shingle to write the incoming data. The write speed then drops to 2-4 MB/s.</p> <p>Does this sound right in my situation? I don&#39;t really have a reason to believe the drive is bad, even SMART h",
        "id": 4406095,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvlqte/regretting_purchase_of_smr_hdd_wd40ezaz_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Regretting purchase of SMR HDD (WD40EZAZ) for storing 4K Bluray rips. So freakin' slow",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/51dux",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T23:42:52.595105+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T19:22:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi folks, I recently had one of my old NMVEs die on me or at least it seems like that.</p> <p>After failing, my motherboard refused to boot with it and remained stuck in b5 mode.</p> <p>After moving it to another motherboard, it gets detected but I cannot access it from a Debian live install, it has the XFS file system but even on windows with that paragon software, the drive comes up but cannot be mounted.</p> <p>My goal is to try to find an NVME to USB enclosure that can take a drive like the WD SN750 that has a heat sink, see if I could attempt a repair on it or read the contents.</p> <p>This was just a single unprotected pool that I only used for downloads, but if possible I would love to avoid having to re-download that TB and figure out exactly what I lost since I generally don&#39;t catalogue/backup these kinds of pools.</p> <p>Most enclosures I find can&#39;t take such drives and I already have to return one so I would like to know if someone ",
        "id": 4406698,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvkonr/any_nvme_to_usb_enclosure_that_takes_drives_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any NVME to usb enclosure that takes drives with heatsinks?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SakuraKira1337",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T19:38:58.690213+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T19:06:56+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvkc6g/christmas/\"> <img src=\"https://preview.redd.it/uxl51lt9fe9g1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f90e1c62e2aef3e5186a624bc080e260c2bf706\" alt=\"Christmas\" title=\"Christmas\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Got myself an extension for server01 and new fancy 30TB drives for cheap for server02 :)</p> <p>I am actually astonished, how silent these new mozaic drives are. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SakuraKira1337\"> /u/SakuraKira1337 </a> <br/> <span><a href=\"https://i.redd.it/uxl51lt9fe9g1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvkc6g/christmas/\">[comments]</a></span> </td></tr></table>",
        "id": 4405744,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvkc6g/christmas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/uxl51lt9fe9g1.jpeg?width=640&crop=smart&auto=webp&s=5f90e1c62e2aef3e5186a624bc080e260c2bf706",
        "title": "Christmas",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/redditunderground1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T19:38:59.903278+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T19:00:33+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvk71b/organizing_a_photo_archive/\"> <img src=\"https://a.thumbs.redditmedia.com/eQEloWmP7X-O7SsGvmf34BVtd_yTzSTf2Cb0PR3m7N4.jpg\" alt=\"Organizing a photo archive\" title=\"Organizing a photo archive\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/yx3nn547be9g1.jpg?width=1576&amp;format=pjpg&amp;auto=webp&amp;s=bae481f2a6ca0bd5348846bf86d0d434036cdf7f\">https://preview.redd.it/yx3nn547be9g1.jpg?width=1576&amp;format=pjpg&amp;auto=webp&amp;s=bae481f2a6ca0bd5348846bf86d0d434036cdf7f</a></p> <p>I&#39;ve been working on organizing a digital archive I acquired. The collection consisted of nearly 7,000 photos and was about 150gb in size. Originally it was near a terabyte and was all TIFF files. First thing I did was convert to JPEG. Too much godlike qualities are put into TIFF as opposed to JPEG.</p> <p>Here...</p> <p><a href=\"https://archive.org/details/1stGenerationJpegTestCyanotypeD.",
        "id": 4405745,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvk71b/organizing_a_photo_archive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/eQEloWmP7X-O7SsGvmf34BVtd_yTzSTf2Cb0PR3m7N4.jpg",
        "title": "Organizing a photo archive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Matt_Bigmonster",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T19:39:00.603206+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T18:43:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I like having a copy of my personal data with me on my keyring (Sandisk dual drive 1tb). I was able to create and bitlock a partition on that drive that I can access on my Windows laptop.</p> <p>I can access the other unencrypted part of that ssd with my android phone. Is there a way or 3rd party app that would let me access and decrypt that second locked partition?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Matt_Bigmonster\"> /u/Matt_Bigmonster </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvjtn5/bitlocker_and_multiple_partitions_on_ssd_with/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvjtn5/bitlocker_and_multiple_partitions_on_ssd_with/\">[comments]</a></span>",
        "id": 4405746,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvjtn5/bitlocker_and_multiple_partitions_on_ssd_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Bitlocker and multiple partitions on SSD with Android.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/blera",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T23:42:53.011806+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T18:13:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey <a href=\"/r/DataHoarder\">r/DataHoarder</a>, I\u2019m trying to build a \u201csingle feed\u201d for products I keep checking across a bunch of online shops. I follow around 10\u201315 lingerie retailers (Hunkem\u00f6ller, Women\u2019secret, Intimissimi, VS, etc.) and manually checking category pages is eating time.</p> <p>What I want is a ToS-friendly setup where I can paste category URLs (bras, bodysuits, sets) and it periodically collects product name, product link, main photo, and current price. Ideally it stays organized by shop and category, and I can keep a history (so I can see new arrivals + price drops). Bonus if it can push updates to Telegram/WhatsApp or at least a local dashboard I can scroll.</p> <p>Does anyone already run something like this? Looking for recommended stacks/tools (self-hosted, Docker-friendly if possible). I\u2019m fine with low-frequency checks and playing nicely with rate limits.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.r",
        "id": 4406699,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvj5wk/best_way_to_archivetrack_product_listings_photos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best way to archive/track product listings (photos + prices) from multiple retailers?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Mobile-Mountain-5450",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T18:28:13.904092+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T18:13:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>Installed yt-dlp in win11 using winget.</p> <p>But teachable yt-dlp is not able to download. it says url not supported. I copied the lecture url</p> <p>Also no Video downloader works for teachable even paid one. And Video downloadhelper extension is very slow.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Mobile-Mountain-5450\"> /u/Mobile-Mountain-5450 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvj5mv/ytdlp/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvj5mv/ytdlp/\">[comments]</a></span>",
        "id": 4405492,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvj5mv/ytdlp",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "yt-dlp",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jsrbert",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T18:28:14.210004+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T18:05:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am thinking of organising my movies, videos etc by like who directed it, release date, cast etc. I just have a dump of videos for now. Will slowly organise it</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jsrbert\"> /u/jsrbert </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvizfe/do_you_guys_organise_your_data_or_is_it_just_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvizfe/do_you_guys_organise_your_data_or_is_it_just_a/\">[comments]</a></span>",
        "id": 4405493,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvizfe/do_you_guys_organise_your_data_or_is_it_just_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Do you guys organise your data or is it just a data dump?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/-yphen",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T18:28:14.522607+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T18:04:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to up my backup game and had some problems with rsync not copying files correctly if they are being written to. I currently just \u2014ignore the folders but I\u2019d love to back them up too. Should I have a script that closes all my docker containers in the middle of the night so no file are being written to or something else you suggest? Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/-yphen\"> /u/-yphen </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pviylq/how_to_backup_files_that_are_being_written_to/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pviylq/how_to_backup_files_that_are_being_written_to/\">[comments]</a></span>",
        "id": 4405494,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pviylq/how_to_backup_files_that_are_being_written_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to backup files that are being written to",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DMZQFI",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T18:28:12.350292+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T17:56:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>how much of what you save do you actually go back to. i\u2019m starting to think i keep things more out of fear than usefulness. fear it\u2019ll be gone. fear future me will want it. </p> <p>storage keeps growing but usage doesn\u2019t. not sure if that\u2019s just how the world works now. what\u2019s your reason for keeping things long term?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DMZQFI\"> /u/DMZQFI </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvirpu/do_you_actually_rewatch_stuff_or_just_feel_safer/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvirpu/do_you_actually_rewatch_stuff_or_just_feel_safer/\">[comments]</a></span>",
        "id": 4405490,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvirpu/do_you_actually_rewatch_stuff_or_just_feel_safer",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "do you actually rewatch stuff or just feel safer having it",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/angryslothbear",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T18:28:13.530695+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T17:35:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I need a NAS for two purposes: For professional work storing photography, and also for storing personal files and videos for a media server. I am torn between having a four disk NAS in raid 10, or two separate 2 disk NAS in raid 1. The dual NAS is appealing for keeping my professional and personal data separated, but i know that the 4 bay in raid 10 will give me more space. Just looking for some opinions. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/angryslothbear\"> /u/angryslothbear </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pviba1/two_dual_bay_nas_or_one_4_bay_nas/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pviba1/two_dual_bay_nas_or_one_4_bay_nas/\">[comments]</a></span>",
        "id": 4405491,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pviba1/two_dual_bay_nas_or_one_4_bay_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Two dual bay NAS or one 4 Bay NAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/um_mhm_yup",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T17:20:40.729654+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T16:38:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have some switch and wii u roms on my micro sd card for this android emulator I bought and I make sure to click eject on the card every time and I inserted it into the android device today and those roms were just gone. I put it back into my windows pc and it said there was a problem with the device. The files are still there because the storage is being taken up but theyre just no where to be seen in the folder??? I&#39;ve never had a problem like this with a micro sd card and I made sure to get an sdxc one so that stuff like this didnt happen... does anyone know how to get it to stop doing this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/um_mhm_yup\"> /u/um_mhm_yup </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvh3wa/1tb_sandisk_extreme_sdxc_micro_sd_card_files/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvh3wa/1tb_sandisk_extreme_sdxc",
        "id": 4405199,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvh3wa/1tb_sandisk_extreme_sdxc_micro_sd_card_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "1tb sandisk extreme sdxc micro sd card files corrupting",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Icy_Can_4652",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T23:42:53.680242+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T16:25:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have encountered an issue with Wf downloader, where it wont download the images but json files with info about the pins. Anyone else has this issue? Did you manage to fix it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Icy_Can_4652\"> /u/Icy_Can_4652 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvguam/wf_downloader_no_longer_works/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvguam/wf_downloader_no_longer_works/\">[comments]</a></span>",
        "id": 4406700,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvguam/wf_downloader_no_longer_works",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Wf downloader no longer works",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Unclemilty76",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T17:20:40.507693+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T16:19:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m glad to find like minded datahoarders here. I have a drive with all of my important music and files that I back up using the 3-2-1 method. I have 2 drives (main drive and backup 1) in a 4-bay Terramaster DAS. I have the drive scheduled to be backed up weekly via Carbon Copy Cloner. Te drives are always mounted and some weeks they don&#39;t grow at all and other weeks they might grow a lot. I used to back them up manually when I remembered.</p> <p>My question now is for the 3rd, offsite drive. When I update it with the new data, do I copy from the main drive or backup 1? Im thinking from a stress to drive sense. Does it matter?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Unclemilty76\"> /u/Unclemilty76 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pvgpov/backup_strategy_for_321_specifically_the_offsite/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoard",
        "id": 4405198,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvgpov/backup_strategy_for_321_specifically_the_offsite",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Backup strategy for 3-2-1 (Specifically the offsite drive)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/esahins",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T15:07:08.526120+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T14:34:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>First of all, I apologise if this is a noob question. I\u2019ve tried to find as much information as possible, but I need answers from experienced users with at least 10 years&#39; experience of using/archiving hard disks or other backup tools. Thanks in advance for any answers or contributions.</p> <ol> <li><p>I\u2019m looking for hard drives for a while, but I&#39;ve noticed that prices are quite high. I found recertified hard drives (server parts deals), but I\u2019m not sure how reliable they are. I\u2019m planning to buy 28 TB, but if they fail after five years, it wouldn&#39;t be a cheap purchase.</p></li> <li><p>What about LaCie drives? A friend of mine who works in video production strongly recommended LaCie d2 drives. He says that their company uses a lot of hard disks, but that LaCie drives are the most reliable and have been working for over 10 years without any problems. Is this true?</p></li> <li><p>While researching, I found out that ",
        "id": 4404553,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvelf0/hard_disk_recommendations",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hard Disk recommendations",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/swaroop_34",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T11:45:11.466453+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T11:30:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I developed the python app named TidyBit. It is a File Organizer app. Few weeks ago i posted about it and received good feedback. I made improvements to the app and released new version. The app is now available to download from Microsoft store and Linux Snap store.</p> <p><strong>What My Project Does:</strong></p> <p>TidyBit is a File Organizer app. It helps organize messy collection of files in folders such as Downloads, Desktop or from External drives. The app identifies each file type and assigns a category. It groups files with same category and total file count in each category then displays that information in main UI. It creates category folders in desired location and moves files to their category folders.</p> <p><em>The best part is: The File Organization is Fully Customizable.</em></p> <p>This is one of the important feedback that i got. The previous version didn&#39;t have this feature. In this latest version, in app settings, there are fi",
        "id": 4403605,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pvbicb/tidybit_file_organizer_desktop_app_now_available",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "TidyBit - File Organizer desktop app. Now available on Microsoft Store and Linux Snap Store",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/seekified",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T10:38:19.316829+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T09:52:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a NAS with 3x WD120EFBX and would like a fourth, but I see the helium Red Plus drives are discontinued. Noise is my primary concern and so I need something that is similarly quiet to the EFBX in the 12 TB range. Ironwolfs are too loud.</p> <p>According to Toshiba&#39;s datasheets, the N300 should fit the bill. Has anyone here used both helium Red Plus drives and N300s and can comment on what they&#39;re like?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/seekified\"> /u/seekified </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pva2qu/n300_as_an_efbx_alternative/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pva2qu/n300_as_an_efbx_alternative/\">[comments]</a></span>",
        "id": 4403304,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pva2qu/n300_as_an_efbx_alternative",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "N300 as an EFBX alternative?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SolQuarter",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T09:33:08.375398+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T09:21:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I bought my first NAS roughly 4 months ago. Ugreen DXP 4800 Plus, 2x4TB NVME in Raid1 und 4x8TB HDD in Raid5. I thought back then that this would be plenty of space and I&#39;ll never run out for sure. But fast-forward to now and I only have 5.4TB left on my HDD volume. The NVME is fine as it&#39;s growing very slowly (1.5TB of 3.6TB used) as I mostly backup my photos/videos there.</p> <p>I never thought this Jellyfin project will become so big...I just wanted to stream a couple of movies and TV shows in the beginning. Now it became a true hobby of collection movies and TV shows and I&#39;ll eventually run out of space. But how will I upgrade eventually? It seems that I&#39;ll need to sell all 4 HDDs and rebuy bigger ones? So it would be a rather big investment.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SolQuarter\"> /u/SolQuarter </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv9mv",
        "id": 4403067,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv9mvp/what_will_be_the_best_way_to_upgrade_storage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What will be the best way to upgrade storage?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Moth_Detective",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T08:26:39.305352+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T07:42:29+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv87yk/got_myself_a_little_christmas_present/\"> <img src=\"https://preview.redd.it/tv6846h51b9g1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a9e7d75675f69b15b5db4d7aca67dcdaf7f9da3\" alt=\"Got myself a little Christmas present\" title=\"Got myself a little Christmas present\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Moth_Detective\"> /u/Moth_Detective </a> <br/> <span><a href=\"https://i.redd.it/tv6846h51b9g1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv87yk/got_myself_a_little_christmas_present/\">[comments]</a></span> </td></tr></table>",
        "id": 4402880,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv87yk/got_myself_a_little_christmas_present",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/tv6846h51b9g1.jpeg?width=640&crop=smart&auto=webp&s=5a9e7d75675f69b15b5db4d7aca67dcdaf7f9da3",
        "title": "Got myself a little Christmas present",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CapableContract6643",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T09:33:09.327987+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T07:24:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Maybe this is a totally unnecessary effort, but considering this app has been around for basically 11 years in a way: i feel like there is a significant amount of stories and other internet history that is being made on that site. Countless memes and videos end up first on that app due to its widespread use (for example, the assassination in September 2025 was first widely available on TikTok). That\u2019s also why i think it\u2019ll be difficult, let me know what your opinion on TikTok\u2019s ability to be archived. </p> <p>Personally i believe the way the internet is going, so much of the stuff going on is going to be left forgotten. It\u2019s a miracle that we have infrastructure for viewing old internet stuff like Usenet logged on Google groups and old forums sometimes being left online. I don\u2019t think this is something I\u2019ll be seeing for my generation though, as there has already been a lot of lost content in the 7 years or so tiktok has been blowing up and god knows",
        "id": 4403068,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv7yiu/would_tiktok_be_even_possible_to_archive_in_any",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Would tiktok be even possible to archive in any sort of way?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TNTomato",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T07:21:55.649630+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T06:27:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>After several years of inactivity, Open Video Downloader is receiving support again. I\u2019m interested in using it, but I\u2019m also concerned about the sudden release of v3 after such a long gap. Is there any way to verify that this release is legitimate and not malware?</p> <p><a href=\"https://github.com/jely2002/youtube-dl-gui\">https://github.com/jely2002/youtube-dl-gui</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TNTomato\"> /u/TNTomato </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv73uj/can_anyone_confirm_this_youtubedl_gui_is_legit/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv73uj/can_anyone_confirm_this_youtubedl_gui_is_legit/\">[comments]</a></span>",
        "id": 4402700,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv73uj/can_anyone_confirm_this_youtubedl_gui_is_legit",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can anyone confirm this YouTube-dl GUI is legit?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/morphik69",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T06:21:02.544200+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T05:45:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey fellow hoarders,</p> <p>I&#39;m reaching out for help with something that&#39;s turning into a bit of a time crunch. I have a paid subscription to a course on <a href=\"http://Rodha.co.in\">Rodha.co.in</a>, which uses Spayee CDN for hosting videos. The problem is my access to the platform will expire in about 10 days, and I really need to archive these course videos for personal offline reference and study.</p> <p>The videos are served through HLS (.m3u8) playlists. I\u2019ve already:</p> <ul> <li>Logged in and confirmed the video plays fine in-browser.</li> <li>Located the correct index.m3u8 file via DevTools.</li> <li>Verified it&#39;s pointing to stream variants like hls_1M_.m3u8 and hls_audio_.m3u8.</li> <li>Exported browser cookies via an extension and saved them to cookies.txt.</li> <li>Tried downloading using yt-dlp with full flags, including --cookies, --referer, --user-agent, etc.</li> </ul> <p>yt-dlp is able to fetch the playlist and starts dow",
        "id": 4402516,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv6gay/urgent_help_required_trying_to_archive_paid",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "URGENT HELP REQUIRED : Trying to Archive Paid Course Before Access Expires ,yt-dlp Fails on Encrypted .m3u8 (AES Key Issue)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/-_Stasis_-",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T05:12:35.441084+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T04:51:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Playing this on PC. I just want subtitles in the commercial blu-ray I bought without losing all of the cool interactive menus with the extras. My plan was to remux it and add the subs, and then try to convert the .MKV files back to .M2TS so that they would be compatible with the .MPLS playlists but that&#39;s proving really hard to do. I haven&#39;t been able to find software that can export as .M2TS while also accepting my subtitles files and the .XML tags. I&#39;m not sure what to do anymore. Any ideas?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/-_Stasis_-\"> /u/-_Stasis_- </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv5ly0/how_to_rip_bluray_to_add_subtitles_and_tags_while/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv5ly0/how_to_rip_bluray_to_add_subtitles_and_tags_while/\">[comments]</a></span>",
        "id": 4402332,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv5ly0/how_to_rip_bluray_to_add_subtitles_and_tags_while",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to rip blu-ray to add subtitles and tags while preserving the original interactive menus?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Hefty-Report6360",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T04:08:32.202835+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T03:22:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m moving from a Mac Pro with a separate internal HDD for TimeMachine to a Mac Studio. I haven&#39;t seen a great external TimeMachine option. My Mac Studio internal drive is 16 TB, so the TimeMachine should be 32 TB or greater.</p> <p>Do people use TerraMaster or QNAP for this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hefty-Report6360\"> /u/Hefty-Report6360 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv452c/recommended_drive_for_external_timemachine/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv452c/recommended_drive_for_external_timemachine/\">[comments]</a></span>",
        "id": 4402169,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv452c/recommended_drive_for_external_timemachine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Recommended drive for external TimeMachine",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/No_Professional_582",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T04:08:32.298298+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T03:09:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello all. Though I am not quite the data horder that some of you are, my home server/lab has recently been alerting me to some unreadable and uncorrectable sectors on a couple of my drives. I have 5x Seagate Exos 16tb HDD in a RaidZ2 that comprise my main storage. Within this array, 2 or 3 of the disks have been spitting out anywhere from 10 to 16 bad sectors during long S.M.A.R.T. scans, though not consistently (some tests pass while other spit out the errors). </p> <p>What should I do?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No_Professional_582\"> /u/No_Professional_582 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv3x5o/unreadable_uncorrectable_sectors/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv3x5o/unreadable_uncorrectable_sectors/\">[comments]</a></span>",
        "id": 4402170,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv3x5o/unreadable_uncorrectable_sectors",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Unreadable / Uncorrectable Sectors",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/robo__sheep",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T04:08:31.942178+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T03:05:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello All, </p> <p>I had a question on hosting my own music for streaming or offline playing. For many years I&#39;ve ripped my own DVD&#39;s and Blurays. Generally I run them through Handbrake to reduce the size, and the resulting .mkv&#39;s are played directly through Kodi on a mini PC connected to my TV. I also have a Jellyfin installed on the same mini PC, and it just uses the same video directories as Kodi, but its more convenient for my wife to have access to the video library to use Jellyfin to stream on her phone or tablet. </p> <p>I wanted to do the same with music. Most of the music I listen to is basically singles I purchased many many years ago on iTunes. I used to have an ipod, but thats long gone, so I have this music that just has sat unused for a very long time. We do use Spotify, but I&#39;d like to eventually get away from that subscription, it&#39;ll probably take some convincing for my wife, but she did get weaned off Netflix and D",
        "id": 4402168,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv3urq/would_appreciate_some_advice_on_hosting_my_own",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Would appreciate some advice on hosting my own music",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ghost_of_Panda",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T03:04:52.756400+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T02:19:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I noticed that Exislow\u2019s awesome tool with 2,000 stars, and his GitHub account, were <a href=\"https://github.com/exislow/tidal-dl-ng\">removed suddenly</a>. Does anyone have a backup of the installers for the latest release?</p> <p><a href=\"https://github.com/exislow/tidal-dl-ng\">https://github.com/exislow/tidal-dl-ng</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ghost_of_Panda\"> /u/Ghost_of_Panda </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv33wg/does_anyone_have_a_backup_of_exislows_tidaldlng/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv33wg/does_anyone_have_a_backup_of_exislows_tidaldlng/\">[comments]</a></span>",
        "id": 4401979,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv33wg/does_anyone_have_a_backup_of_exislows_tidaldlng",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does anyone have a backup of Exislow\u2019s Tidal-DL-NG?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Global_Cherry748",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T01:58:35.437978+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T01:45:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m pretty new to DVD ripping and putting content onto USB drives. Trying to convert my DVD collection to digital, but I&#39;ve run into a couple of problems, and I could really use some guidance.</p> <p>Yeah, it&#39;s possible to rip DVDs without re-encoding, but I&#39;m running into compatibility issues with my devices. I&#39;ve heard that re-encoding to MP4/H.264 is a good solution. I&#39;m unsure about how to do this without losing quality. As a beginner, I find it confusing, especially with settings in tools like ffmpeg or HandBrake. I&#39;m not sure how to adjust settings like bitrate, frame rate, or de-interlacing.</p> <p>Another issue. I&#39;m not sure how to deal with soft subtitles vs hard subtitles. I&#39;d prefer to keep the subtitles selectable rather than burned into the video, but I&#39;m open to solutions.</p> <p>I&#39;d love to know if there are easier workflows or best practices. Any suggestions would be appreciated!</p> </div><!",
        "id": 4401810,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv2j9g/how_to_extract_dvds_to_usb_with_reencoding_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to extract DVDs to USB with Re-encoding and Keep Subtitles Selectable",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AdSensitive6271",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T04:08:31.844360+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T00:53:01+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv1ncp/you_guys_reckon_apple_music_next/\"> <img src=\"https://preview.redd.it/9oj6vs41099g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=448fdbd66821bca7ff05ebdbb7511fa987ec1259\" alt=\"You guys reckon Apple Music next? :)\" title=\"You guys reckon Apple Music next? :)\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AdSensitive6271\"> /u/AdSensitive6271 </a> <br/> <span><a href=\"https://i.redd.it/9oj6vs41099g1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv1ncp/you_guys_reckon_apple_music_next/\">[comments]</a></span> </td></tr></table>",
        "id": 4402167,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv1ncp/you_guys_reckon_apple_music_next",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/9oj6vs41099g1.png?width=640&crop=smart&auto=webp&s=448fdbd66821bca7ff05ebdbb7511fa987ec1259",
        "title": "You guys reckon Apple Music next? :)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Firestarter321",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-25T00:51:22.121138+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-25T00:11:42+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv0x39/i_think_i_have_a_problemsigh/\"> <img src=\"https://b.thumbs.redditmedia.com/Y02mt5EGPQSMWySKuoj9cWOUXD06mbEEfAeQzNRNJxc.jpg\" alt=\"I think I have a problem\u2026sigh\" title=\"I think I have a problem\u2026sigh\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I also have an offsite Supermicro CSE-826 125TB UnRAID server that isn\u2019t picture.</p> <p>The second picture are spares. I wish selling a few wasn\u2019t such a pain where I live as only 4 of the servers in the rack are on 24/7.</p> <p>They\u2019re all X10 systems except for 1 of the CSE-826\u2019s. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Firestarter321\"> /u/Firestarter321 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1pv0x39\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pv0x39/i_think_i_have_a_problemsigh/\">[comments]</a></span> </td></tr></table>",
        "id": 4401580,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pv0x39/i_think_i_have_a_problemsigh",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/Y02mt5EGPQSMWySKuoj9cWOUXD06mbEEfAeQzNRNJxc.jpg",
        "title": "I think I have a problem\u2026sigh",
        "vote": 0
    }
]