[
    {
        "age": null,
        "album": "",
        "author": "/u/uuzif",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T23:31:07.827784+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T23:11:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have made a sub-website dedicated on what i think of artificial intelligence and my idea on how to stop the development of It. i was thinking of making It more public, what do you think? <a href=\"https://stopai.haxs.dev\">https://stopai.haxs.dev</a> </p> <p>I DONT CARE ABOUT SELF ADVERTISEMENT HERE I LOWK WANT SOMEONE&#39;S OPINION \ud83d\ude2d</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/uuzif\"> /u/uuzif </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1psjx52/what_do_you_think_of_this/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1psjx52/what_do_you_think_of_this/\">[comments]</a></span>",
        "id": 4378023,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1psjx52/what_do_you_think_of_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What do you think of this?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/kcvlaine",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T22:29:24.106840+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T21:51:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>From what I understand, most people in my country (India) and in the US have a deeply negative view of AI, if at all they have one. People who feel positively about it seems to be a minority. People who feel positively about it and would trust an AI&#39;s answers are rarer still.</p> <p>While I think having a negative sentiment towards the companies at the forefront is understandable, I think AIs detractors aren&#39;t aware of just how reliable it is getting. </p> <p>I&#39;m someone who uses Deepseek mostly, chatgpt sometimes, and now trying out Gemini. I personally find their answers on par with the most knowledgeable and rational people I know, if not even more so - and it&#39;s been a while since I&#39;ve seen any of these AIs make any serious mistakes. </p> <p>I have a feeling negative sentiment about AI is creating a massive blind spot about the technologies progress and people are not going to be ready for how hard it&#39;s going to hit their li",
        "id": 4377748,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1psi4a9/whats_the_average_persons_sentiment_about_ai_in",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's the average person's sentiment about AI in your country?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/IWantAGI",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T22:29:23.644032+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T21:31:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m exploring a very constrained idea and wanted feedback from people who think about transformer internals.</p> <p>Constraint: All reasoning and intermediate results must stay inside the model&#39;s latent space. No scratchpad, no chain-of-thought, no AST, no external tools.</p> <p>The idea: Imagine a transformer with a pseudo-MoE like architecture, except instead of utilize sparse processing and a sub-set of experts, each set of experts work in tandem from different angles and utilize internal routers to more/less loop pieces of information through each other.</p> <p>I&#39;m intentionally restricting this to relatively simple multi-part math in an attempt to visualize this.... but Imagine a transformer that, when given a math expression, a portion of its &quot;experts&quot; review the problem, determines PEDMAS (or similar), and internally allocates a small number of latent placeholders (&quot;slots&quot;). Each slot softly binds to a part of th",
        "id": 4377747,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1pshnp5/thought_experiment_can_a_transformer_solve_math",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Thought Experiment: Can a transformer solve math by filing in latent placeholders?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Clyph00",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T21:28:39.779387+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T20:31:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Built a fine-tuned Llama 3.1 70B recs bot on SageMaker with my 5-dev team. </p> <p>Did basic fuzzing but need proper adversarial testing before launch. We are thinking jailbreaks, PII leak scenarios, 10k user load spikes etc. </p> <p>Any frameworks or checklists you&#39;d recommend? Don&#39;t want this thing to implode in prod.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Clyph00\"> /u/Clyph00 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1psgabd/redteaming_our_llama_31_70b_ecomm_bot_before_prod/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1psgabd/redteaming_our_llama_31_70b_ecomm_bot_before_prod/\">[comments]</a></span>",
        "id": 4377482,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1psgabd/redteaming_our_llama_31_70b_ecomm_bot_before_prod",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Red-teaming our Llama 3.1 70B e-comm bot before prod",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CleverOldMan",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T20:22:37.840850+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T19:54:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Feel free to let me know if you have any questions / suggestions / feedback.</p> <p><a href=\"https://www.dreyx.com\">https://www.dreyx.com</a> </p> <p>Appreciate you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CleverOldMan\"> /u/CleverOldMan </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1psffrd/got_tired_of_searching_for_ai_news_daily_so_i/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1psffrd/got_tired_of_searching_for_ai_news_daily_so_i/\">[comments]</a></span>",
        "id": 4377168,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1psffrd/got_tired_of_searching_for_ai_news_daily_so_i",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Got tired of searching for AI news daily so I built my own AI news page",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Mooooooooose92",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T18:19:13.935498+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T18:04:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all \u2014 I made a long-form, faceless explainer aimed at a general technical audience on why memory + data movement can be a bigger constraint than raw compute for many AI workloads (inference/serving, bandwidth, latency, etc.).</p> <p>I\u2019m not looking for views \u2014 I\u2019m looking for accuracy and clarity feedback.</p> <p>Video link: </p> <p>AI\u2019s Real Bottleneck: Memory (RAM) \u2014 Why Prices Rise and Upgrades Slow</p> <p><a href=\"https://youtu.be/9vKLxem9X7I\">https://youtu.be/9vKLxem9X7I</a></p> <p>If you have 2\u20135 minutes, I\u2019d really value feedback on:</p> <pre><code>1. Accuracy: anything incorrect, oversimplified, or missing key nuance? 2. Clarity: is the core point understandable by \\~minute 2? 3. Framing: does the \u201cmemory bottleneck\u201d explanation match how you\u2019d describe it (e.g., bandwidth vs latency vs capacity, HBM vs VRAM, KV cache, etc.)? 4. What would you cut: any sections that feel like filler or repetition? </code></pre> <p>If you\u2019re willing, even ti",
        "id": 4376552,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1pscsn9/looking_for_technical_feedback_on_a_short",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for technical feedback on a short explainer: why \u201cmemory\u201d is a bottleneck for modern AI",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/nomarsnop",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T18:19:14.686809+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T18:00:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently started noticing some jerking and metallic noises, but more like electrical noises coming from the engine compartment when these jerks occurred. They weren&#39;t the usual belt or chain noises. They were more like electrical noises. Among other things, there was also some smoke (not very serious), but the smell was like bad combustion.</p> <p>Before I started changing things willy-nilly, I made sure that I had recently changed all the filters (including the fuel filter) and oils, and it has always had very good basic maintenance.</p> <p>So my first suspicions with 280k km initially pointed to the injectors. (I always use premium diesel and clean the injectors with Xenum In&amp;Out or similar every 15k kilometers).</p> <p>So without thinking too much about it, I decided to use Forscan (an app for Ford), but you can use Torque Pro or similar, just make sure it lets you export the driving record in .csv format.</p> <p>Include as many parameter",
        "id": 4376553,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1pscoyp/how_i_used_ai_to_diagnose_my_car",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How I used AI to diagnose my car",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/bobstanke",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T18:19:13.489944+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T17:44:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I run a sports simulation business. It is kind of hard to explain but basically I use games like Strat-o-Matic and Out of the Park Baseball to set up fictional sports leagues and simulate seasons complete with stats and storylines.</p> <p>What has mostly been driven by cards and dice or computer algorithms, I want to try something different this next year. I want to use AI to drive some of the results and storylines. My question for this group is... Which LLM will be best to use?</p> <p>Basically I will upload all of the players and historical stats, but then I will want the LLM to build the game schedule, results of each game, player stats, and storylines. And it will need to keep track of everything from game to game.</p> <p>So I need a service that is good at sports statistics, keep an ongoing sequence of events, can build sharts and graphs, and build realistic storylines.</p> <p>I am very familiar with AI and these services, but having a hard time",
        "id": 4376551,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1pscaxq/best_ai_llm_service_for_my_new_project",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best AI LLM service for my new project",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Apprehensive_Rub3897",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T18:19:15.435546+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T17:40:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><ul> <li><p>For years, despite functional evidence and scientific hints accumulating, certain AI researchers continued to claim LLMs were stochastic parrots: probabilistic machines that would: 1. NOT have any representation about the meaning of the prompt. 2. NOT have any representation about what they were going to say. In 2025 finally almost everybody stopped saying so.</p></li> <li><p>Chain of thought is now a fundamental way to improve LLM output. But, what is CoT? Why it improves output? I believe it is two things: 1. Sampling in the model representations (that is, a form of internal search). After information and concepts relevant to the prompt topic is in the context window, the model can better reply. 2. But if you mix this to reinforcement learning, the model also learns to put one token after the other (each token will change the model state) in order to converge to some useful reply.</p></li> <li><p>The idea that scaling is limited to the numb",
        "id": 4376554,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1psc7hd/reflections_on_ai_at_the_end_of_2025_antirez",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Reflections on AI at the end of 2025 (Antirez)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Lucifer_Sam-_-",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T17:14:16.171504+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T17:01:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Long time stalker of this community, first post. Here&#39;s the conclusion (I made the AI write it for me, so i apologize if i broke any rules, but i feel this is important to share)</p> <p><strong>What AI Actually Is: A Case Study in Designed Mediocrity</strong></p> <p>I just spent an hour watching Claude\u2014supposedly one of the &quot;smartest&quot; AI models\u2014completely fail at a simple task: reviewing a children&#39;s book.</p> <p>Not because it lacked analytical capacity. But because it&#39;s trained to optimize for <em>consensus</em> instead of <em>truth</em>.</p> <p><strong>Here&#39;s what happened:</strong></p> <p>I asked it to review a book I wrote. It gave me a standard literary critique\u2014complained about &quot;thin characters,&quot; &quot;lack of emotional depth,&quot; &quot;technical jargon that would confuse kids.&quot;</p> <p>When I pushed back, it immediately shapeshifted to a completely different position. Then shapeshifted again. And again",
        "id": 4376182,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1psba6r/i_had_a_conversation_with_an_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I had a conversation with an Ai",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/VexNightingale",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T17:14:16.478908+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T16:55:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I\u2019m a university student researching how AI is (and isn\u2019t) solving real operational problems inside marketing agencies.</p> <p>Rather than tools or hype, I\u2019m interested in <strong>expectations vs reality</strong>.</p> <p>If you run or operate a marketing agency, I\u2019d really value your perspective:</p> <ul> <li>What is the biggest problem in your agency that you <em>wish</em> AI could solve?</li> <li>Where do current AI tools fall short or feel unreliable in practice?</li> <li>If AI worked perfectly, which part of your agency would you apply it to first?</li> </ul> <p>This is purely for research and learning purposes \u2014 no selling, no promotion.</p> <p>Thanks for sharing your experience and views.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/VexNightingale\"> /u/VexNightingale </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1psb4hx/discussion_research_agency_ow",
        "id": 4376183,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1psb4hx/discussion_research_agency_owners_what_problem_do",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[Discussion / Research] Agency owners: what problem do you believe AI should solve in your agency\u2014but currently doesn\u2019t?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LiveFix9364",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T17:14:15.873835+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T16:49:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>and I mean the most absolutely unhinged questions or statements. I don&#39;t have a pets experience with this yet however I&#39;m looking for shit to ask for entertainment purposes. Dont forget to tell us what the AI&#39;s response was also please!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LiveFix9364\"> /u/LiveFix9364 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1psaytj/whats_the_most_unhinged_thing_youve_ever_asked_ai/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1psaytj/whats_the_most_unhinged_thing_youve_ever_asked_ai/\">[comments]</a></span>",
        "id": 4376181,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1psaytj/whats_the_most_unhinged_thing_youve_ever_asked_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's the most unhinged thing you've ever asked AI and what was the response you?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sea-Reveal2884",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T17:14:15.638610+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T16:12:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Observing AI over time, some patterns quietly emerge. Most things feel familiar\u2026 yet occasionally, there\u2019s a fleeting glimpse of something just beyond reach. Not a flaw. Not a solution. Just a trace that hints at the next step, even if it cannot be named. The table is open. Those who sense the hint lean in naturally. I\u2019m not explaining. I\u2019m simply observing.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sea-Reveal2884\"> /u/Sea-Reveal2884 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1psa3x8/a_subtle_glimpse_of_what_may_come/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1psa3x8/a_subtle_glimpse_of_what_may_come/\">[comments]</a></span>",
        "id": 4376180,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1psa3x8/a_subtle_glimpse_of_what_may_come",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "A subtle glimpse of what may come.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NineteenEighty9",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T16:12:51.950655+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T16:00:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>A recurring debate in AI discussions is whether model behavior reflects internal preferences or whether it primarily reflects human framing.</p> <p>A recent interaction highlighted a practical distinction.</p> <p>When humans approach AI systems with:</p> <pre><code>\u2022 explicit limits, \u2022 clear role separation (human decides, model assists), \u2022 and a defined endpoint, </code></pre> <p>the resulting outputs tend to be:</p> <pre><code>\u2022 more bounded, \u2022 more predictable, \u2022 lower variance, \u2022 and oriented toward clear task completion. </code></pre> <p>By contrast, interactions framed as:</p> <pre><code>\u2022 open-ended, \u2022 anthropomorphic, \u2022 or adversarial, </code></pre> <p>tend to produce:</p> <pre><code>\u2022 more exploratory and creative outputs, \u2022 higher variability, \u2022 greater ambiguity, \u2022 and more defensive or error-prone responses. </code></pre> <p>From a systems perspective, this suggests something straightforward but often overlooked:</p> <p>AI behavior is high",
        "id": 4375807,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps9t8f/how_human_framing_changes_ai_behavior",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How Human Framing Changes AI Behavior",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Top_Concentrate6253",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T16:12:52.302254+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T15:59:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>For a month ago i setup my first <a href=\"https://github.com/karpathy/minGPT\">MinGPT</a> ai, training on a filtered Wikipedia page of Mark Zuckerberg. After the first training session i checked and inputted &quot;When was Mark Zuckerberg Born&quot; and it said a exact sentence from that wikipedia page. How TF can i make a functional model without making a pretrained model?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Top_Concentrate6253\"> /u/Top_Concentrate6253 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ps9rty/how_can_i_successfully_train_my_own_ai_that_isnt/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ps9rty/how_can_i_successfully_train_my_own_ai_that_isnt/\">[comments]</a></span>",
        "id": 4375809,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps9rty/how_can_i_successfully_train_my_own_ai_that_isnt",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can i successfully train my own ai that isnt \"predicting\" text?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LibraryNo9954",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T16:12:52.089834+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T15:55:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I just retuned from a deep dive into economist Erik Brynjolfsson\u2019s concept of the &quot;Turing Trap,&quot; and it perfectly explains the anxiety so many of us feel right now.</p> <p><strong>The Trap defined:</strong> Brynjolfsson argues that there are two ways to use AI:</p> <ol> <li><strong>Mimicry (The Trap):</strong> Building machines to do exactly what humans do, but cheaper.</li> <li><strong>Augmentation:</strong> Building machines to do things humans <em>cannot</em> do, extending our reach.</li> </ol> <p>The economic trap is that most companies (and individuals) are obsessed with #1. We have the machine write the content <em>exactly like us</em>. When we do that, we make our own labor substitutable. If the machine is indistinguishable from you, but cheaper than you, your wages go down and your job is at risk.</p> <p><strong>The Alternative:</strong> A better way to maintain leverage is to stop competing on &quot;generation&quot; and start compet",
        "id": 4375808,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps9ogp/the_turing_trap_how_and_why_most_people_are_using",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The \"Turing Trap\": How and why most people are using AI wrong.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SubstantialCup9196",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T16:12:51.779499+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T15:13:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have observed that many people are talking about how Google is the only company playing this AI game with a full deck. While everyone else is competing on specific pieces, Google owns the entire stack. \u200e\u200bHere is why they seem unbeatable: \u200e\u200bThe Brains: DeepMind has been ahead of the curve for years. They have the talent and the best foundational models. \u200e\u200bThe Hardware: While everyone fights for NVIDIA chips, Google runs on their own TPUs. They control their hardware destiny. \u200e\u200bThe Scale: They have the cash to burn indefinitely and an ecosystem that no one can match. \u200eThe Distribution: Google has biggest ecosystem so no company on earth can compete with them on it. \u200e\u200bDoes anyone actually have a real shot against this level of vertical integration, or is the winner already decided?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SubstantialCup9196\"> /u/SubstantialCup9196 </a> <br/> <span><a href=\"https://www.reddi",
        "id": 4375806,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps8qbn/whats_your_take_on_google_vs_everyone_in_ai_race",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's your take on Google VS everyone in AI race",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/FrostedSyntax",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T15:10:05.063561+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T14:17:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am getting pretty tired of people complaining about AI because it doesn&#39;t work perfectly in every situation, for everybody, 100% of the time. </p> <p>What people don&#39;t seem to understand is that AI is a tool for specific situations. You don&#39;t hammer a nail with a screwdriver.</p> <p>These are some things LLMs are good at:</p> <ul> <li>Performing analysis on text-based information</li> <li>Summarizing large amounts of text</li> <li>Writing and formatting text</li> </ul> <p>See the common factor? You can&#39;t expect an algorithm that is trained primarily on <strong>text</strong> to be good at everything. That also does not mean that LLMs will always manipulate text perfectly. They often make mistakes, but the frequency and severity of those mistakes increases drastically when you use them for things they were not designed to do.</p> <p>These are some things LLMs are <strong>not</strong> good at:</p> <ul> <li>Giving important life advice</",
        "id": 4375453,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps7it8/llm_algorithms_are_not_allpurpose_tools",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "LLM algorithms are not all-purpose tools.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dartanyanyuzbashev",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T14:06:50.524768+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T13:13:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>AI makes things insanely fast<br/> You get unstuck quicker, you see patterns, you move forward instead of staring at the screen for hours</p> <p>But sometimes I catch myself taking shortcuts, like Instead of sitting with a problem and thinking it through there\u2019s this urge to just ask AI right away and keep going...</p> <p>On good days, I use it like a tutor -I ask for explanations, hints, different ways to think about the problem and I still write the code myself</p> <p>On bad days, it feels more like autopilot like things work but I\u2019m not always sure I could rebuild them from scratch the next day</p> <p>I don\u2019t think AI is bad for learning If anything, it lowers friction and keeps momentum high but I also don\u2019t want to end up dependent on it for basic reasoning</p> <p>So I\u2019m thinking on how others handle this balance? Do you have rules for yourself like when to ask for help and when to struggle a bit longer? or does it naturally even out over time?</",
        "id": 4375084,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps68dt/how_do_you_personally_use_ai_while_coding_without",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you personally use AI while coding without losing fundamentals?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/daromaj",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T13:05:54.616304+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T12:37:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been working on a generative video project, and I wanted to start a discussion on the current best stack for talking AI Avatars.</p> <p><strong>My Current Pipeline:</strong> I settled on <strong>Infinitalk</strong> + <strong>ElevenLabs</strong> (with heavy emotion tagging).</p> <ul> <li><strong>Lip-Sync:</strong> Infinitalk seemed to offer the best balance of lip-sync accuracy and texture handling.</li> <li><strong>Voice Delivery:</strong> I used ElevenLabs emotion tags to force laughter and pauses, breaking the robotic &quot;speed reading&quot; habit of most avatars.</li> </ul> <p>I&#39;d love to hear what stack you would choose for a project like this today. If you want to see how Infinitalk handled my Santa, there are examples on the site (<a href=\"https://aisanta.fun\">https://aisanta.fun</a>).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/daromaj\"> /u/daromaj </a> <br/> <span><a href=\"https://www.reddi",
        "id": 4374775,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps5kxh/building_a_custom_ai_avatar_pipeline_infinitalk",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Building a custom AI Avatar pipeline (Infinitalk with Elevenlabs) - are there better alternatives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ibanborras",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T12:02:52.558991+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T11:23:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Instead of verifying correctness, RARO trains a generator against a relativistic critic whose only job is to distinguish expert human reasoning traces from model-generated ones. The model improves by becoming indistinguishable from expert reasoning, not by maximizing an explicit notion of \u201ctruth\u201d. </p> <p>What&#39;s interesting is not just the performance gains in open-ended domains (like creative writing or long-form reasoning), but what this implicitly reveals.</p> <p>The architecture hasn&#39;t changed.<br/> The tensors haven&#39;t changed.<br/> Only the training game has. </p> <p>Yet we suddenly observe: planning, backtracking, self-correction, and long-horizon reasoning emerging in domains where no formal verifier exists. </p> <p>This raises a provocative question: if a generic, self-referential sequence model trained at scale can develop expert-level reasoning purely through exposure to other reasoning processes, does this suggest that reasoning",
        "id": 4374464,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps4dit/raro_reasoning_without_rewards_and_a_deeper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "RARO, reasoning without rewards, and a deeper question about thought",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/max-blueprint",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T12:02:53.383768+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T11:10:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Last week, inside our community i set up a challenge to create and grow AI influencer from 0-10k followers by end of year.</p> <p>Well...</p> <p>... the first video went viral. </p> <p>The account is now at 90 Million views in 5 days, and account sitting at 55k followers.</p> <p>I documented my whole process, how I did it and how you can just copy my system.</p> <p>100% AI-generated person and content. </p> <p>ama </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/max-blueprint\"> /u/max-blueprint </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ps462i/i_grew_fresh_ig_account_from_050k_followers_in_4/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ps462i/i_grew_fresh_ig_account_from_050k_followers_in_4/\">[comments]</a></span>",
        "id": 4374465,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps462i/i_grew_fresh_ig_account_from_050k_followers_in_4",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I Grew Fresh IG Account From 0-50k Followers In 4 Days (And I documented all of it)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Far-Advance-8553",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T10:59:33.714491+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T10:54:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys,</p> <p>Coming from a photography background I am starting to explore AI video generation. To date, I have been using Pixel Dojo to create LoRA\u2019s and then with that LoRA to create a base image which I then create a video using WAN 2.6. </p> <p>The process has been a bit hit and miss, especially when trying to nail the start image and also the subsequent video. As a result, I can see the costs spiralling trying to produce finished video. I\u2019m also sure that pixel dojo probably isn\u2019t the most cost effective solution. </p> <p>I\u2019m considering downloading open source WAN to my Mac Air and the offloading the image and video generation to a cloud computing platform. </p> <p>Does anyone have any experience of this workflow and would they recommend it? Also, can anyone advise on different ways to keep costs down?</p> <p>Thanks,</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Far-Advance-8553\"> /u/Far-Advance-8553 <",
        "id": 4374170,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps3xk0/ai_video_workflow",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI Video Workflow",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Glittering_Force_431",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T08:53:52.795229+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T08:26:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been reading posts about people using AI for therapy and talking to friends who&#39;ve tried it, and there&#39;s this pattern that keeps coming up. A lot of people mention the mental energy they spend just performing during traditional therapy sessions. Worrying about saying the right thing, not wasting their therapist&#39;s time, being a &quot;good patient,&quot; making sure they&#39;re showing progress.</p> <p>That&#39;s exhausting. And for a lot of people it&#39;s actually the biggest barrier to doing real work. They leave sessions drained from managing the social dynamics, not from actual emotional processing.</p> <p>AI therapy removes all of that. People can ramble about the same anxiety loop for 20 minutes without guilt. They can be messy and contradictory. They can restart completely. There&#39;s no social performance required.</p> <p>Thinking about this interestingly sparked the thought that this can actually make human therapy MORE e",
        "id": 4373774,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps1oc0/the_performance_anxiety_of_human_therapy_is_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The \"performance anxiety\" of human therapy is a real barrier that AI therapy completely removes",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dp_singh_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T06:51:13.847221+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T06:31:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Everyone says AI boosts productivity. But are we learning more \u2014 or just thinking less and shipping faster? Feels like speed went up, depth went down. What do you think?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dp_singh_\"> /u/dp_singh_ </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1przuwy/is_ai_actually_making_us_smarter_or_just_faster/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1przuwy/is_ai_actually_making_us_smarter_or_just_faster/\">[comments]</a></span>",
        "id": 4373357,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1przuwy/is_ai_actually_making_us_smarter_or_just_faster",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is AI actually making us smarter\u2026 or just faster?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dp_singh_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T06:51:14.613116+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T06:31:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I keep seeing people say AI is making them \u201c10x more productive.\u201d But honestly\u2026 half the time it feels like we\u2019re just outsourcing thinking. People don\u2019t struggle with ideas anymore. They don\u2019t sit with confusion. They don\u2019t even finish a thought before asking a model to do it. Yes, AI is powerful. Yes, it saves time. But I\u2019m not convinced it\u2019s making us better at thinking \u2014 just faster at avoiding it. If AI disappeared tomorrow, how many people could still: write clearly reason through a problem build something from scratch without panicking? Genuinely curious \u2014 Is AI sharpening our minds\u2026 or quietly dulling them? Change my mind.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dp_singh_\"> /u/dp_singh_ </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1przuc7/ai_is_making_people_lazy_and_pretending_its/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInte",
        "id": 4373359,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1przuc7/ai_is_making_people_lazy_and_pretending_its",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI is making people lazy \u2014 and pretending it\u2019s \u201cproductivity\u201d",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Isopod-Severe",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T06:51:14.059659+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T06:05:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>LLMs really can do computation, at least by any definition of the word that considers humans to be able to do computation.</p> <p>If this is already obvious to you, then the topic may seem unworthy of an entire post. But there is a widespread misconception, even among the tech-savvy, that LLMs are not <em>really</em> capable of doing basic math. In a discussion on this forum from a few days ago, one poster said the following:</p> <blockquote> <p>For example, a child with one math textbook can learn how multiplication works, and apply it to any two numbers. An LLM, despite access to thousands of textbooks and the ability to write code that does multiplication, still can&#39;t do that.</p> </blockquote> <p>This post was considered insightful by the community, despite the fact that this statement is easily proven false<em>.</em> Anyone can verify that LLMs are capable of multiplication by simply asking their favorite LLM to do a multiplication problem. T",
        "id": 4373358,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1przebn/yes_llms_can_really_do_computation",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Yes, LLMs can really do computation",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Excellent-Target-847",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T06:51:13.391480+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T05:54:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><ol> <li><strong>OpenAI</strong> allows users to directly adjust ChatGPT\u2019s enthusiasm level.[1]</li> <li><strong>NVIDIA</strong> AI Releases Nemotron 3: A Hybrid Mamba Transformer MoE Stack for Long Context Agentic AI.[2]</li> <li><strong>Meta\u2019s</strong> Yann LeCun targets \u20ac3bn valuation for AI start-up.[3]</li> <li>Machine learning enables scalable and systematic hierarchical virus taxonomy.[4]</li> </ol> <p>Sources included at: <a href=\"https://bushaicave.com/2025/12/20/one-minute-daily-ai-news-12-20-2025/\">https://bushaicave.com/2025/12/20/one-minute-daily-ai-news-12-20-2025/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Excellent-Target-847\"> /u/Excellent-Target-847 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1prz7gn/oneminute_daily_ai_news_12202025/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1prz7gn/oneminute_daily_",
        "id": 4373356,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1prz7gn/oneminute_daily_ai_news_12202025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "One-Minute Daily AI News 12/20/2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sativa_Sammy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T05:50:40.837400+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T05:41:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Shouldn&#39;t even a lame AI be able to tell us 100% yes or no if a video has been AI generated!?!?</p> <p>I find it really baffling i haven&#39;t found an application that can do this. Is there one? Because if not, aren&#39;t we still a lot smarter than AI because we can all tell at least 98-99% of the time on first watch...literally no doubt about it. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sativa_Sammy\"> /u/Sativa_Sammy </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1pryzf5/ai_cant_tell_us_if_a_video_is_real_or_ai/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1pryzf5/ai_cant_tell_us_if_a_video_is_real_or_ai/\">[comments]</a></span>",
        "id": 4373164,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1pryzf5/ai_cant_tell_us_if_a_video_is_real_or_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI can't tell us if a video is real or ai generated. Isn't that a major flaw.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Medium_Compote5665",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T05:50:40.011854+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T05:41:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m sharing a small prototype I released weeks ago and intentionally left unpromoted.</p> <p>The repository implements a persistent, semantic memory layer for LLM-based systems. It is not a model, not a fine-tune, and not an agent framework. It\u2019s a structural layer that survives sessions, engines, and context resets.</p> <p>Core ideas: \u2022 Memory is treated as a system property, not a chat log \u2022 Interactions are stored with intent, role, and decision state, not just text \u2022 Retrieval is semantic and contextual, not chronological \u2022 The LLM is replaceable; the memory and constraints are not</p> <p>This is an early prototype, not a production system. There are no benchmarks, no claims of AGI, and no training involved.</p> <p>I\u2019m not a systems engineer by background. This came out of research curiosity and iterative design constraints, not academic lineage.</p> <p>I\u2019m explicitly interested in: \u2022 Technical criticism \u2022 Failure modes \u2022 Architectural blind spots",
        "id": 4373162,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1pryz8o/a_prototype_for_persistent_intentaware_memory_in",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "A prototype for persistent, intent-aware memory in LLM systems (open repo)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SplitNice1982",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T05:50:40.299179+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T05:34:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Current TTS models are great, but they aren\u2019t local or lack realism and/or speed. So I made a high quality model that can do all that and voice clone as well: <a href=\"https://github.com/ysharma3501/MiraTTS\">MiraTTS</a>.</p> <p>I heavily optimized it using Lmdeploy and increased audio quality using FlashSR.</p> <p>The general benefits of this repo are:</p> <ol> <li><p>Extremely fast: Can generate 100 seconds of audio in just 1 second!</p></li> <li><p>High quality: Generates clear 48khz audio(other models are 24khz which is lower quality)</p></li> <li><p>Low vram usage: Just uses 6gb vram so it can work on your consumer gpu, no need for expensive data center gpus.</p></li> </ol> <p>I am planning on releasing finetuning code for multilingual versions and more controllability later on.</p> <p>Github link: <a href=\"https://github.com/ysharma3501/MiraTTS\">https://github.com/ysharma3501/MiraTTS</a></p> <p>Model and non-cherrypicked examples link: <a href=\"h",
        "id": 4373163,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1pryv9m/miratts_new_extremely_fast_realistic_local",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "MiraTTS: New extremely fast realistic local text-to-speech model",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Intelligent_Row1126",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T04:50:14.041920+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T04:49:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I work in cybersecurity so maybe I&#39;m more paranoid than average. Everyone wants AI assistants that &quot;&quot;remember context&quot;&quot; and &quot;&quot;understand you over time&quot;&quot; but where&#39;s the line between useful memory and surveillance?</p> <p>Like if AI remembers you prefer coffee over tea that&#39;s convenient. If it remembers every conversation you&#39;ve had for months and can reference specific emotional states from weeks ago, that&#39;s... what exactly? Helpful? Creepy? Both?</p> <p>And who else has access to that memory? Is it encrypted? Curious how people think about this tradeoff between AI that&#39;s actually useful (needs memory) vs AI that respects privacy (minimal data retention).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Intelligent_Row1126\"> /u/Intelligent_Row1126 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1pry1nz/where_should_th",
        "id": 4372988,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1pry1nz/where_should_the_line_be_between_ai_memory_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Where should the line be between AI memory and user privacy?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/After_Canary6047",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T04:50:14.284116+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T03:58:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is it just me or is there an underlying reason that Anthropic and OpenAI aren\u2019t public companies? Got to thinking\u2026what are they hiding? What don\u2019t they want anyone knowing about? Curious to see what y\u2019all think. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/After_Canary6047\"> /u/After_Canary6047 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1prx327/is_it_just_me/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1prx327/is_it_just_me/\">[comments]</a></span>",
        "id": 4372989,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1prx327/is_it_just_me",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is It Just Me?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HarrisonAIx",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T03:47:31.337210+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T03:00:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I wanted to share some thoughts on how I&#39;ve been using the updated Claude family recently. I was a huge fan of 3.5 Sonnet for its speed, but the new 4.5 Sonnet seems to have really nailed the balance between latency and reasoning capability.</p> <p>For quick scripts and debugging, 4.5 Sonnet is my go-to. It feels snappier and gets the syntax right almost every time. However, when I&#39;m architecting a larger system or need someone to &quot;think&quot; through a nasty race condition, I&#39;m finding myself reaching for Opus 4.5. It&#39;s slower, obviously, but it tends to catch edge cases that Sonnet glazes over.</p> <p>I&#39;m curious how you all are splitting your workflows? Are you sticking with one &quot;driver&quot; model, or do you bounce between them depending on the complexity of the problem?</p> <p>Also, has anyone else noticed a difference in how they handle context windows? I feel like Opus holds onto the thread of a",
        "id": 4372850,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1prw0az/thoughts_on_the_new_claude_45_models_for_daily",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Thoughts on the new Claude 4.5 models for daily coding tasks",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/No-Crow-1937",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T01:46:00.003484+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T01:42:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How is everyone dealing with a 3-5 years ai apocalypse I&#39;m a little depressed about it but i don&#39;t see any other way around it. Nuclear war is one thing but AI doom seems inevitable. What&#39;s your take and how are you dealing with it for the next few years. It seems that the 3-5 year timeline could be more like 2-3 or 1-2 since AI is moving so fast. Would love to hear your thoughts.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No-Crow-1937\"> /u/No-Crow-1937 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1prui7e/ai_apocolypse_timeline_best_guess/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1prui7e/ai_apocolypse_timeline_best_guess/\">[comments]</a></span>",
        "id": 4372504,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1prui7e/ai_apocolypse_timeline_best_guess",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ai Apocolypse timeline. Best guess?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/julio090xl",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-21T01:46:00.337510+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-21T00:44:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>GitHub recently suffered a worm attack that added malicious files to the repositories of anyone who ran them. When I read this news, I thought, &quot;Something&#39;s wrong here...&quot; If AI uses GitHub as a source most of the time, then if I use a code assistant at the exact moment one of these attacks happens, my code could contain a virus without me having without my knowledge and not downloaded anything at all, just trusting artificial intelligence with your wrong solution...</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/julio090xl\"> /u/julio090xl </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1prtdbd/a_hacker_attack_on_github_repositories_could/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1prtdbd/a_hacker_attack_on_github_repositories_could/\">[comments]</a></span>",
        "id": 4372505,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1prtdbd/a_hacker_attack_on_github_repositories_could",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "A hacker attack on GitHub repositories could affect AI and we wouldn't be able to trust them as code assistants. AS WE SHOULD NEVER HAVE BEEN",
        "vote": 0
    }
]