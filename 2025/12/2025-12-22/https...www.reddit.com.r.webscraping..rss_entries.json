[
    {
        "age": null,
        "album": "",
        "author": "/u/Scoobidoooo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-22T18:29:46.760254+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-22T18:13:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking to extract structured data from about 30 similar webpages.<br/> Each page has a static URL, and I only need to pull about 15 text-based items from each one.</p> <p>I want to automate the process so it runs roughly every hour and stores the results in a database for use in a project.</p> <p>I&#39;ve tried several online tools, but they all felt too complex or way overkill for what I need.</p> <p>I have some IT skills, but I&#39;m not a programmer. I know basic HTML, can tweak PHP or other languages when needed, and I&#39;m comfortable running Docker containers (I host them on a Synology NAS). </p> <p>I also host my own websites.</p> <p>Could you recommend a good, minimalistic tutorial to get started with web scraping?<br/> Something simple and beginner-friendly.</p> <p>I want to start slow.</p> <p>Kind thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Scoobidoooo\"> /u/Scoobidoooo <",
        "id": 4384136,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pt6m91/suggest_me_a_good_tuto_for_starting_in_web",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Suggest me a good tuto for starting in web scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/albert_in_vine",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-22T18:29:47.123476+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-22T18:13:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need information from this ASPX<a href=\"https://register.college-ic.ca/Public-Register-EN/Licensee/Profile.aspx?ID=14656\"> website</a>, specifically from the Licensee section. I cannot find any requests in the browser&#39;s network tools. Is using a headless browser the only option?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/albert_in_vine\"> /u/albert_in_vine </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pt6lkt/help_scraping_aspx_website/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pt6lkt/help_scraping_aspx_website/\">[comments]</a></span>",
        "id": 4384137,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pt6lkt/help_scraping_aspx_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help scraping aspx website",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ok_Wrangler_3835",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-22T18:29:47.446570+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-22T14:29:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Does anyone know of a way to scrape the emails of the hosts of booking? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok_Wrangler_3835\"> /u/Ok_Wrangler_3835 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pt0xqn/scraping_bookingcom_for_host_emails/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pt0xqn/scraping_bookingcom_for_host_emails/\">[comments]</a></span>",
        "id": 4384138,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pt0xqn/scraping_bookingcom_for_host_emails",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping booking.com for host emails?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Known-Shame-3097",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-22T09:49:13.286624+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-22T09:18:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I built a small tool that scrapes Medium articles into clean text</p> <p>Hi everyone,</p> <p>I recently built a simple web tool that lets you extract the full content of any Medium article in a clean, readable format.</p> <p>Link: <a href=\"https://mediumscraper.lovable.app/?utm_source=chatgpt.com\">https://mediumscraper.lovable.app/</a></p> <p>The idea came from constantly needing to save Medium articles for notes, research, or offline reading. Medium does not make this very easy unless you manually copy sections or deal with cluttered formatting.</p> <p>What the tool does<br/> You paste a Medium article URL and it fetches the main article content without the extra noise. No signup, no paywall tricks, just a quick way to get the text for personal use or analysis.</p> <p>Who it might be useful for<br/> Developers doing NLP or text analysis<br/> Students and researchers collecting sources<br/> People who prefer saving articles as markdown or plain text<b",
        "id": 4380314,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1psv8si/i_built_a_small_tool_that_scrapes_medium_articles",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I built a small tool that scrapes Medium articles into clean text",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/StefanCreed66",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-22T08:48:19.245139+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-22T07:52:01+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1pstx7g/nexus_flow_a_local_private_http_control_panel/\"> <img src=\"https://b.thumbs.redditmedia.com/dA5KZiLJeRpehBrt6fowHdHBaNVNv96MWuXCsbG30cg.jpg\" alt=\"Nexus Flow \u2013 A local, private HTTP control panel\" title=\"Nexus Flow \u2013 A local, private HTTP control panel\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I wanted to share a side project I\u2019ve been hacking on called <strong>Nexus Flow</strong>.</p> <p>Basically, I do a lot of HTTP testing and automation, and I got annoyed constantly rewriting the same Python code just to handle proxy rotation, user-agents, and complex request sequences. I wanted something visual like Postman, but specifically designed for high-volume automation and privacy.</p> <p><strong>What it actually does:</strong></p> <ul> <li><strong>Local &amp; Private:</strong> It runs entirely on your machine via a Python script. No data leaves your network.</li> <li><strong>Sma",
        "id": 4380038,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pstx7g/nexus_flow_a_local_private_http_control_panel",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/dA5KZiLJeRpehBrt6fowHdHBaNVNv96MWuXCsbG30cg.jpg",
        "title": "Nexus Flow \u2013 A local, private HTTP control panel",
        "vote": 0
    }
]