[
    {
        "age": null,
        "album": "",
        "author": "/u/x3Nemorous",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-09T20:43:39.812003+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-09T20:21:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Last NCL season exposed a huge bottleneck in our team&#39;s workflow during the password-cracking challenges. Every themed challenge meant manually scraping Wikipedia or Fandom wikis, then spending 20-30 minutes manually copying and formatting hundreds of potential passwords.</p> <p>I built wordreaper to automate this process, a tool that scrapes any site with CSS selectors and auto-cleans the data. It can also apply case conversions, permutations, and Hashcat-style transformations.</p> <p>Real impact: We cracked Harry Potter-themed passwords using wordlists scraped from Fandom in under 10 seconds total. Helped us finish top 10 out of ~500 teams.</p> <p>Full tutorial: <a href=\"https://medium.com/@smohrwz/ncl-password-challenges-how-to-scrape-themed-wordlists-with-wordreaper-81f81c008801\">https://medium.com/@smohrwz/ncl-password-challenges-how-to-scrape-themed-wordlists-with-wordreaper-81f81c008801</a></p> <p>Tool is open source: <a href=\"https://githu",
        "id": 4278657,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pii3wy/i_built_a_web_scraper_for_targeted_password",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I built a web scraper for targeted password cracking w/ CSS selectors",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ghughes20",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-09T19:39:12.108158+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-09T18:45:12+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1pifhdf/noob_question_regarding_web_scraping/\"> <img src=\"https://b.thumbs.redditmedia.com/qYr7Uy3u7Ppjp11BcDWgl0VNbAarbzVeRRnL9Ky9w5w.jpg\" alt=\"Noob Question Regarding Web Scraping\" title=\"Noob Question Regarding Web Scraping\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to write code (Python) that will pull data from a ski mountain&#39;s trail report each day. Essentially, I want to track which ski trails are opened and the last time they were groomed. The problem I&#39;m having is that I don&#39;t see the data I need in the &quot;html&quot; of the webpage, but I do see data when I &quot;Inspect Element&quot;. (Full disclosure, I&#39;m doing this from a Mac with Safari).</p> <p>I suspect the pages I&#39;m trying to scrape from are too complex for BeautifulSoup or Selenium.</p> <p>Below is the link </p> <p><a href=\"https://www.stratton.com/the-mountain/mountain-report\">https://www.stratton.c",
        "id": 4277979,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pifhdf/noob_question_regarding_web_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/qYr7Uy3u7Ppjp11BcDWgl0VNbAarbzVeRRnL9Ky9w5w.jpg",
        "title": "Noob Question Regarding Web Scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AracnoidBlue",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-09T18:02:36.276557+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-09T17:13:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Budget: <strong>$2000\u2013$2500</strong> (one-time gig) <strong>/ 15% equity for cofounder-level role</strong></p> <p>We\u2019re a fast-growing, bootstrapped SaaS company with <strong>$10K MRR</strong>, <strong>90% margins</strong>, and a <strong>4-member team</strong>. Our browser extension product serves single-license customers today, and we\u2019re now preparing to scale into enterprise \u2014 a <strong>potential 100\u00d7 MRR leap</strong>.</p> <p>Our only blocker: <strong>Outreach Integration</strong>.<br/> We\u2019re looking for an expert who can help us map and integrate internal API endpoints and handle <strong>JWT auth/refresh token flow</strong> inside the extension.</p> <p><strong>Ideal candidate:</strong></p> <ul> <li>Strong experience in API reverse engineering / web protocol analysis</li> <li>Fluent with DevTools/MITM proxies (Burp/Charles/Fiddler)</li> <li>Deep understanding of JWT auth &amp; refresh workflows</li> </ul> <p>If you\u2019ve reverse engineered private Saa",
        "id": 4277290,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pid3t8/hiring_reverse_engineer_for_internal_outreach_api",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hiring Reverse Engineer for Internal Outreach API (JWT Auth)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AdVivid5763",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-09T16:55:09.806917+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-09T15:58:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Im trying to build a Reddit scraping tool that analyses patterns in devs to spot opportunities/ problems they encounter, also trying to build it for idea/problem validation.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AdVivid5763\"> /u/AdVivid5763 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pib3d7/are_there_alternatives_to_the_reddit_api/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pib3d7/are_there_alternatives_to_the_reddit_api/\">[comments]</a></span>",
        "id": 4276619,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pib3d7/are_there_alternatives_to_the_reddit_api",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are there alternatives to the Reddit API ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/gigsdottech",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-09T20:43:40.133398+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-09T14:41:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I\u2019m the founder of a niche job board focused exclusively within a booming Microsoft niche market.</p> <p>I am looking for a technical co-founder (or long-term partner) who specializes in web scraping and data engineering to take over the backend architecture.</p> <p><strong>The Context (The Business Side):</strong> </p> <p>I am a non-technical founder covering the business operations. I have already validated the market and handling the distribution:</p> <ul> <li>I have a network of 3,000+ professionals in this specific tech niche.</li> <li>I\u2019m actively running the SEO, content marketing, and outreach strategies.</li> <li>Traffic is growing, but the product quality depends entirely on our ability to aggregate/parse accurate data.</li> </ul> <p><strong>The Challenge (The Engineering Side):</strong> </p> <p>I have outsourced the MVP build and have validated the need. To scale, we need a custom infrastructure that can:</p> <ol> <li>Ha",
        "id": 4278658,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pi94je/looking_for_cofounderpartner_scaling_a_niche_job",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for Co-Founder/Partner Scaling a Niche Job Aggregator",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Amr_on_reddit",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-09T14:50:22.784751+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-09T14:12:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want something that can get 9000 company names monthly and produce a sheet with the company names sites emails and phones the emails need to be real and the phones in international format . Convenient features like queueing up tasks and notifications and integrations with google sheets or brevo crm are also nice . It needs to cost around 50 usd per month or better as that is the current cost of manual scraping</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Amr_on_reddit\"> /u/Amr_on_reddit </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pi8fjr/scraper_suggestions/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pi8fjr/scraper_suggestions/\">[comments]</a></span>",
        "id": 4275394,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pi8fjr/scraper_suggestions",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraper suggestions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-09T13:46:44.441216+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-09T13:01:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels\u2014whether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>If you&#39;re new to web scraping, make sure to check out the <a href=\"https://webscraping.fyi\">Beginners Guide</a> \ud83c\udf31</p> <p>Commercial products may be mentioned in replies. If you want to promote your own products and services, continue to use the <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">monthly thread</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 4274810,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pi6t5e/weekly_webscrapers_hiring_faqs_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weekly Webscrapers - Hiring, FAQs, etc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Substantial_Sock5427",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-09T03:32:07.774234+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-09T02:53:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been toying around with using a proxy to monitor requests that are being sent to API\u2019s on certain mobile apps, and upon locating the proper endpoint that responds with the data I am looking for, I tried to replicate this request on Postman and browser, but received a 403 error with a captcha. </p> <p>What exactly is not present in the request that the server is looking for, and is there a way to find this using a tool like Charles \u2014 or how does one work around a problem like this?</p> <p>I have found the endpoint which has the data I need. I just can\u2019t access it outside of using Charles. </p> <p>Thank you in advance for any help or suggestions. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Substantial_Sock5427\"> /u/Substantial_Sock5427 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1phwg65/curl_mobile_requests_getting_hit_with_a_403/\">[link]</a></span> &#32; <span><a href=\"https:/",
        "id": 4271562,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1phwg65/curl_mobile_requests_getting_hit_with_a_403",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "cURL mobile requests getting hit with a 403 captcha in the browser",
        "vote": 0
    }
]