[
    {
        "age": null,
        "album": "",
        "author": "/u/Kind-Shake-9511",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T23:36:45.306772+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T23:18:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Bought 3 8tb WD red drives on Facebook for 100 dollars each. The guy said they were only used for 3 months. I check them and they had between 8000 and 10000 hours of power on time. </p> <p>I&#39;m just wondering if I overpaid and what i could do better next time. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kind-Shake-9511\"> /u/Kind-Shake-9511 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pg30r4/did_i_overpay_for_used_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pg30r4/did_i_overpay_for_used_drives/\">[comments]</a></span>",
        "id": 4257533,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pg30r4/did_i_overpay_for_used_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Did I overpay for used drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/sem1845",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T22:32:35.323752+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T22:18:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Seeding vs transcoding?</p> <p>How do you handle seeding vs transcoding? </p> <p>I&#39;m currently at 128 TB used of 140 TB. I want to keep seeding but more harddrives isn&#39;t going to happen at this point. I need to start transcoding what&#39;s in Plex and not being seeded. Is there an easy way to compare torrents in to what&#39;s in Plex and figure out what can safely be transcoded with tdarr/unmanic without messing up seeding torrents? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sem1845\"> /u/sem1845 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pg1o61/seeding_vs_transcoding/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pg1o61/seeding_vs_transcoding/\">[comments]</a></span>",
        "id": 4257250,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pg1o61/seeding_vs_transcoding",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seeding vs transcoding?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/meat_loafers",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T22:32:34.983174+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T21:53:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Many years ago I had a scansnap 1500m scanner for my Mac that served me very well for about 10 years. It finally started giving up and I got an ix 1600. Its great for speed and does OK for docs with images, but I miss the CCD image quality of the 1500. </p> <p>Are there any current doc scanners like the above, but with CCD? Im having trouble finding a lot of information on it. TIA</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/meat_loafers\"> /u/meat_loafers </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pg145s/ccd_docment_scanner/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pg145s/ccd_docment_scanner/\">[comments]</a></span>",
        "id": 4257249,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pg145s/ccd_docment_scanner",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "CCD docment scanner",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ZOODUDE100",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T21:31:56.587839+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T21:24:37+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pg0fss/upload_to_internet_archive_error/\"> <img src=\"https://preview.redd.it/0zn47jy9in5g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=58108fa3c0855de486f184d6921c64f5daee34c2\" alt=\"Upload to Internet Archive Error\" title=\"Upload to Internet Archive Error\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I have a group of 52 tracks to upload to the Internet Archive. This is the only one that won&#39;t work. Any thoughts or ideas on why or how to correct the issue?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ZOODUDE100\"> /u/ZOODUDE100 </a> <br/> <span><a href=\"https://i.redd.it/0zn47jy9in5g1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pg0fss/upload_to_internet_archive_error/\">[comments]</a></span> </td></tr></table>",
        "id": 4256957,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pg0fss/upload_to_internet_archive_error",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/0zn47jy9in5g1.png?width=640&crop=smart&auto=webp&s=58108fa3c0855de486f184d6921c64f5daee34c2",
        "title": "Upload to Internet Archive Error",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DarkAce5",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T21:31:57.149123+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T20:28:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am collecting large amounts of data from high throughout microscope systems. Will aquire and save the data on the microscope PC and then move to a portable drive (likely a robust SSD? Or should I go with a WD passport?). The data from the microscope PC is wiped every month or so.</p> <p>Then for extra safety, I&#39;d take the data on my portable drive to a desktop backup drive that&#39;s connected to my laptop on my desk and mirror it there while working on my laptop. Is this the right approach? If so, how would you set it up to work automatically? Or will I have to manually copy and paste the new folders over to the desktop back up? Or is this overkill?</p> <p>Are these large capacity desktop HDDs robust for portable use or the like? Like can I take it to the microscope room and back etc and reliability use it or stick with the WD passport or Samsung T7? Is there a desktop drive you&#39;d recommend? For portable drives I had a Seagate, and the conn",
        "id": 4256958,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfz548/desktop_and_portable_backup_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Desktop and Portable Backup Drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/blinkenjim",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T20:27:40.785656+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T20:11:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi hoarders,</p> <p>Just noticed this deal, lifetime access to Internext&#39;s 100TB cloud storage service:</p> <p><a href=\"https://shop.mashable.com/sales/internxt-cloud-storage-lifetime-subscription-100tb\">https://shop.mashable.com/sales/internxt-cloud-storage-lifetime-subscription-100tb</a></p> <p>I have a chunk of my 2025 tech budget left and am seriously considering spending the grand on this service. Before I do, I&#39;d love to hear some feedback from anyone who&#39;s tried this service from Linux or macOS.</p> <p>The main questions: What did you like or dislike about the service? Did it meet your needs? Did it seem fast and stable?</p> <p>My lab is fully non-Windows: macOS Tahoe and Ubuntu 24.04 LTS, but it&#39;s the Linux side where I have the most concerns.</p> <p>The research I&#39;ve done suggests that the best interface from Linux would be to avoid the Internxt GUI client and instead install the Internxt CLI plus clone. This is supposed t",
        "id": 4256607,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfyr5r/seeking_info_on_internxt_cloud_storage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seeking info on Internxt cloud storage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SrPakura",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T20:27:39.971307+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T20:07:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been tracking my lifts for 3 years on a popular app. I tried to migrate my data yesterday and realized I&#39;m locked in. Their so-called &quot;Export Data&quot; feature is a joke; <strong>it consistently generates a broken CSV.</strong> It&#39;s either corrupted on arrival and fails to open, or so badly formatted that any attempt to parse it just throws an error.</p> <p>Basically, if I stop paying or if they shut down, my entire history evaporates. I\u2019m tired of renting my own biometrics. Has anyone found a solid Local-First or Open Source tracker that actually lets you own your data (clean CSV/JSON export)? I refuse to use cloud-only trackers anymore.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SrPakura\"> /u/SrPakura </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfynw5/fitness_apps_are_becoming_data_prisons_why_is/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com",
        "id": 4256606,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfynw5/fitness_apps_are_becoming_data_prisons_why_is",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Fitness Apps are becoming \"Data Prisons\". Why is exporting to JSON/CSV not the standard?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Hello-There-Im-Zach",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T19:21:30.789496+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T18:42:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello all, longtime lurker and recently been archiving some media I find interesting and historically important. I am currently scouring the web for a complete collection location of American Experience from PBS, there are 38 seasons but it&#39;s proving hard to find the collection in its entirety, although I have had some luck and found a sporatic 130 or so episodes on an old PC drive. Those episodes are from the late 80s to early mid 2000s so that&#39;s a nice win. If anyone is interested in the ones I have let me know and If any kind friend has info or advice or even suggestions of good documentarys to archive that would be cool too!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hello-There-Im-Zach\"> /u/Hello-There-Im-Zach </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfwlej/american_experience_pbs_1988/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/c",
        "id": 4256280,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfwlej/american_experience_pbs_1988",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "American experience (PBS 1988)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/tdizzlcz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T19:21:31.091465+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T18:30:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I\u2019m looking for some help with an issue that suddenly appeared in my LTO setup.</p> <p>I\u2019m using a SymplyPRO LTO Desktop LTO-8 drive, connected via the original Thunderbolt cable to a MacBook Pro M4 Max running macOS Tahoe 26.1. For backups I\u2019m using Hedge Canister. This setup has been working flawlessly for quite a while, and I haven\u2019t intentionally changed anything in my workflow, cabling, or software configuration.</p> <p>In the last few days, though, backups and restores have started to fail. Jobs will run for a while and then basically stall, as if there\u2019s some kind of timeout on the connection. The process hangs for a long time and then just stops without completing. When this happens, the tape is stuck in the drive and can\u2019t be ejected via software \u2013 the only way to get it out is to power-cycle the LTO drive.</p> <p>To rule out media issues, I\u2019ve tried four different LTO-8 tapes and the behaviour is the same with all of the",
        "id": 4256281,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfwbb3/symplypro_lto8_issues_on_macos_tahoe",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SymplyPRO LTO-8 Issues on macOS Tahoe (Timeouts/Stuck Tapes)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EvilCowEater",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T17:09:29.534086+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T17:07:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is ther any speed minimum or spec I should be paying attention to when looking for a 16+ tb HD for my Plex server? </p> <p>I have a 16tb iron wolf pro 7200 that I paid $180 for.. I see I got a good deal. I need another now. Looking for something 20-24tb. I typically have 3-5 people using Plex at the same time</p> <p>Thank you</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EvilCowEater\"> /u/EvilCowEater </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfu9mc/speed_data_access_question_plex_server/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfu9mc/speed_data_access_question_plex_server/\">[comments]</a></span>",
        "id": 4255478,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfu9mc/speed_data_access_question_plex_server",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Speed / data access question Plex server",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheRealSectimus",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T17:09:28.914964+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T16:47:44+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfts68/just_hit_a_decade_of_power_on_time_on_my_oldest/\"> <img src=\"https://preview.redd.it/b0tqn1zw4m5g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=54eb86d48e273ad52a9b0b554170cc465c79bf25\" alt=\"Just hit a decade of power on time on my oldest drive on my dev box. Got me wondering, what's your longest currently running drive?\" title=\"Just hit a decade of power on time on my oldest drive on my dev box. Got me wondering, what's your longest currently running drive?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>She&#39;s gotta be drawing a pension by now.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheRealSectimus\"> /u/TheRealSectimus </a> <br/> <span><a href=\"https://i.redd.it/b0tqn1zw4m5g1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfts68/just_hit_a_decade_of_power_on_time_on_my_oldest/\">[comments]</a></span> </",
        "id": 4255477,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfts68/just_hit_a_decade_of_power_on_time_on_my_oldest",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/b0tqn1zw4m5g1.png?width=640&crop=smart&auto=webp&s=54eb86d48e273ad52a9b0b554170cc465c79bf25",
        "title": "Just hit a decade of power on time on my oldest drive on my dev box. Got me wondering, what's your longest currently running drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Extension_Use664",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T17:09:30.565100+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T16:13:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a Wd external 4 tb hard drive full of movies and series that I just got 3 weeks ago. I copied a lot over from another drive and have downloaded a lot which is why it may be at 45 already. Is this going to effect my videos? Will they become currupt because of fragmentation? I collect Kyodai Hero films and series (Ultraman and other giant Japanese superheros) and am hoping nothing is effected. Im trying to make three copies of this 4 tb drive eventually. So should I fragment before moving? Are my videos okay?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Extension_Use664\"> /u/Extension_Use664 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfsykl/external_hard_drive_45_fragmented/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfsykl/external_hard_drive_45_fragmented/\">[comments]</a></span>",
        "id": 4255483,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfsykl/external_hard_drive_45_fragmented",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "External hard drive 45% fragmented.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Kitty_Meow_Meow_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T16:03:34.267379+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T15:56:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I downloaded all of my Twitter bookmarks recently, and the final total was around 11,000 files (years of bookmarking every post I even mildly like will do that ig lol) and it&#39;s all mostly art. I want to sort all of these by different series/character, but doing it by hand is gonna take for ever. So I wanted to know if there was any kinda (AI?) tool that could scan through and categorize the ones that it has a high level of confidence in.<br/> If anyone knows anything like this that might exist, I would really appreciate the info. Thanks yall!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kitty_Meow_Meow_\"> /u/Kitty_Meow_Meow_ </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfskh9/looking_for_a_sorting_tool_that_most_likely/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfskh9/looking_for_a_sorting_tool_that_most_likely/\">[comments]</a></sp",
        "id": 4255142,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfskh9/looking_for_a_sorting_tool_that_most_likely",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a sorting tool that most likely doesn't exist but i gotta ask anyways cuz i got to many files",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/roerius",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T16:03:33.886375+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T15:32:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I just had to geek out over this for a sec. DNA Storage that allows for PB level storage in a cassette size storage unit. Obviously its not available for consumer use yet but its exciting to think of the possibilities! :D</p> <p><a href=\"https://www.tomshardware.com/pc-components/storage/worlds-first-scalable-dna-data-storage-offering-announced-offering-a-staggering-60pb-in-60-cubic-inches-enough-to-hold-660-000-4k-movies-atlas-data-storage-claims-its-solution-is-1000x-denser-than-lto-10-tape\">https://www.tomshardware.com/pc-components/storage/worlds-first-scalable-dna-data-storage-offering-announced-offering-a-staggering-60pb-in-60-cubic-inches-enough-to-hold-660-000-4k-movies-atlas-data-storage-claims-its-solution-is-1000x-denser-than-lto-10-tape</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/roerius\"> /u/roerius </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfs0my/now_we_can_bac",
        "id": 4255141,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfs0my/now_we_can_backup_the_entire_internet_at_home",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Now we can backup the entire internet at home!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/megafrost_app",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T17:09:29.803582+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T14:57:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Would it make sense to use Google Archive to backup images and videos? Google Drive charges $20/year for 100GB but the same space in Google Archive is only $1.44/year.</p> <p>Restoring is expensive but given that the gallery of the average user fits in the storage of a modern phone, this is only needed in case of disaster.</p> <p>What are your thoughts?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/megafrost_app\"> /u/megafrost_app </a> <br/> <span><a href=\"https://megafrost.cloud\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfr7y9/google_archive_wrapper/\">[comments]</a></span>",
        "id": 4255479,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfr7y9/google_archive_wrapper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Google Archive wrapper",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/UpstairsTap9206",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T17:09:30.044946+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T14:12:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to download and backup some networking videos from spike but youtube-dl doesn&#39;t seem to work on this site. Is there anyway to download from it?</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/UpstairsTap9206\"> /u/UpstairsTap9206 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfq90l/how_to_download_spike_videos/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfq90l/how_to_download_spike_videos/\">[comments]</a></span>",
        "id": 4255480,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfq90l/how_to_download_spike_videos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to download spike videos?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TehMaat",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T13:55:13.286491+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T13:43:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, hi everyone I\u2019m here asking for an advice. I have an UGreen Nas (4 bay ) with 2x4Tb on Raid0 ( i had limited budget) and it\u2019s almost full. Right now I\u2019m looking at 4x16Tb (Refurbished Exos Seagate HDD). What would it be the best way to migrate data ? Can I add one of the 16Tb to the nas and copy the data, then create a 3x Raid5 with the others new HDDs, copy again the data and then adding the last one?</p> <p>This is my only idea, if someone has a better one or can point to me errors/misjudgement it\u2019ll be appreciated. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TehMaat\"> /u/TehMaat </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfpmkr/best_way_to_migrate_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfpmkr/best_way_to_migrate_data/\">[comments]</a></span>",
        "id": 4254371,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfpmkr/best_way_to_migrate_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best way to migrate data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Impressive_Mirror837",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T17:09:30.239009+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T13:39:45+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfpjrx/chat_am_i_cooked/\"> <img src=\"https://preview.redd.it/3zvwhmxk7l5g1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5fc93081dc583a664d0d6e14e1e1656f495fc4f8\" alt=\"Chat am I cooked?\" title=\"Chat am I cooked?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Please save me storage experts. So as a millennial (98\u2019 baby) I grew up on Snapchat in high school, college all the way up to post grad life. Being a broke kid meant i could usually only afford the base storage on my phones so I used Snapchat pretty often to store memories and pictures to save storage of course. Now, I have a ton of memories that I\u2019ve never exported all of and I\u2019ve definitely exceeded the limit here. Is my best option to pay them to keep using their storage or is there a way for me to extract it all? </p> <p>My other sort of dilemma with this is that I recently bought a 16 Pro. I\u2019m the kind of person that keeps their phone for as ma",
        "id": 4255481,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfpjrx/chat_am_i_cooked",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/3zvwhmxk7l5g1.jpeg?width=640&crop=smart&auto=webp&s=5fc93081dc583a664d0d6e14e1e1656f495fc4f8",
        "title": "Chat am I cooked?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mooch91",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T13:55:13.704356+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T13:33:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>Trying to understand what type of behavior the subject issue (resulting in the need for the 3.3v pin mod) causes.</p> <p>Does it always prevent a drive from working entirely, or can it cause intermittent issues with the drive?</p> <p>Reason I ask: I purchased two <strong>Seagate EXOS X16 ST14000NM005G 14TB</strong> drives which came with connectors to address the issue that I never installed in my HP Elitedesk 800 G5 TrueNAS server. Everything worked great for a few months, then one of the drives started to get a little flaky.</p> <p>Could be a bad drive, could be a SATA cable, etc., but I&#39;d like to rule out the power disable feature as well (since I don&#39;t completely understand the problem it causes).</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mooch91\"> /u/mooch91 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfpf5t/satasas_power_disable_featur",
        "id": 4254372,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfpf5t/satasas_power_disable_feature33v_pin",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SATA/SAS Power Disable Feature/3.3v pin",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fit-Foundation746",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T12:48:12.956717+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T11:47:20+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfngbm/data_data_data/\"> <img src=\"https://preview.redd.it/qo01cvnink5g1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=812f63e4f7019e1fe9822632c1d64ac15028d2f4\" alt=\"Data data data\" title=\"Data data data\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>So... I just upgraded some of my setup and now my file server has 115TiB of space. Its sitting at about 56% full according to truenas and it&#39;s run on a threadripper 3960x with a fancy Broadcom HBA cards to support the SAS drives in a JBOD. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Fit-Foundation746\"> /u/Fit-Foundation746 </a> <br/> <span><a href=\"https://i.redd.it/qo01cvnink5g1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfngbm/data_data_data/\">[comments]</a></span> </td></tr></table>",
        "id": 4254056,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfngbm/data_data_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/qo01cvnink5g1.jpeg?width=640&crop=smart&auto=webp&s=812f63e4f7019e1fe9822632c1d64ac15028d2f4",
        "title": "Data data data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Dron22",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T09:35:12.756016+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T09:11:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a few flash drives I have not used in a year or so. Should I expect data loss from bit rot? I heard it can happen after 6-12 months. Is it the same with Micro SD&#39;s?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Dron22\"> /u/Dron22 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfkzh0/how_long_can_flash_drives_preserve_data_without/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfkzh0/how_long_can_flash_drives_preserve_data_without/\">[comments]</a></span>",
        "id": 4253198,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfkzh0/how_long_can_flash_drives_preserve_data_without",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How long can flash drives preserve data without being used?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/adminmikael",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T17:09:30.390980+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T08:55:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m a cheapskate hoarder and bought some old used enterprise Toshiba MG04ACA400EY drives as an emergency measure to replace a failing Seagate ST4000DM005 and it&#39;s desktop tier brethren i really don&#39;t trust anymore. I ran full SMART tests on them before putting them to use, put together a fresh 12TB array with 2 disk redundancy, pushed all ~6TB of previously backed up data on to the drives and sighed in relief. In under 48 hours i got to test the redundancy in practice after one of the &quot;new&quot; array drives started dishing out reallocated sectors like Oprah.</p> <p>I&#39;m keeping it plugged in and spinning (idling off array) out of curiosity while i wait for the seller to decide if they wanna send me a replacement and i&#39;ve been keeping tabs on the progression of the failure. The amount of reallocated sectors climbed steadily with every automatic self test, until the failure flag threshold was reached and the number of reallocate",
        "id": 4255482,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfkqok/dying_hdd_im_curious_how_to_interpret_the_smart",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dying HDD - i'm curious how to interpret the SMART values?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Lucky-Dust5630",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T17:09:30.729974+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T07:49:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>so basically i download my liked tweets every once in a while using gallery-dl. pretty simple command using \u2014cookies from browser (or whatever idk specifically) and then just x.com/myusername/likes. </p> <p>my issue is that some of the tweets that contain media are loading that media from external sites?? i think?? the weird part is jdownloader2 will download the media from those tweets no issue but gallery-dl can\u2019t even find the tweet. </p> <p>if anyone has a solution it\u2019d be greatly appreciated :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lucky-Dust5630\"> /u/Lucky-Dust5630 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfjqes/very_niche_gallerydl_issue/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfjqes/very_niche_gallerydl_issue/\">[comments]</a></span>",
        "id": 4255484,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfjqes/very_niche_gallerydl_issue",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "very niche gallery-dl issue \ud83d\ude2d",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Daxivarga",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T07:30:59.238886+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T06:06:10+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfi1av/noob_what_makes_these_2tb_from_wd_widely/\"> <img src=\"https://preview.redd.it/vkq0r8j4yi5g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2609b9c5f6394f0e04b2a6bac4ef406d8edbe0e6\" alt=\"(Noob) What makes these 2TB from WD widely different prices?\" title=\"(Noob) What makes these 2TB from WD widely different prices?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I hoard photos and digital art<br/> I Currently use a <a href=\"https://www.amazon.com/dp/B00ODEGWN8?th=1\">WD 4TB</a> for all my stuff - but don&#39;t want to put all eggs in one basket and want to separate and have a 2nd physical backup. </p> <p>I just don&#39;t understand what the difference between all these 3 is? They all look different is it just the shape and physical protection for the drive? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Daxivarga\"> /u/Daxivarga </a> <br/> <span><a href=\"https:/",
        "id": 4252788,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfi1av/noob_what_makes_these_2tb_from_wd_widely",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/vkq0r8j4yi5g1.png?width=640&crop=smart&auto=webp&s=2609b9c5f6394f0e04b2a6bac4ef406d8edbe0e6",
        "title": "(Noob) What makes these 2TB from WD widely different prices?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/bravespacelizards",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T05:24:44.382583+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T05:04:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m not quite a hoarder (yet). But recently, Apple Music has removed access to an album I purchased from them, and I\u2019m considering becoming one.</p> <p>This incident reminded me of iTunes LPs. They were a really fun format that kind of replicated the feeling of flipping through a CD booklet, or watching DVD extras (they had a similar format for movies too). Naturally, Apple discontinued the format back in 2018. I remember having picked up Blueprint III and a Muse album.</p> <p>My question is: does anyone here know how to play the format?</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/bravespacelizards\"> /u/bravespacelizards </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfgy52/question_about_itunes_lps/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfgy52/question_about_itunes_lps/\">[comments]</a></span>",
        "id": 4252401,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfgy52/question_about_itunes_lps",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Question about iTunes LPs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SquidingTin",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-06T02:14:46.350302+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-06T02:05:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I wanna know if anyone here has had issues with short life spans on the drives, ive seen the negative reviews on the amazon listing but i want reviews from you guys on it. (mind you, i want your input because i dont think ive ever made a review on my WD 2621 yet it has worked for nearly 6 years)</p> <p>Id love to know ASAP as my external drive appears to be having issues and i want to not load it as often to extend its life </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SquidingTin\"> /u/SquidingTin </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfdhi0/plan_to_buy_a_870_evo/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pfdhi0/plan_to_buy_a_870_evo/\">[comments]</a></span>",
        "id": 4251849,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pfdhi0/plan_to_buy_a_870_evo",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Plan to buy a 870 EVO",
        "vote": 0
    }
]