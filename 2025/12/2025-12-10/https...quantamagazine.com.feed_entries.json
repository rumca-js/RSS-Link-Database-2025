[
    {
        "age": null,
        "album": "",
        "author": "Peter Hall",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-10T15:42:13.898116+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-10T15:31:15+00:00",
        "description": "Large language models such as ChatGPT come with filters to keep certain info from getting out. A new mathematical argument shows that systems like this can never be completely safe.             <p>The post <a href=\"https://www.quantamagazine.org/cryptographers-show-that-ai-protections-will-always-have-holes-20251210/\" target=\"_blank\">Cryptographers Show That AI Protections Will Always Have Holes</a> first appeared on <a href=\"https://www.quantamagazine.org\" target=\"_blank\">Quanta Magazine</a></p>",
        "id": 4285526,
        "language": "en-US",
        "link": "https://www.quantamagazine.org/cryptographers-show-that-ai-protections-will-always-have-holes-20251210",
        "manual_status_code": 0,
        "page_rating": 29,
        "page_rating_contents": 91,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 490,
        "source_url": "https://quantamagazine.com/feed",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://www.quantamagazine.org/wp-content/uploads/2025/12/GPTJailbreak-crWei-AnJin-Default.webp",
        "title": "Cryptographers Show That AI Protections Will Always Have Holes",
        "vote": 0
    }
]