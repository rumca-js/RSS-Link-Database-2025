[
    {
        "age": null,
        "album": "",
        "author": "/u/mpmare00",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-13T22:17:15.655470+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-13T21:58:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Trying to figure out how to scrape all owner names from rental listings, then scrape the primary address, find emails and phone numbers. Why is this so hard?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mpmare00\"> /u/mpmare00 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1plx7lt/mls_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1plx7lt/mls_scraping/\">[comments]</a></span>",
        "id": 4313960,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1plx7lt/mls_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "MLS Scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mehmetflix_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-13T22:17:15.847236+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-13T21:48:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>this could be a bad question and in my defence im a newbie, i dont see anyone using js scripts for web automation, is it bad practice or anything?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mehmetflix_\"> /u/mehmetflix_ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1plwz8b/why_does_nobody_use_js_scripts_for_automation/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1plwz8b/why_does_nobody_use_js_scripts_for_automation/\">[comments]</a></span>",
        "id": 4313961,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1plwz8b/why_does_nobody_use_js_scripts_for_automation",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "why does nobody use js scripts for automation?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LocalDraft8",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-13T17:46:46.705181+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-13T16:56:54+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1plq45v/i_built_a_universal_reddit_scraper_with_dashboard/\"> <img src=\"https://b.thumbs.redditmedia.com/GHoZJJx0PdsZRBO2YRtOaiPYG75u9u6_Dnz95ATkYRQ.jpg\" alt=\"I built a Universal Reddit Scraper with Dashboard &amp; Scheduling\" title=\"I built a Universal Reddit Scraper with Dashboard &amp; Scheduling\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I just open-sourced my <strong>Universal Reddit Scraper Suite</strong> - a full-featured tool that scrapes posts, comments, images, videos, and galleries from any subreddit or user profile.</p> <p><a href=\"https://preview.redd.it/suc2yp64507g1.png?width=2558&amp;format=png&amp;auto=webp&amp;s=0b99bc82d208e8d8024ecec536a278cbe9de1e1c\">https://preview.redd.it/suc2yp64507g1.png?width=2558&amp;format=png&amp;auto=webp&amp;s=0b99bc82d208e8d8024ecec536a278cbe9de1e1c</a></p> <p><a href=\"https://github.com/ksanjeev284/reddit-universal-scraper\">https://github.com/ksanjeev284/r",
        "id": 4312525,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1plq45v/i_built_a_universal_reddit_scraper_with_dashboard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/GHoZJJx0PdsZRBO2YRtOaiPYG75u9u6_Dnz95ATkYRQ.jpg",
        "title": "I built a Universal Reddit Scraper with Dashboard & Scheduling",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/No-Helicopter-2317",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-13T15:24:22.910482+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-13T14:33:10+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1plmqst/found_a_recently_popular_tool_related_to/\"> <img src=\"https://b.thumbs.redditmedia.com/jrDKaZXgu3tnh8qvo47q3LAQvdMSNJ8FK-G46K62YPI.jpg\" alt=\"Found a recently popular tool related to web-scraping, too many open good first issues anyone who wants to get into OSS development, it can be a good start\" title=\"Found a recently popular tool related to web-scraping, too many open good first issues anyone who wants to get into OSS development, it can be a good start\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Github: <a href=\"https://github.com/kaifcodec/user-scanner.git\">https://github.com/kaifcodec/user-scanner.git</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No-Helicopter-2317\"> /u/No-Helicopter-2317 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1plmqst\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1plmqst/fo",
        "id": 4311698,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1plmqst/found_a_recently_popular_tool_related_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/jrDKaZXgu3tnh8qvo47q3LAQvdMSNJ8FK-G46K62YPI.jpg",
        "title": "Found a recently popular tool related to web-scraping, too many open good first issues anyone who wants to get into OSS development, it can be a good start",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lesner-21",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-13T09:46:13.152527+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-13T09:24:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>For production use, should we use the stable version of Squid Proxy available in the distro, or is it better to compile the latest version from source?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lesner-21\"> /u/lesner-21 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1plhdsu/squid_proxy_use_distros_stable_version_or_compile/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1plhdsu/squid_proxy_use_distros_stable_version_or_compile/\">[comments]</a></span>",
        "id": 4310065,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1plhdsu/squid_proxy_use_distros_stable_version_or_compile",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Squid Proxy - Use Distro's Stable Version or Compile Latest Source?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Puzzleheaded_Risk323",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-13T09:46:13.327386+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-13T06:59:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>GET /internal/courses/lang-rewrite-evaluation?pageLoadId=a2f05f2c-d396-450c-86e6-518c26c3f674 HTTP/2</p> <p>Host: <a href=\"http://www.remotasks.com\">www.remotasks.com</a></p> <p>Cookie: _gcl_au=1.1.1287395246.1757962357; _fbp=fb.1.1757966441235.299435599694897544; OptanonAlertBoxClosed=2025-09-16T18:04:53.467Z; next-i18next=en; _cfuvid=B04SeOoNj_OjgxOQU.OuSHqvKbCt9db1B5L4AHVrBwU-1765524507099-0.0.1.1-604800000; canary=off; _gid=GA1.2.1360970995.1765524528; analytics_session_id=1765524534022; _clck=1mjpwvm%5E2%5Eg1s%5E0%5E2084; _jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiI1ODRiNTc3NS0yMTdlLTRjNTMtYjQxYy1hNDdjNTdmOTExZDkiLCJ1c2VySWQiOiI2OTJkZTQ2ZDFhYTJjNmYyZWY1MDA0YmYiLCJzdGFydGVkQXQiOjE3NjU1MjQ1NjUyMTAsIm1heFJlZnJlc2giOjE3NzA3MDg1NjUyMTAsImlhdCI6MTc2NTUyNDU2NSwiZXhwIjoxNzY1NzgzNzY1fQ.AqkhhegIJLVvwTdadFQB8p5Sjdf4o2p1lzn81HPLfkE; _csrf=bWW4m4DoDZ71%2FDwpa%2BewuD0estozRjFpFFRdsW1k13s%3D%3AyDVI4y2dkKVFG5f2GCynyw%3D%3D; cognito={%22identityId%22:%22",
        "id": 4310066,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1plf6hl/403_bypass",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "403 bypass",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Stock-Loquat111",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-13T05:13:21.615894+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-13T01:03:35+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1pl8jti/python_scraper_for_valorant_stats_from_vlrgg/\"> <img src=\"https://external-preview.redd.it/Us2qNZeiYrKH451BVEwbUWPHRiBqcHnuh_sHE7QBEqw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=39bdf7d23d28a485d2322555bbab0ab5b1ffe8f6\" alt=\"Python scraper for Valorant stats from VLR.gg \u2014 Career &amp; Tournament stats, plus player images!\" title=\"Python scraper for Valorant stats from VLR.gg \u2014 Career &amp; Tournament stats, plus player images!\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I created a simple Python scraper that pulls <strong>Valorant player stats</strong> from <strong>VLR.gg</strong>. It lets you collect <strong>career stats</strong> for players across all tournaments or <strong>just tournament stats</strong> for specific events. Unlike most scrapers, it also grabs <strong>player images</strong>. You can scrape <strong>multiple tournaments at once</strong> or focus on just one. Great for data a",
        "id": 4309182,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pl8jti/python_scraper_for_valorant_stats_from_vlrgg",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/Us2qNZeiYrKH451BVEwbUWPHRiBqcHnuh_sHE7QBEqw.png?width=640&crop=smart&auto=webp&s=39bdf7d23d28a485d2322555bbab0ab5b1ffe8f6",
        "title": "Python scraper for Valorant stats from VLR.gg \u2014 Career & Tournament stats, plus player images!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/gptwhisperer",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-13T01:56:24.979655+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-13T00:52:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.youtube.com/watch?v=CiAWu1gHntM\">https://www.youtube.com/watch?v=CiAWu1gHntM</a></p> <p>So I&#39;ve been hunting for a small dog that can easily adjust in my apartment. Checked Petfinder - listings are outdated, broken links, slow loading. Called a few shelters - they tell me to check their websites daily because dogs get adopted fast.</p> <p>Figured this is the perfect way to dogfood what my team&#39;s been building.</p> <p>Used Claude Code to build an app that checks 15+ local animal shelters in parallel 2x every day with Mino API. <br/> None of these websites have APIs btw.</p> <p>Making the difference very clear here - this wasn\u2019t scraping. Each shelter website is completely different with multi-step navigation and the listings constantly change. Normally scrapers would break. Claude and Gemini CUA (even Comet and Atlas) are expensive to check these many websites constantly. Plus they hallucinate.</p> <p>Give it a URL (or mult",
        "id": 4308538,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pl8bfr/built_an_app_that_visits_15_animal_adoption",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Built an app that visits 15+ animal adoption websites in parallel",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sizofrenikyksl",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-13T00:44:25.335361+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-13T00:22:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I\u2019ve been working on a dynamic web scraping project for a while and I finally shaped it into something shareable. I\u2019m not claiming it\u2019s \u201cperfect\u201d or \u201cindustry-level\u201d, but I tried to build it properly from day one \u2014 clean architecture, modular structure, test-first mindset, etc.</p> <p>I built the whole project to be <strong>scalable, configurable and easy to extend</strong>, not just a single script that scrapes one site.</p> <p>A quick overview of what\u2019s inside:</p> <h1>Main features</h1> <ul> <li>Dynamic site detection (HTML analyzer + selector logic)</li> <li>Proxy rotation system + validation + fallback</li> <li>User-agent manager with randomization</li> <li>Anti-bot strategies (wait utils, retries, handling 403/429, etc.)</li> <li>Separate modules for scraping, parsing, enrichment, exporting</li> <li>CSV/JSON export pipeline</li> <li>Config-driven behavior</li> </ul> <h1>Testing</h1> <p>I set up a pretty big test structure be",
        "id": 4308240,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pl7o4r/built_a_modular_web_scraper_looking_for_technical",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Built a modular web scraper \u2014 looking for technical feedback",
        "vote": 0
    }
]