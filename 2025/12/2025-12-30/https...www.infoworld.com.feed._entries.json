[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T15:24:02.439010+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T15:22:44+00:00",
        "description": "<div id=\"remove_no_follow\">\n\t\t<div class=\"grid grid--cols-10@md grid--cols-8@lg article-column\">\n\t\t\t\t\t  <div class=\"col-12 col-10@md col-6@lg col-start-3@lg\">\n\t\t\t\t\t\t<div class=\"article-column__content\">\n<section class=\"wp-block-bigbite-multi-title\"><div class=\"container\"></div></section>\n\n\n\n<p>Nvidia has licensed intellectual property from inferencing chip designer Groq, and hired away some of its senior executives, but stopped short of an outright acquisition.</p>\n\n\n\n<p>\u201cWe\u2019ve taken a non-exclusive license to Groq\u2019s IP and have hired engineering talent from Groq\u2019s team to join us in our mission to provide world-leading accelerated computing technology,\u201d an Nvidia spokesman said Tuesday, via email. But, he said, \u201cWe haven\u2019t acquired Groq.\u201d</p>\n\n\n\n<p>Groq designs and sells chips optimized for AI inferencing. These chips, which Groq calls language processing units (LPUs), are lower-powered, lower-priced devices than the GPUs Nvidia designs and sells, which these days are primarily used ",
        "id": 4436186,
        "language": "en-US",
        "link": "https://www.infoworld.com/article/4112134/nvidia-licenses-groqs-inferencing-chip-tech-and-hires-its-leaders-2.html",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 468,
        "source_url": "https://www.infoworld.com/feed/",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Nvidia licenses Groq\u2019s inferencing chip tech and hires its leaders",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T09:45:49.004800+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T09:00:00+00:00",
        "description": "<div id=\"remove_no_follow\">\n\t\t<div class=\"grid grid--cols-10@md grid--cols-8@lg article-column\">\n\t\t\t\t\t  <div class=\"col-12 col-10@md col-6@lg col-start-3@lg\">\n\t\t\t\t\t\t<div class=\"article-column__content\">\n<section class=\"wp-block-bigbite-multi-title\"><div class=\"container\"></div></section>\n\n\n\n<p>For more than a decade, many considered cloud outages a theoretical risk, something to address on a whiteboard and then quietly deprioritize during cost cuts. In 2025, this risk became real. A major Google Cloud outage in June caused hours-long disruptions to popular consumer and enterprise services, with ripple effects into providers that depend on Google\u2019s infrastructure. Microsoft 365 and Outlook also faced code failures and notable outages, as did collaboration platforms like Slack and Zoom. Even security platforms and enterprise backbones suffered extended downtime.</p>\n\n\n\n<p>None of these incidents, individually, was apocalyptic. Collectively, they changed the tone in the boardroom. Execut",
        "id": 4434122,
        "language": "en-US",
        "link": "https://www.infoworld.com/article/4112014/2026-the-year-we-stop-trusting-any-single-cloud.html",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 468,
        "source_url": "https://www.infoworld.com/feed/",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "2026: The year we stop trusting any single cloud",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T09:45:48.866147+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T09:00:00+00:00",
        "description": "<div id=\"remove_no_follow\">\n\t\t<div class=\"grid grid--cols-10@md grid--cols-8@lg article-column\">\n\t\t\t\t\t  <div class=\"col-12 col-10@md col-6@lg col-start-3@lg\">\n\t\t\t\t\t\t<div class=\"article-column__content\">\n<section class=\"wp-block-bigbite-multi-title\"><div class=\"container\"></div></section>\n\n\n\n<p><a href=\"https://www.infoworld.com/article/2335814/what-is-retrieval-augmented-generation-more-accurate-and-reliable-llms.html\">Retrieval-augmented generation</a> (RAG) has quickly become the enterprise default for grounding <a href=\"https://www.infoworld.com/article/2338115/what-is-generative-ai-artificial-intelligence-that-creates.html\">generative AI</a> in internal knowledge. It promises less hallucination, more accuracy, and a way to unlock value from decades of documents, policies, tickets, and institutional memory. Yet while nearly every enterprise can build a proof of concept, very few can run RAG reliably in production.</p>\n\n\n\n<p>This gap has nothing to do with model quality. It is a sys",
        "id": 4434121,
        "language": "en-US",
        "link": "https://www.infoworld.com/article/4108159/how-to-build-rag-at-scale.html",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 468,
        "source_url": "https://www.infoworld.com/feed/",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b2b-contenthub.com/wp-content/uploads/2025/12/RAG-stack.png?w=1024",
        "title": "How to build RAG at scale",
        "vote": 0
    }
]