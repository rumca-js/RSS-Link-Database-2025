[
    {
        "age": null,
        "album": "",
        "author": "/u/JamesRitchey",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T23:22:59.742137+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T23:00:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Bonus question: What are your biggest hurdles to still using DVD/CD?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JamesRitchey\"> /u/JamesRitchey </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzwjgu/for_those_of_you_still_using_dvdcd_for_backups_or/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzwjgu/for_those_of_you_still_using_dvdcd_for_backups_or/\">[comments]</a></span>",
        "id": 4439404,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzwjgu/for_those_of_you_still_using_dvdcd_for_backups_or",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "For those of you still using DVD/CD for backups (or part of your backups), what the main reasons you haven't switched to BD, or away from optical media?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Kappaccino100",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T23:22:59.161551+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T22:20:21+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzvksm/got_my_first_nas/\"> <img src=\"https://preview.redd.it/5eo4j69c2fag1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cc9a83f10256d58cc08d58e97438e5c0e2ed3e04\" alt=\"Got my first NAS\" title=\"Got my first NAS\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Got my first NAS at the beginning of the month, a little two bay TerraMaster F2-425. Moved all my video files from my desktop SSD to the NAS, filled the SSD up with the rest of my games, and went wild the rest of December filling up the HDDs with every movie and series I could think of. </p> <p>Shout out to Xfinity for giving a free data cap overage every 12 months. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kappaccino100\"> /u/Kappaccino100 </a> <br/> <span><a href=\"https://i.redd.it/5eo4j69c2fag1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzvksm/got_my_first",
        "id": 4439403,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzvksm/got_my_first_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/5eo4j69c2fag1.jpeg?width=640&crop=smart&auto=webp&s=cc9a83f10256d58cc08d58e97438e5c0e2ed3e04",
        "title": "Got my first NAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/aintgotnoclue117",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T23:23:00.030987+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T22:16:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey there. I have an External Seagate drive with warranty still at Best Buy. Because it failed, I&#39;m concerned about the data on the drive. Should I be worried? I couldn&#39;t access it to delete it-- So. Since the price of the drive is more then the fix, I doubt they would attempt any fixes. What should I do? Thanks. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/aintgotnoclue117\"> /u/aintgotnoclue117 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzvheh/hard_drive_physical_failure_on_an_external/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzvheh/hard_drive_physical_failure_on_an_external/\">[comments]</a></span>",
        "id": 4439405,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzvheh/hard_drive_physical_failure_on_an_external",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hard drive physical failure on an external Seagate HDD. Concerned about data with return:",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/gta721",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T22:10:20.488562+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T22:07:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have landed on these encoding settings for anime. My intent is to get essentially identical quality to a 2 Mbps H.265 scene encode at about 1.5 Mbps instead. My priorities are sharpness and detail preservation as well as easy decoding on the CPU of a cheap Android box.</p> <p><code>--rc 0 --crf 30 --preset 6 --tune 0 --mbr 6000 --luminance-qp-bias 10 --sharpness 3 --qp-scale-compress-strength 1 --ac-bias 1 --enable-qm 1 --qm-min 6 --qm-max 15 --chroma-qm-min 4 --chroma-qm-max 15 --keyint 5s --tile-rows 2 --tile-columns 2 --enable-cdef 0 --enable-restoration 0 --enable-tf 0 --scm 0 --color-primaries 1 --transfer-characteristics 1 --matrix-coefficients 1 --enable-variance-boost 1 --variance-boost-strength 1 --variance-octile 4</code></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/gta721\"> /u/gta721 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzv9hu/what_do_you_think_of_these_av1_enco",
        "id": 4439028,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzv9hu/what_do_you_think_of_these_av1_encoding_settings",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What do you think of these AV1 encoding settings?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Exotic-Secretary8019",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T22:10:22.318633+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T21:10:52+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Exotic-Secretary8019\"> /u/Exotic-Secretary8019 </a> <br/> <span><a href=\"https://meawfy.com/?enjoy=aovznu5s6i61\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pztvo8/found_this_amazing_free_file_search_engine/\">[comments]</a></span>",
        "id": 4439029,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pztvo8/found_this_amazing_free_file_search_engine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "\ud83d\udd0d Found this amazing free file search engine! Perfect for finding Mega files instantly.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/shallowTrough",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T21:02:06.852249+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T20:42:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>First, yes, I have done my due diligence--various internet searches with different keyword variations (&quot;CTB recorder stutters&quot; etc) produce no relevant results. And there is no webforum for CTB recorder on which I could ask this on. In fact, my searches led me to this reddit thread as basically the only place on the web in which CTB Recorder is discussed except its own help file (which doesn&#39;t have a troubleshooting section).</p> <p>I&#39;m having an ongoing problem with CTB Recorder. It happens during active use when I specify a new recording, but it occurs unpredictably, i.e. not every time I start recording a new model. I have no idea exactly what triggers it. Here&#39;s what happens: suddenly CTB recorder will start ending my recordings and beginning new ones, over and over again. All these recordings will be very short, about a minute. </p> <p>Example: say I&#39;m recording WoohooTease_2025-12-30_13-00-27_446.ts. Suddenly it will st",
        "id": 4438526,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzt6w0/ctb_recorder_stuttering",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "CTB recorder stuttering",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/umutkrdgg",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T21:02:06.506020+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T20:19:34+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzsm84/got_some_128gb_2242_nvme_for_11each/\"> <img src=\"https://preview.redd.it/7bi8hbimgeag1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7bdac095cb179b9fd5fc9602a9f4e608f6a5c84f\" alt=\"got some 128gb 2242 nvme for 11$/each\" title=\"got some 128gb 2242 nvme for 11$/each\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>tested them all and all of them %100 health and just 4h uptime. i wasn&#39;t planning buy more than 1 but it seemed cheap and i bought 10 of them from pc repair shop(i wanted to buy more but guy said he is going to use them on mini pc he sells). planning to trade/sell(not here) them for bigger storage or can use couple of them for boot/cache disks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/umutkrdgg\"> /u/umutkrdgg </a> <br/> <span><a href=\"https://i.redd.it/7bi8hbimgeag1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoa",
        "id": 4438524,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzsm84/got_some_128gb_2242_nvme_for_11each",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/7bi8hbimgeag1.jpeg?width=640&crop=smart&auto=webp&s=7bdac095cb179b9fd5fc9602a9f4e608f6a5c84f",
        "title": "got some 128gb 2242 nvme for 11$/each",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Pavithran_mimox",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T21:02:07.595219+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T19:53:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am very aware that its a hit or miss thing. some can last many many years while some can die within months. But which company has the best track record in the sense of longevity.</p> <p>Looking at western digital and Seagate as they are the most 2 common companies for regular consumer. If there are other companies that do have better reliability than the 2 common ones, please let me know.</p> <p>Planning to buy a HDD that has 2-5tb just for images and more of cold storage. I don&#39;t mind it dying but i want a warning like weird noise and etc. Rather than loosing all of my shit.</p> <p>Any help is appreciated and yes i will have some backups of the more important stuff.</p> <p>Happy new years everyone, cheers to more data hoarding!</p> <p>edit: i am looking for external 2.5 drives</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Pavithran_mimox\"> /u/Pavithran_mimox </a> <br/> <span><a href=\"https://www.reddit.c",
        "id": 4438528,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzry9g/which_hard_drives_companies_produce_the_most",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "which hard drives companies produce the most reliable hdd?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/maximm3k",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T19:47:01.202401+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T18:53:30+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzqdam/am_i_dumb_lazy_or_both/\"> <img src=\"https://preview.redd.it/2k51k0lf1eag1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=206d32cfd80c6a4e4d7bb55925157f69901be33a\" alt=\"Am I dumb, lazy or both?\" title=\"Am I dumb, lazy or both?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I\u2019ve dabbled with building my own nas, but I always end up buying a new one and adding it as a separate mounted pool to my main nas. This is my third unifi nas. I\u2019ve figured it cost me $100 per drive and it would be more expensive to run my own 24 disk nas. Or am I wrong? </p> <p>It has 8x28tb exos. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/maximm3k\"> /u/maximm3k </a> <br/> <span><a href=\"https://i.redd.it/2k51k0lf1eag1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzqdam/am_i_dumb_lazy_or_both/\">[comments]</a></span> </td></tr></table>",
        "id": 4438042,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzqdam/am_i_dumb_lazy_or_both",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/2k51k0lf1eag1.jpeg?width=640&crop=smart&auto=webp&s=206d32cfd80c6a4e4d7bb55925157f69901be33a",
        "title": "Am I dumb, lazy or both?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SnooStories263",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T21:02:06.988840+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T18:38:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey!</p> <p>I\u2019m a motion designer and 3D generalist working exclusively on a MacBook Pro (1 TB internal). Almost all my work lives on an external SSD, with a full backup on a 4TB HDD.</p> <p>I\u2019m curious how other creatives handle backups, especially with huge assets and heavy projects.</p> <p>My challenges as of right now :</p> <p>My asset library is really heavy\u2026 Backing it up to something like Google Drive would exceed my storage and take forever to sync.</p> <p>My projects can also be very heavy, especially Houdini sims, caches, and large renders.</p> <p>Questions for you :</p> <p>What\u2019s your backup workflow for work files and assets? Do you back everything to the cloud, or only critical files?</p> <p>For very heavy data (caches, sims, renders), do you just rely on local HDD backups and relax the 3-2-1 rule?</p> <p>How do you handle old projects long-term: local only, cloud, or a mix?</p> <p>-</p> <p>Basically trying to find a sane, reliable system",
        "id": 4438527,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzpyz7/best_backup_workflow_for_creatives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best backup workflow for creatives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/boomatog",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T22:10:19.867446+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T17:54:54+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzospd/deciphering_date_of_manufacture_on_newer_seagate/\"> <img src=\"https://a.thumbs.redditmedia.com/We60mtznk8MVjUlA56gMHVTxEGj4XXmBaS_vm0rnE74.jpg\" alt=\"Deciphering Date of Manufacture on newer Seagate drives\" title=\"Deciphering Date of Manufacture on newer Seagate drives\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey folks I know that pre 2016 there was a (relatively) straightforward way of determining the DOM of a drive but these days I cant find any info on google. Any graybeards have some wisdom for me? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/boomatog\"> /u/boomatog </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1pzospd\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzospd/deciphering_date_of_manufacture_on_newer_seagate/\">[comments]</a></span> </td></tr></table>",
        "id": 4439027,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzospd/deciphering_date_of_manufacture_on_newer_seagate",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/We60mtznk8MVjUlA56gMHVTxEGj4XXmBaS_vm0rnE74.jpg",
        "title": "Deciphering Date of Manufacture on newer Seagate drives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cocacole111",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T18:35:53.480814+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T17:26:00+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzo14g/new_24_tb_refurbished_hard_drive_from_amazon/\"> <img src=\"https://preview.redd.it/mmvq2k92kdag1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4153387fec028c8c14ad1298c78dfc0efe6c2135\" alt=\"New 24 TB Refurbished Hard drive from Amazon. Should I return it?\" title=\"New 24 TB Refurbished Hard drive from Amazon. Should I return it?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;m newer and getting more acquainted with stuff. I bought a 24 TB hard drive from Amazon about a week and a half ago to go into my Plex server. I started transferring some movies to it but it started sounding weird. I went to Youtube to hear what bad sounds are like, but my hard drive doesn&#39;t sound like those clicky sounds. Just kinda loud as it&#39;s reading and writing. I&#39;ve had a 4 TB HDD in my main desktop for a few years and it&#39;s never sounded anywhere near as loud. </p> <p>Additionally, the transfer speed",
        "id": 4437615,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzo14g/new_24_tb_refurbished_hard_drive_from_amazon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/mmvq2k92kdag1.jpeg?width=320&crop=smart&auto=webp&s=4153387fec028c8c14ad1298c78dfc0efe6c2135",
        "title": "New 24 TB Refurbished Hard drive from Amazon. Should I return it?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AlpineGuy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T17:25:51.925642+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T17:17:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>I am trying to set up a new server to replace my old one. It is mainly for storage and running some self-hosted docker applications. </p> <p>Current server is a Celeron N3000 mini PC with two external harddrives in a zfs mirror (I know, not so good). The thing is running Debian, everything is set up manually. </p> <p>Why replace it? Growing concern of harddisk errors not knowing if they just appear due to bad usb connection or actual failures. Also, performance.</p> <p>I would like to replace this with a more powerful machine with internal harddrives, again use zfs, replace Debian with Ubuntu Server (no nas-specific OS), and set everything up using ansible (have been preparing for this for a while). </p> <p>Hardware decision; what I found so far:</p> <ul> <li>Option A: The self-built route: Jonsbo N3 case, Ryzen 3 processor, ECC-compatible mainboard and RAM...</li> <li>Option B: Ugreen DXP4800 Plus box, plus RAM, plus SSD for a new OS. (it&",
        "id": 4437034,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pznsrm/deciding_for_a_new_home_server_storage_system",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Deciding for a new home server / storage system - looking for a sanity check",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/_the__Goat_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T17:25:51.507057+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T17:03:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently built a new array of 24TB drives. Once I consolidate everything onto the new array I can sell off the drives from the old arrays. They are 4TB Seagate barracuda drives. I&#39;m sure they have plenty of life left in them.</p> <p>I usually sell stuff on eBay. But maybe they&#39;re is a better place to sell used hard drives?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/_the__Goat_\"> /u/_the__Goat_ </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzng5q/best_place_to_sell_used_hard_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzng5q/best_place_to_sell_used_hard_drives/\">[comments]</a></span>",
        "id": 4437032,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzng5q/best_place_to_sell_used_hard_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best place to sell used hard drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/soupiejr",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T17:25:51.669723+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T16:59:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve got quite a number of DVDs of my kids&#39; tournaments and family videos and would like to archive them into digital format. I&#39;d also like to copy the digital format into a external drive and plug that into a TV&#39;s usb port to play the videos directly.</p> <ol> <li>What do you guys use to digitise the DVDs into digital format while preserving the chapters in the DVDs into the digital format?</li> <li>What codec should I use to digitise the DVDs so that it&#39;s playable on various TV&#39;s?</li> <li>Is there a software that does everything in 1 go?</li> </ol> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/soupiejr\"> /u/soupiejr </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pznc2p/archiving_dvds_of_personal_videos/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pznc2p/archiving_dvds_of_personal_videos/\">[comments]</a></span>",
        "id": 4437033,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pznc2p/archiving_dvds_of_personal_videos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Archiving DVDs of personal videos",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dr_verystrange",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T17:25:52.120684+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T16:53:54+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzn6ct/does_samsung_990_pro_2tb_2025_make_also_have/\"> <img src=\"https://b.thumbs.redditmedia.com/k51ov6ztm35m4UJdUFveG93NrwdC4irk_gf5AvBjvJk.jpg\" alt=\"Does Samsung 990 pro 2tb 2025 make also have issues?\" title=\"Does Samsung 990 pro 2tb 2025 make also have issues?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Just bought one last night and learned about the issue with Samsung 990 pro premature deaths and accelerated wear. </p> <p>I have not opened the box yet, but would love to keep it because I got for a sane price. All other vendors, where I live, are price gouging. Don&#39;t even need scalpers tbh. </p> <p>I was wondering if the folks here know weather Samsung actually did fix the issue in this year&#39;s version, or is it same hardware and I still need to rely on the firmware. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dr_verystrange\"> /u/dr_verystrange </a",
        "id": 4437035,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzn6ct/does_samsung_990_pro_2tb_2025_make_also_have",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/k51ov6ztm35m4UJdUFveG93NrwdC4irk_gf5AvBjvJk.jpg",
        "title": "Does Samsung 990 pro 2tb 2025 make also have issues?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mombaska",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T14:00:48.580991+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T13:25:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I need to store a massive amount of audio samples, we are talking more than 16tb<br/> I know I can get crazy speed from external SSD enclosure and I do have a working drive </p> <p>from owc, the 1M2 USB4 with an 8tb SSD in it, the speed is insane but I need a backup of this drive, with more storage, no redundancy but my only need is to hit this 15 to 20mb/s read and write speed to quickly grap files from it</p> <p>I am not really a tech nerd, so I would love your advice, I want the most cost efficient storage solution to achieve 16 to 20tb storage with those speed</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mombaska\"> /u/mombaska </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzi2jc/whats_the_cheapest_external_storage_to_get_around/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzi2jc/whats_the_cheapest_external_storage_to_get_around/\">",
        "id": 4435541,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzi2jc/whats_the_cheapest_external_storage_to_get_around",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's the cheapest external storage to get around 15mb/s write and read speed from and to my macbook pro m4",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Aigneas",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T14:00:48.932872+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T13:08:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone! I have a little question.</p> <p>From what I understood, you can\u2019t burn DVDs with a 1080p setting (ofc I might be wrong). </p> <p>I would like to burn discs to turn them into blu rays, so I can upload the actual quality of it. Some videos are 1080p, and some 4k as my phone allows this quality now (I\u2019d like to turn family and travel videos into discs for archiving and cool gifts for my family). And also do some menu to select different videos into the same disc. </p> <p>But I am totally lost. Do you have trusted tutorial to follow? Things to do? If it\u2019s free (except the hardware ofc) it\u2019s even better.</p> <p>Thanks \ud83e\udd70 </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Aigneas\"> /u/Aigneas </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzhpdv/burn_my_own_blurays/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzhpdv/burn_my_own_blurays/\">[",
        "id": 4435542,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzhpdv/burn_my_own_blurays",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Burn my own blu-rays",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Professional_Ad_6180",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T08:22:35.209523+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T08:14:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, i have this old samsung r40 laptop sitting around, it has like 1gb of ram and a 200ish gb hdd in ide format, couple of months ago i booted and it took me a whole hour just to get my hands on the files i needed, mind you this was months ago.</p> <p>Im gonna throw it away and throw that old ide into my rig, is it really worth it? I planned on use it as a backup drive, nothing too heavy, might as well just download wikipedia on it \ud83d\ude02. What do you guys think?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Professional_Ad_6180\"> /u/Professional_Ad_6180 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzckwi/ide_hdd_for_backups/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pzckwi/ide_hdd_for_backups/\">[comments]</a></span>",
        "id": 4433751,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzckwi/ide_hdd_for_backups",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "IDE HDD for backups?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Tuesdal",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T18:35:55.242450+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T06:43:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>A bit over 6 months ago I bought a recertified Seagate drive (Exos X20 18TB) from a reputable seller for 280 euros+15.5 shipping.</p> <p>The drive failed within warranty period and after some back and forth the seller offered me a replacement Seagate Ironwolf Pro drive (New but damaged (dented), factory tested) which I accepted.</p> <p>Upon receiving the replacement drive I noticed it was partitioned and looked at SMART data and it&#39;s not new at all (12000 power on hours, 68TB written, 1.36PB read)</p> <p>Seller apologised for the error since the drive was marked as new in their stock and offered me 3 options:</p> <ol> <li>Keep this replacement drive and receive a 50 euro refund</li> <li>Receive a low POH,undamaged, recertified replacement drive (same model Seagate Ironwolf Pro) but I&#39;d have to pay 60 euros extra</li> <li>Receive a full refund on my original purchase</li> </ol> <p>I&#39;m honestly not sure how to feel about this and what to pic",
        "id": 4437616,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pzb10e/recertified_drive_failed_which_warranty_option_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Recertified drive failed - Which warranty option to pick",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/IngwiePhoenix",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T05:05:02.901194+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T04:47:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I am rebuilding my NAS in a 1U case and I already picked and received some parts for it; mainly an ICYDOCK 5.25&quot; cage for SATA drives (4x 2.25&quot;) and I have another 5.25&quot; bay free to use - and in that, I want to put NVMe drives.</p> <p>IcyDock offers one solution that mounts m.2 SSDs and offers OcuLink in the rear, and another version that goes to MiniSAS (or something like it - it&#39;s one of the SFF with numbers plugs; I am relatively new to those). On my board, I have a x16 slot I can bifocate into 4x4 just fine.</p> <p>Now, that IcyDock cage costs easily 500\u20ac (ranges from 450-550 depending if I find it on Amazon.de or eBay.de) but I am a little surprised by the price; sure, adapting PCIe signals requires a lot of engineering, but compared to the 60\u20ac I paid for the SATA cage, this seems... a little excessive.</p> <p>Are there other solutions for this that hopefuly are less expensive?</p> <p>I want to mount 4 PCIe Gen3 or Gen4 SSDs",
        "id": 4433037,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pz8um6/nvmes_in_a_525_enclosure_which_to_pick",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "NVMe's in a 5.25\" enclosure - which to pick?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/1080addict",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T05:05:03.005347+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T04:26:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Does anyone have any idea how to batch convert BDMV files to ISO files from multiple different folder? I can do it one at a time it would be nice to batch it. I have no code writing skills. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/1080addict\"> /u/1080addict </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pz8f4t/batch_convert_bdmv_to_iso_images/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pz8f4t/batch_convert_bdmv_to_iso_images/\">[comments]</a></span>",
        "id": 4433038,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pz8f4t/batch_convert_bdmv_to_iso_images",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Batch convert BDMV to ISO images?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/FaudMauxe",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T05:05:03.166472+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T04:16:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I have an 18TB MyBook (Western Digital) which usually functions just fine. But ever since getting a Mac and having to use a USB-A to USB-C adapter, my drive spins down after a period of inactivity. Could this be the drive not getting sufficient power due to the adapter? When files are actively transferring, it seems fine and stays powered on. But when browsing for files to transfer to it, I\u2019ll notice it spins down after a minute or so like it\u2019s using some sort of power saving feature. So when I drag and drop a file to it, it has to spin back up all over again (takes 10 seconds or so) before the file starts transferring, it\u2019s quite annoying. What I\u2019ve done so far is disabled the Mac from \u201cputting hard disks to sleep when possible\u201d feature. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/FaudMauxe\"> /u/FaudMauxe </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pz87lj/hdd_keeps_cycling_of",
        "id": 4433039,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pz87lj/hdd_keeps_cycling_off_between_file_transfers",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "HDD keeps cycling off between file transfers",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Original_Hearing_342",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T05:05:03.315866+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T04:02:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello all. I have just started using the Stashapp by <a href=\"/u/codingwithoutpants\">u/codingwithoutpants</a> for the last couple of days. </p> <p>Trying to migrate from schema v72 to v75. As soon as I click on &quot;Perform schema migration&quot; I am greeted with this message-</p> <p><strong>Migration failed</strong></p> <p><em>The following error was encountered while migrating the database:</em></p> <blockquote> <p>&gt; error backing up database: vacuum failed: unable to open database: Stash_abc.72.20251230_035054: The system cannot find the file specified.</p> </blockquote> <p>Can anyone help me with the issue??</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Original_Hearing_342\"> /u/Original_Hearing_342 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pz7xbs/help_needed_with_failing_to_migrate_on_stashapp/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/",
        "id": 4433040,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pz7xbs/help_needed_with_failing_to_migrate_on_stashapp",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help needed with failing to migrate on Stashapp",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Juna_superfan",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T03:00:26.261629+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T01:59:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Im looking for the cheapest/simplest way to get my bunch of externals into a nas like thing, if I were to shuck them . Will only be used for Plex or seeding stuff. Any data that could be lost is easily redownloadable and a long period of downtime doesn&#39;t matter.</p> <p>I looked into raid, and I don&#39;t need any performance boosts from Raid 0 and pooling all the disks doesn&#39;t provide any meaningful benefit in my use case for the extra risk.</p> <p>Pretty much , if I can access each drive on its own over the network that&#39;s all I need.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Juna_superfan\"> /u/Juna_superfan </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pz580w/non_raid_nas_for_dummies/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pz580w/non_raid_nas_for_dummies/\">[comments]</a></span>",
        "id": 4432564,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pz580w/non_raid_nas_for_dummies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Non raid nas for dummies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Iginashi",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T04:02:00.074307+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T01:51:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m worry about A/I hiking prices so should I get the large capacity Seagate Expansion now with their current price or wait until the next bigger sale?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Iginashi\"> /u/Iginashi </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pz51hi/seagate_expansion_desktop_hard_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pz51hi/seagate_expansion_desktop_hard_drive/\">[comments]</a></span>",
        "id": 4432816,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pz51hi/seagate_expansion_desktop_hard_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seagate Expansion Desktop Hard Drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/signoutdk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T00:46:39.844131+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T00:32:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Many years ago when a 6.4 Gbyte Maxtor PATA drive was king of the hill in terms of price/gb maxtor had a tool called powermax for testing their (and connor) drives in your own machine. Including a factory recertification test that would basically do a full drive write and read to test all sectors and re-map defective sectors. </p> <p>I&#39;m curious: Do any hard disk manufacturer (or even third party) have tools like this available for the end user to download and run?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/signoutdk\"> /u/signoutdk </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pz39ko/from_history_education_to_a_question_about/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pz39ko/from_history_education_to_a_question_about/\">[comments]</a></span>",
        "id": 4432036,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pz39ko/from_history_education_to_a_question_about",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "From history education to a question about current times",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Dry_Inflation307",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-30T00:46:39.923974+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-30T00:01:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I currently have an array of 6x14TB drives in RAID 10 using mdadm and LVM. I&#39;m going to be moving to a new case that will allow the array to expand to 14 drives. While I&#39;m pretty settled on sticking with 14TB drives, I haven&#39;t quite settled on how I&#39;d like to expand. </p> <p>Here are the options I&#39;m considering:</p> <ol> <li>Grow existing array using mdadm and LVM</li> <li>Create a separate array and add to LVM volume group</li> <li>Migrate to RAID-Z2 on zfs</li> </ol> <p>While I have experience with #1 and think it may give better performance, #3 is tempting due to potentially higher reliability and storage efficiency.</p> <p>Is there a clear-cut path here?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Dry_Inflation307\"> /u/Dry_Inflation307 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1pz2jc2/thoughts_on_expansion/\">[link]</a></span> &#32; <span><a ",
        "id": 4432037,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1pz2jc2/thoughts_on_expansion",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Thoughts on Expansion?",
        "vote": 0
    }
]