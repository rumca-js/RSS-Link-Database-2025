[
    {
        "age": null,
        "album": "",
        "author": "/u/yukkstar",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-12T08:49:07.971475+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-12T06:35:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Set up SearXNG for privacy this past summer, but used it in a way recently I thought would be relevant to bring up here. To get the respective addresses and other information needed for a list of businesses, I sent requests to the (out of the box) API endpoint and then searched the html-parsed response for &lt;article&gt; tags. No captcha, no bot detection, no rate limit beyond your system\u2019s capacity. And it doesn\u2019t only pull from Google search engine, but also Bing, DDG and dozens of others. Hope this helps someone out there when they feel like they \u201cneed\u201d to scrape Google\u2019s search results. This is a different way that worked for me, without the headache.</p> <pre><code>response = requests.get(&#39;http://localhost:8888/search?q=law+offices+NYC&#39;) soup = BeautifulSoup(response.text, &#39;html.parser&#39;) results = soup.find_all(&#39;article&#39;) # Each result is an article tag </code></pre> <p><a href=\"https://docs.searxng.org/admin/installation",
        "id": 4301511,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pkl390/self_hosted_search_engine_nocaptcha_google",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Self Hosted Search Engine: No-Captcha Google Alternative for Scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Different-Network957",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-12-12T03:46:17.234770+00:00",
        "date_dead_since": null,
        "date_published": "2025-12-12T03:30:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Not necessarily.</p> <p>I am starting to hear more and more in meetings to \u201cuse AI\u201d to scrape XYZ site / web frontend. And yes, while some web scrapers can use AI. That does not automatically make every implementation of a web scrapers AI.</p> <p>I know, they\u2019re probably using AI as a short hand for \u201cbot\u201d, since I suppose a proper scraping system is going to be acting sort of like a bot, but it\u2019s NOT AI. Heck half the time I don\u2019t even code any logic into my scrapers. It\u2019s a glorified API client that talks to the hidden API endpoint. That\u2019s not AI. That\u2019s an API client.</p> <p>Rant over.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Different-Network957\"> /u/Different-Network957 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pkhldh/web_scraping_is_not_ai/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1pkhldh/web_scraping_is_not_ai/\">[comments]</a",
        "id": 4300156,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1pkhldh/web_scraping_is_not_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Web scraping is not AI",
        "vote": 0
    }
]