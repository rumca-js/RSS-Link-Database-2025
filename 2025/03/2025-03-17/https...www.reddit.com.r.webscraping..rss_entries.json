[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-17T20:55:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I don&#39;t feel very good about asking this question, but I think web scraping has always been on the borderline between legal and illegal... We&#39;re all in the same boat...</p> <p>Just as you can&#39;t avoid bugs in software development, novice developers who attempt web scraping will \u201cinevitably\u201d encounter detection and blocking of targeted websites.</p> <p>I&#39;m not looking to do professional, large-scale scraping, I just want to scrape a few thousand images from <a href=\"http://pixiv.net\">pixiv.net</a>, but those images are often R-18 and therefore authentication required.</p> <p>Wouldn&#39;t it be risky to use my own real account in such a situation?</p> <p>I also don&#39;t want to burden the target website (in this case pixiv) with traffic, because my purpose is not to develop a mirror site within a search engine that collects data in real time, but rather to develop a program that I will only run once in my life. Full scan and gone.</p> <",
        "id": 2344460,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jdnk13/real_account_or_bot_account_when_login_required",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "real account or bot account when login required?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-17T19:19:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Client thinks that if he bungs me an extra $30 I will be able to write code that can overcome any captcha on any website at any time. No.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kilnarix\"> /u/Kilnarix </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jdl6ax/clients_have_no_idea_what_a_captcha_is_or_how/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jdl6ax/clients_have_no_idea_what_a_captcha_is_or_how/\">[comments]</a></span>",
        "id": 2344081,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jdl6ax/clients_have_no_idea_what_a_captcha_is_or_how",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Client's have no idea what a captcha is or how they work",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-17T19:11:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Could you share a really great Amazon Product Scraper that you have tested and it works properly. Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Calm_Hovercraft_7400\"> /u/Calm_Hovercraft_7400 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jdkyu3/could_you_share_a_really_great_amazon_product/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jdkyu3/could_you_share_a_really_great_amazon_product/\">[comments]</a></span>",
        "id": 2344459,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jdkyu3/could_you_share_a_really_great_amazon_product",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Could you share a really great Amazon Product Scraper.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-17T17:31:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I know there\u2019s no such thing as 100% protection, but how can I make it harder? There are APIs that are difficult to access, and even some scraper services struggle to reach them, How can I make my API harder to scrape and only allow my own website to access it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/One_Dig_2271\"> /u/One_Dig_2271 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jdig1u/how_can_i_protect_my_api_from_being_scraped/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jdig1u/how_can_i_protect_my_api_from_being_scraped/\">[comments]</a></span>",
        "id": 2342988,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jdig1u/how_can_i_protect_my_api_from_being_scraped",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can I protect my API from being scraped?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-17T11:47:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is there an online website, or a desktop app, where I can just bulk drop a few hundred URLs and it will list all the emails listed on those URLs?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sarrcom\"> /u/sarrcom </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jdapy5/website_or_desktop_app_where_i_can_bulk_drop_urls/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jdapy5/website_or_desktop_app_where_i_can_bulk_drop_urls/\">[comments]</a></span>",
        "id": 2340252,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jdapy5/website_or_desktop_app_where_i_can_bulk_drop_urls",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Website or desktop app where I can bulk drop URLs?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-17T08:35:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a client who has a 360 degrees Street View at a subdomain. It was created with Pano2VR player. And the Pictures are hosted at a subdomain.</p> <p>Is somebody able to copy it, so i can use it on my subdomain?</p> <p>The reason is, that my customer is canceling the work with his agency, and they will not continue to provide the 360 street view- so we need it.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sevenoldi\"> /u/sevenoldi </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jd7xvi/need_help_someone_who_can_copy_a_360_street_view/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jd7xvi/need_help_someone_who_can_copy_a_360_street_view/\">[comments]</a></span>",
        "id": 2339088,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jd7xvi/need_help_someone_who_can_copy_a_360_street_view",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help. Someone who can copy a 360 street view from a subdmomain",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-17T03:11:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have been trying to scrape <a href=\"http://realtor.ca\">realtor.ca</a> for almost 3 months and I still made no progress. There has been constant issues and life got in the way. Still there is not scraper and there is no data. </p> <p>Please send me a dm if you have information regarding tackling this task.<br/> Thanks,</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/meph0ria\"> /u/meph0ria </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jd38ot/i_need_help_with_scraping_a_heavily_protected/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jd38ot/i_need_help_with_scraping_a_heavily_protected/\">[comments]</a></span>",
        "id": 2337988,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jd38ot/i_need_help_with_scraping_a_heavily_protected",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I need help with scraping a heavily protected website. Please DM",
        "vote": 0
    }
]