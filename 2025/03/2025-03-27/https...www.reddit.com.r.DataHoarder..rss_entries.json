[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T22:12:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What\u2019s the difference between verbatim m discs and such. I read a lot about verbatim being bad but nothing on the mdisc website linked on Wikipedia. Is it better or the same or what? I just want a disc I can store a bit of data on that\u2019ll last a long time in reasonable conditions hands off. Ideally like 100-200 some years. Cold storage. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/J00433996\"> /u/J00433996 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jlfc8z/m_disc_companies/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jlfc8z/m_disc_companies/\">[comments]</a></span>",
        "id": 2425678,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jlfc8z/m_disc_companies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "M disc companies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T21:26:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Run a VPN server and VPN in? Open the ports and mount directly? Just use a webui like owncloud instead of mounting?</p> <p>Also want to prevent it from constantly trying to reconnect when I am remote, but connect automatically when home</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/drupadoo\"> /u/drupadoo </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jle86i/what_is_the_beat_practice_for_mounting_nas_on/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jle86i/what_is_the_beat_practice_for_mounting_nas_on/\">[comments]</a></span>",
        "id": 2425274,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jle86i/what_is_the_beat_practice_for_mounting_nas_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What is the beat practice for mounting NAS on laptop that is used away from the location frequently?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T20:30:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>To save space I only selected the DTS-HD MA tracks and not the DTS core tracks when ripping my blurays. Now I noticed that probably my firetv stick 4k is incompatible with the HD MA format and it causes severe audio sync issues. Now I want to encode the audio tracks to EAC3 or AC3 and wanted to ask which is better to experience the full surround effect? I\u2018m planning to do that with ffmpeg, encode just the audio and then use mkvtoolnix to migrate it into the original mkv file. If there\u2019s a better/easier option please point it out. P.S I can\u2019t simply re-rip the discs because some where from the library, friends etc.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/quietgui\"> /u/quietgui </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jlcsuk/encode_surround_audio_tracks_for_better/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jlcsuk/encode_surround_a",
        "id": 2425275,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jlcsuk/encode_surround_audio_tracks_for_better",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Encode surround audio tracks for better compatibility",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T19:26:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi folks,</p> <p>I have ~20 TB of data spread across multiple hard drives. The general vibe from here seems to be that it&#39;s time to get a NAS, but there&#39;s one problem... I currently am stuck with a shared xfinitywifi network. I want to be the only person to look at my horde of obscure CD rips, I don&#39;t want anyone else to access files directly nor via some kind of man-in-the-middle. My internet is also 100% wireless (no ethernet) and about 25 Mbps down/1 Mbps ip.</p> <p>What I currently have: * Moderate experience with Docker, Linux, and Windows * A raspberry Pi which can be turned into a server/offline storage system/doorstop * Three preowned 3.5&quot; internal HDDs, one 8 TB and two 1 TB * Two external HDDs, both 8 TB (one is ancient and will likely fail soon) * A half dozen small (~100 GB) 2.5&quot; preowned internal HDDs I got for basically free</p> <p>My PC case is too small to fit more than 2 3.5&quot; drives and even then they are s",
        "id": 2424746,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jlbw1z/looking_for_a_better_storage_solution",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a better storage solution",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T18:38:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have used and worked with computers my entire life, and I have accrued a considerable amount of data during the years. I mean everything from old pictures and videos, media of all sorts, personal music projects, work projects (mostly programming, but sometimes including large datasets), personal banking and administrative information and so on and on.</p> <p>My ADHD has pushed me to try different lines of work, and sometimes I&#39;ve abandoned projects for a long time before resuming them months and even years after. Additionally, I regularly use two different workstations in addition to a laptop and, sometimes, an additional desktop at work.</p> <p>I have over the years been trying to come up with a system to keep track of everything in a way that makes sense and keeps my folder structures from disintegrating into chaos or inescrutable deep hierarchies that makes finding things impossible, with varying degrees of success.</p> <p>I recently built a",
        "id": 2424287,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jlb66d/advice_on_managing_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Advice on managing data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T18:22:14+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Pe45nira3\"> /u/Pe45nira3 </a> <br/> <span><a href=\"/r/homelab/comments/1jlap9x/would_an_old_used_pc_with_intel_core_i34130_2/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jlarxs/would_an_old_used_pc_with_intel_core_i34130_2/\">[comments]</a></span>",
        "id": 2424286,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jlarxs/would_an_old_used_pc_with_intel_core_i34130_2",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Would an old used PC with Intel Core i3-4130 2 core CPU, and 8GB DDR3 1600Mhz RAM be enough to use as a NAS with two 4TB HDD's in Raid 1?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T18:03:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Until recently I was able to backup almost everything on a single external 20TB drive; it&#39;s no longer the case. What would be the best solution for an ever increasing storage size.</p> <ul> <li><p>Buy a 22TB or 24TB external drive</p> <ul> <li>(+) easy</li> <li>(-) short term solution</li> <li>(-) need to buy another drive</li> <li>(-) not growable</li> </ul></li> <li><p>Concatenate 2 or 3 drives in a linear RAID (ex: 14TB + 12TB + 8TB = 34TB)</p> <ul> <li>(+) no need to buy other drives (already have them)</li> <li>(+) linear RAID is supported with mdadm on Linux</li> <li>(-) no redundancy; like RAID 0, if one drive fails, everything is lost</li> <li>(-) not growable</li> <li>(-) need a PC or NAS enclosure, for the backup</li> </ul></li> <li><p>Create a RAID5 with 3 or 4 drives </p> <ul> <li>(+) redundancy</li> <li>(+) growable</li> <li>(-) need to buy at least 2 other drives</li> <li>(-) need a PC or NAS enclosure for the backup</li> </ul></li>",
        "id": 2423646,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jlabjz/solution_for_a_biggish_backup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Solution for a \"biggish\" backup",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T16:44:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was gifted an external hard drive </p> <p>Toshiba Canvio Basics 2TB Portable External Hard Drive USB 3.0, Black - HDTB520XK3AA</p> <p><a href=\"https://a.co/d/1414AYG\">https://a.co/d/1414AYG</a> </p> <p>I put my data on it for gaming and music everything was going fine until one day my iMac decided to automatically update itself and then the hard drive stopped mounting to my computer. It is formatted in MAC OS Journal ( I didnt learn until later that there were better formats for it). Naturally I ejected it from the computer and then when I tried mounting it to another mac computer with older softer it still did not work and I noticed that it wiped itself of my data which sucks. I didnt realize how much I didnt know about hard drives until I really did a youtube deep dive and on top of that realized that Toshiba sucks. I am a sims player and music producer so I wanted to store my gaming files and my VST files on a separate device since the iMac I wo",
        "id": 2422994,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl8e66/is_it_possible_for_my_data_recovery_for_a_toshiba",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is it Possible for my data recovery for a Toshiba External hard drive (HDD)z",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T16:43:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Thanks in advanced </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CaptainFearless8579\"> /u/CaptainFearless8579 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl8dmm/what_partition_type_do_you_recommend_for_a_cased/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl8dmm/what_partition_type_do_you_recommend_for_a_cased/\">[comments]</a></span>",
        "id": 2422995,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl8dmm/what_partition_type_do_you_recommend_for_a_cased",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What partition type do you recommend for a Cased Portable SSD M2? For full offline Wikipedia and files up to 64gb? Compatible with Android/Linux/Windows.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T16:28:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I just recently made my first refurb HDD purchase of an MDD 22TB HDD from GoHardDrive ebay store to put in my 6-bay TerraMaster DAS and was curious what you guys normally do first, second, etc after getting one of these drives regarding stress testing/identifying/conditioning/formatting/whatever-ing.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Leather_Necessary184\"> /u/Leather_Necessary184 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl804o/best_practices_after_buying_refurb_hdd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl804o/best_practices_after_buying_refurb_hdd/\">[comments]</a></span>",
        "id": 2422996,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl804o/best_practices_after_buying_refurb_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best practices after buying refurb HDD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T16:18:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The specs for my Dell OptiPlex 550 SFF desktop, roughtly 10 years old I believe, show a maximum drive size as 2TB. Other more recent PCs seem to show the same limitations. However, I can&#39;t believe that there&#39;s any real limitation of that sort - 2TB is a pretty modest HDD these days. </p> <p>I&#39;m considering adding a Seagate Barracuda 8GB 5,400rpm while the specs say 2TB/7,400RPM.</p> <p>Do PCs like this generally work will with larger or faster disks? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/gulliverian\"> /u/gulliverian </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl7rtt/pc_specs_show_max_drive_at_2tb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl7rtt/pc_specs_show_max_drive_at_2tb/\">[comments]</a></span>",
        "id": 2422997,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl7rtt/pc_specs_show_max_drive_at_2tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "PC Specs show max drive at 2TB",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T15:56:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, </p> <p>I&#39;m after HP Lto-4 1760 W62D firmware. Does anyone have this file that they could please send / share if you have it. </p> <p>Bonus if you have other firmware files to send for all / any varients. I did get a google drive from here previously. but it doesnt have it unfortunately. </p> <p>PLEASE HELP </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/R3PAIRS\"> /u/R3PAIRS </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl78ou/lto4_1760_w62d_download/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl78ou/lto4_1760_w62d_download/\">[comments]</a></span>",
        "id": 2425276,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl78ou/lto4_1760_w62d_download",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "LTO-4 1760 W62D download",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T15:51:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have an enclosure that can hold 4 drives. Currently it was 2 14 TB drives with a ZFS striped set up. I want to add 2 more 14 TB drives, and end up with 3 striped, one parity. Is there a way to do this without copying all the data off and back on again?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/IWriteTheBuggyCode\"> /u/IWriteTheBuggyCode </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl74sx/zfs_expansion_question/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl74sx/zfs_expansion_question/\">[comments]</a></span>",
        "id": 2425679,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl74sx/zfs_expansion_question",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "ZFS Expansion Question",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T15:35:05+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl6qzw/is_this_a_good_deal/\"> <img src=\"https://preview.redd.it/vex61ldm49re1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b7cc425a200038fa3262441978ba04e6d51cb73\" alt=\"Is this a good deal?\" title=\"Is this a good deal?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Western Digital 10TB WD_Black Performance Internal Hard Drive HDD - 7200 RPM, SATA 6 Gb/s, 512 MB Cache, 3.5&quot; - WD102FZBX</p> <p>On sale for 200$ on Amazon. Worth buying for my PC? Looking to backup my data (mostly media) and it seems cheap for 20$ per TB to me.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Aggressive-Energy465\"> /u/Aggressive-Energy465 </a> <br/> <span><a href=\"https://i.redd.it/vex61ldm49re1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl6qzw/is_this_a_good_deal/\">[comments]</a></span> </td></tr></table>",
        "id": 2422282,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl6qzw/is_this_a_good_deal",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/vex61ldm49re1.png?width=640&crop=smart&auto=webp&s=9b7cc425a200038fa3262441978ba04e6d51cb73",
        "title": "Is this a good deal?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T15:23:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, </p> <p>I&#39;ve researched a lot here and elsewhere but still failing to get a clear answer. Hoping some of you fine people can advise.</p> <p>I&#39;m a photographer/director and need a new larger archiving solution.</p> <p>Currently I have a 10TB G-Drive Raid (2 Bay) Thunderbolt 3 set up as Raid 1. So 5TB storage in total. </p> <p>I also have a 5TB external that I keep offsite and sync once a month. (This is secure enough for me as I also have the last months of work on my external &#39;shoot HDs&#39;).</p> <p>I have no need for it to be online either now or in the future so a NAS system isn&#39;t necessary. I also have no interest in costly cloud storage subscriptions.</p> <p>So, I&#39;m considering these options:</p> <p>Option 1 - Replace the Raid drives with 2x26TB (WD Ultrastars 7200)<br/> - making use of the existing enclosure and thunderbolt 3 speed<br/> - I&#39;d also have 3rd separate 26TB for off site backup</p> <p>Option 2 - Buy a new",
        "id": 2425680,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl6h4o/archive_solution_2_bay_vs_4_bay",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Archive solution - 2 bay vs 4 bay",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T13:59:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have an Exos X24 Model No: ST24000NM007H with SAS interface, what connector can I use to connect it to a SATA motherboard?</p> <p>Is there a SAS to SATA cable?</p> <p>Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/_stracci\"> /u/_stracci </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl4k0h/help_setting_up_hard_disk_sas_to_sata/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl4k0h/help_setting_up_hard_disk_sas_to_sata/\">[comments]</a></span>",
        "id": 2421624,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl4k0h/help_setting_up_hard_disk_sas_to_sata",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help setting up hard disk SAS to SATA",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T13:11:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have 500+ gb of over 40,000 video game music files (flac/mp3/ogg) saved to a hard drive. I want to save it all to a microSD so I can listen to all of it seamlessly on the go. I&#39;m wondering if anyone can recommend any music players that support multiple file types at the same time and bigger (probably 1+ tb) microSD capacity.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/marmosettacos\"> /u/marmosettacos </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl3kj7/whats_the_best_flacmp3_player_in_2025/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl3kj7/whats_the_best_flacmp3_player_in_2025/\">[comments]</a></span>",
        "id": 2420964,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl3kj7/whats_the_best_flacmp3_player_in_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's the best flac/mp3 player in 2025?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T11:08:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I use &quot;Aka&quot; which is a less known version of Nicegram to save vids from private canals and it works perfectly well. The thing is, because I didn\u2019t watch completely some saved videos, these didn\u2019t load until the very end but in the meantime the canals got deleted. I find myself having the vids in my saved messages of the app but without having them played completely and when I try to download them it\u2019s stuck to where I left the video the last time I watched it for example (4.9MB/ 23.7MB) Is there a way to fix the problem ? Are the vids definitely lost ? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Aight__T\"> /u/Aight__T </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl1dvd/problem_related_to_the_use_of_a_thirdparty/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl1dvd/problem_related_to_the_use_of_a_thirdparty/\">[comments]</a></span>",
        "id": 2420342,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl1dvd/problem_related_to_the_use_of_a_thirdparty",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Problem related to the use of a third-party Telegram Client",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T09:45:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>Originally posted on <a href=\"/r/techsupport\">r/techsupport</a>, not getting much, I&#39;d be interested in the thoughts of this community.</p> <p>Thinking about the bathtub curve for hard drive failures, how do you go about burning in / stress testing your new drives, particularly those that are used for cold storage? Do you do it at all? What&#39;s your approach / reasoning?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/rslegacy86\"> /u/rslegacy86 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl06y2/recommendation_hard_drive_burnin_methods/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl06y2/recommendation_hard_drive_burnin_methods/\">[comments]</a></span>",
        "id": 2420343,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl06y2/recommendation_hard_drive_burnin_methods",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Recommendation: Hard drive burn-in methods",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T09:35:00+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jl01yc/free_cloud_storage_good_as_a_backup_for_non/\"> <img src=\"https://external-preview.redd.it/uu6V1qt29owH2DMhA7194LbRvfyqF1XdXpWk4St8ECw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2915aee79391460cf46ef0eaeb38937ae1e585e2\" alt=\"free cloud storage? good as a backup for non importants?\" title=\"free cloud storage? good as a backup for non importants?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>so i\u2019ve been using this site for the last month or so. no clue where they came from, but they offer infinite free cloud storage.</p> <p>whats the catch? they get to \u201canonymously\u201d use your data\u2026. </p> <p>I\u2019ve always strictly avoided cloud storage till I came across this. I still dislike it tbh and all my \u201creal\u201d backups are sharded with duplication across a series of physical drives. that said, i do various side projects where i wind up with large datasets and dont really care to store them. i\u2019ve been uploadin",
        "id": 2420341,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jl01yc/free_cloud_storage_good_as_a_backup_for_non",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/uu6V1qt29owH2DMhA7194LbRvfyqF1XdXpWk4St8ECw.jpg?width=640&crop=smart&auto=webp&s=2915aee79391460cf46ef0eaeb38937ae1e585e2",
        "title": "free cloud storage? good as a backup for non importants?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T06:09:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I downloaded and tried to use this <a href=\"https://github.com/prof79/fansly-downloader-ng?tab=readme-ov-file\">https://github.com/prof79/fansly-downloader-ng?tab=readme-ov-file</a></p> <p>I thought I&#39;d set everything up but I keeps throwing this error, [43]ERROR | 16:03 || Unexpected error during Timeline download:</p> <p>Traceback (most recent call last):</p> <p>File &quot;download\\common.py&quot;, line 151, in process_download_accessible_media</p> <p>File &quot;download\\media.py&quot;, line 202, in download_media</p> <p>File &quot;fileio\\dedupe.py&quot;, line 74, in dedupe_media_file</p> <p>File &quot;fileio\\fnmanip.py&quot;, line 71, in get_hash_for_image</p> <p>File &quot;imagehash\\__init__.py&quot;, line 272, in phash</p> <p>File &quot;PyInstaller\\loader\\pyimod02_importers.py&quot;, line 419, in exec_module</p> <p>File &quot;scipy\\fftpack\\__init__.py&quot;, line 93, in &lt;module&gt;</p> <p>File &quot;PyInstaller\\loader\\pyimod02_importers.py",
        "id": 2418793,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkxdtn/can_someone_help_me_get_fansly_downloader_to_work",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can someone help me get fansly downloader to work?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T04:47:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a bunch of interactive videos, meaning there are choices that you select, and the outcome may end. eg if you choose the wrong option, the video ends, you can replay that choice or restart the entire video.<br/> All the files use adobe flash media player to run, is there a self hosted media server where it will detect each folder(the folder with each vid) and allow me to still play. Netflix has a bear grills show that does the same.</p> <p>Each folder has 4 files,</p> <p>1 folder with all the vids (Scene 1-choice 1 and 2 etc)<br/> 1 folder with all the thumbnails ( of the choices)<br/> 1 swl file( the one that needs to be dragged into flash)<br/> and a game.xml file ( helps to actually run the interactivness, like choosing the option and stuff)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/xTHEFLASH0504x\"> /u/xTHEFLASH0504x </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkw6b3/n",
        "id": 2418374,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkw6b3/need_help_with_playing_interactive_videos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help with playing interactive videos",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T03:14:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The title says it all, I was originally trying to use wget to download this specific collection <a href=\"https://catalog.archives.gov/search-within/530707\">https://catalog.archives.gov/search-within/530707</a>, but it just wont download. I want to archive this because I don&#39;t only find it cool and I want to keep a copy of it on my drive, but I also want to do my part to combat the purges. I would also know how to filter the download to only download the images and documents, and none of the site assets? Such as only downloading the .tiff, .jpg/jpeg, png, and pdf files in the catalog.</p> <p>Wget command I was running: wget --mirror --page-requisites --convert-link --no-clobbe robots=off --no-parent --user-agent=Mozilla --random-wait --recursive --domains archives.gov <a href=\"https://catalog.archives.gov/search-within/530707\">https://catalog.archives.gov/search-within/530707</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://w",
        "id": 2418159,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkukjq/how_can_i_scrapedownload_gov_sites_like",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can I scrape/download .gov sites like archives.gov?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T02:17:40+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Pythonistar\"> /u/Pythonistar </a> <br/> <span><a href=\"https://www.seagate.com/content/dam/seagate/en/content-fragments/products/datasheets/barracuda-3-5-hdd/barracuda-3-5-hddDS2131-3-US2411-en_US.pdf\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkthi8/seagate_barracuda_24tb_released_a_few_days_ago/\">[comments]</a></span>",
        "id": 2417924,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkthi8/seagate_barracuda_24tb_released_a_few_days_ago",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seagate Barracuda 24TB released a few days ago. Any good?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T01:23:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all, I appreciate the work y\u2019all do. (For yourself or the community)</p> <p>I am someone who considers themself an avid video game lover. With the slow decline of physical media in the gaming space (I know I\u2019ll always be there but it is becoming less common). What are my options if I want to have offline storage and preserve my game collection digitally? I currently am on PS5 but wouldn\u2019t be concerned with switching over to PC. </p> <p>I\u2019m very much wanting to continue having \u201cownership\u201d of my data in whatever way I can and just don\u2019t see that when I\u2019m at Sonys or Microsoft\u2019s will on if they want to pull something from the store or ban my account if they so choose to do so(which would prevent me from playing my digitally purchased games from their storefronts) this is a very noob answer as I have no idea where to begin and I\u2019m just seeking guidance on the best way to preserve what I love </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=",
        "id": 2417714,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkseuu/nondatahoarder_has_questions",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Non-data-hoarder has questions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-27T00:20:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Earlier today, I went to capture a web page with archive.today. As normal, when I click the &quot;save&quot; button, it gives me a CAPTCHA prompt, which I was able to solve without problems. Just now however, I went to capture a web page, and while solving the CAPTCHA, my browser was abruptly redirected to <code>https://rurtnews . com</code> (URL purposefully broken to make it more difficult to click, it&#39;s some sort of Russian news website I think). I clicked &quot;Back&quot; a few times to get back to the archive.ph home page, then tried to save the page again. This time I didn&#39;t try to solve the CAPTCHA, I just waited to see what would happen while on the CAPTCHA page. Sure enough, my browser sent me to the same weird news website again. This happens no matter how I end up on archive.today&#39;s CAPTCHA page, and the redirect happens quickly enough I&#39;m unable to solve the CAPTCHA in time.</p> <p>I am pretty confident my machine isn&#39;",
        "id": 2417402,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkr4pz/archivetoday_redirecting_to_a_weird_russian_news",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "archive.today redirecting to a weird Russian news site when trying to capture a page?",
        "vote": 0
    }
]