[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T22:01:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I\u2019m trying to scrape data from <a href=\"https://www.pagesjaunes.fr/\"><strong>Pages Jaunes</strong></a>, but the site is really good at blocking scrapers. I\u2019ve tried rotating user agents, adding delays, and using proxies, but nothing seems to work.</p> <p>I need to extract <strong>name, phone number, and other basic details</strong> for shops in specific industries and regions. I already have a list of industries and regions to search, but I keep running into anti-bot measures. On top of that, some pages <strong>time out</strong>, making things even harder.</p> <p>Has anyone dealt with something like this before? Any advice or ideas on how to get around these blocks? I\u2019d really appreciate any help!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ReactNativeDevZ\"> /u/ReactNativeDevZ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2ur45/struggling_to_scrape_pages_jaune",
        "id": 2240037,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j2ur45/struggling_to_scrape_pages_jaunes_need_advice",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Struggling to Scrape Pages Jaunes \u2013 Need Advice",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T21:45:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I&#39;ve been running into issues with Cloudflare challenge page while scraping. I was using <strong>Puppeteer with a real browser</strong>, which worked decently, but since it&#39;s <strong>no longer receiving updates</strong>, I&#39;m looking for alternatives.</p> <p>I&#39;ve tried different approaches, but many seem unreliable or inconsistent. What are some effective strategies or open-source solutions that you\u2019ve had success with?</p> <p>Would love to hear your thoughts\u2014thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Riidv\"> /u/Riidv </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2udn4/best_approach_for_solving_cloudflare_challenge/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2udn4/best_approach_for_solving_cloudflare_challenge/\">[comments]</a></span>",
        "id": 2239623,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j2udn4/best_approach_for_solving_cloudflare_challenge",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best Approach for Solving Cloudflare Challenge page?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T18:57:43+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1j2qbi4/help_download_court_rulings_pdf_from_chilean/\"> <img src=\"https://a.thumbs.redditmedia.com/ILRw42nxPQilOpXXXFqTNcmfxt1ZvyYQ9RhYN6jtok4.jpg\" alt=\"Help: Download Court Rulings (PDF) from Chilean Judiciary?\" title=\"Help: Download Court Rulings (PDF) from Chilean Judiciary?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>I\u2019m trying to automate the download of court rulings in PDF from the Chilean Judiciary\u2019s Virtual Office (<a href=\"https://oficinajudicialvirtual.pjud.cl/\">https://oficinajudicialvirtual.pjud.cl/</a>). I have already managed to search for cases by entering the required data in the form, but I\u2019m having issues with the final step: opening the case details and downloading the PDF of the ruling.</p> <p>I have tried using Selenium and Playwright, but the main issue is that the website\u2019s structure changes dynamically, making it difficult to access the PDF link.</p> <p>Man",
        "id": 2238634,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j2qbi4/help_download_court_rulings_pdf_from_chilean",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/ILRw42nxPQilOpXXXFqTNcmfxt1ZvyYQ9RhYN6jtok4.jpg",
        "title": "Help: Download Court Rulings (PDF) from Chilean Judiciary?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T18:38:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have been try to do google scraping using requests lib however it is failing again and again. It says to enable the javascript. Any come around for thi? </p> <pre><code>&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;title&gt;Google Search&lt;/title&gt;&lt;style&gt;body{background-color:#fff}&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;noscript&gt;&lt;style&gt;table,div,span,p{display:none}&lt;/style&gt;&lt;meta content=&quot;0;url=/httpservice/retry/enablejs?sei=tPbFZ92nI4WR4-EP-87SoAs&quot; http-equiv=&quot;refresh&quot;&gt;&lt;div style=&quot;display:block&quot;&gt;Please click &lt;a href=&quot;/httpservice/retry/enablejs?sei=tPbFZ92nI4WR4-EP-87SoAs&quot;&gt;here&lt;/a&gt; if you are not redirected within a few seconds.&lt;/div&gt;&lt;/noscript&gt;&lt;script nonce=&quot;MHC5AwIj54z_lxpy7WoeBQ&quot;&gt;//# sourceMappingURL=data:application/json;charset=utf-8;base64, </code></pre> </div><!-- SC_ON --> &#32; submitted by &#32; <a",
        "id": 2238158,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j2pucl/how_to_do_google_scraping_on_scale",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to do google scraping on scale?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T16:19:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anyone been scraping X lately? I&#39;m struggling trying to not halt the rate limits so I would really appreciate some help from someone with more experience on it.</p> <p>A few weeks ago I managed to use an account for longer, got it scraping nonstop for 13k twets in one sitting (a long 8h sitting) but now with other accounts I can&#39;t manage to get past the 100...</p> <p>Any help is appreciated! :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jsandi99\"> /u/jsandi99 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2mefo/does_anyone_know_how_not_to_halt_the_rate/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2mefo/does_anyone_know_how_not_to_halt_the_rate/\">[comments]</a></span>",
        "id": 2237074,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j2mefo/does_anyone_know_how_not_to_halt_the_rate",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does anyone know how not to halt the rate limiting on Tw\u00edtter?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T15:47:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Would it be possible to use proxys in some way to make aliexpress acounts and get a lot of welcome deal bonusses? Has something like this been done before?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Shot_Status2339\"> /u/Shot_Status2339 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2ln66/aliexpress_welcome_deals/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2ln66/aliexpress_welcome_deals/\">[comments]</a></span>",
        "id": 2237075,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j2ln66/aliexpress_welcome_deals",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Aliexpress welcome deals",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T10:07:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a list of around 3000 URLs, such as <a href=\"https://www.goodrx.com/trimethobenzamide\"><code>https://www.goodrx.com/trimethobenzamide</code></a>, that I need to scrape. I&#39;ve tried various methods, including manipulating request headers and cookies. I&#39;ve also used tools like Playwright, Requests, and even <code>curl_cffi</code>. Despite using my cookies, the scraping works for about 50 URLs, but then I start receiving 403 errors. I just need to scrape the HTML of each URL, but I&#39;m running into these roadblocks. Even tried getting Google Caches. Any suggestions?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Super_Duck_2116\"> /u/Super_Duck_2116 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2ffiz/difficulty_in_scraping_website_with_perimeter_x/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2ffiz/difficulty_in_scraping_website_",
        "id": 2235027,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j2ffiz/difficulty_in_scraping_website_with_perimeter_x",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Difficulty In Scraping website with Perimeter X Captcha",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T08:35:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>For those of you who scrape websites regularly, how do you handle situations where the site&#39;s HTML structure changes and breaks your selectors?</p> <p>Do you manually review and update selectors when issues arise, or do you have an automated way to detect and fix them? If you use any tools or strategies to make this process easier, let me know pls</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/alimadat\"> /u/alimadat </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2e75q/how_do_you_handle_selector_changes_in_web_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2e75q/how_do_you_handle_selector_changes_in_web_scraping/\">[comments]</a></span>",
        "id": 2233958,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j2e75q/how_do_you_handle_selector_changes_in_web_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How Do You Handle Selector Changes in Web Scraping?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T05:40:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The first rule of web scraping? Don\u2019t talk about web scraping\u2026 unless you\u2019re here. Then, it\u2019s basically your only conversation topic. All your friends are tired of hearing about headers, delays, and CAPTCHAs, but we live for it. So let\u2019s gather and actually talk about it, or else we\u2019ll start scraping the conversation. \ud83d\ude09</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/uvanwu\"> /u/uvanwu </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2bq7a/the_first_rule_of_web_scraping_is_dont_talk_about/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2bq7a/the_first_rule_of_web_scraping_is_dont_talk_about/\">[comments]</a></span>",
        "id": 2233497,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j2bq7a/the_first_rule_of_web_scraping_is_dont_talk_about",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The First Rule of Web Scraping is... Dont Talk About Web Scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T05:15:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys, i am making an app that scrapes phones and ac units and compares their prices. The names on different sites are totally different even though its the same product. I cant seem to find a good match unless i clean them manually which isnt productive. I looked into clustering but i dont know how to do it correctly. The problem is that it matches iPhone 15 with iPhone 16 for example, or Vivax ACP-12CH35AERI+R32 with Vivax ACP-12CH35AEHI+R32. Any help? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tall_Rabbit_5100\"> /u/Tall_Rabbit_5100 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2bb1h/web_scraping_and_clustering/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2bb1h/web_scraping_and_clustering/\">[comments]</a></span>",
        "id": 2233498,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j2bb1h/web_scraping_and_clustering",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Web scraping and CLUSTERING",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T04:34:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I just wanna Scrape Indigo website for getting Information about departure time,fare but i cannot scrape that data . idonot know why its happening as i think it works well i asked chatgpt and it said on logical level the code is correct but doesnt help in identifying the problem. so please help me out on this problem</p> <p>Link : <a href=\"https://github.com/ripoff4/Web-Scraping/tree/main/indigo\">https://github.com/ripoff4/Web-Scraping/tree/main/indigo</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Perry_2013\"> /u/Perry_2013 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2alxs/indigo_website_scraping_problem/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j2alxs/indigo_website_scraping_problem/\">[comments]</a></span>",
        "id": 2233496,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j2alxs/indigo_website_scraping_problem",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Indigo website Scraping Problem",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-03T03:11:48+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1j294z8/help_download_court_rulings_pdf_from_chilean/\"> <img src=\"https://b.thumbs.redditmedia.com/XsTxV0xiTbgQ9TuONMCMxrIiDUg-_eJfylWQyL4ZSAw.jpg\" alt=\"Help: Download Court Rulings (PDF) from Chilean Judiciary?\" title=\"Help: Download Court Rulings (PDF) from Chilean Judiciary?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>I\u2019m trying to automate the download of court rulings in PDF from the Chilean Judiciary\u2019s Virtual Office (<a href=\"https://oficinajudicialvirtual.pjud.cl/\">https://oficinajudicialvirtual.pjud.cl/</a>). I have already managed to search for cases by entering the required data in the form, but I\u2019m having issues with the final step: opening the case details and downloading the PDF of the ruling.</p> <p>I have tried using Selenium and Playwright, but the main issue is that the website\u2019s structure changes dynamically, making it difficult to access the PDF link.</p> <p>Man",
        "id": 2233499,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j294z8/help_download_court_rulings_pdf_from_chilean",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/XsTxV0xiTbgQ9TuONMCMxrIiDUg-_eJfylWQyL4ZSAw.jpg",
        "title": "Help: Download Court Rulings (PDF) from Chilean Judiciary?",
        "vote": 0
    }
]