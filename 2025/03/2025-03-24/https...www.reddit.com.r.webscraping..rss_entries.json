[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-24T21:30:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to build a web scraper using puppeteer in firebase functions, but i keep getting the following error message in the firebase functions log;</p> <p>&quot;Error: Could not find Chrome (ver. 134.0.6998.35). This can occur if either 1. you did not perform an installation before running the script (e.g. `npx puppeteer browsers install chrome`) or 2. your cache path is incorrectly configured.&quot;</p> <p>It runs fine locally, but it doesn&#39;t when it runs in firebase. It&#39;s probably a beginners fault but i can&#39;t get it fixed. The command where it probably goes wrong is;</p> <pre><code> browser = await puppeteer.launch({ args: [&quot;--no-sandbox&quot;, &quot;--disable-setuid-sandbox&quot;], headless: true, }); </code></pre> <p>Does anyone know how to fix this? Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Few_Web7636\"> /u/Few_Web7636 </a> <br/> <span><a href=\"https://www.r",
        "id": 2398888,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jj2k5l/firebase_functions_puppeteer_could_not_find_chrome",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Firebase functions & puppeteer 'Could not find Chrome'",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-24T20:09:39+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1jj0iqi/app_from_webscraping/\"> <img src=\"https://external-preview.redd.it/OHNlazN6bnQycHFlMVJft5v86VMbwmdu9cgXqa68y4nlrjNPibf8ZHraKzlQ.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=09ffdfa3441afc40cd8025bdea3bfb88020a1739\" alt=\"App from webscraping ;)\" title=\"App from webscraping ;)\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/YalebB\"> /u/YalebB </a> <br/> <span><a href=\"https://v.redd.it/ryyr37st2pqe1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jj0iqi/app_from_webscraping/\">[comments]</a></span> </td></tr></table>",
        "id": 2398106,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jj0iqi/app_from_webscraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/OHNlazN6bnQycHFlMVJft5v86VMbwmdu9cgXqa68y4nlrjNPibf8ZHraKzlQ.png?width=640&crop=smart&auto=webp&s=09ffdfa3441afc40cd8025bdea3bfb88020a1739",
        "title": "App from webscraping ;)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-24T20:08:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have been looking for the best course of action to tackle a webscraping problem which requires constant monitoring of website(s) for changes, such as stock number. Up until now, I believed I can use Playwright and set delays, like rescraping every 1 minute to detect change, but I don&#39;t think that will work..</p> <p>Also, would it be best to scrape the html or reverse engineer the api?</p> <p>Thanks in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/astrobreezy\"> /u/astrobreezy </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jj0hv4/what_is_the_best_tool_to_consistently_scrape_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jj0hv4/what_is_the_best_tool_to_consistently_scrape_a/\">[comments]</a></span>",
        "id": 2398107,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jj0hv4/what_is_the_best_tool_to_consistently_scrape_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What is the best tool to consistently scrape a website for changes",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-24T19:39:02+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1jizq76/homemade_project_for_2_years_1k_pages_daily_but/\"> <img src=\"https://b.thumbs.redditmedia.com/xMv6YODL9JDctVdaWcmo6wrrBsNJWNrrE5Nhxgajccg.jpg\" alt=\"Homemade project for 2 years, 1k+ pages daily, but still for fun\" title=\"Homemade project for 2 years, 1k+ pages daily, but still for fun\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Not self-promotion, I just wanted to share my experience about my skinny and homemade project I have been running for 2 years already. No harm for me, anyway I don&#39;t see a way how I can monetize this.</p> <p>2 years ago, I started looking for the best mortgage rates around and it was hard to find and compare the average rates, see trends and follow the actual rates. I like to leverage my programming skills and built tiny project to avoid manual work. So, challenge accepted - I&#39;ve built a very small project and run it daily to see actual rates from popular and publi",
        "id": 2397527,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jizq76/homemade_project_for_2_years_1k_pages_daily_but",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/xMv6YODL9JDctVdaWcmo6wrrBsNJWNrrE5Nhxgajccg.jpg",
        "title": "Homemade project for 2 years, 1k+ pages daily, but still for fun",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-24T14:41:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I usually get the US Dollar vs British Pount exchange rates from yahoo finance, at this page: <a href=\"https://finance.yahoo.com/quote/GBPUSD%3DX/history/\">https://finance.yahoo.com/quote/GBPUSD%3DX/history/</a></p> <p>Until recently, I would just save the html page, open it, find the table and copy-paste it into a spreadsheet. Today I tried that and found the data table is no longer packaged in the html page. Does anyone know how I can overcome this? I am not very well versed in scraping. Any help appreciated.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tyroboot\"> /u/tyroboot </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jis8yy/how_to_scrape_forex_data_from_yahoo_finance/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jis8yy/how_to_scrape_forex_data_from_yahoo_finance/\">[comments]</a></span>",
        "id": 2395152,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jis8yy/how_to_scrape_forex_data_from_yahoo_finance",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape forex data from yahoo finance?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-24T13:51:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello - i try to request an api using the following code:</p> <pre><code>import requests resp = requests.get(&#39;https://www.brilliantearth.com/api/v1/plp/products/?display=50&amp;page=1&amp;currency=USD&amp;product_class=Lab%20Created%20Colorless%20Diamonds&amp;shapes=Oval&amp;cuts=Fair%2CGood%2CVery%20Good%2CIdeal%2CSuper%20Ideal&amp;colors=J%2CI%2CH%2CG%2CF%2CE%2CD&amp;clarities=SI2%2CSI1%2CVS2%2CVS1%2CVVS2%2CVVS1%2CIF%2CFL&amp;polishes=Good%2CVery%20Good%2CExcellent&amp;symmetries=Good%2CVery%20Good%2CExcellent&amp;fluorescences=Very%20Strong%2CStrong%2CMedium%2CFaint%2CNone&amp;real_diamond_view=&amp;quick_ship_diamond=&amp;hearts_and_arrows_diamonds=&amp;min_price=180&amp;max_price=379890&amp;MIN_PRICE=180&amp;MAX_PRICE=379890&amp;min_table=45&amp;max_table=83&amp;MIN_TABLE=45&amp;MAX_TABLE=83&amp;min_depth=3.1&amp;max_depth=97.4&amp;MIN_DEPTH=3.1&amp;MAX_DEPTH=97.4&amp;min_carat=0.25&amp;max_carat=38.1&amp;MIN_CARAT=0.25&amp;MAX_CARAT=38.1&am",
        "id": 2394600,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jir5ch/403response_when_requesting_api",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "403-response when requesting api?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-24T09:38:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have build a scraper with python scrapy to get table data from this website:</p> <p><a href=\"https://datacvr.virk.dk/enhed/virksomhed/28271026?fritekst=28271026&amp;sideIndex=0&amp;size=10\">https://datacvr.virk.dk/enhed/virksomhed/28271026?fritekst=28271026&amp;sideIndex=0&amp;size=10</a></p> <p>As you can see, this website has a table with employee data under &quot;Antal Ansatte&quot;. I managed to scrape some of the data, but not all. You have to click on &quot;Vis alle&quot; (show more) to see all the data. In the script below I attempted to do just that by adding <code>PageMethod(&#39;click&#39;, &quot;button.show-more&quot;)</code> to the playwright_page_methods. When I run the script, it does identify the button (<code>locator resolved to 2 elements. Proceeding with the first one: &lt;button type=&quot;button&quot; class=&quot;show-more&quot; data-v-509209b4=&quot;&quot; id=&quot;antal-ansatte-pr-maaned-vis-mere-knap&quot;&gt;Vis alle&lt;/but",
        "id": 2392709,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jimssa/scraping_all_table_data_after_clicking_show_more",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping all table data after clicking \"show more\" button",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-24T09:19:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking to create a pcpartpicker for cameras. Websites I&#39;m looking at say don&#39;t scrape, but is there an issue if I do? Worst case scenario I get a C&amp;D right? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Zlushiie\"> /u/Zlushiie </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jimk90/violating_tos_matter/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jimk90/violating_tos_matter/\">[comments]</a></span>",
        "id": 2392710,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jimk90/violating_tos_matter",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Violating TOS matter?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-24T06:04:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m working on a project to scrape job descriptions from Indeed and Unstop, but I\u2019ve run into an issue\u2014Indeed has an early CAPTCHA that prevents bots from accessing data.</p> <p>I\u2019d love some guidance on:</p> <ol> <li><p>Avoiding bot detection \u2013 What are the best techniques to prevent getting flagged?</p></li> <li><p>Scraping tools &amp; frameworks \u2013 Which libraries or headless browsers work well for this kind of task?</p></li> <li><p>General proxy usage tips \u2013 What strategies can help maintain anonymity and avoid rate limiting?</p></li> <li><p>Common mistakes to avoid \u2013 What things should I be cautious about while scraping these sites?</p></li> </ol> <p>I\u2019m not looking for specific product recommendations, just general advice on best practices. Any insights would be appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Killer_Bee_28\"> /u/Killer_Bee_28 </a> <br/> <span><a href=\"https://www.reddit.com/r/we",
        "id": 2391974,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jik2ga/best_practices_for_scraping_job_descriptions",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best Practices for Scraping Job Descriptions Without Getting Blocked",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-24T05:21:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m new to this but really enjoying learning and the process. I\u2019m trying to create an automated dashboard that scrapes various prices from this website (example product: <a href=\"https://www.danmurphys.com.au/product/DM_915769/jameson-blended-irish-whiskey-1l?isFromSearch=false&amp;isPersonalised=false&amp;isSponsored=false&amp;state=2&amp;pageName=member_offers\">https://www.danmurphys.com.au/product/DM_915769/jameson-blended-irish-whiskey-1l?isFromSearch=false&amp;isPersonalised=false&amp;isSponsored=false&amp;state=2&amp;pageName=member_offers</a>) one a week. The further I get into my research the more I learn this will be very challenging. Could someone kindly explain in your most basic noob language why this is so hard? Is it because the location of the price within the code changes regularly, or am I getting that wrong? Is there any simple no code services out there that I could do this with to deposit into a Google doc? Thanks! </p> </div><!--",
        "id": 2391975,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jijgna/noob_question",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Noob question",
        "vote": 0
    }
]