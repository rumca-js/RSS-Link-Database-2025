[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-28T20:04:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What I&#39;m trying to do is extract the content of a web site that has a wiki style format/layout. I dove into the source code and there is a lot of pointless code that I don&#39;t need. The content itself rests inside a frame/table with the necessary formatting information in the CSS file. Just wondering if there&#39;s a smarter way to create an offline archive thats browsable offline on my phone or the desktop?</p> <p>Ultimatley I think I&#39;ll transpose everything into Obsidian MD (the note taking app that feels like it has wiki style features but with offline usage and uses the markup language to format everything).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Specific-Judgment410\"> /u/Specific-Judgment410 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jm484s/trying_to_download_a_niche_wiki_site_for_offline/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/websc",
        "id": 2433487,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jm484s/trying_to_download_a_niche_wiki_site_for_offline",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to download a niche wiki site for offline use",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-28T18:58:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Disclaimer:</strong> I am not even remotely a web dev and have been working as a developer for only about 3 years in a non web company. I&#39;m not even sure &quot;element&quot; is the correct term here.</p> <p>I&#39;m using BeautifulSoup in Python.</p> <p>I&#39;m trying to get the song lyrics of all the songs of a band from <a href=\"http://genius.com\">genius.com</a> and save them. Through their API I can get all the URLs of their songs (after getting the ID of the band by inspecting in Chrome) but that only gets me as far the page where the song is located. From there I do the following:</p> <pre><code>song_path = r_json[&quot;response&quot;][&quot;song&quot;][&quot;path&quot;] r_song_html = requests.get(f&quot;https://genius.com{song_path}&quot;, headers=header) song_html = BeautifulSoup(r_song_html.text, &quot;html5lib&quot;) lyrics = song_html.find(attrs={&quot;data-lyrics-container&quot;: &quot;true&quot;}) </code></pre> <p>And this <str",
        "id": 2432990,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jm2o3z/are_big_html_elements_split_into_small_ones_when",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are big HTML elements split into small ones when received via API?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-28T16:36:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>In regards to automation / botting without being detected, are there are positives to using the playwright version of chromium?</p> <p>Should you use the local installed version of Chrome? Does it matter?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/bluemangodub\"> /u/bluemangodub </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlzaly/any_reason_to_use_playwright_version_of_chromium/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlzaly/any_reason_to_use_playwright_version_of_chromium/\">[comments]</a></span>",
        "id": 2431430,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jlzaly/any_reason_to_use_playwright_version_of_chromium",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any reason to use playwright version of chromium?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-28T15:33:44+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1jlxujr/wrote_a_web_scraper_for_the_nc_dmv/\"> <img src=\"https://external-preview.redd.it/JknFDc1XuPeiXsAvwxJiBQtyfTq_bjb_TRGKPd8KdYk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5ba5ce9df81adcbdaebfa4a851a285e0dbaef30\" alt=\"Wrote a web scraper for the NC DMV\" title=\"Wrote a web scraper for the NC DMV\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Needed a DMV appointment, but did not want to wait 90 days, and also did not want to travel 200 miles, so instead I wrote a scraper which sends messages to a discord webhook when appointments are available </p> <p><a href=\"https://preview.redd.it/z4buk4jc8gre1.png?width=799&amp;format=png&amp;auto=webp&amp;s=9d4b54b1222d7c926bfcc87c216bc0c98bf0b1b6\">https://preview.redd.it/z4buk4jc8gre1.png?width=799&amp;format=png&amp;auto=webp&amp;s=9d4b54b1222d7c926bfcc87c216bc0c98bf0b1b6</a></p> <p>I also open sourced it: <a href=\"https://github.com/tmcelroy2202/NC-DMV-Scr",
        "id": 2430720,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jlxujr/wrote_a_web_scraper_for_the_nc_dmv",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/JknFDc1XuPeiXsAvwxJiBQtyfTq_bjb_TRGKPd8KdYk.jpg?width=640&crop=smart&auto=webp&s=e5ba5ce9df81adcbdaebfa4a851a285e0dbaef30",
        "title": "Wrote a web scraper for the NC DMV",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-28T15:29:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, Im building a small offline reading app and looking for a good solution to extracting articles from html. I&#39;ve seen SwiftSoup and Readability? Any others? Strong preferences? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nicolaswalker\"> /u/nicolaswalker </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlxr8p/how_would_you_scrape_an_article_from_a_webpage/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlxr8p/how_would_you_scrape_an_article_from_a_webpage/\">[comments]</a></span>",
        "id": 2430721,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jlxr8p/how_would_you_scrape_an_article_from_a_webpage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How would you scrape an article from a webpage?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-28T15:20:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I remember back in the days of WinRunner that you could automate actual interactions on the whole screen, with movements of the mouse, etc.</p> <p>Does Selenium work this way, or does it have an option to? I thought it used to have a plugin or something that did this.</p> <p>Does Playwright work this way?</p> <p>Is there any advantage here with this approach for web apps as far as being more likely to bypass bot detection? If I understand correctly, both of these tools now work with headless browsers, although they still execute JavaScript. Is that correct?</p> <p>What advantages do Selenium and Playwright have when it comes to bot detection over other tools?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dca12345\"> /u/dca12345 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlxix8/desktop_automation_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/",
        "id": 2430719,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jlxix8/desktop_automation_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Desktop automation / scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-28T15:15:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Im looking for someone who has decent webscraping knowledge as chat gpt only gets me so far. please reply if interested </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Aware_Yard_7314\"> /u/Aware_Yard_7314 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlxfn5/looking_for_webscraper/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlxfn5/looking_for_webscraper/\">[comments]</a></span>",
        "id": 2430722,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jlxfn5/looking_for_webscraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "looking for webscraper",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-28T12:21:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is there a simple way to search Target&#39;s data for the lowest price nationwide for an item by its DPCI?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nickberti\"> /u/nickberti </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlts4d/target_inventory_prices_across_us/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlts4d/target_inventory_prices_across_us/\">[comments]</a></span>",
        "id": 2429087,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jlts4d/target_inventory_prices_across_us",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Target Inventory Prices Across US",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-28T10:08:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have no coding knowledge, is there a solution to my problem? I want to scrape news articles from about 20 different websites, filtering them on today&#39;s date. For the purposes of summarizing them and creating a briefing.<br/> I&#39;ve found that <a href=\"http://make.com\">make.com</a> along with feedly or inoreader works well, but the problem is that feedly and inoreader only look at the feed (front page), and ideally i would need something that can go through a couple pages of news.<br/> Any ideas, i greatly appreciate.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hakey22\"> /u/hakey22 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlroeg/how_should_i_scrape_news_articles_from_20_sources/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlroeg/how_should_i_scrape_news_articles_from_20_sources/\">[comments]</a></span>",
        "id": 2428226,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jlroeg/how_should_i_scrape_news_articles_from_20_sources",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How should i scrape news articles from 20 sources, daily?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-28T06:14:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Does anyone know a way to not get detected by Reuters while scraping there news feed? I m trying to build a dashboard where I want to scrape news data from Reuters </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PuzzleheadedDrama675\"> /u/PuzzleheadedDrama675 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlolua/reuters_web_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jlolua/reuters_web_scraping/\">[comments]</a></span>",
        "id": 2427400,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jlolua/reuters_web_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Reuters Web scraping",
        "vote": 0
    }
]