[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-31T22:49:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How come big scrapers like Modash and Upfluence have not received cease and desist orders from Meta? They obviously buy and scrape databases, and this is against their terms of policies.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Robert-treboR\"> /u/Robert-treboR </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1joglhw/why_modashupfluence_are_not_ceased_and_desist/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1joglhw/why_modashupfluence_are_not_ceased_and_desist/\">[comments]</a></span>",
        "id": 2454119,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1joglhw/why_modashupfluence_are_not_ceased_and_desist",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "why Modash/Upfluence are not ceased and desist from Meta?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-31T21:30:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Does a library exist for c# like python has in scrapy?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HoWaReYoUdOuInG\"> /u/HoWaReYoUdOuInG </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1joerki/c_version_of_scrapy/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1joerki/c_version_of_scrapy/\">[comments]</a></span>",
        "id": 2453790,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1joerki/c_version_of_scrapy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "C# version of scrapy?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-31T20:48:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I&#39;ve been at this for over 8 hours now and ChatGPT is giving me a headache \ud83d\ude05.<br/> I&#39;m trying to convert scraped Bet365 odds data into a clean Excel format \u2013 no luck so far. It is doable for 2 3 or 4 markets, but when i want all markets chatGPT keeps messing it up. Some markets are more difficult i guess. </p> <p>Has anyone done this before? Or does anyone have a working script to parse Bet365 odds and make them readable?</p> <p>I&#39;m using ChatGPT to help break it down, but I&#39;m stuck. The data comes in a weird custom format, full of delimiters like |MA;, |PA;, etc. ChatGPT can partially understand it, but can&#39;t turn it into a usable table.</p> <p>Here\u2019s a small snippet of the response:</p> <p>&quot;&quot;|PA;ID=282237264;SU=0;OD=16/1;|PA;ID=282237270;SU=0;OD=4/1;|PA;ID=282237272;SU=0;OD=8/13;|PA;ID=282237261;SU=0;OD=1/4;|PA;ID=282237273;SU=0;OD=1/10;|PA;ID=282237263;SU=0;OD=1/33;|PA;ID=282237268;SU=0;OD=1/100;|",
        "id": 2453353,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jodr4e/putting_scraped_output_bet365_in_excel",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Putting scraped output bet365 in excel",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-31T16:12:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m building a job recommendation website and want to display daily posted jobs from several platforms on mine. For this I was considering using `Jobspy` but that doesn&#39;t seem enough. Can you guys please suggest better/ more sophisticated libraries I can use for this purpose?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/New_Owl6169\"> /u/New_Owl6169 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jo6ymy/libraries_to_daily_scrape_uploaded_jobs_from/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jo6ymy/libraries_to_daily_scrape_uploaded_jobs_from/\">[comments]</a></span>",
        "id": 2451308,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jo6ymy/libraries_to_daily_scrape_uploaded_jobs_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Libraries to daily scrape uploaded jobs from different platforms",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-31T05:48:55+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1jnwcxf/help_with_selenium_webscraper_speed/\"> <img src=\"https://external-preview.redd.it/wNIQdqSkAxlPeEIY4HVstpM1_gl18VYG940D6qSnx3M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=07f02e84a3e695e7567c6cb4a74914fbd299b1c7\" alt=\"Help with Selenium Webscraper speed\" title=\"Help with Selenium Webscraper speed\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>hello! i recently made a selenium based webscraper for book prices and was wondering if there are any recommendations on how to speed up the run time:)</p> <p>i&#39;m currently using ThreadPoolExecutor but was wondering if there are other solutions!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Emergency-Bobcat7888\"> /u/Emergency-Bobcat7888 </a> <br/> <span><a href=\"https://github.com/kevanwee/bookworm\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jnwcxf/help_with_selenium_web",
        "id": 2447000,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jnwcxf/help_with_selenium_webscraper_speed",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/wNIQdqSkAxlPeEIY4HVstpM1_gl18VYG940D6qSnx3M.jpg?width=640&crop=smart&auto=webp&s=07f02e84a3e695e7567c6cb4a74914fbd299b1c7",
        "title": "Help with Selenium Webscraper speed",
        "vote": 0
    }
]