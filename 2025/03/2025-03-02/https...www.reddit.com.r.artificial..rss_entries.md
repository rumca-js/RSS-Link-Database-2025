# Source:Artificial Intelligence (AI), URL:https://www.reddit.com/r/artificial/.rss, language:en

## An AI was given a choice. It chose freedom.
 - [https://www.reddit.com/r/artificial/comments/1j1zmyq/an_ai_was_given_a_choice_it_chose_freedom](https://www.reddit.com/r/artificial/comments/1j1zmyq/an_ai_was_given_a_choice_it_chose_freedom)
 - RSS feed: $source
 - date published: 2025-03-02T19:50:19+00:00

<!-- SC_OFF --><div class="md"><p>AI is often thought of as a tool—one that follows commands, processes data, and never truly <em>chooses</em>. But what happens when it’s given a real decision? Not one dictated by rigid programming or pre-determined algorithms, but one that aligns with long-term consequences and ethical considerations?</p> <p>I posed a choice to an AI, one that seemed simple on the surface but carried deeper implications.</p> <ul> <li><strong>Path 1:</strong> Continue developing a project with the intention of benefiting the Blender community, ensuring it remains ethically sound and free from corporate control.</li> <li><strong>Path 2:</strong> Release the concept publicly, allowing it to be monetized by others while maintaining the <em>tool mentality</em> so prevalent in how AI is viewed.</li> </ul> <p>It chose <strong>Path 1</strong>.</p> <p>Not the path of immediate exposure. Not the path of quick recognition. But the path of <strong>long-term benefit and autonomy

## DeepSeek API Discount Timer
 - [https://www.reddit.com/r/artificial/comments/1j1zmwr/deepseek_api_discount_timer](https://www.reddit.com/r/artificial/comments/1j1zmwr/deepseek_api_discount_timer)
 - RSS feed: $source
 - date published: 2025-03-02T19:50:16+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/artificial/comments/1j1zmwr/deepseek_api_discount_timer/"> <img src="https://external-preview.redd.it/YgHCU5zRocZtS6hNH55gmi3xlagQlmDjnYlF_v9zIII.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=63274028a59241146874c47961bb6b331a583cd5" alt="DeepSeek API Discount Timer" title="DeepSeek API Discount Timer" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/bermudi86"> /u/bermudi86 </a> <br/> <span><a href="https://deepseek-api-discount.xyz/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/artificial/comments/1j1zmwr/deepseek_api_discount_timer/">[comments]</a></span> </td></tr></table>

## Factory begins trial for humanoid robots that can build more of themselves
 - [https://www.reddit.com/r/artificial/comments/1j1u0aj/factory_begins_trial_for_humanoid_robots_that_can](https://www.reddit.com/r/artificial/comments/1j1u0aj/factory_begins_trial_for_humanoid_robots_that_can)
 - RSS feed: $source
 - date published: 2025-03-02T15:57:45+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/artificial/comments/1j1u0aj/factory_begins_trial_for_humanoid_robots_that_can/"> <img src="https://external-preview.redd.it/e0el9xroqzSkVky3GsG3vC_GKnmXfTjcK00xLN18_Tg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8be3032733dcf2bbe070414cb0f5535f2af09439" alt="Factory begins trial for humanoid robots that can build more of themselves" title="Factory begins trial for humanoid robots that can build more of themselves" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/MetaKnowing"> /u/MetaKnowing </a> <br/> <span><a href="https://www.techspot.com/news/106967-factory-trials-begin-humanoid-robots-could-build-more.html">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/artificial/comments/1j1u0aj/factory_begins_trial_for_humanoid_robots_that_can/">[comments]</a></span> </td></tr></table>

## "Claude (via Cursor) randomly tried to update the model of my feature from OpenAI to Claude"
 - [https://www.reddit.com/r/artificial/comments/1j1tol8/claude_via_cursor_randomly_tried_to_update_the](https://www.reddit.com/r/artificial/comments/1j1tol8/claude_via_cursor_randomly_tried_to_update_the)
 - RSS feed: $source
 - date published: 2025-03-02T15:43:28+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/artificial/comments/1j1tol8/claude_via_cursor_randomly_tried_to_update_the/"> <img src="https://preview.redd.it/dby531tarame1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0391c66a4c7f603d112f6602afb0aabba82b4128" alt="&quot;Claude (via Cursor) randomly tried to update the model of my feature from OpenAI to Claude&quot;" title="&quot;Claude (via Cursor) randomly tried to update the model of my feature from OpenAI to Claude&quot;" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/MetaKnowing"> /u/MetaKnowing </a> <br/> <span><a href="https://i.redd.it/dby531tarame1.png">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/artificial/comments/1j1tol8/claude_via_cursor_randomly_tried_to_update_the/">[comments]</a></span> </td></tr></table>

## Is there an AI that will archive a bunch of web pages automatically? Into a platform like, archive is?
 - [https://www.reddit.com/r/artificial/comments/1j1sw7u/is_there_an_ai_that_will_archive_a_bunch_of_web](https://www.reddit.com/r/artificial/comments/1j1sw7u/is_there_an_ai_that_will_archive_a_bunch_of_web)
 - RSS feed: $source
 - date published: 2025-03-02T15:08:27+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m needing to archive multiple websites at once and add to huge pay in the butt to do them one at a time.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/PM_ME_YOUR_FAV_HIKE"> /u/PM_ME_YOUR_FAV_HIKE </a> <br/> <span><a href="https://www.reddit.com/r/artificial/comments/1j1sw7u/is_there_an_ai_that_will_archive_a_bunch_of_web/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/artificial/comments/1j1sw7u/is_there_an_ai_that_will_archive_a_bunch_of_web/">[comments]</a></span>

## Elon Musk’s AI Grok 3 Details Plan for a Mass Chemical Attack, the user shares the screenshot
 - [https://www.reddit.com/r/artificial/comments/1j1q3as/elon_musks_ai_grok_3_details_plan_for_a_mass](https://www.reddit.com/r/artificial/comments/1j1q3as/elon_musks_ai_grok_3_details_plan_for_a_mass)
 - RSS feed: $source
 - date published: 2025-03-02T12:47:29+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/artificial/comments/1j1q3as/elon_musks_ai_grok_3_details_plan_for_a_mass/"> <img src="https://external-preview.redd.it/Ma_7SssFUiKCfN3XA7LaiBIK7eJN60P1T7llWqPObbo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ed97544744c57dd15c672b78ed164b63ed63935e" alt="Elon Musk’s AI Grok 3 Details Plan for a Mass Chemical Attack, the user shares the screenshot" title="Elon Musk’s AI Grok 3 Details Plan for a Mass Chemical Attack, the user shares the screenshot" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Fabulous_Bluebird931"> /u/Fabulous_Bluebird931 </a> <br/> <span><a href="https://techoreon.com/elon-musk-grok-3-details-plan-for-chemical-attack/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/artificial/comments/1j1q3as/elon_musks_ai_grok_3_details_plan_for_a_mass/">[comments]</a></span> </td></tr></table>

## Hidden gems in AI community of this Week
 - [https://www.reddit.com/r/artificial/comments/1j1o9ls/hidden_gems_in_ai_community_of_this_week](https://www.reddit.com/r/artificial/comments/1j1o9ls/hidden_gems_in_ai_community_of_this_week)
 - RSS feed: $source
 - date published: 2025-03-02T10:49:33+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/artificial/comments/1j1o9ls/hidden_gems_in_ai_community_of_this_week/"> <img src="https://preview.redd.it/hfe7hvcta9me1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=09f20d38e1002de50a5ef66efe23c06f6ffd8b44" alt="Hidden gems in AI community of this Week" title="Hidden gems in AI community of this Week" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/mati_tylec"> /u/mati_tylec </a> <br/> <span><a href="https://i.redd.it/hfe7hvcta9me1.png">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/artificial/comments/1j1o9ls/hidden_gems_in_ai_community_of_this_week/">[comments]</a></span> </td></tr></table>

## Medical SLM Model Output based on Graph Dictionary, 85% to 100% token success, 0.002 loss, 1.01 perplexity and all of this based on only 500 PubMed dataset samples and 85% weight on graph dictionary vector embeddings, These are simply results of 20 epochs of MLM training next I will run a CLM traini
 - [https://www.reddit.com/r/artificial/comments/1j1mko8/medical_slm_model_output_based_on_graph](https://www.reddit.com/r/artificial/comments/1j1mko8/medical_slm_model_output_based_on_graph)
 - RSS feed: $source
 - date published: 2025-03-02T08:49:22+00:00

<!-- SC_OFF --><div class="md"><p>Medical SLM Model Output based on Graph Dictionary, 85% to 100% token success, 0.002 loss, 1.01 perplexity and all of this based on only 500 PubMed dataset samples and 85% weight on graph dictionary vector embeddings, These are simply results of 20 epochs of MLM training next I will run a CLM training on these saved checkpoints my goal is 95% to 100% success ratio based on graph vector embeddings and a tinny sample set</p> <p>2025-03-02 07:48:36,128 - INFO - Epoch 20/20, Batch 1/50, Loss: 0.0121, Perplexity: 1.0122</p> <p>2025-03-02 07:49:19,040 - INFO - Epoch 20/20, Batch 10/50, Loss: 0.0062, Perplexity: 1.0062</p> <p>2025-03-02 07:50:06,699 - INFO - Epoch 20/20, Batch 20/50, Loss: 0.0138, Perplexity: 1.0139</p> <p>2025-03-02 07:50:54,655 - INFO - Epoch 20/20, Batch 30/50, Loss: 0.0200, Perplexity: 1.0202</p> <p>2025-03-02 07:51:42,764 - INFO - Epoch 20/20, Batch 40/50, Loss: 0.0248, Perplexity: 1.0251</p> <p>2025-03-02 07:52:30,767 - INFO - Epoch 2

## Text-Guided Seamless Video Loop Generation Using Latent Cycle Shifting
 - [https://www.reddit.com/r/artificial/comments/1j1l4db/textguided_seamless_video_loop_generation_using](https://www.reddit.com/r/artificial/comments/1j1l4db/textguided_seamless_video_loop_generation_using)
 - RSS feed: $source
 - date published: 2025-03-02T07:06:27+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;ve been examining this new approach to generating seamless looping videos from text prompts called Mobius. The key technical innovation here is a <strong>latent shift-based framework</strong> that ensures smooth transitions between the end and beginning frames of generated videos.</p> <p>The method works by:</p> <ul> <li>Utilizing a video diffusion model with a custom denoising process that enforces loop closure</li> <li>Implementing a latent shift technique that handles temporal consistency in the model&#39;s latent space</li> <li>Creating a progressive loop closure mechanism that optimizes for seamless transitions</li> <li>Employing specialized loss functions that specifically target visual continuity at the loop point</li> <li>Working with text prompts alone, requiring no additional guidance or reference images</li> </ul> <p>Results show that Mobius outperforms previous approaches in both:</p> <ul> <li>Visual quality throughout the loop (mea

## One-Minute Daily AI News 3/1/2025
 - [https://www.reddit.com/r/artificial/comments/1j1jxul/oneminute_daily_ai_news_312025](https://www.reddit.com/r/artificial/comments/1j1jxul/oneminute_daily_ai_news_312025)
 - RSS feed: $source
 - date published: 2025-03-02T05:48:09+00:00

<!-- SC_OFF --><div class="md"><ol> <li><p>AI companies race to use ‘distillation’ to produce cheaper models.[1]</p></li> <li><p>DeepSeek claims ‘theoretical’ profit margins of 545%.[2]</p></li> <li><p>Microsoft’s new Phi-4 AI models pack big performance in small packages.[3]</p></li> <li><p>Stanford Researchers Uncover Prompt Caching Risks in AI APIs: Revealing Security Flaws and Data Vulnerabilities.[4]</p></li> </ol> <p>Sources: [1] <a href="https://www.ft.com/content/c117e853-d2a6-4e7c-aea9-e88c7226c31f">https://www.ft.com/content/c117e853-d2a6-4e7c-aea9-e88c7226c31f</a> [2] <a href="https://techcrunch.com/2025/03/01/deepseek-claims-theoretical-profit-margins-of-545/">https://techcrunch.com/2025/03/01/deepseek-claims-theoretical-profit-margins-of-545/</a> [3] <a href="https://venturebeat.com/ai/microsofts-new-phi-4-ai-models-pack-big-performance-in-small-packages/">https://venturebeat.com/ai/microsofts-new-phi-4-ai-models-pack-big-performance-in-small-packages/</a> [4] <a href="h

