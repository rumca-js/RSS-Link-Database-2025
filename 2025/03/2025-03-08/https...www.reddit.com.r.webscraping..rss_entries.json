[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-08T23:42:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How is web scraping different from copying data from a website by hand, and why would someone use a web scraping tool instead?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Little-Knowledge1111\"> /u/Little-Knowledge1111 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j6ucf4/difference_between_web_scraping_and_copying_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j6ucf4/difference_between_web_scraping_and_copying_data/\">[comments]</a></span>",
        "id": 2278503,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j6ucf4/difference_between_web_scraping_and_copying_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Difference between Web Scraping and Copying Data?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-08T23:29:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>I&#39;m working on a project to scrape product URLs from Costco, Sam&#39;s Club, and Kroger. My current setup uses Selenium for both retrieving URLs and extracting product information, but it&#39;s extremely slow. I need to scrape at least 8,000\u201310,000 URLs daily to start, then shift to a weekly schedule.</p> <p>I&#39;ve tried a few solutions but haven&#39;t found one that works well for me. I&#39;m looking for advice on how to improve my scraping speed and efficiency.</p> <p><strong>Current Setup:</strong></p> <ul> <li>Using Selenium for URL retrieval and data extraction.</li> <li>Saving data in different formats.</li> </ul> <p><strong>Challenges:</strong></p> <ul> <li>Slow scraping speed.</li> <li>Need to handle a large number of URLs efficiently.</li> </ul> <p><strong>Looking for:</strong></p> <ul> <li>Looking for any 3rd party tools, products or APIs.</li> <li>Recommendations for efficient scraping tools or methods.</li> <l",
        "id": 2278504,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j6u2mh/scrape_810k_product_urls_dailyweekly",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scrape 8-10k product URLs daily/weekly",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-08T14:24:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anybody had any luck scraping article links from Google news? I&#39;m building a very simple programme in Scrapy with Playwright enabled, primarily to help me understand how Scrapy works through &#39;learning by doing&#39;</p> <p>I understand Google have a few sophisticated measures in place to stop programmes scraping data. I see this project as something that I can <strong>incrementally build in complexity</strong> over time - for instance introducing pagination, proxies, user agent sampling, cookies, etc. However at this stage I&#39;m just trying to get off the ground by scraping the first page.</p> <p>The problem I&#39;m having is that it instead of being directed to the URL, it instead is redirected to the following <strong>consent page</strong> that needs accepting. <a href=\"https://consent.google.com/m?continue=https://news.google.com/rss/articles/CBMimwFBVV95cUxNVmJMNUdiamVCNkJSb1E4NVU0SlBFQUNneXpEaHFuRUJpN3lwRXFNNGdRalpITmFUQUh4Z3lsOVZ4e",
        "id": 2276157,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j6i7t6/scraping_information_from_google_news_overcoming",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping information from Google News - overcoming consent forms",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-08T13:02:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m starting a pet project that is supposed to scrape data, and anticipate to run into quite a bit of captchas, both invisible and those that require human interaction.<br/> Is it feasible to scrape data in such environment with BS, or should I abandon this idea and try out Selenium or Puppeteer from right from the start?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/purelyceremonial\"> /u/purelyceremonial </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j6gows/is_beautifulsoup_viable_in_2025/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j6gows/is_beautifulsoup_viable_in_2025/\">[comments]</a></span>",
        "id": 2275557,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j6gows/is_beautifulsoup_viable_in_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is BeautifulSoup viable in 2025?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-08T12:00:49+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1j6fp32/innovation_comes_from_necessity_automated_spotify/\"> <img src=\"https://external-preview.redd.it/u9pLqM5-jTlbDG1kZlI-MPZLIEXRTzt7XyDXGK0JPJQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e3aff2e9036f84fb1d407d611fbcc9b7a7113ab2\" alt=\"Innovation comes from necessity! Automated Spotify Downloads.\" title=\"Innovation comes from necessity! Automated Spotify Downloads.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hello everyone, with the increasing monopoly of the Big Tech on our lives and attention I believe it is time to make use of the old ways. I have created a python script to automate song downloads from spotify Liked playlist. It will take some time depending on the number of songs you have in your Liked playlist.</p> <p>I was fed up of ads, so I just had to figure something out myself. I am sure all the devs will have no problem running this script and also modifying it to their liking but I h",
        "id": 2275305,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j6fp32/innovation_comes_from_necessity_automated_spotify",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/u9pLqM5-jTlbDG1kZlI-MPZLIEXRTzt7XyDXGK0JPJQ.jpg?width=640&crop=smart&auto=webp&s=e3aff2e9036f84fb1d407d611fbcc9b7a7113ab2",
        "title": "Innovation comes from necessity! Automated Spotify Downloads.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-08T09:00:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The header already explains it well, I own a digital marketing agency and oftentimes, my leads have a Google maps / google business acc. So I can scrape all informations, but mostly still no email address ? However, my cold outreach ist mostly through email- how do I find any details to the contact person / business email, if their online presence is not really good.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/InternetVisible8661\"> /u/InternetVisible8661 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j6d8sk/how_to_find_out_the_email_of_a_potential_lead/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j6d8sk/how_to_find_out_the_email_of_a_potential_lead/\">[comments]</a></span>",
        "id": 2274814,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j6d8sk/how_to_find_out_the_email_of_a_potential_lead",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to find out the email of a potential lead with no website ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-08T05:44:15+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1j6ag7v/why_cant_puppeteer_find_any_element_in_this/\"> <img src=\"https://b.thumbs.redditmedia.com/edGeYOil2TPt0vd_iHdtW6IgrOEMCWR9o23kruvrV0A.jpg\" alt=\"Why can't Puppeteer find any element in this drop-down menu?\" title=\"Why can't Puppeteer find any element in this drop-down menu?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/m2z6pyjhlene1.png?width=3377&amp;format=png&amp;auto=webp&amp;s=d13b5a61f38a292f2167c0bcd14d3a30e065817f\">https://preview.redd.it/m2z6pyjhlene1.png?width=3377&amp;format=png&amp;auto=webp&amp;s=d13b5a61f38a292f2167c0bcd14d3a30e065817f</a></p> <p>Trying to find any element in this search-suggestions div and Puppeteer can&#39;t find anything I try. It&#39;s not an iframe, not sure what to try and grab? Please note that this drop-down dynamically appears once you&#39;ve started typing in the text-input.</p> <p>Any suggestions?</p> </div><!-- SC_ON --> &#3",
        "id": 2274232,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j6ag7v/why_cant_puppeteer_find_any_element_in_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/edGeYOil2TPt0vd_iHdtW6IgrOEMCWR9o23kruvrV0A.jpg",
        "title": "Why can't Puppeteer find any element in this drop-down menu?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-08T03:25:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>After countless hours spent automating tasks only to get blocked by Cloudflare, rage-quitting over reCAPTCHA v3 (why is there no button to click?), and nearly throwing my laptop out the window, I built PyDoll. </p> <p>GitHub: <a href=\"https://github.com/thalissonvs/pydoll/\">https://github.com/thalissonvs/pydoll/</a> </p> <p>It\u2019s not magic, but it solves what matters:<br/> - Native bypass for reCAPTCHA v3 &amp; Cloudflare Turnstile (just click in the checkbox).<br/> - 100% async \u2013 because nobody has time to wait for requests.<br/> - Currently running in a critical project at work (translation: if it breaks, I get fired). </p> <p>FAQ (For the Skeptical): - \u201cIs this illegal?\u201d \u2192 No, but I\u2019m not your lawyer.<br/> - \u201cDoes it actually work?\u201d \u2192 It\u2019s been in production for 3 months, and I\u2019m still employed.<br/> - \u201cWhy open-source?\u201d \u2192 Because I suffered through building it, so you don\u2019t have to (or you can help make it better). </p> <p>For those struggling wit",
        "id": 2273911,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j683ag/the_library_i_built_because_i_hate_selenium",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The library I built because I hate Selenium, CAPTCHAS and my own life",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-08T02:26:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been playing around with the search functionality in ChatGPT and it&#39;s honestly impressive. I&#39;m particularly wondering how they scrape the internet in such a fast and accurate manner while retrieving high quality content from their sources.</p> <p>Anyone have an idea? They&#39;re obviously caching and scraping at intervals, but anyone have a clue how or what their method is?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok_Coyote_8904\"> /u/Ok_Coyote_8904 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j670vi/how_does_openai_scrape_sources_for_gptsearch/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j670vi/how_does_openai_scrape_sources_for_gptsearch/\">[comments]</a></span>",
        "id": 2273734,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j670vi/how_does_openai_scrape_sources_for_gptsearch",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How does OpenAI scrape sources for GPTSearch?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-08T00:57:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am interested in parsing some data in a mobile only page. I was able to setup MITMProxy and see the traffic and get most of it done. However, the app seems to generate ASP.NET_SessionId out of thin air then register it to the server. And I can&#39;t find a way to replicate the behavior. If I copy the ASP.NET_SessionId into my code, it works fine.</p> <p>As a result I am giving out a bounty for someone who can successfully automate this first. If you are interested, please reach out via DM. I have a google doc with details description of the requirement, as well as testing code.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GabrielXiao\"> /u/GabrielXiao </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j65b0z/bounty_500_usd_want_some_help_parsing_an_mobile/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j65b0z/bounty_500_usd_want_some_help_parsing_",
        "id": 2273326,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j65b0z/bounty_500_usd_want_some_help_parsing_an_mobile",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Bounty $500 USD: Want some help parsing an mobile only page",
        "vote": 0
    }
]