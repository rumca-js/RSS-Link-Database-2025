[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-16T21:16:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi there,</p> <p>I&#39;m experiencing a really weird error trying to use Selenium in Docker. The most frustrating part is that I&#39;ve had this working when I move it over to other machines, then all of a sudden I&#39;m getting this error: selenium.common.exceptions.SessionNotCreatedException: Message: session not created: probably user data directory is already in use, please specify a unique value for --user-data-dir argument, or don&#39;t use --user-data-dir. I&#39;ve tried setting different --user-data-dir settings, playing around with permissions for those folders, all sorts of different things but I&#39;m at my wits end.</p> <p>Any thoughts?</p> <p>I have a tonne more info I can provide along with code, etc. but just wondering maybe someone has encountered this before and it&#39;s something simple?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/zpnrg1979\"> /u/zpnrg1979 </a> <br/> <span><a href=\"https://w",
        "id": 2336967,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jcvz78/issue_with_selenium_in_docker",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Issue with Selenium in Docker -- SessionNotCreatedException",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-16T13:15:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to scrape an eCommerce store to create a chatbot that is aware of the store data (RAG).<br/> I am using crawl4ai but the scrapping takes forever...</p> <p>My current flow is as follows:</p> <ol> <li>look for `robots.txt` try to find the index sitemap, if not found try to use well-known sitemap locations: <code> &quot;/sitemap.xml&quot;, &quot;/sitemap\\_index.xml&quot;, &quot;/sitemap/sitemap.xml&quot;, &quot;/wp-sitemap.xml&quot;, &quot;/wp-sitemap-posts-post-1.xml&quot; </code></li> </ol> <p>if not found i&#39;m using the homepage and following the links in it (as long as they are in the same domain)</p> <ol> <li>Categorize the content by the <code>url</code> (<code>/product/, /faq</code> etc...) <strong>Q</strong>. Is there a better way? somehow to leverage the LLM for the categorization process</li> </ol> <p>``` if content_type == &#39;product&#39;: logger.debug(f&quot;Using product config for URL: {url}&quot;) return self.product_c",
        "id": 2334417,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jcl77v/ecommerce_scraping_for_rag",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "eCommerce scraping for RAG",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-16T07:24:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><h1>I&#39;m completely new to webscraping. I was wondering how does a promptable AI scraper work? Does it dyncamically set css selectors based on the prompt or it just passes the full budy html for AI parsing? This latter scenario seems irrealistic due to input token limits!?</h1> <p>Example prompts it works great for:</p> <p>- Help me find out pricing plan of {company}</p> <p>- What references does {company} have</p> <p>- Is {company} a B2B company</p> <p>edit: promptable</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/xxxxx3432524\"> /u/xxxxx3432524 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jcg5fh/promtable_ai_scraper_how_do_they_work/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jcg5fh/promtable_ai_scraper_how_do_they_work/\">[comments]</a></span>",
        "id": 2333039,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jcg5fh/promtable_ai_scraper_how_do_they_work",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Promtable AI scraper. How do they work?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-16T07:11:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I tried scraping it but it didn\u2019t work. Ran into cloud flare issues </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Brave_Bullfrog1142\"> /u/Brave_Bullfrog1142 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jcfzic/is_it_possible_to_web_scrape_chatgptcom/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jcfzic/is_it_possible_to_web_scrape_chatgptcom/\">[comments]</a></span>",
        "id": 2333040,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jcfzic/is_it_possible_to_web_scrape_chatgptcom",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is it possible to web scrape ChatGPT.com?",
        "vote": 0
    }
]