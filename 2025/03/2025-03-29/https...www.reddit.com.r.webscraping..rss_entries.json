[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T22:12:51+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1jmxoa5/i_built_an_open_source_library_to_generate/\"> <img src=\"https://external-preview.redd.it/-ZbgSdf9brNo1nMxkPkgcs2DeU1-NCPtdSjQ0LtArTE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=af1f4e208d8223afe95fb9004ac2a32ebc054a3f\" alt=\"I built an open source library to generate Playwright web scrapers using AI\" title=\"I built an open source library to generate Playwright web scrapers using AI\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Generate Playwright web scrapers using AI. Describe what you want -&gt; get a working spider. \ud83d\udcaa\ud83c\udffc\ud83d\udcaa\ud83c\udffc</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/carlosplanchon\"> /u/carlosplanchon </a> <br/> <span><a href=\"https://github.com/carlosplanchon/spidercreator/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmxoa5/i_built_an_open_source_library_to_generate/\">[comments]</a></span> </td></tr></table>",
        "id": 2439869,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmxoa5/i_built_an_open_source_library_to_generate",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/-ZbgSdf9brNo1nMxkPkgcs2DeU1-NCPtdSjQ0LtArTE.jpg?width=640&crop=smart&auto=webp&s=af1f4e208d8223afe95fb9004ac2a32ebc054a3f",
        "title": "I built an open source library to generate Playwright web scrapers using AI",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T22:12:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am currently trying to pass the turnstile captcha on a website to be able to complete a purchase directly via API. (it is a background request, the classic case that a turnstile widget is created on the website with a token) </p> <p>Does anyone have experience with CLoudflare turnstile and know how to \u201cbypass\u201d the system? I am currently using a real browser to recreate turnstile.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Erzengel9\"> /u/Erzengel9 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmxnnj/cloudflare_turnstile_cirumventing_captcha/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmxnnj/cloudflare_turnstile_cirumventing_captcha/\">[comments]</a></span>",
        "id": 2439870,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmxnnj/cloudflare_turnstile_cirumventing_captcha",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cloudflare Turnstile Cirumventing Captcha",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T21:43:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Here&#39;s some HTML</p> <p>&lt;meta property=&quot;og:title&quot; content=&quot;XXX&quot;&lt;/meta&gt;</p> <p>There are many meta tags but I want the one where property is &quot;og:title&quot;.</p> <p>I&#39;ve tired variants of</p> <p>soup.find_all(&quot;meta&quot;, {&quot;property&quot;,&quot;og:title&quot;})</p> <p>but those don&#39;t work. However, if I do</p> <p>x = soup.find_all(&quot;meta&quot;)</p> <p>I find it at index 5</p> <p>x[5]</p> <p>&lt;meta &lt;=&quot;&quot; content=&quot;XXX&quot; meta=&quot;&quot; property=&quot;og:title&quot;/&gt;</p> <p>What&#39;s the secret to finding this without resorting to a loop? Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/madmyersreal\"> /u/madmyersreal </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmx1jd/python_beautifulsoup_and_meta_problem/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jm",
        "id": 2439871,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmx1jd/python_beautifulsoup_and_meta_problem",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Python Beautifulsoup and meta problem",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T15:46:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to scrape a site(can\u2019t mention it due to filters) but it starts with Linked and ends with In. </p> <p>I came across this chrome extension that does exactly what I need but I\u2019m curious on how it\u2019s even implemented. I imagine the chrome extension is just getting the pages html. But also there are PDFs on the page that it is able to download. How is this possible?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/bruhidk123345\"> /u/bruhidk123345 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmp61s/chrome_extensions_and_pdfs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmp61s/chrome_extensions_and_pdfs/\">[comments]</a></span>",
        "id": 2438298,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmp61s/chrome_extensions_and_pdfs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Chrome Extensions and PDFs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T15:01:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Guys, how can i fetch the public_email field meta (i*ns*ta*gram) on requests?</p> <pre><code>{ &quot;response&quot;: { &quot;data&quot;: { &quot;user&quot;: { &quot;friendship_status&quot;: { &quot;following&quot;: false, &quot;blocking&quot;: false, &quot;is_feed_favorite&quot;: false, &quot;outgoing_request&quot;: false, &quot;followed_by&quot;: false, &quot;incoming_request&quot;: false, &quot;is_restricted&quot;: false, &quot;is_bestie&quot;: false, &quot;muting&quot;: false, &quot;is_muting_reel&quot;: false }, &quot;gating&quot;: null, &quot;is_memorialized&quot;: false, &quot;is_private&quot;: false, &quot;has_story_archive&quot;: null, &quot;supervision_info&quot;: null, &quot;is_regulated_c18&quot;: false, &quot;regulated_news_in_locations&quot;: [], &quot;bio_links&quot;: [ { &quot;image_url&quot;: &quot;&quot;, &quot;is_pinned&quot;: false, &quot;link_type&quot;: &quot;external&quot;, &quot;lynx_url&quot;: &quot;https://l.meta.com/?u=https",
        "id": 2437929,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmo6fm/scraping_business_meta_emails",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Business Meta Emails",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T14:03:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey folks!</p> <p>I\u2019ve built a cloud-based bot using <strong>Playwright</strong> and <strong>Docker</strong>, which works flawlessly locally. However, I\u2019m running into <strong>session management issues</strong> in the cloud environment and would love your suggestions.</p> <h1>The Problem:</h1> <ul> <li>The bot requires user login to interact with a website.</li> <li>Sessions expire due to <strong>inactivity/timeouts</strong>, breaking automation.</li> <li>I need a way to: <ol> <li><strong>Notify users</strong> when their session is about to expire or has expired.</li> <li><strong>Prompt them to re-login</strong> seamlessly (without restarting the bot).</li> <li><strong>Update the new session tokens/cookies</strong> in the backend/database automatically.</li> </ol></li> </ul> <h1>Current Setup:</h1> <ul> <li>Playwright for browser automation.</li> <li>Dockerized for cloud deployment.</li> </ul> <h1>Where I Need Help:</h1> <ol> <li><strong>Session Expi",
        "id": 2437583,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmmyt8/need_help_handling_session_expiry_relogin_for_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need Help Handling Session Expiry & Re-Login for a Cloud-Based Bot",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T09:48:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey there, I am looking for a way to scrape my betting data from my provider which is Tipico. I finally want to see if or.. well how much I&#39;ve lost over the years in total. Maybe it helps me to stop. How should I start? Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Heppenser\"> /u/Heppenser </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmiu12/scraping_my_betting_data_from_tipico/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmiu12/scraping_my_betting_data_from_tipico/\">[comments]</a></span>",
        "id": 2436390,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmiu12/scraping_my_betting_data_from_tipico",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping my betting data from tipico",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T08:56:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m starting this project in telegram @WhatIsPoppinNow That scrape Trending topics from X, Google Trends, Reddit also use Al to summarize and parse .</p> <p>Any interested in this you can follow also can share details also open to any suggestions of improvement about the scraping</p> <p>Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MrMag0-0\"> /u/MrMag0-0 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmi696/scraping_for_trending_topics_and_top_news/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmi696/scraping_for_trending_topics_and_top_news/\">[comments]</a></span>",
        "id": 2436141,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmi696/scraping_for_trending_topics_and_top_news",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping for Trending Topics and Top News",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T08:23:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Im a total noob trying to learn data scraping.From where sould i start and resources should i use ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Over-Examination8663\"> /u/Over-Examination8663 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmhreg/how_can_i_get_started_in_data_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmhreg/how_can_i_get_started_in_data_scraping/\">[comments]</a></span>",
        "id": 2436142,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmhreg/how_can_i_get_started_in_data_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can i get started in data scraping?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T08:14:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.youtube.com/watch?v=DqtlR0y0suo\">https://www.youtube.com/watch?v=DqtlR0y0suo</a></p> <p>was watching this video and realized this might be a useful workaround to extract product information</p> <p>very new to all this, but from what i gathered an ecommerce platform would have to be using internal api&#39;s for this method explained in the link to work</p> <p>perusing some of the sites that i want to scrape, it is not very straightforward to find the relevant sections via fetch/xhr filter </p> <p>anyone able to elaborate on this for me so i can get a better understanding?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/redd_dott\"> /u/redd_dott </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmhn7v/is_this_method_more_reliable_than_html_parsing/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmhn7v/is_this_method_more_reliable_th",
        "id": 2436143,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmhn7v/is_this_method_more_reliable_than_html_parsing",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is this method more reliable than HTML parsing via playwright et al.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T04:39:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"http://truepeoplesearch.com\">truepeoplesearch.com</a> automation to scrape persons phone number based on the home address, I want to make a bot to scrape information from the website. But this website is little bit difficult to scrape, Have you guys scraped this before?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BloodEmergency3607\"> /u/BloodEmergency3607 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmemxz/is_there_any_tool_to_scrape_truepeoplesearch/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmemxz/is_there_any_tool_to_scrape_truepeoplesearch/\">[comments]</a></span>",
        "id": 2435396,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmemxz/is_there_any_tool_to_scrape_truepeoplesearch",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there any tool to scrape truepeoplesearch?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T01:20:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have been scraping with selenium and it\u2019s been working fine. However I am looking to speed things up with beautiful soup. My issue is then when I scrape the site from my local machine, beautiful soup works great. However, my site is using a VPS and only selenium works there. I am assuming beautiful is being blocked by the site I\u2019m trying to scrape. I have tried using residential proxies but to no avail. </p> <p>Does anyone have any suggestions or guidance as so how I can successfully use beautiful soup as it feels much faster. My background is programming. Have only been doing web dev for a couple years and only just stared scraping about a year ago. Any and all help would be appreciated! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Motor_Ship1522\"> /u/Motor_Ship1522 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jmb2nf/selenium_vs_beautiful_soup/\">[link]</a></span> &#32; <span><a",
        "id": 2434873,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jmb2nf/selenium_vs_beautiful_soup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Selenium vs beautiful soup",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-29T00:02:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m new to data scraping. I&#39;m wondering what types of data you guys are mining.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Over-Examination8663\"> /u/Over-Examination8663 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jm9im6/what_sort_of_data_are_you_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jm9im6/what_sort_of_data_are_you_scraping/\">[comments]</a></span>",
        "id": 2434602,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jm9im6/what_sort_of_data_are_you_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What sort of data are you scraping?",
        "vote": 0
    }
]