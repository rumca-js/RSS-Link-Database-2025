[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T23:05:04+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jeioxt/the_jfk_files_have_been_released/\"> <img src=\"https://external-preview.redd.it/VxPPXD7n-KfFP_Y8mcYMtCf5tCq7y9L2w9k4Xg147Vw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=03dfb24c59f6b7fee0b6c234d01d642dbe32dd8f\" alt=\"The JFK files have been released\" title=\"The JFK files have been released\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/omarc1492\"> /u/omarc1492 </a> <br/> <span><a href=\"https://www.archives.gov/research/jfk/release-2025\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jeioxt/the_jfk_files_have_been_released/\">[comments]</a></span> </td></tr></table>",
        "id": 2354277,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jeioxt/the_jfk_files_have_been_released",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/VxPPXD7n-KfFP_Y8mcYMtCf5tCq7y9L2w9k4Xg147Vw.jpg?width=640&crop=smart&auto=webp&s=03dfb24c59f6b7fee0b6c234d01d642dbe32dd8f",
        "title": "The JFK files have been released",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T22:35:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Are these recertified drives any good? <a href=\"https://www.amazon.com/Seagate-Recertified-Exos-Internal-Drive/dp/B0DTSVC7H7\">https://www.amazon.com/Seagate-Recertified-Exos-Internal-Drive/dp/B0DTSVC7H7</a></p> <p>I&#39;m using it for financial data that can be re-downloaded so data loss wouldn&#39;t be that critical.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dheera\"> /u/dheera </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jei0vv/are_seagate_recertified_drives_any_good/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jei0vv/are_seagate_recertified_drives_any_good/\">[comments]</a></span>",
        "id": 2354278,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jei0vv/are_seagate_recertified_drives_any_good",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are Seagate recertified drives any good?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T22:33:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently ordered a dual bay NVMe SSD enclosure that takes up to 8TB each for a total of 16TB, for longevity / future use.</p> <p>But for now, I only need 4 TB, so I just purchased one 4TB &quot;drive&quot; (is this the right word?). I didn&#39;t do two x 2 TBs because I wanted the option to buy the second 4 TB &quot;drive&quot; when I needed it, instead of having to overhaul the whole thing.</p> <p>However, it just dawned on me that perhaps this might cause instability issues -</p> <p>Is it generally a bad practice to leave one bay empty in this type of enclosure, or is it safe to proceed with just one 4TB drive in the 2 bay device?</p> <p>Thank you in advance for your generous time - Theresa</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/meandererai\"> /u/meandererai </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jehyzq/2_bay_nvme_technical_question_ok_to_add_just_1/\">[link]</a></spa",
        "id": 2354279,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jehyzq/2_bay_nvme_technical_question_ok_to_add_just_1",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "2 Bay (NVMe) technical question - OK to add just 1?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T19:58:16+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MioCuggino\"> /u/MioCuggino </a> <br/> <span><a href=\"https://old.reddit.com/r/selfhosted/comments/1jedzev/help_me_make_the_leap_beelink_s12_pro_to_synology/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jee9l4/crosspost_help_me_make_the_leap_beelink_s12_pro/\">[comments]</a></span>",
        "id": 2352952,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jee9l4/crosspost_help_me_make_the_leap_beelink_s12_pro",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "CrossPost - Help me make the leap - Beelink S12 PRO to ??? (Synology DS1821+?)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T19:43:13+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jedwkw/bad_health_status_for_brand_ramsta/\"> <img src=\"https://preview.redd.it/70yk4z1e4ipe1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0bce40bfcbd79e748f7b4d38802f2dd0aef2438e\" alt=\"Bad Health Status for brand (Ramsta)\" title=\"Bad Health Status for brand (Ramsta)\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>i got Bad Health Status for brand (Ramsta). I can&#39;t find any sources about the lifetime and warranty of this SSD. Can&#39;t find also how much can it write, it should be on terabytes right? It&#39;s currently on 5733 GB.</p> <p>Anybody know if this is a false positive or it&#39;s actually bad?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Michael679089\"> /u/Michael679089 </a> <br/> <span><a href=\"https://i.redd.it/70yk4z1e4ipe1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jedwkw/bad_health_status_for_bran",
        "id": 2352951,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jedwkw/bad_health_status_for_brand_ramsta",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/70yk4z1e4ipe1.png?width=640&crop=smart&auto=webp&s=0bce40bfcbd79e748f7b4d38802f2dd0aef2438e",
        "title": "Bad Health Status for brand (Ramsta)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T18:45:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i have had issues with archiving SNSD pictures with my 2TB nvme drive (it dies after it gets half full) Are hard drives still the best thing to mass archive pictures on? I&#39;m talking 2 million pictures. JPG/JPEG. [yes i know this is weird but i have been a fan of them since i was 14] love you guys please help if you have time &lt;3</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MuseManiac\"> /u/MuseManiac </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jecg2s/best_storage_type_for_image_archival_3/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jecg2s/best_storage_type_for_image_archival_3/\">[comments]</a></span>",
        "id": 2352389,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jecg2s/best_storage_type_for_image_archival_3",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "best storage type for image archival? <3",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T18:28:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>WD external 3 TB elements. Had it for 9 years, connects just fine to my TV still to watch video from I just worry something may be going on with it.</p> <p>have another drive doing the same thing. This started after a recent Win 10 update</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/palepatriot76\"> /u/palepatriot76 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jec0y6/all_of_the_sudden_one_of_my_external_hdd_is_not/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jec0y6/all_of_the_sudden_one_of_my_external_hdd_is_not/\">[comments]</a></span>",
        "id": 2352390,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jec0y6/all_of_the_sudden_one_of_my_external_hdd_is_not",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "All of the sudden one of my external HDD is not being recognized on PC or takes several minutes too show up, what does this mean?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T17:34:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>when you save the webpage for a youtube video and it saves the video too, it saves it in a lower quality than the original video. only if you have an account, download the video from youtube, and upload it directly to <a href=\"http://archive.org\">archive.org</a> does it save it in the original quality. i figured this out by downloading a youtube video with jdownloader 2, then downloading the version saved from archive.org&#39;s snapshot of the youtube webpage and comparing the bitrate in properties. the one i downloaded from archive.org had a significantly lower bitrate than the original one on youtube downloaded with jdownloader 2. i then took my own youtube video and hashed it with Get-FileHash in powershell. i uploaded a copy of my youtube video directly to archive.org, then downloaded it back from archive.org, hashed the freshly downloaded copy from archive.org, and compared the hashes. the hash from the uploaded to archive.org then downloaded ag",
        "id": 2351849,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jeape3/til_archiveorg_doesnt_save_the_original_quality",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "TIL archive.org doesn't save the original quality of youtube videos (and how to 'fix' it)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T17:31:02+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jeam12/chief_keef_uf_overload_2009/\"> <img src=\"https://b.thumbs.redditmedia.com/VlGE9KXPbowBoHjQvzHQH5urizrhdwROK9DeA2EB74A.jpg\" alt=\"Chief Keef - U.F Overload (2009)\" title=\"Chief Keef - U.F Overload (2009)\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hello, just askin if anyone has this lost mixtape, it&#39;s apparently been on DatPiff and SoulSeekQt years ago? Been tryna find it since 2014.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tendovvi\"> /u/Tendovvi </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1jeam12\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jeam12/chief_keef_uf_overload_2009/\">[comments]</a></span> </td></tr></table>",
        "id": 2351852,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jeam12/chief_keef_uf_overload_2009",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/VlGE9KXPbowBoHjQvzHQH5urizrhdwROK9DeA2EB74A.jpg",
        "title": "Chief Keef - U.F Overload (2009)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T17:25:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking for ways to archive entire public Facebook posts of a certain profile, I need a tool that can extract and save all posts efficiently, is there anyway to do this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/elontusk998\"> /u/elontusk998 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jeah01/any_way_to_archive_facebook_public_posts/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jeah01/any_way_to_archive_facebook_public_posts/\">[comments]</a></span>",
        "id": 2351850,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jeah01/any_way_to_archive_facebook_public_posts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any way to archive facebook public posts",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T16:41:58+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1je9ebh/ia_interact_making_the_internet_archive_cli_tool/\"> <img src=\"https://preview.redd.it/y3kqcoab7hpe1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=745d3209a68082d271bacde6dab79a139a101824\" alt=\"IA Interact - Making the Internet Archive CLI tool usable for everyone.\" title=\"IA Interact - Making the Internet Archive CLI tool usable for everyone.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://github.com/harrypm/IA-Interact\">IA Interact</a> is a simple wrapper, that makes the pain in the ass that is <a href=\"https://archive.org/developers/internetarchive/cli.html\">Internet Archive CLI</a> Usable to a lot more people.</p> <p>This cost me hours of lifespan and fighting Copilot to get everything working, but now I am no longer tied to the GUI web tool that has for 2 weeks not been reliable. </p> <p>Basically did all this just so I could finish the <a href=\"https://archive.org/details/Vid",
        "id": 2351278,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je9ebh/ia_interact_making_the_internet_archive_cli_tool",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/y3kqcoab7hpe1.png?width=640&crop=smart&auto=webp&s=745d3209a68082d271bacde6dab79a139a101824",
        "title": "IA Interact - Making the Internet Archive CLI tool usable for everyone.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T16:00:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This website (<a href=\"https://www.raremaps.com/gallery/detail/71035/second-world-war-germany-das-grossdeutsche-reich-artaria-co-freytag-berndt\">https://www.raremaps.com/gallery/detail/71035/second-world-war-germany-das-grossdeutsche-reich-artaria-co-freytag-berndt</a>) has some interesting old rare maps on it, along with some other sites. However, when you click download, it only lets you download a tiny version of it, but I can zoom in on it and see all of the little details. I want to get the full scans off this website but i&#39;m not sure how I could, what format it&#39;s in or what. This stuff has historical importance. I don&#39;t just want someone to do it for me, I also want to know how to do it myself.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LindyKamek\"> /u/LindyKamek </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je8egs/need_help_downloading_maps_off_websites/\">[link]",
        "id": 2351279,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je8egs/need_help_downloading_maps_off_websites",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help downloading maps off websites",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T15:22:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone! I\u2019m a mod from <a href=\"/r/UgreenNASync\">r/UgreenNASync</a>, and we\u2019ve partnered with <a href=\"/r/DataHoarder\">r/DataHoarder</a> to emphasize the importance of backup best practices\u2014something crucial for all of us to stay on top of. With World Backup Day coming up on March 31st, we\u2019re bringing the community together to share tips, experiences, and strategies to keep your data safe. It\u2019s all about supporting each other in avoiding data disasters and ensuring everyone knows how to protect what matters most, all under the theme: <strong>Backup Your Data, Protect Your World.</strong></p> <p><strong>Event Duration</strong>:<br/> Now through April 1 at 11:59 PM (EST).<br/> \ud83c\udfc6 Winner Announcement: April 4, posted here.</p> <p>\ud83d\udca1 <strong>How to Participate:</strong><br/> Everyone is welcome! First upvote the post, then simply comment below with anything backup-related, such as:</p> <ul> <li>Why backups matter to you</li> <li>Devices you use (or p",
        "id": 2350650,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je7hs9/prevent_data_disasters_share_your_backup_secrets",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Prevent Data Disasters: Share Your Backup Secrets & Win Big!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T15:06:51+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1je74sk/extremely_large_old_hdd_any_ideas_what_it_is/\"> <img src=\"https://b.thumbs.redditmedia.com/shHKeh4ffw8-SFHczbx5kz6gOv-2BW2uN1SDWVKR0RQ.jpg\" alt=\"Extremely large old HDD. Any ideas what it is?\" title=\"Extremely large old HDD. Any ideas what it is?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/ecizww6tqgpe1.png?width=4080&amp;format=png&amp;auto=webp&amp;s=46763133f8ef9d16c3ecc55488038887a18b3e89\">https://preview.redd.it/ecizww6tqgpe1.png?width=4080&amp;format=png&amp;auto=webp&amp;s=46763133f8ef9d16c3ecc55488038887a18b3e89</a></p> <p>I have this thing sitting on a shelf. Normal 2.5inch SSD for scale.</p> <p><a href=\"https://preview.redd.it/6h6nwhx0rgpe1.png?width=4080&amp;format=png&amp;auto=webp&amp;s=6fa9f5c084ea4bc2700fd2fb7ed2f3ee4dbd1b30\">https://preview.redd.it/6h6nwhx0rgpe1.png?width=4080&amp;format=png&amp;auto=webp&amp;s=6fa9f5c084ea4bc2700fd2fb7ed2f3ee4dbd1",
        "id": 2350651,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je74sk/extremely_large_old_hdd_any_ideas_what_it_is",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/shHKeh4ffw8-SFHczbx5kz6gOv-2BW2uN1SDWVKR0RQ.jpg",
        "title": "Extremely large old HDD. Any ideas what it is?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T14:54:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Would this work?: Connecting PC 1 to PC 2 via HDMI capture card, to stream videos from PC 2 web browser and capture it on PC 1. Also, could it be detected by the website itself (youtube/netflix/etc), and get an IP ban?</p> <p>Also, for the same reasons, can websites such as Library websites detect screenshots if you take screenshots of books, and also get an IP ban?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ChaoticAstronomy\"> /u/ChaoticAstronomy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je6uhb/screen_recording_and_screenshots/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je6uhb/screen_recording_and_screenshots/\">[comments]</a></span>",
        "id": 2350652,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je6uhb/screen_recording_and_screenshots",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Screen Recording and Screenshots",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T14:50:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a use case where I have really large media files that I download. I want to know what would be the best strategy to manage the storage.</p> <p>Buy renewed NAS HDDs to replace my 4TBx2 setup in Synology 220+ What is the largest size I can go for the NAS and is renewed HDD a sound strategy? And from which vendor you would recommend purchasing.</p> <p>Or buy an external 26TB HDD and connect to my existing mini PC for storage of these large media files?</p> <p>TIA</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/y2raza\"> /u/y2raza </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je6qvj/buy_larger_hdd_for_nas/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je6qvj/buy_larger_hdd_for_nas/\">[comments]</a></span>",
        "id": 2350653,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je6qvj/buy_larger_hdd_for_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Buy larger HDD for NAS?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T14:32:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The general advice on Windows backups are use imaging software (I use Veeam) but here&#39;s a question I&#39;ve always had and can&#39;t seem to find any real answer on: is there some reason I can&#39;t use imaging software to backup ONLY the EFI and Recovery partitions and then use something like Kopia to backup the Windows drive?</p> <p>I&#39;m asking because I honestly kind of hate imaging software primarily because if any part of it gets corrupt, then whole thing is gone - I&#39;ve had this happen with Veeam a few times and, yes, as a data hoarder :) I had a backup to my backup so in the end it was okay but the stress sucked!</p> <p>But honestly, my strong preference would be to image the necessary boot partitions and then use Kopia with VSS to backup everything on my Windows drive. That&#39;s basically how it works on Linux - you backup your system and home folder and then, if you need to restore, reinstall the OS from a live drive then just cop",
        "id": 2351280,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je6cql/windows_backup_question_i_cant_get_a_straight",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Windows backup question I can't get a straight answer on",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T13:49:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have stored them on Google photos and Amazon photos, although I\u2019m more fond of Amazon photos as I find it easier to use and weirdly, Google photos often compresses my photos when I redownload them. </p> <p>Might have to cancel the Amazon photos subscription annoyingly &amp; I\u2019ve heard that Google photos isn\u2019t the most secure and might even remove/compress photos if you ever cancel the subscription.</p> <p>I would like easy access to my photos - I don\u2019t know much on USB sticks and whatever, but I don\u2019t want to have to open up my laptop every time I want to redownload/look at deleted photos. What would you guys recommend? My phone is an IPhone 12 Pro Max as well, I\u2019m unsure on ICloud. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Adventurous-Smoke-41\"> /u/Adventurous-Smoke-41 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je5e6f/180k_photos_saved_whats_the_best_way_to_store_them/\">[l",
        "id": 2351281,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je5e6f/180k_photos_saved_whats_the_best_way_to_store_them",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "180K+ photos saved - what\u2019s the best way to store them?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T12:52:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, as mentioned above, I am using use PhotoRec 7.2 WIP.</p> <p>As of now 50% recovery took about morethan 10 Hours.</p> <p>Is this is correct or I am missing something. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/WealthCraftsman\"> /u/WealthCraftsman </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je489f/whats_the_time_required_for_1_tb_data_recovery_in/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je489f/whats_the_time_required_for_1_tb_data_recovery_in/\">[comments]</a></span>",
        "id": 2349368,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je489f/whats_the_time_required_for_1_tb_data_recovery_in",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's the time required for 1 TB data recovery in PhotoRec",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T12:43:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m finding a Windows program that could track the data within a folder. Like GIT or GIT LFS, it could detect changes within a folder, track the changes like adding files, moving files, deleting files. Commit a &quot;version&quot; of the changed dataset.</p> <p>And the most important part, and it&#39;s not easy to do with GIT - <strong>Able to apply the changes to other cold storage copies according to the commit.</strong> You could do git push when you have a git server running. But I don&#39;t prefer setting up a git server, and I only have multiple copies of cold storage, none of them are &quot;primary&quot;.</p> <p>It&#39;ll be amazing to just handle a single copy of data, arrange it, update it, and when other cold storages are online, I could just press a button to pass the update to the other copy instead of manually arranging the folders in the other copy again. And it&#39;ll be very clear to see the other backup is X commits behind.</p> <",
        "id": 2349367,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je41n8/how_would_you_deal_with_data_updates_in_terms_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How would you deal with data updates in terms of cold storages?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T11:01:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.adorama.com/wd260kfgx.html\">https://www.adorama.com/wd260kfgx.html</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ghostyroasty\"> /u/ghostyroasty </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je2b5h/possible_price_error_wd_red_pro_26_tb_24798/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je2b5h/possible_price_error_wd_red_pro_26_tb_24798/\">[comments]</a></span>",
        "id": 2348358,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je2b5h/possible_price_error_wd_red_pro_26_tb_24798",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Possible price error. WD Red Pro 26 TB $247.98?!?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T10:24:48+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1je1r8k/best_sata_ssd/\"> <img src=\"https://b.thumbs.redditmedia.com/GnV3sKnI3-gcFNKohDgjhFkhWVm9EhBM68VpxVy-FhI.jpg\" alt=\"Best SATA SSD\" title=\"Best SATA SSD\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;m currently looking to max out an old Ideapad to just expand my mobile workstation and storage for things like photos (saving in JPG and RAW really take a lot of space). Between these two SATA drives which I found are the ones to get the most recommendations, which is better? I can see that there are some minor differences 20MB/s Sequential Write, but many still stand by Crucial MX500.</p> <p><a href=\"https://preview.redd.it/li7mr7yvcfpe1.png?width=530&amp;format=png&amp;auto=webp&amp;s=5a0e7b48c7ea274f965b04802bf87f1221260696\">https://preview.redd.it/li7mr7yvcfpe1.png?width=530&amp;format=png&amp;auto=webp&amp;s=5a0e7b48c7ea274f965b04802bf87f1221260696</a></p> </div><!-- SC_ON --> &#32; submitted by",
        "id": 2348359,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je1r8k/best_sata_ssd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/GnV3sKnI3-gcFNKohDgjhFkhWVm9EhBM68VpxVy-FhI.jpg",
        "title": "Best SATA SSD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T09:51:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Anyone know if there are upcoming deals for this for example cloud backup provders, backup apps, hard drives etc? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/movingtolondonuk\"> /u/movingtolondonuk </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je1a7f/world_backup_day_march_31st_any_deals/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je1a7f/world_backup_day_march_31st_any_deals/\">[comments]</a></span>",
        "id": 2347935,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je1a7f/world_backup_day_march_31st_any_deals",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "World Backup Day March 31st - Any deals?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T08:54:57+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1je0jml/you_can_now_have_a_selfhosted_spotifylike/\"> <img src=\"https://external-preview.redd.it/O_XUm0ywlFsvwV9tefKiLxUh6p-gff2RJdKPhU1t6GQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ede7df7613620933e39bff3b45c1e2a17c2029b6\" alt=\"You can now have a self-hosted Spotify-like recommendation service for your local music library.\" title=\"You can now have a self-hosted Spotify-like recommendation service for your local music library.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Another__one\"> /u/Another__one </a> <br/> <span><a href=\"https://youtu.be/vux7mDaRCeY\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1je0jml/you_can_now_have_a_selfhosted_spotifylike/\">[comments]</a></span> </td></tr></table>",
        "id": 2347592,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je0jml/you_can_now_have_a_selfhosted_spotifylike",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/O_XUm0ywlFsvwV9tefKiLxUh6p-gff2RJdKPhU1t6GQ.jpg?width=320&crop=smart&auto=webp&s=ede7df7613620933e39bff3b45c1e2a17c2029b6",
        "title": "You can now have a self-hosted Spotify-like recommendation service for your local music library.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T08:36:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Dear All, I\u2019ve been a happy Synology user for many years though - to tell you the truth - I never had an incident that put the resilience of my storage setup to the test.</p> <p>Synology offers something they call Cloud Sync that - like the name suggests - can synchronize a NAS folder or volume with - for example - an S3 resource on AWS or other supporting cloud providers . The NAS encrypts the contents at source and stores the key to keep operating without the need of an admin intervention every time something needs to be synchronized.</p> <p>I\u2019ve realized in the last few days, though, that - in case of NAS failure - my only option is to use some Synology \u201cCloud Sync Decryption Tool\u201d software that only runs on windows or x86 Ubuntu and Fedora Linux. As the Apple Silicon (aarch64) platform is now almost inevitable for Mac users, it looks like I\u2019d be in big trouble if anything happened. Even installing VirtualBox on my Mac, for example, would require ",
        "id": 2347593,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1je0bwl/a_sustainable_nas_choice_for_mac_users",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "A sustainable NAS choice for Mac users",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T05:13:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I been reading comments to encrypt the HDD in case of RMA, but have a few questions as I am a bit new to this. I shucked three 24TB External HDD from Best Buy, but I am worried since they were Seagate Barracudas that they may fail and if I need to RMA them as I would be using them for my Plex server. </p> <ol> <li><p>What encryption program to use that is recommended, preferably free?</p></li> <li><p>Would encrypting a HDD cause an issue with the Plex server accessing the movies/tv on it?</p></li> <li><p>I see people claim Seagate has to honor their warranty even if you shuck despite Seagate claiming they will not honor it if you shuck it. I have the Best Buy Total Tech Warranty which gives 2 years of warranty. Do I need to keep the external case if I have to RMA, or just the HDD is good enough?</p></li> </ol> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EuSorrow\"> /u/EuSorrow </a> <br/> <span><a href=\"https://ww",
        "id": 2351282,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jdxoyu/what_form_of_encryption_to_use_for_hdd_that_will",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What form of encryption to use for HDD that will be used for a Plex server?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T04:25:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone.</p> <p>Currently I have two main situations.</p> <p>The first is that I have a 5TB HDD, and I use that for torrenting. As I have fast internet, you can imagine just one drive can take issue with trying to seed the many pieces of a torrent (random reads) to the point where it becomes a bottleneck. It should be noted that this is a gaming computer, so I will put a stop to it to make sure that I don&#39;t encounter any stuttering when gaming due to any CPU usage.</p> <p>The second is that I purchased some cheap 1TB drives (I can buy more), and have managed to fill all my SATA ports on my computer. I don&#39;t currently use these extra drives for storing torrent files yet (they are empty), but that is the idea for the future. I&#39;ve become a bit fascinated with the important concept of redundancy (checksums, parity data, that kind of thing), while also wanting to get a bit of a performance improvement out of HDD&#39;s. You&#39;d think I&#",
        "id": 2346611,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jdwyiq/what_should_i_use_to_run_a_cheap_nas_system",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What should I use to run a cheap NAS system?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T03:55:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking for recommendations for file storage / backup for the following scenario and details:</p> <p>Windows only I&#39;m a professional photographer and videgrapher and create 4-6TB a year. I work off a laptop and my router is not in a safe spot for a plugged in Nas nor can I plug my laptop in via network cable during daytime use I&#39;d like a regular backup system and to be able to access 1 or 2 years back of files. File upload/access via wifi would be nice if feasible. </p> <p>Picky I know but what would you all suggest? </p> <p>For now I work off external sandisk SSD and try to have an identical hdd copy of this drive that&#39;s offline and updated monthly but I&#39;m bad at making this a habit. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheGrovester\"> /u/TheGrovester </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jdwg1r/recommations_for_a_photographer/\">[link]</a></s",
        "id": 2346612,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jdwg1r/recommations_for_a_photographer",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Recommations for a photographer.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T02:57:31+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ohwowgee\"> /u/ohwowgee </a> <br/> <span><a href=\"/r/OpenBambu/comments/1jdu84k/backing_up_makerworld_collections/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jdve6n/backing_up_makerworld_collections/\">[comments]</a></span>",
        "id": 2346444,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jdve6n/backing_up_makerworld_collections",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Backing up MakerWorld collections",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T02:10:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just came across this when looking at Lee and Herring&#39;s FIst of Fun. Think I&#39;d seen this before but forgot about it.</p> <p><a href=\"https://vhistory.wordpress.com/\">https://vhistory.wordpress.com/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/steviefaux\"> /u/steviefaux </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jduhiy/vhs_archive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jduhiy/vhs_archive/\">[comments]</a></span>",
        "id": 2346250,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jduhiy/vhs_archive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "VHS archive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T01:49:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have some hardware I can cobble together to make a NAS, but I don&#39;t know if it&#39;s recommended to use what I have.</p> <p>I inherited an M-series Mac mini, and I have a bunch of WD My Passport HDDs that I currently use to backup the laptops in my household and store our family photos. I clone the main drive to the other HDDs in case the drive fails.</p> <p>Are there any concerns with using these USB-powered HDDs as a full-time DAS? While it would be powered on all the time, the backups would happen at night, and otherwise the main activity would be managing photos. In other words, this would be a low-demand NAS.</p> <p>Thanks for your advice!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/julybanana\"> /u/julybanana </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jdu30k/wd_my_passport_hdd_as_fulltime_das/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarde",
        "id": 2346249,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jdu30k/wd_my_passport_hdd_as_fulltime_das",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WD My Passport HDD as full-time DAS?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T01:46:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>When backing up ISOs, I also want to unpack to MKV for easier streaming. My issue, is that every file is labeled the same generic &quot;VTS_02_3&quot; style.</p> <p>I can use VLC to open the ISOs as if watching straight from the DVD, but the title doesn&#39;t change throughout the menus. </p> <p>How can I identify which file is related to which content?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/WolfieVonD\"> /u/WolfieVonD </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jdu0qf/anyway_to_know_which_file_the_index_is_calling/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jdu0qf/anyway_to_know_which_file_the_index_is_calling/\">[comments]</a></span>",
        "id": 2346251,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jdu0qf/anyway_to_know_which_file_the_index_is_calling",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyway to know which file the index is calling for an ISO?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T01:24:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a DVR filled with recordings of TeenNick and Nick rewind and I didn&#39;t know if I should archive it, can anyone give me any advice on whether I should archive it or not</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MADMAN5555555522\"> /u/MADMAN5555555522 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jdtkcb/is_there_any_need_for_teennicknick_rewind_archives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jdtkcb/is_there_any_need_for_teennicknick_rewind_archives/\">[comments]</a></span>",
        "id": 2345980,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jdtkcb/is_there_any_need_for_teennicknick_rewind_archives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there any need for TeenNick/Nick rewind archives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T00:55:47+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jdszbl/200_icloudgoogle_replacement_project_6_months/\"> <img src=\"https://b.thumbs.redditmedia.com/LgcpYb7VOBGP9xxUmCKkCiQH4tfrQby4aTGe4Mn6PSo.jpg\" alt=\"&lt;200\u20ac iCloud/Google Replacement Project - 6 months update + GitHub docs and guide\" title=\"&lt;200\u20ac iCloud/Google Replacement Project - 6 months update + GitHub docs and guide\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I shared this project 6 month ago, with the goal of achieving independence from Google and Apple without monthly fees or expensive hardware.</p> <p>I&#39;m happy to share that I\u2019ve successfully achieved my personal goals, as well as notes from the old post - requesting a written guide, and concerns about security. Thanks for the input, everyone!</p> <ul> <li><strong>iPhone sync</strong>: photo sync and gallery, with external photo sharing.</li> <li><strong>Drive replacement</strong>: web files upload, browse, sharing and download.</li>",
        "id": 2345981,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jdszbl/200_icloudgoogle_replacement_project_6_months",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/LgcpYb7VOBGP9xxUmCKkCiQH4tfrQby4aTGe4Mn6PSo.jpg",
        "title": "<200\u20ac iCloud/Google Replacement Project - 6 months update + GitHub docs and guide",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T00:21:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey Everyone,</p> <p>I need to scan a not insignificant amount of business records and will likely use a Fujitsu ScanSnap iX1600 ADF Scanner - 600 dpi Optical to do the scanning into PDF.</p> <p>My objective in digitising the records is to automate the extraction of the customer data and historical purchases from the PDFs and feed it into a new (TBD) CRM.</p> <p>What&#39;s the best way to achieve the above?</p> <p>Any and all help will be appreciated!</p> <p>Best<br/> Nic</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Particular-Nature138\"> /u/Particular-Nature138 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jds9zt/automating_scanning_to_populating_excelsheets/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jds9zt/automating_scanning_to_populating_excelsheets/\">[comments]</a></span>",
        "id": 2345982,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jds9zt/automating_scanning_to_populating_excelsheets",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Automating scanning to populating Excel/Sheets",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-18T00:10:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>goHardDrive</strong> has <a href=\"https://www.goharddrive.com/MDD-16TB-3-5-SAS-12Gbps-Hard-Drive-p/g01-1499-mdd.htm\">16TB MDD SAS 12Gb/s 3.5&quot; 7200RPM Enterprise Hard Drive</a> (Refurbished, MD16TSAS25672E) for $119.95. Shipping is free.</p> <ul> <li>Note: This is a SAS Hard Drive, it will not compatible with SATA interface.</li> <li>Delivers 7200-RPM spin speed along with sustained data rates up to 250MB/s and burst data rates of 12Gb/s.</li> <li>Stores up to 10 PB in a single 42U rack with helium technology</li> <li>Advanced Write Caching provides a 20% performance boost</li> <li>Up to 21% improvement in IOPS/watt</li> <li>Customised with PowerChoice and RAID Rebuild</li> <li>550 TB/yr \u2014 10\u00d7 the workload rating of desktop drive</li> <li>Stores up to 9 PB in a single 42U rack with helium technology</li> <li>Advanced Write Caching provides a 20% performance boost</li> <li>Perfect for OLTP and HPC applications</li> <li>Hyperscale SAS model",
        "id": 2345764,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jds1ai/16tb_mdd_sas_12gbs_35_7200rpm_enterprise_hard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "16TB MDD SAS 12Gb/s 3.5\" 7200RPM Enterprise Hard Drive - Refurb",
        "vote": 0
    }
]