[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T23:15:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>so youtube has been back giving me warning about ads, but my problem is that idm doesnt show at all on youtube video. does anyone else have the same problem?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Street_Mine_1969\"> /u/Street_Mine_1969 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkppes/does_anyone_else_have_the_same_problem/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkppes/does_anyone_else_have_the_same_problem/\">[comments]</a></span>",
        "id": 2417046,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkppes/does_anyone_else_have_the_same_problem",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "does anyone else have the same problem?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T23:15:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Use pc for storage and Plex server, don\u2019t have a huge list of files, maybe upgrade in the future to a nas, but right now I just need 1 HDD, which one is good quality and durability, speeds etc that people would recommend for future proofing to a NAS and stuff</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sweatydoodoo\"> /u/sweatydoodoo </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkpp1p/recommended_hdd_brand_and_product_for_storing/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkpp1p/recommended_hdd_brand_and_product_for_storing/\">[comments]</a></span>",
        "id": 2417047,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkpp1p/recommended_hdd_brand_and_product_for_storing",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Recommended HDD brand and product for storing movies/tv shows, pc, only need 1 HDD.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T22:46:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am trying to download media from a site using Cyotek Webcopy. Webcopy crashes or errors out periodically during this procedure, so I would like to be able to resume the copy rather than restarting. </p> <p>Can anyone suggest a way to configure the settings so that existing files will be skipped rather than downloading them again?</p> <p>By default, Webcopy starts from be beginning each time and re-downloads the existing files and adds a number to them, so I get duplicates of the same already downloaded files. I don&#39;t know why this would be the default behavior or why this would be useful to anyone.</p> <p>Unfortunately, Cyotek support seems to be offline, and the Cyotek forums were taken offline for maintenance, so the answers to this question are no longer accessible. Even <a href=\"http://archive.org\">archive.org</a> doesn&#39;t have the forum posts indexed.</p> <p>Any help would be greatly appreciated.</p> <p>Thanks</p> </div><!-- SC_ON --> &",
        "id": 2417048,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkp13d/skipping_existing_files_using_cyotek_webcopy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Skipping existing files using Cyotek Webcopy",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T22:15:01+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkobm6/internet_archive_is_currently_offline/\"> <img src=\"https://preview.redd.it/02h3nue2z3re1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b406b8c62dd6d346a4fd5c90d7efdafad5088ee2\" alt=\"Internet Archive is currently offline\" title=\"Internet Archive is currently offline\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Armchair_Anarchy\"> /u/Armchair_Anarchy </a> <br/> <span><a href=\"https://i.redd.it/02h3nue2z3re1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkobm6/internet_archive_is_currently_offline/\">[comments]</a></span> </td></tr></table>",
        "id": 2416696,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkobm6/internet_archive_is_currently_offline",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/02h3nue2z3re1.png?width=640&crop=smart&auto=webp&s=b406b8c62dd6d346a4fd5c90d7efdafad5088ee2",
        "title": "Internet Archive is currently offline",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T21:27:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I&#39;m wanting to download the BBC 1&#39;s Future Pop recorded episodes. I am currently in the USA. </p> <p>I used get_iplayer to extract the audio. It exported .m4a files in 96kbps. I&#39;m wondering if it&#39;s available in higher quality, maybe inside the UK.</p> <p>I am also wanting to eventually cut the audio and have it play as a gapless album. The episode websites has a function that tells you the current song playing and works when you skip around the episode also.</p> <p>Is there a way to exact the timestamp metadata of when the song starts and ends for ease of cutting?</p> <p>Here&#39;s the particular episodes I&#39;m trying to archive before it expires in a few weeks:</p> <p><a href=\"https://www.bbc.co.uk/sounds/play/m0028gdv\">https://www.bbc.co.uk/sounds/play/m0028gdv</a> <a href=\"https://www.bbc.co.uk/sounds/play/m0028rtb\">https://www.bbc.co.uk/sounds/play/m0028rtb</a></p> <p>Thanks,</p> <p>EDIT: As per usual, I find more info ri",
        "id": 2416697,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkn7d4/best_way_to_archive_extract_bbc_1_radio_episodes",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best way to archive extract BBC 1 radio episodes with time stamps",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T20:49:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m a bit terrified right now and don&#39;t know how to best handle it, so I need your advice on this.</p> <p>About 5 years ago (+/- 1 year) I build myself a NAS in a 19&quot; rack based on TrueNAS. 15 HDDs split on 2 pools, later added some SSDs for cache etc. 1 pool consists of 8 12TB drives, shucked from external WD drives, in a single raidz2. The other 7 are 4TB drives from mixed manufacturers and mixed models, in a single raidz3. All drives were new when bought (no refurbished or used parts etc). Got them connected via 2 Dell PERC 310 HBAs in IT mode.</p> <p>The NAS was mostly shut down. I turned it on about once or twice a week for 3-8 hours, all drives spin down when idling for 10 minutes. </p> <p>I had to move in January, so I packed everything together around first week of January. Got the NAS out of the rack, put it in my cars trunk with some blankets around as &quot;buffer&quot;. Drove 10 minutes on normal streets to the new address. U",
        "id": 2416286,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkmbjs/suddenly_my_whole_nas_is_degraded",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Suddenly my whole NAS is degraded?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T20:47:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Way back when, I used to use the Firefox plugin DownThemAll with the AntiContainer add-on to save images from websites to my own collection. The advantage of this setup was it worked within the browser to automatically identify images you wanted to save and then go out and grab those images from the hosting sites directly. Websites often have images hosted on &quot;container&quot; pages so you can&#39;t just save the link to the image otherwise you end up saving an HTML file. The AntiContainer add-on let you create an XML configuration file for each image hosting site (and DownThemAll created a whole bunch of them for you) that tells DownThemAll how to grab the actual image in the container page.</p> <p>I am looking to see if anyone knows of any similar image downloader (preferably a browser plug-in) that allows you to create your own custom capture scheme without relying on the developer to do it for you.</p> </div><!-- SC_ON --> &#32; submitted by ",
        "id": 2416287,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkm9pq/modern_downthemallanticontainer_plugin",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Modern DownThemAll/AntiContainer Plugin",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T19:06:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is there something that I can set running to grab everything from a fansly?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/clarkky55\"> /u/clarkky55 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkjssc/whats_a_good_program_for_saving_fansly_content_to/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkjssc/whats_a_good_program_for_saving_fansly_content_to/\">[comments]</a></span>",
        "id": 2415310,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkjssc/whats_a_good_program_for_saving_fansly_content_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What\u2019s a good program for saving fansly content to my computer?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T18:32:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi!</p> <p>I have an extensive sample library of audio files (about 7 TB), which I use almost every day for work. At the moment, I have two different SSDs (4 TB each) that I carry around. However, it&#39;s a bit inconvenient, as I use twice the ports and it&#39;s a bit annoying to update and search the library, especially with soudly.</p> <p>I thought of buying a 8 TB SSD, and at the moment there are 4 available: SanDisk, Samsung T5, Samsung MZ, and WD_BLACK. I would choose the last one for the high read/write speed - although it&#39;s not that fundamental, as it&#39;s kind of a storage from which I export audio files every day, so I don&#39;t think speed is essential.</p> <p>The question is: since I would connect/disconnect and bring around this SSD often, is it a safer option than HDs when it comes down to durability and damage? Or should I save myself 600 \u20ac and just buy an HD?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.",
        "id": 2415311,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkiyhc/ssds_or_hd_for_my_sample_library",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SSDs or HD for my sample library",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T18:30:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I ordered one of the 28tb and got ST28000DM000 this appears to be a CMR Barracuda drive. please correct me if I&#39;m wrong. Or if there is any test you want me to run on it. </p> <p>So the question I have is should I go with.<br/> Exos Seagate Recertified ST28000NM000C on ebay $335<br/> or new Barracuda STKP28000400 on amazon $330. </p> <p>I have a server with 24 drives. So I&#39;m thinking Exos but idk how used or good the Recertified Drives are but they do come with a 2 year Seller Warranty from server parts deals.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/james7360\"> /u/james7360 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1jkiwut\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkiwut/got_one_of_the_seagate_expansion_desktop_28tb_to/\">[comments]</a></span>",
        "id": 2415308,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkiwut/got_one_of_the_seagate_expansion_desktop_28tb_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Got one of the Seagate Expansion Desktop 28TB to test.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T18:13:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Why does Aliexpress have a bunch of LTO-8 drives listed for $80 to $150? Are these legit? I do notice on one of them you go to the product description and it then says LTO-6 but even that price is still pretty good.</p> <p>Has anyone actually tried ordering one of those? Or is this the IT equivalent of the 8-foot flying ghost from old comic book ads?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/strangelove4564\"> /u/strangelove4564 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkiil4/100_lto_drives_on_aliexpress/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkiil4/100_lto_drives_on_aliexpress/\">[comments]</a></span>",
        "id": 2415312,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkiil4/100_lto_drives_on_aliexpress",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "$100 LTO drives on Aliexpress?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T18:09:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ll be moving over seas soon and taking my hard drives with me in my backpack. (Currently) about 9-10TB of would much prefer it was saved, but not life or death data. </p> <p>I\u2019d like something fairly cheap just as a peace of mind backup. Don\u2019t need anything with super high speeds or anything. </p> <p>Just need upload once, download once (if needed)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NotBashB\"> /u/NotBashB </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkiepu/cheap_ish_way_to_back_up_temporarily_to_the_cloud/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkiepu/cheap_ish_way_to_back_up_temporarily_to_the_cloud/\">[comments]</a></span>",
        "id": 2415309,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkiepu/cheap_ish_way_to_back_up_temporarily_to_the_cloud",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cheap (ish) Way to back up temporarily to the Cloud",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T18:08:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need to offload a bulk of data from my RAID6, and was thinking of getting the 28TB drives. Are these drives just recertified, or do they have platter(s) disabled because 28 is just an unusual number. Also, are these drives HAMR or SMR or PMR?</p> <p>The data I&#39;m going to offload (BD / UHD Full discs), they are not extremely important like photos etc. but I did spend a lot of time collecting them. I am not sure, maybe I will get two drives and have two copies. But how are these drives in general? Those who are using these new drives (24 / 26 / 28), what are your gut feelings about these drives?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/manzurfahim\"> /u/manzurfahim </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkidof/thinking_of_getting_the_28tb_seagate_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkidof/thinking_of_getting_th",
        "id": 2415313,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkidof/thinking_of_getting_the_28tb_seagate_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Thinking of getting the 28TB Seagate drives \ud83d\ude2c",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T17:53:21+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jki0hw/keep_hdds_running_as_long_as_we_can_rather_than/\"> <img src=\"https://preview.redd.it/50alrswgnyqe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d46e4cc7ccb7c6e5783e1d918715bccc39288596\" alt=\"Keep HDDs running as long as we can rather than shutting them down occasionally and power them up to make them last longer?\" title=\"Keep HDDs running as long as we can rather than shutting them down occasionally and power them up to make them last longer?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SomeOrdinary_Indian\"> /u/SomeOrdinary_Indian </a> <br/> <span><a href=\"https://i.redd.it/50alrswgnyqe1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jki0hw/keep_hdds_running_as_long_as_we_can_rather_than/\">[comments]</a></span> </td></tr></table>",
        "id": 2414689,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jki0hw/keep_hdds_running_as_long_as_we_can_rather_than",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/50alrswgnyqe1.jpeg?width=640&crop=smart&auto=webp&s=d46e4cc7ccb7c6e5783e1d918715bccc39288596",
        "title": "Keep HDDs running as long as we can rather than shutting them down occasionally and power them up to make them last longer?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T17:51:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Not even because it just removes videos or let&#39;s people take down videos, it&#39;s UI is bloated and so it allows for mistakes, like I save a video to a playlist but some glitch happens in between my device and the server, so it doesn&#39;t register. Or a short played but it didn&#39;t register on my phone so I didn&#39;t know what the short was until I screenshotted it and image searched it.</p> <p>And on top of that, on the TV app they put the library of video history before subscriptions because they want to retain you with stuff they know you like than risk you leaving for another app if someone you subscribed to made a bad video and you go somewhere else. There have been times on the website where the opposite happens and history isn&#39;t even available. It&#39;s like that instead of letting you look at stuff they just tracked tv and laptop viewers and gave them whichever results that would increase viewer retention.</p> </div><!-- SC_ON --",
        "id": 2414691,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkhz6o/youtube_is_terrible_for_archival",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "YouTube is terrible for archival.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T17:26:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi! </p> <p>I am working a bit at Wikimedia Commons, and there, the shutdown of USGOV websites is a huge topic. Has someone a good advice? </p> <p><a href=\"https://commons.m.wikimedia.org/wiki/Commons:Village_pump\">https://commons.m.wikimedia.org/wiki/Commons:Village_pump</a> (far to the bottom of the page)</p> <p>&quot;With the very likely shutdown of the Voice of America, I&#39;ve begun copying what I can to Wikimedia Commons, before they start deleting their various websites. I&#39;d encourage anyone who has a few moments to go to the VOA websites and copy anything that is copyright-free for use here. Especially if you speak another language, there&#39;s a trove of good information there that will likely be of interest in the future. I doubt much is getting archived by the current US administration either, making this even more important.&quot;</p> <p>Thanks! (Maybe there is even an online mirror or someone already backing up?)</p> </div><!-- SC_O",
        "id": 2414690,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkhc47/help_needed_for_saving_voa_content",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help needed for saving VOA content",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T15:33:17+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkel24/mlogic_in_need_of_repairs/\"> <img src=\"https://b.thumbs.redditmedia.com/BrkdUGcR0-aL13iJT8p5d_LbRzbMlnJAU2iWcFAHDSg.jpg\" alt=\"mLogic in need of repairs\" title=\"mLogic in need of repairs\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Good afternoon fellow data hoarders, I have an mLogic desktop thunderbolt LTO tape drive that is displaying an SCD 5 with a flashing amber exclamation point. Unit is fully up to date on firmware, but I\u2019ve read this means it\u2019s in \u201cerror condition\u201d and internals will likely need to be looked at. </p> <p>I understand this is old tech, but I\u2019m trying to get around sending it to California to be worked on. Does anyone know of a repair facility in the NY metro area that could assist in these repairs? </p> <p>Many thanks </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cdesmith16\"> /u/cdesmith16 </a> <br/> <span><a href=\"https://www.reddit",
        "id": 2413359,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkel24/mlogic_in_need_of_repairs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/BrkdUGcR0-aL13iJT8p5d_LbRzbMlnJAU2iWcFAHDSg.jpg",
        "title": "mLogic in need of repairs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T14:45:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What&#39;s the best windows formatting tool currently for wiping a used disk completely for archival purposes ?</p> <p>I have couple of very old wd black 50ogb internal hdds that I got off off used market which I would like to completely wipe before starting to use em for archival purposes .</p> <p>Is the windows disk management tool enough ? Is command line disklart better ? Or should I be using tools like rufus or lowleveldiskformatting tool by hdd guru or any other software which cleans up disks proper and aligns sectors well ?</p> <p>What&#39;s the best tool / software to completely wipe and old used disk on windows which isn&#39;t too complicated and wudnt cause much issues / harm with a few disks plugged in ?</p> <p>Regards ,</p> <p>ColaFizz</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nikcolafizzzz\"> /u/nikcolafizzzz </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jkdgyr/best_w",
        "id": 2412685,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jkdgyr/best_windows_formatting_tool",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best windows formatting tool ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T11:15:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is there any program/project related to that? Preferably on python.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BeamBlizzard\"> /u/BeamBlizzard </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk9bdx/tiktok_downloader_that_automatically_downloads/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk9bdx/tiktok_downloader_that_automatically_downloads/\">[comments]</a></span>",
        "id": 2411012,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jk9bdx/tiktok_downloader_that_automatically_downloads",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "TikTok Downloader that automatically downloads when a user posts?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T10:52:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What would your approach be to building the quietest possible NAS?</p> <p>Speed and cost per TB are secondary.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SheepherderSelect622\"> /u/SheepherderSelect622 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk8yjs/quietest_nas/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk8yjs/quietest_nas/\">[comments]</a></span>",
        "id": 2411013,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jk8yjs/quietest_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Quietest NAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T08:18:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Background-I am an addict, like many others I have accumulated a large library of games without the time or hardware to run it.</p> <p>Now, I found an old 2tb hdd that I ordered from Amazon and forgot about, it works fine event hough it&#39;s an internal 3.5inch drive running via an adapter with power cable.</p> <p>Should I download my entire library on to the drive just for kicks and free up the storage on my aging laptop (.5tb + .5tb internal and another 1tb connected by usb) all ssd? Will gaming from hard disk be significantly slower?</p> <p>Might built a new system soon, looking for economics of it, so can install this drive into the new PC as games only drive.</p> <p>Thanks for the help.</p> <p>P.s. electric bill avg around $20.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AccomplishedMud110\"> /u/AccomplishedMud110 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk6vli/hdd_vs_ssd",
        "id": 2410112,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jk6vli/hdd_vs_ssd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hdd vs ssd",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T06:41:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is there any cloud provider that provides 8 GB/s throughput SSDs? PCIe 5.0?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ilikebillyhashbrown\"> /u/ilikebillyhashbrown </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk5mct/pcie_50_cloud_provider_for_8_gbs_throughput/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk5mct/pcie_50_cloud_provider_for_8_gbs_throughput/\">[comments]</a></span>",
        "id": 2409559,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jk5mct/pcie_50_cloud_provider_for_8_gbs_throughput",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "PCIe 5.0 cloud provider for 8 Gb/s throughput?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T06:02:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I tried to find a data sheet on it, but every data sheet I found didn&#39;t include this specific model. Is it a typo or a real product?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SnooSeagulls1810\"> /u/SnooSeagulls1810 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk53f1/anyone_got_the_specs_for_the_seagate_st8000ntz01/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk53f1/anyone_got_the_specs_for_the_seagate_st8000ntz01/\">[comments]</a></span>",
        "id": 2409560,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jk53f1/anyone_got_the_specs_for_the_seagate_st8000ntz01",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone got the specs for the Seagate st8000ntz01?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T05:27:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m trying to archive a webpage using services like the Wayback Machine or archive.today, but Cloudflare keeps blocking the crawler with its &quot;Checking your browser&quot; page or CAPTCHA. The site I\u2019m trying to save doesn\u2019t have an existing archive, and manual saving isn\u2019t practical for my use case. </p> <p><strong>What I\u2019ve tried</strong>:<br/> - Wayback Machine, archive.today, and other public archivers.</p> <ol> <li>Are there tools or archivers that can bypass Cloudflare\u2019s anti-bot checks?<br/></li> </ol> <p><em>Any advice or shared experiences would be hugely appreciated!</em> </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MrQmar\"> /u/MrQmar </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk4l6c/how_to_archive_a_web_page_blocked_by_cloudflares/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk4l6c/how_to_archive_a_web_page_blocked_by_clou",
        "id": 2409303,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jk4l6c/how_to_archive_a_web_page_blocked_by_cloudflares",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to Archive a Web Page Blocked by Cloudflare\u2019s Anti-Bot Protection?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T04:05:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am looking for a better backup solution for my security camera setup, but I am debating whether or not to get one of those Ugreen prebuilt NASs instead of building my own and building my first rack. I want to spend at least about 2k because I&#39;d like something that lasts. This would need to be able to scale up to at least four more Rio link cameras as I currently have nine and can&#39;t fit another drive into the DVR itself, so I was looking to use an FTP backup.</p> <p>My biggest concern would be cooling the server. The garage where I am and the security cameras are pretty poorly insulated, so I&#39;m slightly concerned about venting the Heat. I have thought about venting it into the upstairs area between the roof but would rather not. In my mind, the main upsides to building my own would be much better Hardware as well, as it&#39;s roughly about the same price as what I&#39;m looking to spend. I have looked at some used Dell servers that are p",
        "id": 2409099,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jk39w0/prebuilt_versus_building_my_own_for_ftp_backup_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Pre-built versus building my own for FTP backup on security cameras",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T03:25:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Due to cheap manufacturing, Warner HDDVDs AND DVDs from the same era have been found to have incredibly early disc rot, characterized by clouded splotched between the data layer and the protective coat. This is caused by air pockets seeping through when the layers aren&#39;t properly sealed.</p> <p>While HDDVDs had it the worst, some showing clouding even when purchased new at the time, just now, DVDs from the same era are showing the same signs of decay.</p> <p>Someone else has compiled a comprehensive list of the affected releases and you may want to consider backing up your copies if you have them:</p> <p><a href=\"https://drive.google.com/file/d/1CyLGHyuhA2mfhPr4Bkyj8RAapl_0LTmN/\">https://drive.google.com/file/d/1CyLGHyuhA2mfhPr4Bkyj8RAapl_0LTmN/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ninja-Trix\"> /u/Ninja-Trix </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jk2ks1/warner",
        "id": 2409100,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jk2ks1/warner_home_media_dvds_from_20068_are_defective",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Warner Home Media DVDs from 2006-8 are defective!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-26T02:08:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi folks, I&#39;m thinking about building the lowest-possible-cost cold-storage service using Amazon S3 Glacial Deep Archive for infrequently accessed data.</p> <p>The pricing model would be something like:</p> <p>$2/mo fixed base price + $1/tb/mo for storage + $2.5/tb for retrieval (Maybe a small 10% service charge due to stripe fees).</p> <p>What do you think? Would such a service be useful to you?</p> <p>Edit: Why a service over Amazon S3 Glacial Deep Archive directly? - To use Amazon directly you&#39;d have to set up a lot of things: billing, apis, record-keeping for what files are stored where, retrieval. The barrier to entry can be quite high for people who are not technical. I&#39;m curious about what people are currently using for cold storage and whether this price model is better than those.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ybmeng\"> /u/ybmeng </a> <br/> <span><a href=\"https://www.reddit.",
        "id": 2408654,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jk134l/1tbmo_for_cold_storage_what_do_you_think",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "$1/tb/mo for Cold Storage? What do you think?",
        "vote": 0
    }
]