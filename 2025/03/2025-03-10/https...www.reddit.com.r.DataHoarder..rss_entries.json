[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T23:48:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My current 2tb sata drive is failing and I am looking to transfer my data to a new drive. Will be using it as my main boot drive as my motherboard only has one nvme slot.</p> <p>Use case, data archiving, light to medium gaming and basic windows operations.</p> <table><thead> <tr> <th align=\"left\">Brand &amp; Model</th> <th align=\"left\">Capacity</th> <th align=\"left\">Price</th> <th align=\"left\">PCIe Gen</th> <th align=\"left\">Controller</th> <th align=\"left\">DRAM Cache</th> <th align=\"left\">NAND Type</th> </tr> </thead><tbody> <tr> <td align=\"left\"><strong>Kingston NV3</strong></td> <td align=\"left\">4 TB</td> <td align=\"left\">$299.00</td> <td align=\"left\">PCIe 4.0</td> <td align=\"left\">Unknown</td> <td align=\"left\">No</td> <td align=\"left\">QLC</td> </tr> <tr> <td align=\"left\"><strong>TEAMGROUP T-FORCE Z44A7</strong></td> <td align=\"left\">4 TB</td> <td align=\"left\">$299.00</td> <td align=\"left\">PCIe 4.0</td> <td align=\"left\">InnoGrit IG5236</td> <td ali",
        "id": 2292263,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j8d8in/which_of_the_following_ssds_would_you_buy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Which of the following SSD's would you buy?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T23:44:30+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1j8d52h/all_my_portable_storage_in_one_photo/\"> <img src=\"https://preview.redd.it/5cw4wfuf8yne1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1f1f19f1fdac2eac24db473c195171612389c1e7\" alt=\"All my portable storage in one photo.\" title=\"All my portable storage in one photo.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/imtotally6feettall\"> /u/imtotally6feettall </a> <br/> <span><a href=\"https://i.redd.it/5cw4wfuf8yne1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j8d52h/all_my_portable_storage_in_one_photo/\">[comments]</a></span> </td></tr></table>",
        "id": 2292259,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j8d52h/all_my_portable_storage_in_one_photo",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/5cw4wfuf8yne1.jpeg?width=640&crop=smart&auto=webp&s=1f1f19f1fdac2eac24db473c195171612389c1e7",
        "title": "All my portable storage in one photo.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T22:57:42+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1j8c2yo/20yr_old_ide_hdds/\"> <img src=\"https://preview.redd.it/014achf30yne1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=18c4d2c6cfa89448e9410d12dac47095342177cf\" alt=\"20yr old IDE HDD's\" title=\"20yr old IDE HDD's\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>guys - got a cheap adaptor which supplied external power directly from the power outlet and a separate data cable going to USB port. 3 out of 3 20 yr old HDD&#39;s had some smell coming out. Do the electricals of these HDD&#39;s fail easily or is it likely this adaptor PS was just not meant for this purpose? See image. Doesn\u2019t matter much since I can physically erase the HDDs now but just a curiosity question thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dohat34\"> /u/dohat34 </a> <br/> <span><a href=\"https://i.redd.it/014achf30yne1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com",
        "id": 2291865,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j8c2yo/20yr_old_ide_hdds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/014achf30yne1.jpeg?width=640&crop=smart&auto=webp&s=18c4d2c6cfa89448e9410d12dac47095342177cf",
        "title": "20yr old IDE HDD's",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T22:11:16+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PricePerGig\"> /u/PricePerGig </a> <br/> <span><a href=\"https://pricepergig.com/it\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j8azab/i_updated_pricepergigcom_to_add_italy_amazonit_as/\">[comments]</a></span>",
        "id": 2291864,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j8azab/i_updated_pricepergigcom_to_add_italy_amazonit_as",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I Updated PricePerGig.com to add \ud83c\uddee\ud83c\uddf9Italy Amazon.it\ud83c\uddee\ud83c\uddf9 as requested in this sub",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T21:39:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Currently running a home desktop with 6 different internal drives holding about 20 tb of personal media (home photos, videos) spread across them. No raid. Online backup w/backblaze and local with external drive. </p> <p>I like this stup b/c being local, I can do inexpensive backup with backblaze. But organizing across them is a pain and not fault/drive failure tolerance like raid would have. </p> <p>I&#39;m running out of space and wondering best upgrade path. Do I just replace oldest/smallest with larger, new drives and keep same strategy? Can I do raid internally and still get regular backblaze service?</p> <p>I&#39;ve considered a NAS but not sure I see a lot of upside in terms of value if I have to pay by the tb for online b/up and buy multiple new drives to start it. </p> <p>Any downside to staying local with a few large drives in the box?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lotsacrudoutthere\"> ",
        "id": 2291512,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j8a8sk/local_disk_strategy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Local disk strategy",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T20:13:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Am I totally screwed? I have a StableBit Drivepool that consisted of 4 drives. I added a 5th drive. Clicked remove on drive 3 and 4 and waited for it to finish moving the files over to the rest of the available space in the pool. I received no errors whatsoever. I checked those drives to make sure they were empty. I then removed them from the computer. </p> <p>I am missing a TON of stuff. I plugged back in the 2 drives to verify they are empty. They are. Am I just shit out of luck?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jrizz43\"> /u/jrizz43 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j8852a/stablebit_drivepool_files_are_missing/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j8852a/stablebit_drivepool_files_are_missing/\">[comments]</a></span>",
        "id": 2291024,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j8852a/stablebit_drivepool_files_are_missing",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Stablebit Drivepool Files are Missing",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T20:08:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve ~10,000+ screenshots in my PC and they&#39;re piling up fast. They aren&#39;t exactly &#39;mission critical&#39; but still important enough that I&#39;d hate losing them. </p> <p>At first, I thought I&#39;d just create a bunch of Google Drive accounts and dump them there but I don&#39;t want to risk my main account getting banned. I also briefly considered TeraBox with its quote/unquote &quot;1TB&quot; storage but I just don&#39;t have a lot of faith in it.</p> <p>There&#39;s also Instagram but... it just feels wrong and I&#39;m not sure if they would even allow uploading 10k+ images in one go! </p> <p>But then an idea popped into my mind: What if I add them to a 4K video running at 60FPS?</p> <p>After all, a 3 minute long video running at 60FPS &#39;does&#39; have 10,800 frames and its much easier to deal with a single video file than 10k JPEGs. </p> <p>Quality is not really an issue so I&#39;m not concerned about that, at least not at 4K. ",
        "id": 2291025,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j880ug/trying_to_convert_10000_jepgs_into_a_3_minutes",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to convert 10,000+ JEPGs into a ~3 minutes long video. Stupid?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T17:46:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, My plan is to buy an internal 3.5&quot; HDD, put it in an enclosure, and use it to copy data from my parents computer to it as a backup. 2TB should be enough.</p> <p>Now, the cheapest I&#39;ve found new in my city is the Seagate Barracuda, but there are others similarly priced 2TB disks, like the Toshiba P3000, and the WD Blue and Purple. But then I read that IronWolf seems better for a usecase like this and now I&#39;m confused.</p> <p>Honestly the HDD will see new data maybe twice a year, since it&#39;s mostly for vacation photos. I just want to know if SMR and CMR matters in this case or if one of the models I mentioned would be better than the others. I&#39;m mostly concerned with reliability, as in, the HDD won&#39;t have many writes nor reads (I think that&#39;s called cold storage, but I&#39;m still learning) and I&#39;m not sure if that can be bad for the HDD.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"h",
        "id": 2289987,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j84lkf/confused_about_what_hdd_to_buy_for_simple_backup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Confused about what HDD to buy for simple backup (too many options)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T16:55:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am awaiting a 28TB CMR hard disk. ST28000NM000C-FR</p> <p>This is a huge server disk that I acquired and I wanted to put it into a USB box but I am not sure who&#39;s box can handle the biggest hard disks, 36TB are now shipping and WD suggest 40TB by year end,.</p> <p>So 3.5&quot; boxes are available but some choke in 12TB disks let alone bigger hard disks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HedgeFundManager1997\"> /u/HedgeFundManager1997 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j83dhb/usb_box_for_a_28tb_server_hard_disk/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j83dhb/usb_box_for_a_28tb_server_hard_disk/\">[comments]</a></span>",
        "id": 2289394,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j83dhb/usb_box_for_a_28tb_server_hard_disk",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "USB box for a 28TB server hard disk",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T15:30:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Which one should I get? I am getting a 20TB drive for backups.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/temeroso_ivan\"> /u/temeroso_ivan </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j81b72/hdd_toshiba_n300_vs_mg10/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j81b72/hdd_toshiba_n300_vs_mg10/\">[comments]</a></span>",
        "id": 2288836,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j81b72/hdd_toshiba_n300_vs_mg10",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "HDD Toshiba N300 vs MG10",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T15:04:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Title. Looks like Scott Galloway&#39;s 2025 Forecast keynote got taken private. NYU boards are saying it may have gotten pulled by external request. Anyone have it downloaded by chance?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hova092\"> /u/hova092 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j80pka/request_anyone_able_to_download_scott_galloways/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j80pka/request_anyone_able_to_download_scott_galloways/\">[comments]</a></span>",
        "id": 2288306,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j80pka/request_anyone_able_to_download_scott_galloways",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "REQUEST: Anyone able to download Scott Galloway's SXSW keynote from last week?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T14:35:59+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1j801z6/lto_and_3592_data_erasure_lets_chat_tape/\"> <img src=\"https://external-preview.redd.it/8HNyF82O8xvJfYdNdRkpC4YacN0pIhObrEY2HY6qVRU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b916056bb4f4f43384f3142f1bda5fc2440ce18\" alt=\"LTO and 3592 Data Erasure, Lets chat tape\" title=\"LTO and 3592 Data Erasure, Lets chat tape\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/InsurgoTapeMedia\"> /u/InsurgoTapeMedia </a> <br/> <span><a href=\"https://youtu.be/dMeyjMGbjlc?si=xPDhxjFOBOadADHB\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j801z6/lto_and_3592_data_erasure_lets_chat_tape/\">[comments]</a></span> </td></tr></table>",
        "id": 2288307,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j801z6/lto_and_3592_data_erasure_lets_chat_tape",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/8HNyF82O8xvJfYdNdRkpC4YacN0pIhObrEY2HY6qVRU.jpg?width=320&crop=smart&auto=webp&s=7b916056bb4f4f43384f3142f1bda5fc2440ce18",
        "title": "LTO and 3592 Data Erasure, Lets chat tape",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T13:17:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anyone lately had issues with Seagate Ironwolf Prodrives, bought them from wellknown reseller. Installed them in my NAS, saw that 2 out of 6 drives were not functional.</p> <p>This means that 33% of those disks are faulty?</p> <p>Anyone else had same experience?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Endjag\"> /u/Endjag </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7ydca/seagate_ironwolf_pro_6_x_16tb_disk_and_2_of_them/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7ydca/seagate_ironwolf_pro_6_x_16tb_disk_and_2_of_them/\">[comments]</a></span>",
        "id": 2286972,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7ydca/seagate_ironwolf_pro_6_x_16tb_disk_and_2_of_them",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seagate IronWolf Pro 6 x 16TB disk and 2 of them are DOA",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T13:07:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Aiming to create a script that would create a pure UDF iso (So can burn 4gb+ video etc...) to a bluray disc with extra protection via dvdisaster.</p> <p>Just can&#39;t figure the issue out. Got &#39;wrong fs type, bad option, bad superblock on /dev/loop1, missing codepage or helper program, or other error.&#39; mount error.</p> <p>Is this due to some linux kernel restriction on UDF?</p> <p>Have a look and see if it makes sense to you.</p> <p>```bash</p> <h1>!/bin/bash</h1> <h1>Blu\u2011ray Archival Script</h1> <h1>Warning: Not working... got &#39;wrong fs type, bad option, bad superblock on /dev/loop1, missing codepage or helper program, or other error.&#39; mount error</h1> <h1>This script creates a blank UDF image sized for Blu\u2011ray media,</h1> <h1>formats it using mkudffs, and optionally mounts it for copying files.</h1> <h1>It is intended for archival to Blu\u2011ray only.</h1> <h1>Usage: ./create_bluray_udf.sh &lt;source_folder&gt; [&lt;image_name&gt;]</h1",
        "id": 2286973,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7y6lx/how_would_you_create_a_pure_udf_iso_for_burning",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How would you create a pure UDF iso for burning into a 25gb Blu-Ray disc via linux cli? Got a bash script if you can fix it.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T11:22:57+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7wcil/any_website_that_has_all_the_official_artworks/\"> <img src=\"https://b.thumbs.redditmedia.com/_QEHACNuTv_vUTOFDZY86gPaJGczc_ofuJs9dSdFXTA.jpg\" alt=\"Any Website That Has All the Official Artworks, Screenshots, Concept Arts and Character Renders for Old Games?\" title=\"Any Website That Has All the Official Artworks, Screenshots, Concept Arts and Character Renders for Old Games?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Are there any websites that has <strong><em>all</em></strong> or almost all of the official artworks, screenshots, concept arts, character renders for like 1990s and early 2010s games released back in the day for promotional purposes and other stuff and in their original resolutions <strong><em>without</em></strong> compression (like an official screenshot in 1920x1080 resolution <strong><em>without</em></strong> being compressed to 1280x720)?</p> <p>For example, I&#39;m looking for ",
        "id": 2286974,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7wcil/any_website_that_has_all_the_official_artworks",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/_QEHACNuTv_vUTOFDZY86gPaJGczc_ofuJs9dSdFXTA.jpg",
        "title": "Any Website That Has All the Official Artworks, Screenshots, Concept Arts and Character Renders for Old Games?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T10:22:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I&#39;m not the most tech savvy person and I was wondering if someone would know how to download my baby&#39;s funeral service from one room</p> <p>Thank you so much \u2764\ufe0f</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Cocoshbe\"> /u/Cocoshbe </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7vgj7/how_can_i_download_my_sons_funeral_service_from/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7vgj7/how_can_i_download_my_sons_funeral_service_from/\">[comments]</a></span>",
        "id": 2286309,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7vgj7/how_can_i_download_my_sons_funeral_service_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can I download my son's funeral service from one room?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T08:45:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>As Synology offers Hyper Backup, if you wanted to run a backup copy to tape, would you prefer to tar all files as they are, or tar the backup file which Hyper Backup creates?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DiskBytes\"> /u/DiskBytes </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7u6ay/backing_up_synology_nas/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7u6ay/backing_up_synology_nas/\">[comments]</a></span>",
        "id": 2284637,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7u6ay/backing_up_synology_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Backing up Synology NAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T08:28:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a one month premium subscription and some of the topics I want to read from have thousands of results. I would like to know if there exists a tool that will allow me to bulk download pdfs?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Aniconomics\"> /u/Aniconomics </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7tyli/is_there_a_method_to_bulk_download_papers_from/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7tyli/is_there_a_method_to_bulk_download_papers_from/\">[comments]</a></span>",
        "id": 2284638,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7tyli/is_there_a_method_to_bulk_download_papers_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a method to bulk download papers from academia.edu?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T07:48:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So listing was for factory recertified 12tb seagate iron wolf. Model ST12000VN0007. So the seller DealsCenter (S/N Recorded) sent me factory certified ST12000NM0127 which I come to find out is a enterprise seagate from 2018. Then when I reach out to the seller about what they sent me. He reply&#39;s &quot;we only sold ST12000VN0007 on this listing&quot; Like dude. I sent you numerous photos. And you give me a one sentence answer and don&#39;t even respond to the photos that show the make and model of what you sent me ?</p> <p>I didn&#39;t initially realize it. Bc it had same white label etc. until I installed it and noticed the model numbers where different. </p> <p>Not to mention the seller shipped it.... wait for it. In 2 of those free usps bubble mailers rolled up. No crush proof box no nothing. Just HDD inside its static bag inside two of those bubble mailers and dumped into my mailbox. </p> <p>At this point bc it wasn&#39;t sold and shipped from",
        "id": 2284634,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7tg5j/amazon_seller_sent_me_wrong_model_seagate",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Amazon seller sent me wrong model seagate\u2026.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T07:03:52+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7svpe/help_with_dual_drive_setup/\"> <img src=\"https://preview.redd.it/h9ztko6x9tne1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b79b46da33b6a667b857d91a2220f197b545b086\" alt=\"Help with dual drive setup\" title=\"Help with dual drive setup\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hello all, fairly new here and kinda inexperienced with SATA/non external hard drives. So I have 2 x 20tb Toshiba drives in a SATA adapter. When I insert the drive for movies, I can easily add and manipulate data. Same for my other drive for TV, when inserted on its own as well. But when I plug in both, I am unable to do anything and it damn near bogs down my PC. Is this simply me choosing the wrong dock for these drives? I&#39;d like to have both plugged in and accessible at the same time. Thanks all!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Top-Camera9387\"> /u/Top-Camera938",
        "id": 2284635,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7svpe/help_with_dual_drive_setup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/h9ztko6x9tne1.jpeg?width=640&crop=smart&auto=webp&s=b79b46da33b6a667b857d91a2220f197b545b086",
        "title": "Help with dual drive setup",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T02:38:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Local county has entire newspaper archive on a website hosted by the company that scanned the images. Unfortunately, the website is deeply flawed and constantly get errors when searching. They have each page of a newspaper listed as &quot;image&quot; but it&#39;s a pdf when downloading. Talking about 100 years worth of content, but I would like to download all of these easily and index myself. Probably a few tens of thousands of files. Any ideas?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/madamedutchess\"> /u/madamedutchess </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7omzv/best_way_to_download_all_imagespdfs_from_a_public/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7omzv/best_way_to_download_all_imagespdfs_from_a_public/\">[comments]</a></span>",
        "id": 2284639,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7omzv/best_way_to_download_all_imagespdfs_from_a_public",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best way to download all (images/pdfs) from a public domain website",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T02:24:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Doing what I normally do -- right click, inspect, network, m3u -- but as of late, the links for the full hd file always seem to be a small dummy file that&#39;s like a second long and just a still image. I can still grab the low res sd links, but I can&#39;t seem to access the 1080p video link. Help please?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/redrooster1918\"> /u/redrooster1918 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7od81/trying_to_save_freetostream_films_from_nfbca_but/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7od81/trying_to_save_freetostream_films_from_nfbca_but/\">[comments]</a></span>",
        "id": 2284640,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7od81/trying_to_save_freetostream_films_from_nfbca_but",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to save free-to-stream films from nfb.ca but encountering issue with the 1080p m3u links",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T02:04:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, Ive got a big photo album (5.41 Gb) and it has a lot of duplicate photos most of the dupes are whatsapp sent images vs the original DCMI image. Im looking for a software to manage said album. I already tried digiKam (too complex for a one time thing) and AwesomePhotoDuplicate finder? (Too simple and it didnt really fix much). So, what is the go-to tool for someone in my situation?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/depressedfox69\"> /u/depressedfox69 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7nyzu/software_for_managing_duplicate_photos/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7nyzu/software_for_managing_duplicate_photos/\">[comments]</a></span>",
        "id": 2284636,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7nyzu/software_for_managing_duplicate_photos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Software for managing duplicate photos?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T00:32:06+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ALMOSTDEAD37\"> /u/ALMOSTDEAD37 </a> <br/> <span><a href=\"/r/homelab/comments/1j7m1j4/u2_to_m2_sff_8639_adapter_u3_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7m5up/u2_to_m2_sff_8639_adapter_u3_drive/\">[comments]</a></span>",
        "id": 2284371,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7m5up/u2_to_m2_sff_8639_adapter_u3_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "U.2 to M.2 sff 8639 adapter - U.3 drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T00:24:24+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7m06d/youtube_drm_on_all_videos_with_tv_tvhtml5_client/\"> <img src=\"https://external-preview.redd.it/Xie3Rxefl8tNHHMdt5AG1rpM_J4exl8DiIWjhLJQyMQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b26e43150cb7259ad80c5023eacc4fa16bc4d47e\" alt=\"[YouTube] DRM on ALL videos with tv (TVHTML5) client\" title=\"[YouTube] DRM on ALL videos with tv (TVHTML5) client\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>The end of downloading videos from YouTube (effortlessly) may be near.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/iAmmar9\"> /u/iAmmar9 </a> <br/> <span><a href=\"https://github.com/yt-dlp/yt-dlp/issues/12563\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1j7m06d/youtube_drm_on_all_videos_with_tv_tvhtml5_client/\">[comments]</a></span> </td></tr></table>",
        "id": 2284370,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1j7m06d/youtube_drm_on_all_videos_with_tv_tvhtml5_client",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/Xie3Rxefl8tNHHMdt5AG1rpM_J4exl8DiIWjhLJQyMQ.jpg?width=640&crop=smart&auto=webp&s=b26e43150cb7259ad80c5023eacc4fa16bc4d47e",
        "title": "[YouTube] DRM on ALL videos with tv (TVHTML5) client",
        "vote": 0
    }
]