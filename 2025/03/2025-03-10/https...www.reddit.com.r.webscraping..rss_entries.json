[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T20:59:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This is for an open-source, creative commons project pertaining to nature-based offsets. Trying to find scrapers who can help with non-georeferenced polygons. We&#39;re trying to audit carbon projects folks. dm for more details.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CountVonOrlock\"> /u/CountVonOrlock </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j899aw/looking_for_web_scrapers_who_can_help_out_with/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j899aw/looking_for_web_scrapers_who_can_help_out_with/\">[comments]</a></span>",
        "id": 2291279,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j899aw/looking_for_web_scrapers_who_can_help_out_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for web scrapers who can help out with polygons",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T19:02:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Anyone out there? Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Disastrous_Media_874\"> /u/Disastrous_Media_874 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j86hom/looking_for_a_web_scraper_expert_sm_paid/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j86hom/looking_for_a_web_scraper_expert_sm_paid/\">[comments]</a></span>",
        "id": 2290264,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j86hom/looking_for_a_web_scraper_expert_sm_paid",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a web scraper expert SM [paid]",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T17:46:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>I want to create a bot that would interact with a basic form filling webpage which loads content dynamically. The form would have drop downs, selections, some text fields to fill etc. I want to use an LLM to understand the screen and interact with it. Which tool should I use for &quot;viewing&quot; the website? Since content is dynamically loaded, a one time selenium scan of the page won&#39;t be enough.<br/> I was thinking of a tool that would simulate interactions the way we do, using the UI. But maybe the DOM is useful. </p> <p>Any insights are appreciated Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Mediocre-Nerve-8955\"> /u/Mediocre-Nerve-8955 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j84m20/best_tool_for_scraping_websites_for_ml_model/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j84m20/best_tool_for_scraping_websi",
        "id": 2289693,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j84m20/best_tool_for_scraping_websites_for_ml_model",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best tool for scraping websites for ML model",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T17:34:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a small nodeJs / selenium bot that uses github actions to download a weekly newspaper as an epub once a week after a login and sends it to my kindl by e-mail. Unfortunately, the site recently started using the friendlycaptcha service infront ot the login, which is why the login fails.</p> <p>Is there any way that I can take over the resolving on my smartphone? With recaptcha I think there was kind of a session token and after solving it a resolve token, which I then have to communicate to the website. Does this also work somehow with friendly captcha?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/West_Resident5828\"> /u/West_Resident5828 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j84bof/scraping_friendlycaptcha/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j84bof/scraping_friendlycaptcha/\">[comments]</a></span>",
        "id": 2289694,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j84bof/scraping_friendlycaptcha",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping + friendlyCaptcha",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T14:03:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I m scraping data from a website that uses <em>Cloudflare&#39;s anti-bot</em>.</p> <p>I m using a proxy and cloudscraper to make my requests.</p> <p>Every 2 or 3 days, all my proxies get flagged as ip_blacklisted.</p> <p>My proxies are in this format :</p> <pre><code>&quot;user-ip-10.20.30.40:password@proxy-provider.com:1234&quot; </code></pre> <p>When the blacklist happens, i m obliged to create another user</p> <p>For example : </p> <pre><code>&quot;new_user-ip-10.20.30.40:password@proxy-provider.com:1234&quot; </code></pre> <p>In this case it works again for 2 or 3 days... I don&#39;t understand the problem... how cloudflare is blacklisting my proxy based on the user ? And how to bypass this please ? </p> <p>Thank ! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Menxii\"> /u/Menxii </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j7zc80/tunnel_connection_failed_401_auth_failed_code_ip",
        "id": 2288013,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j7zc80/tunnel_connection_failed_401_auth_failed_code_ip",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tunnel connection failed: 401 Auth Failed (code: ip_blacklisted)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T13:46:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>I&#39;m new to web scraping. I am familiar with Javascript technologies so I use Playwright for web scraping. I have encountered a problem.</p> <p>On certain sites, Cloudflare has a bot protection, which is programmed in such a way that no clicks are allowed, as if it is programmed in such a way that it can&#39;t be bypassed once it is convinced that the browser is not a real browser.</p> <p>I tried the hide the fact as:</p> <pre><code>await page.setViewportSize({ width: 1366, // Ekran geni\u015fli\u011fi height: 768 // Ekran y\u00fcksekli\u011fi }); await context.addInitScript(() =&gt; { Object.defineProperty(navigator, &#39;webdriver&#39;, { get: () =&gt; undefined }); }); </code></pre> <p>I changed the setViewportSize() variable realistically. I tried to use WARP but none of them helped. I need suggestions from someone who has encountered this issue before. </p> <p>Thank you very much.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"",
        "id": 2290825,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j7yz49/bypassing_cloudflare_bot_detection_with_playwright",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Bypassing Cloudflare bot detection with playwright",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T10:25:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking for some assistance scraping the sites of all major sports leagues and teams. Althoght most of the URL schemas a similar across leagues/teams I\u2019m still having an issue doing a bulk scrape.</p> <p>Let me know if you have experience with these types of sites </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Weird_Salary_8707\"> /u/Weird_Salary_8707 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j7vigr/sports_data_project/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j7vigr/sports_data_project/\">[comments]</a></span>",
        "id": 2287484,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j7vigr/sports_data_project",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Sports Data Project",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T09:55:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>If you require assistance with mail extraction services, including bulk processing, please feel free to contact me directly for further details.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Harshitweb\"> /u/Harshitweb </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j7v34t/mail_extraction_service/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j7v34t/mail_extraction_service/\">[comments]</a></span>",
        "id": 2286137,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j7v34t/mail_extraction_service",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Mail Extraction Service.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T08:13:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just the other day I ran into a young man who told me he&#39;s an email marketing expert. He told me that there&#39;s a market for &quot;custom scrappers&quot; and if someone can code in Python they can make a decent living. He also mentioned apolo Io site for reasons I don&#39;t understand. I know Python and I also know BS4 library. How and where can I find some work? I also got GitHub Copilot sub and Replit as well. Any tips and tricks are welcome. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NaeemAkramMalik\"> /u/NaeemAkramMalik </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j7trwj/custom_scrapers_what/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j7trwj/custom_scrapers_what/\">[comments]</a></span>",
        "id": 2285474,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j7trwj/custom_scrapers_what",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Custom scrapers what?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T01:01:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m working on a price comparison page where users can search for an item, set a price range, and my scraper pulls data from multiple e-commerce sites to find the best deals within their budget. Everything works fine when I run the scraper locally, but the moment I deploy it to the cloud (tried both DigitalOcean and Google Cloud), Cloudflare shuts me down.</p> <h1>What\u2019s Working:</h1> <p>\u2705 Scraper runs fine on my local machine (MacOS)<br/> \u2705 Using Puppeteer with stealth plugins and anti-detection measures<br/> \u2705 No blocking issues when running locally</p> <h1>What\u2019s Not Working:</h1> <p>\u274c Same code deployed to the cloud gets flagged by Cloudflare<br/> \u274c Tried both DigitalOcean and Google Cloud, same issue<br/> \u274c No difference between cloud providers \u2013 still blocked</p> <h1>What I\u2019ve Tried So Far:</h1> <p>\ud83d\udd39 Using <code>puppeteer-extra</code> with the stealth plugin<br/> \ud83d\udd39 Random delays and human-like interactions<br/> \ud83d\udd39 Setting correct headers and use",
        "id": 2284526,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j7mqs7/cloudflare_blocking_my_scraper_in_the_cloud_but",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cloudflare Blocking My Scraper in the Cloud, But It Works Locally",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-10T01:00:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m working on a price comparison page where users can search for an item, set a price range, and my scraper pulls data from multiple e-commerce sites to find the best deals within their budget. Everything works fine when I run the scraper locally, but the moment I deploy it to the cloud (tried both DigitalOcean and Google Cloud), Cloudflare shuts me down.</p> <h1>What\u2019s Working:</h1> <p>\u2705 Scraper runs fine on my local machine (MacOS)<br/> \u2705 Using Puppeteer with stealth plugins and anti-detection measures<br/> \u2705 No blocking issues when running locally</p> <h1>What\u2019s Not Working:</h1> <p>\u274c Same code deployed to the cloud gets flagged by Cloudflare<br/> \u274c Tried both DigitalOcean and Google Cloud, same issue<br/> \u274c No difference between cloud providers \u2013 still blocked</p> <h1>What I\u2019ve Tried So Far:</h1> <p>\ud83d\udd39 Using <code>puppeteer-extra</code> with the stealth plugin<br/> \ud83d\udd39 Random delays and human-like interactions<br/> \ud83d\udd39 Setting correct headers and use",
        "id": 2284527,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j7mq4u/cloudflare_blocking_my_scraper_in_the_cloud_but",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cloudflare Blocking My Scraper in the Cloud, But It Works Locally",
        "vote": 0
    }
]