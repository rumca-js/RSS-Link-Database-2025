[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T23:08:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys, I own a small QNAP NAS that only has 1 GB of RAM.<br/> I&#39;m trying to backup all my data (less than 1TB) on a &quot;cloud&quot; box.</p> <p>I tried using the (shitty) QNAP HBS3 backup service by using WebDAV but it does not work. I don&#39;t understand why but it keeps failing.</p> <p>I want to try borg, restic or something like that from my QNAP server to the &quot;cloud&quot; box but I don&#39;t know if my QNAP is capable to withstand either borg and restic since I&#39;ve heard that both are quite RAM hungry and since I&#39;ve only 1GB (less since in idle my NAS has like 600MB free).<br/> Keep in mind that I&#39;d need to run either borg or restic in a docker container. </p> <p>Do you all think this might be doable? Is there a service that you recommend to backup my data via a 3rd party? NAS SFTP/SSH/etc... -&gt; another device that has more than 1GB ram -&gt; &quot;cloud&quot; box? I&#39;ve seen that borg needs the filesystem and I thi",
        "id": 2390633,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jicisg/backup_1tb_on_qnap_nas_with_only_1gb_ram_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Backup 1TB on QNAP NAS with only 1GB RAM with Borg/Restic",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T22:55:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Basically I wanna do the same thing as how you cull photos in Lightroom but I don&#39;t need this app to edit anything, or really do anything but let me rate photos and then perform an action based on those ratings. </p> <p>Ideally the most lightweight thing that does the job would be great.</p> <p>thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/testaccount123x\"> /u/testaccount123x </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jic87n/can_anyone_recommend_the_fastestmost_lightweight/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jic87n/can_anyone_recommend_the_fastestmost_lightweight/\">[comments]</a></span>",
        "id": 2390632,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jic87n/can_anyone_recommend_the_fastestmost_lightweight",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can anyone recommend the fastest/most lightweight Windows app that will let me drag in a batch of photos and flag/rate them as I arrow-key through them and then delete or move the unflagged/unrated photos?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T21:30:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I&#39;m planning on making an external ssd to store some of my data. I know i should backup and use more reliable solutions. But I&#39;m asking for help/advice on how i should pick my drive for replacing my old drive.</p> <p>Currently I&#39;m storing data on a hard drive from a broken laptop, it&#39;s been 9 years and i think i should get ready to retire the drive before anything happens. Also its a 500gb drive and going to 1tb might be wise.</p> <p>I&#39;m on a tight budget, but also trying to get the best solution. After some searching I&#39;m a bit torn between going m.2 or the 2.5 inch sata one. If i use sata I&#39;m saving on buying an enclosure, but the sata drives are similarly priced as the m.2 (some are even more expensive like wd or crucial). The best i could find is a team mp44l, looks like a good drive and the price is cheaper than sata.</p> <p>My criteria is something reliable for the next 3-4 years, budget friendly, and good perform",
        "id": 2390392,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jiabkv/diy_external_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "DIY external drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T20:44:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, I want to save all my photos, videos, artworks, music and games. What should I buy to start?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Guio-\"> /u/Guio- </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji99o1/tips_for_a_starter/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji99o1/tips_for_a_starter/\">[comments]</a></span>",
        "id": 2390161,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji99o1/tips_for_a_starter",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tips for a starter",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T19:50:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>While capturing a site with playright or singlefile, I am trying to figure out how to capture all the javascript for the site as well (buttons and other actions). </p> <h1>Or is there a way to see what styles are used for each button/action?</h1> <p>I am trying to be able to create templates of sites from backups so I can locally run shared domains of backups with an overlay interface connecting them but also allow other actions normally on the site.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/path0l0gy\"> /u/path0l0gy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji7zyu/capturing_javascript_from_site_currently_using/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji7zyu/capturing_javascript_from_site_currently_using/\">[comments]</a></span>",
        "id": 2389854,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji7zyu/capturing_javascript_from_site_currently_using",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Capturing Javascript from site? (Currently using Playwright and singlefile)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T19:36:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I\u2019m considering using <strong>Backblaze Personal Backup</strong> primarily just to back up my Windows OS drive (SSD/NVMe) My main goal is quick and easy recovery of my OS drive if something goes wrong.</p> <p>I do have full offline backup copy of my data but it is 1 month old and i lost 2 14TB drives due to partition failure and 2nd drive sata data connector broke which lead me to come here and ask for help. i am getting tired of swaping drives and offline backups plus i no longer have bigger drives to do offline backups every week or month to aviod this issue </p> <p>Is Backblaze effective for backing up and restoring just the OS drive?</p> <p>My setup:</p> <ul> <li><strong>12 internal HDDs</strong> (2TB, 4TB, 10TB, and 14TB drives), totaling around <strong>70TB+</strong>.</li> <li>Drives are directly connected via SATA and stay online <strong>24/7</strong>.</li> <li>Occasionally, I&#39;ll need to upgrade drives due to space lim",
        "id": 2389855,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji7o1z/using_backblaze_personal_for_os_drive_and_12",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Using Backblaze Personal for OS Drive and 12 Internal drives Backup \u2014 Is It Worth It?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T19:09:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>TL;DR - After coming across yet another internet big brain war over how HDD companies are lying about storage capacities, because TB =/= TiB and computers are somehow special when it comes to measurement and basic arithmetic, my body temperature has gone up and I will be yelling into the void now.</p> <p>BTW, before we even get into it. 1024 is TEN binary digits. Thats 1.25 bytes... &quot;Nice&quot;, &quot;even&quot;, &quot;round&quot;, &quot;binary&quot;...... </p> <p>Why is using base 2 bad when dealing with storage and throughput?</p> <ol> <li>Humans are only taught to do math and think in base 10.</li> <li>It&#39;s moronic to mix two number bases the way it&#39;s done in IT.</li> <li>Bytes are not special.</li> </ol> <p>Believe it or not, humans are shit with numbers. We are taught how to count, read numbers and &quot;do arithmetic&quot;, but really only small numbers mean anything to us. By small I mean single digits. You &quot;add&quot; by memo",
        "id": 2389856,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji708i/measure_all_the_things_in_bits",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Measure all the things... IN BITS!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T18:53:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I collect live streams from a defunct service and have been asked by someone who worked there if I could ship them a hard drive of their work over. I compiled the collection of his stuff recently and it&#39;s around 400 GB. He&#39;s offering me up to $200 for purchase and shipping. I was looking into portable HDDs, SSDs, and USB sticks though it seems like he&#39;d prefer something bigger like the HDDs and SSDs. Base storage I&#39;d need for sure is 512GB but it does seem like 1TB is the minimum option for major names. I was considering going with a Seagate HDD (which I have three of, a 1tb, 2tb, and 4tb) but I was wondering if shipping that from one side of the US to the other would cause damage.</p> <p>I don&#39;t know. What do you all use?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/kianworld\"> /u/kianworld </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji6mgd/best_kind_of_portab",
        "id": 2389580,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji6mgd/best_kind_of_portable_storage_to_ship_domestically",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best kind of portable storage to ship domestically?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T18:47:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am looking to buy this and i have found conflicting results while searching some saying it doesn&#39;t read UHD discs.</p> <p>Looking at specs here:</p> <p><a href=\"https://www.asus.com/motherboards-components/optical-drives/external-blu-ray-drive/bw-16d1x-u/techspec/\">https://www.asus.com/motherboards-components/optical-drives/external-blu-ray-drive/bw-16d1x-u/techspec/</a></p> <p>While as it lists that it can write upto BD-R (QL) it only lists read capability as BD-ROM : 12X, BD-R(SL, M-DISC) : 12X &amp; BD-RE : 10X only.</p> <p>To make it clear, my purpose is not to rip bluray&#39;s using makemkv with this, my purpose is to only write multiple 100GB M-Discs for archival and occasional reading it back.</p> <p>This is the media i intend to write:</p> <p><a href=\"https://www.amazon.com/Verbatim-98913-M-Disc-100GB-Surface/dp/B011PIJPOC?ref_=ast_sto_dp&amp;th=1\">https://www.amazon.com/Verbatim-98913-M-Disc-100GB-Surface/dp/B011PIJPOC?ref_=ast_sto_dp&",
        "id": 2389581,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji6haz/question_regarding_asus_bw16d1xu_compatibility",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Question regarding Asus BW-16D1X-U compatibility with BD-R TL M-Discs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T18:46:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I currently only rsync mirror media files between external drives that are formatted ext4 on LUKS on Linux machines. Renaming source files gets treated as new files which make backups in-efficient.</p> <p>What do you guys suggest? i was looking at a real backup software like Kopia (Borg does not support multi-thread) but mounting repos and interacting with it or playing files apparently some overhead vs. raw file.</p> <p>I guess the source disk can be existing ext4 on LUKS and only the cold storage backup is Kopia repo and not expected to play videos and such on, but curious if there are any other options to consider. Features like snapshots and deduplication are nice in general but they don&#39;t seem useful for binary media files. So far the advantages I see for Kopia is it&#39;s useful for other more complex workflows and datasets (i.e. not really applicable to my use case) with the relevant benefits being: supporting renaming of source files and ",
        "id": 2389582,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji6ggd/backup_media_filesrsyncalternative_that_supports",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Backup media files--rsync-alternative that supports renaming files?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T18:32:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I&#39;m hoping someone can help me figure out what would be best in my case as I&#39;m changing my mind almost daily.</p> <p>I bought a mini pc (Intel N97, 12gb RAM) to use as a small server, along with an Ironwolf 8tb drive. My initial thought was to run the mini pc as follows in Proxmox:</p> <ul> <li>1 VM running OpenMediaVault with 2 cores and 4gb RAM assigned; the 8tb drive would be the main drive for media for the other VM below, as well as to be able to access it on my LAN to move over some files, kind of like a NAS.</li> <li>1 VM running Docker containers, mainly Plex/Jellyfin (and probably some arrs), probably a couple of other things like HomeAssistant and some security stuff and eventually accessing my data from outside my LAN.</li> </ul> <p>I had originally bought a small 4 bay dock for the 8tb drive (and 2 1tb HDD and a 128gb SSD I had laying around) but since then realized the drives heat up too easily - I may have fr",
        "id": 2389583,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji6589/help_deciding_what_i_need",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help deciding what I need",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T18:27:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How do I recover a 4tb sata ssd that has intact data but had hardware problems preventing read and write... i can&#39;t access the data as it&#39;s hardware side and i need an expert in help. This is urgent as it&#39;s gonna only last 1 year before failure... its data is intact and I never backed it up...</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/energycnbkid\"> /u/energycnbkid </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji613y/how_to_recover_a_sata_ssd_data_from_hardware/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji613y/how_to_recover_a_sata_ssd_data_from_hardware/\">[comments]</a></span>",
        "id": 2389584,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji613y/how_to_recover_a_sata_ssd_data_from_hardware",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to recover a sata ssd data from hardware failure",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T18:17:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Also, what are the odds that someone would steal my data if it wasn\u2019t encrypted? Like does this type of thing happen often? I don\u2019t have any sensitive data that I\u2019d upload - just photos and videos because I\u2019m a photographer. Would someone still steal this data even though it\u2019s all photos and videos?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Electrical-Reveal-25\"> /u/Electrical-Reveal-25 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji5sm7/sorry_if_this_is_a_dumb_question_but_why_do_i/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji5sm7/sorry_if_this_is_a_dumb_question_but_why_do_i/\">[comments]</a></span>",
        "id": 2389585,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji5sm7/sorry_if_this_is_a_dumb_question_but_why_do_i",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Sorry if this is a dumb question, but why do I need to encrypt my data when uploading to cloud services?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T17:58:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I am sort of new to serious preservation. I&#39;ve recently bought a bluray drive and hacked the firmware to allow for compatibility with ripping and with 4k discs, and just got a 5TB external drive to store rips onto. I got my MakeMKV perpetual license. I am ready to begin archiving!</p> <p>But something that frustrates me is that MakeMKV only generates discrete files of the contents of the disc but does not preserve the menu structure that you&#39;d see if you put the disc into a standard disc player. I get that the video output is raw from the disc and on that level MakeMKV is a great tool, but is there anything that takes things to the next level and lets me rip a mountable ISO that can boot in VLC with all of the original menu formatting?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lazerpop\"> /u/Lazerpop </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji5bx6/prese",
        "id": 2389586,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji5bx6/preserving_dvd_file_menu_structure_in_11_copy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Preserving DVD file menu structure in 1:1 copy possible?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T17:05:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m wary of using a SSD for long term storage - which in my case means the majority of it&#39;s data isn&#39;t accessed for years, even though the drive itself is used regularly.</p> <p>I was looking at Samsung 4TB with V-NAND MLC (I can&#39;t find an SLC drive). The drive won&#39;t have a lot of writes compared to a boot drive so I was wondering if employing some kind of data scrubbing that periodically checks each bit of data on the drive (and therefore periodically refreshing the charges of the stored bits) would mitigate data loss from infrequent access?</p> <p>If so, what&#39;s the best way to go about this? The drive will be SATA and used internally on Windows 11.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Gazumbo\"> /u/Gazumbo </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji41vy/ssd_mlc_a_viable_long_term_storage_solution_if/\">[link]</a></span> &#32; <span><a href=\"https",
        "id": 2389267,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji41vy/ssd_mlc_a_viable_long_term_storage_solution_if",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SSD MLC a viable long term storage solution if using scrubbing to periodically power cells?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T16:57:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I just got a <strong>Windows 11 laptop (x86 architecture)</strong>, and I\u2019m struggling to find a good way to <strong>manage my storage properly</strong>. On Android, I\u2019m used to <strong>Google Files</strong>, where everything is <strong>well-organized</strong>, and I can <strong>sort by size, type, and filters easily</strong>. But on Windows, Storage Settings and File Explorer feel too basic and don\u2019t show everything properly.</p> <h1>Here\u2019s what I need:</h1> <p>\u2705 <strong>A user-friendly storage manager</strong>\u2014something that\u2019s easy for a first-time Windows laptop user to understand.<br/> \u2705 <strong>Shows all apps, photos, videos, documents, and system files in one place.</strong><br/> \u2705 <strong>Sort &amp; filter by size, type, or last modified date</strong> (like Google Files does).<br/> \u2705 <strong>Shows exact game files &amp; app sizes</strong>, not just &quot;Steam&quot; as one giant folder.<br/> \u2705 <strong>Doesn\u2019t clutter the s",
        "id": 2389587,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji3uol/whats_the_best_storage_manager_for_windows_11",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What\u2019s the Best Storage Manager for Windows 11? (Like Google Files, but Shows EVERYTHING Clearly)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T16:53:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, linux/docker noob here.</p> <p>My goal is to run/host gallery-dl on my TrueNAS server to run downloads for me. I&#39;m familiar with running it via my windows command line on my main PC. I&#39;m unsure as to how to go about doing this, I&#39;ve tried dockge with <a href=\"https://github.com/qx6ghqkz/gallery-dl-server\">https://github.com/qx6ghqkz/gallery-dl-server</a> but the container I made seemed to be broken, and I could not access the webui. I&#39;m basically unsure as to how to proceed, as if I&#39;m not mistaken, I cannot just run gallery-dl from the TrueNAS shell, and it would probably require a dedicated VM like ubuntu server to run it command line style like I&#39;ve been doing so far on my main PC. Anyone could point me towards a guide or suggest a method that would suite a simpleton like me would be appreciated.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Stressemann\"> /u/Stressemann </a> <",
        "id": 2389588,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji3rul/hosting_gallerydl_on_truenas_scale",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hosting gallery-dl on TrueNAS SCALE",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T16:36:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking at ordering some Seagate drives off ebay. Since they are made in a different country but come from the USA any idea if there is an additional tariff on them?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/InternalOcelot2855\"> /u/InternalOcelot2855 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji3d8s/canada_tariff_on_drives_from_ebay/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji3d8s/canada_tariff_on_drives_from_ebay/\">[comments]</a></span>",
        "id": 2388925,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji3d8s/canada_tariff_on_drives_from_ebay",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Canada tariff on drives from ebay?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T15:34:08+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Electrical-Reveal-25\"> /u/Electrical-Reveal-25 </a> <br/> <span><a href=\"/r/cloudstorage/comments/1ji1xep/do_you_know_of_any_cloud_services_where_i_can/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji1xyf/do_you_know_of_any_cloud_services_where_i_can/\">[comments]</a></span>",
        "id": 2388602,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji1xyf/do_you_know_of_any_cloud_services_where_i_can",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Do you know of any cloud services where I can mail in my personal hard drive to be uploaded?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T15:33:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I was reading an older comparison of some image compression systems and I decided to some informal comparisons myself starting from around 700 images for a total of 2825MiB and the results are here followed by a description of the tests and my comments:</p> <p>Elapsed time Resulting Size, Method:</p> <pre><code> 2m05.338s 488MiB AVIF-AOM-s9 6m48.650s 502MiB WebP-m4 8m07.813s 479MiB AVIF-AOM-s8 12m16.149s 467MiB WebP-m6 12m44.386s 752MiB JXL-l0-q85-e4 13m20.361s 1054MiB JXL-l0-q90-e4 18m08.471s 470MiB AVIF-AOM-s7 3m21.332s 2109MiB JXL-l1-q__-e_ 14m22.218s 1574MiB JXL-l0-q95-e4 32m28.796s 795MiB JXL-l0-q85-e7 39m4.986ss 695MiB AVIF-RAV1E-s9 53m31.465s 653MiB AVIF-SVT-s9 </code></pre> <p>Test environment with notes:</p> <ul> <li>Original JPEGs saved in &quot;fine&quot; mode are usually around 4000x3000 pixels photos, most are street scenes, some are magazine pages, some are things. Some are from mid-range Android cellphones, some are from a midrage S",
        "id": 2388603,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji1x4w/some_recentish_informal_tests_of_avif_jpegxl_webp",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Some recent-ish informal tests of AVIF, JPEG-XL, WebP",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T15:31:46+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji1w39/can_we_use_seagate_expansion_10_tb_external/\"> <img src=\"https://preview.redd.it/gaovamvdkgqe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ea1a41767876a2ee96c06c8dbcfadeb1d578e05\" alt=\"Can we use Seagate expansion 10 tb external harddrive in Synology NAS ?\" title=\"Can we use Seagate expansion 10 tb external harddrive in Synology NAS ?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I have a Seagate Expansion 10TB external hard drive, and I\u2019m planning to buy a Synology NAS. Instead of buying a new NAS drive, I was wondering if I could remove the hard drive from the enclosure and install it inside the NAS.</p> <p>Has anyone tried this before? Would it work, or are there any compatibility issues? Also, would the drive be reliable for 24/7 NAS use?</p> <p>Appreciate any insights!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Late_War_81",
        "id": 2388926,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji1w39/can_we_use_seagate_expansion_10_tb_external",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/gaovamvdkgqe1.jpeg?width=640&crop=smart&auto=webp&s=0ea1a41767876a2ee96c06c8dbcfadeb1d578e05",
        "title": "Can we use Seagate expansion 10 tb external harddrive in Synology NAS ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T15:25:43+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji1r5f/windows_explorer_size_indication/\"> <img src=\"https://b.thumbs.redditmedia.com/RlZ7v2nrC63n8R51wfgcXv6KfwBl7bjGOIdl6t29SSI.jpg\" alt=\"Windows explorer size indication\" title=\"Windows explorer size indication\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/I-Achieved-Nothing\"> /u/I-Achieved-Nothing </a> <br/> <span><a href=\"/r/truenas/comments/1ji0j28/windows_explorer_size_indication/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji1r5f/windows_explorer_size_indication/\">[comments]</a></span> </td></tr></table>",
        "id": 2388604,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji1r5f/windows_explorer_size_indication",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/RlZ7v2nrC63n8R51wfgcXv6KfwBl7bjGOIdl6t29SSI.jpg",
        "title": "Windows explorer size indication",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T14:49:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Can someone explain why I would want to get a SAS/SATA raid card rather than just the standard SATA port PCI-E card?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tresdinchan\"> /u/tresdinchan </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji0y0p/pcie_expansion_cards/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji0y0p/pcie_expansion_cards/\">[comments]</a></span>",
        "id": 2388605,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji0y0p/pcie_expansion_cards",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "PCI-E Expansion cards",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T14:45:38+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji0ve3/advice_on_adding_more_hdds/\"> <img src=\"https://preview.redd.it/in5a8mj5cgqe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=31bfb98fc3fa7c0fc8030879893db8296a3737c9\" alt=\"Advice on Adding More HDDs\" title=\"Advice on Adding More HDDs\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey folks! I need some advice. </p> <p>My Antec P101 Silent case is completely full. All 8 drive bays are occupied and I want to add 5 more hard drives to my system, and I&#39;m trying to figure out the best way to do it. Running Proxmox with a TreNAS VM managing the HDDs.</p> <p>I have a 5-bay USB enclosure already, which is probably the easiest option, but I&#39;m concerned about the reliability of running the drives over USB with TrueNAS. My understanding is that if the USB connection gets interrupted while the machine is running, there&#39;s a significant risk of data corruption due to how TrueNAS handles storage. Si",
        "id": 2388600,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji0ve3/advice_on_adding_more_hdds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/in5a8mj5cgqe1.jpeg?width=640&crop=smart&auto=webp&s=31bfb98fc3fa7c0fc8030879893db8296a3737c9",
        "title": "Advice on Adding More HDDs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T14:45:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>A while back I released <a href=\"https://github.com/patrickkfkan/patreon-dl\">patreon-dl</a>, a command-line utility to download Patreon content. Entering commands in the terminal and editing config files by hand is not to everyone&#39;s liking, so I have created a GUI application for it, conveniently named <a href=\"https://github.com/patrickkfkan/patreon-dl-gui\">patreon-dl-gui</a>. Feel free to check it out!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/patrickkfkan\"> /u/patrickkfkan </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji0v7f/patreon_downloader/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji0v7f/patreon_downloader/\">[comments]</a></span>",
        "id": 2388601,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji0v7f/patreon_downloader",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Patreon downloader",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T14:31:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, </p> <p>I am using 5 8TB 7200 rpm disk for backup using USB 3. I was wondering if it matters at all if I use usb3.0 vs USB 3.2 (5G vs 10G) at all?</p> <p>When testing transfer i seems to max between 120 to 220 MB/s.</p> <p>In other words, does the limitation of my sata 3 HD drive 7200 rpm makes this question mote?</p> <p>thx</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Smittus2020\"> /u/Smittus2020 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji0kb9/for_external_backup_does_usb_32_10g_vs_5g_matter/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji0kb9/for_external_backup_does_usb_32_10g_vs_5g_matter/\">[comments]</a></span>",
        "id": 2388257,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji0kb9/for_external_backup_does_usb_32_10g_vs_5g_matter",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "for external backup, does usb 3.2 10G vs 5G Matter for 7200 rpm disk?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T14:21:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I\u2019m considering a Synology DS224+ to host about 4tb video and 2tb music /photos, which will probably grow significantly in the next 5 years (double or more maybe?) To go 1-2-3 backup I assume I need another external HDD to backup the NAS , and something like backblaze. I would probably start with a 12TB disk in the NAS. Do I really need to use RAID as well? A short downtime isn\u2019t really an issue as long as I can restore my files. </p> <p>I want to use the NAS as a plex server, and to stream music and view photos . Currently I\u2019m using a 2013 macbook pro, but it\u2019s annoying to make sure its connected, it overheats and its obsolete and slow.</p> <p>Secondly, I\u2019m a bit puzzled how people back up a NAS, like even a 2 bay could easily get to 32TB , what do you back up to when you have that much data or more? Another NAS? Or a DAS?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Proteus-8742\"> /u/Proteus-8742 </a> <b",
        "id": 2388258,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji0cak/do_i_need_raid",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Do I need RAID?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T14:15:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Some Facebook Pages with Advocate Posts and others with News Articles are getting removed for <em>Suspension</em> or a News Team is about to cease operation due to short-fundings and their Facebook Page is planned to be deleted like they don&#39;t literally exist, I have to get them all as possible for future evidence, Before the rumors and thoughts of people in the future will say that didn&#39;t exist at all.</p> <p>Most extensions for downloading Facebook Albums <em>(DownAlb\\</em>* name)* are no longer useful with frequent Facebook API updates, Some extensions wants me to pay for a Full Version <em>(ESu\\</em>* name)* and I&#39;ll just say Screw Them. Almost everything on a Web Search are dead replacing Ad Links and old videos for downloading Facebook stuffs.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/earvinexes\"> /u/earvinexes </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji081",
        "id": 2388927,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji0811/any_scrapping_tools_for_bulk_downloading_facebook",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any scrapping tools for bulk downloading Facebook Albums containing Pictures and Videos from a Page?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T14:07:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking for a new trinket on my keyring, I work in IT so wouldn&#39;t mind something cool. I feel like current tech is soo good that the biggest capacity and greatest speed is no longer a primary factor.</p> <p>So what interesting and usefull gimmick have you seen? Wateeproof? Dual USB (A and C)?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Matt_Bigmonster\"> /u/Matt_Bigmonster </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji01ng/coolest_usb_stick/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ji01ng/coolest_usb_stick/\">[comments]</a></span>",
        "id": 2388255,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ji01ng/coolest_usb_stick",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Coolest USB stick?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T14:03:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve just gotten started with WFDownloader and I haven&#39;t fully wrapped my head around the software yet so bear with me. As the title says my downloaded Pinterest images does not retain the original filename, but rather names it after the pin ID number.<br/> For instance, the original file name of a pin is 1db7bb1da4248ad75da9e0bfe9c4fd0f.jpg and the downloaded image through WFD is named 143481938124759075.jpg after it&#39;s pin ID that you can see in the URL.</p> <p>Is it possible to change it so I get the original filenames instead? I couldn&#39;t find any options pertaining to this and the only discussion on their homepage had the developer state that WFD does not change filenames. Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ThickPlatypus_69\"> /u/ThickPlatypus_69 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhzyqv/wfdownloader_for_pinterest_downloaded_images/\">[l",
        "id": 2388256,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhzyqv/wfdownloader_for_pinterest_downloaded_images",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WFDownloader for Pinterest: downloaded images named after pin ID # instead of filename. Possible to change?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T13:50:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I could use some critiques, advice, and read some anecdotal stories on my backup solution I&#39;m considering.</p> <p>NAS setup: UGREEN DXP2800, 2 Seagate Ironwolf Pro 20TB setup in RAID 1, 1 Samsung 990 Pro SSD 2TB for caching.</p> <p>Computer: MacBook Air M2 1TB</p> <p>Cloud backup:<br/> - iCloud 2TB backing up my MacBook Air all my other Apple devices and my families Apple devices.<br/> - OneDrive backing up files on my MacBook Air and my iPhone. I have a Microsoft 365 family subscription so I use the 1TB of OneDrive to backup my files and photos.<br/> - Time Machine backing up my MacBook Air on an external WesternDigital 2TB HDD</p> <p>Considering: Backblaze personal plan to backup my MacBook Air and for my NAS, here&#39;s my ida that I wanted to get people&#39;s opinions on. Buying a 20TB+ HDD from <a href=\"http://serverpartdeals.com\">serverpartdeals.com</a> putting it into an external enclosure and connecting that to my UGREEN NAS and backing u",
        "id": 2388928,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhzot3/critique_and_give_advice_on_possible_backup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Critique and Give Advice on Possible Backup Strategy Please",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T13:46:31+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhzmd9/for_hdds_that_dont_have_the_manufacture_date/\"> <img src=\"https://a.thumbs.redditmedia.com/BWEpyNT54OXAgd8gjk_5OVTguX_pHU_SU02_ndob9k8.jpg\" alt=\"For HDDs that don't have the manufacture date printed on them, how can I determine the date of manufacture?\" title=\"For HDDs that don't have the manufacture date printed on them, how can I determine the date of manufacture?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dekoalade\"> /u/dekoalade </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1jhzmd9\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhzmd9/for_hdds_that_dont_have_the_manufacture_date/\">[comments]</a></span> </td></tr></table>",
        "id": 2388261,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhzmd9/for_hdds_that_dont_have_the_manufacture_date",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/BWEpyNT54OXAgd8gjk_5OVTguX_pHU_SU02_ndob9k8.jpg",
        "title": "For HDDs that don't have the manufacture date printed on them, how can I determine the date of manufacture?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T13:44:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I am looking for advice on a cost-efficient backup solution. Let me provide my current setup and a few parameters.</p> <p>Setup :</p> <ul> <li>4-Bay Synology NAS with 4x16TB IronWolf Pro</li> <li>Mostly contains shows I collect on a periodic basis - not looking to backup the shows right now due to budget constraints</li> <li>Looking to backup some photos and documents which should total at most 4-8 TB over the next 10 years or so</li> <li>Currently using freefilesync to manually backup weekly to an external 4TB seagate hdd (old)</li> </ul> <p>Parameters:</p> <ul> <li>Read and write speeds are not a concern</li> <li>Cost is the most important, but integrity is a must for me (if I need to get more than one for redundancy, I will)</li> <li>No plan on leaving the external backup connected due to space and port constraints</li> </ul> <p>I am thinking of getting a hard drive enclosure and getting a 4TB IronWolf HDD on a deal somewhere (",
        "id": 2388259,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhzl7n/seeking_advice_on_costefficient_backup_solution",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seeking Advice on Cost-Efficient Backup Solution",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T13:29:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I just bought a brand new Toshiba Canvio Basics 4TB external drive (the 2022 version) and it makes some clicking noises. I know clicking is considered as a sign of a drive failing but this is brand new so I was wondering if this particular model is louder compared to others. I also have the 1TB version of the 2022 and the older version of the same drive and both of them are more quiet. Should I return it or is this drive just more noisy?<br/> Sound recordings: <a href=\"https://gofile.io/d/1OVVKb\">https://gofile.io/d/1OVVKb</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kinjoko\"> /u/Kinjoko </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhzaai/brand_new_toshiba_canvio_basics_4tb_clicking/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhzaai/brand_new_toshiba_canvio_basics_4tb_clicking/\">[comments]</a></span>",
        "id": 2388260,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhzaai/brand_new_toshiba_canvio_basics_4tb_clicking",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Brand new Toshiba Canvio Basics 4TB clicking noises",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T13:06:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Previously I have been formatting all my SSDs and HDDs that I use to store backups as ext4 and used LUKS for encryption.</p> <p>Now I also own a MacBook and would like to back it up in a way that is compatible with my Linux devices.</p> <p>ext4 and LUKS support seems to be bad on macOS. Is HFS+ with some other encryption scheme (VeraCrypt?) the way to go here? I am honestly a bit confused since I&#39;ve had to deal with either.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LoweringPass\"> /u/LoweringPass </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhyu83/best_file_system_and_encryption_for_macoslinux/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhyu83/best_file_system_and_encryption_for_macoslinux/\">[comments]</a></span>",
        "id": 2387915,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhyu83/best_file_system_and_encryption_for_macoslinux",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best file system and encryption for macOS/Linux backups?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T10:55:41+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/whizzwr\"> /u/whizzwr </a> <br/> <span><a href=\"/r/selfhosted/comments/1jhwnxg/good_backup_job_dashboard_logs_status_notification/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhwoiv/good_backup_job_dashboard_logs_status_notification/\">[comments]</a></span>",
        "id": 2387317,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhwoiv/good_backup_job_dashboard_logs_status_notification",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Good backup job dashboard (logs, status, notification)?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T09:26:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>so this is just me shouting into the wind. I understand brand loyalty is stupid and WD has a very good track record (which is why I bought them in the first place) but it&#39;s still weird.</p> <p>late 2022 I bought five 4tb externals, WD Elements. six months later I bought another batch of five drives. for cold storage.</p> <p>upon delivery my routine is: boot up HD Sentinel, do a quick self check followed by a full write-read and finally an extended self check. everything green, 100% health.</p> <p>so I start downloading the files I want. and 7zipping them afterwards. halfway through the process though, about two weeks later, one of the drives craps itself. gets insanely slow followed by an immediate 13% drop in health.</p> <p>whatever, I&#39;ll just continue with the other drives. until another one craps itself. this one being completely unresponsive. at this point I&#39;m worried but the remaining eight finish the process so I assume they&#39;re ",
        "id": 2387078,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhvfuj/50_failure_rate_my_experience_with_western",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "50% failure rate - my experience with Western Digital based on a small sample",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T06:11:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>I\u2019m looking for help regarding a custom firmware for my UnionSine MD202 SSD External Case , which uses a Realtek RTL9210B-CG controller. I\u2019ve attached a screenshot from the firmware update tool (UTHSB_MPTool_Lite) to provide more details about the device.</p> <p>Here are the specifics:</p> <ul> <li><strong>Device Model:</strong> UnionSine MD202</li> <li><strong>Controller:</strong> Realtek RTL9210B-CG</li> <li><strong>Firmware Version:</strong> 1.29.12</li> <li><strong>Build Date:</strong> 2022.01.11</li> <li><strong>Manufacturer:</strong> Realtek</li> <li><strong>Product:</strong> RTL9210B-CG</li> </ul> <p>I\u2019m interested in a custom firmware to potentially improve performance of this SSD. I\u2019ve tried searching for resources online, but I couldn\u2019t register on Station-Drivers to ask my questions there, so I\u2019m hoping to find some guidance here.</p> <p><strong>Is the firmware at this address compatible with my external SSD enclosur",
        "id": 2388929,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhst6x/custom_firmware_for_realtek_rtl9210bcg_unionsine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Custom Firmware for Realtek RTL9210B-CG (UnionSine MD202) \u2013 Need Guidance",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T05:15:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to capture tv feeds eg news, shows. Was wondering if any off-the-shelf equipment i can use that is programmable in python or any high level language really would work. Thank you</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/azimuth79b\"> /u/azimuth79b </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhs0gg/consumer_video_capture_cards_with_api/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhs0gg/consumer_video_capture_cards_with_api/\">[comments]</a></span>",
        "id": 2386326,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhs0gg/consumer_video_capture_cards_with_api",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Consumer video capture cards with api?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T04:46:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The other day I was sending some large files to a family member who doesn&#39;t have regular internet access. So I took the old reliable <a href=\"https://en.wikipedia.org/wiki/Sneakernet\">sneakernet</a> approach: I put the files on a flash drive, wrapped it in bubble wrap and packed it in a little cardboard box, and took it to my local post office.</p> <p>This made me realize it&#39;s kind of inconvenient to mail a flash drive, especially compared to stamped mail that goes in a collection box, like a regular letter in a <a href=\"https://en.wikipedia.org/wiki/Envelope#North_American_sizes\">No. 10 envelope</a> or a greeting card with some photos. Since envelopes have to go through mail-sorting machines, <a href=\"https://old.reddit.com/r/USPS/comments/sbpg5a/hey_gang_this_is_why_you_cant_just_throw_a_thumb/\">flash drives are a big no-no</a>, as are other rigid items like CDs or DVDs (at least in the US).</p> <p>I guess the smallest option would be an SD",
        "id": 2386325,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhrk3u/best_sneakernet_option_for_stamped_mail_xpost",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best sneakernet option for stamped mail? (x-post r/USPS)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T03:39:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello all.</p> <p>A relative of mine recently got their hands on some Greg Neville Audio &amp; CD-ROMS that contain lessons about Psychosomatic causes of illness (the mind-body connection, including cancer). Greg is a naturopathic psychotherapist teacher in Melbourne, Australia who has documented many of the Psychosomatic causes of mental &amp; health conditions.</p> <p>Sadly, some of these discs have corrupted audio (they are close to 2 decades old), and I haven&#39;t been able to rip them properly with E.A.C. without the audio sounding terrible.</p> <p>Does anyone have any audio, video, or writings of Greg&#39;s teachings?<br/> I&#39;d like to properly archive this all as Greg has retired, and his works are phenomenal.</p> <p>Cheers.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheRealItzLegit\"> /u/TheRealItzLegit </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhqg4j/au_only_would_",
        "id": 2386175,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhqg4j/au_only_would_anyone_happen_to_have_greg_neville",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[AU ONLY] Would anyone happen to have Greg Neville Audio & CD-ROMS that contain lessons?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T03:38:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I used to think that data loss was something that would never happen to me\u2014until one day, my external hard drive suddenly crashed (no idea what happened). Three years&#39; worth of photography work and 4K footage were all gone. I tried every possible recovery method, but nothing worked. That was the moment I truly realized the importance of backups.</p> <p>Decided to go with a friend&#39;s recommendation and invested in a NAS system, and now I feel like I should be good from potential data lost incidents! I got automatic backup setup to save me from forgetting to regularly backup all my stuff. Got RAID 6 protection so that even if a hard drive fails, my data remains safe. Also, theres remote access that allows me to retrieve files anytime, anywhere.</p> <p>With this new stroage and backup setup, I should no longer have to worry about losing my files right? it should be sth like &quot;&quot;set it and forget it&quot;&quot; and it will just work right?",
        "id": 2387625,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhqf5v/always_remember_to_back_up_your_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Always remember to back up your data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T03:20:40+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhq4eb/do_wwe_dvds_usually_look_this_bad/\"> <img src=\"https://preview.redd.it/ii7udx5yxcqe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dbc5d3644f2956d32ae3538d2afcf0b090d6559a\" alt=\"Do WWE DVD\u2019s Usually Look This Bad?\" title=\"Do WWE DVD\u2019s Usually Look This Bad?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I\u2019m currently trying to rip and convert WWE/F DVD\u2019s and while watching the content on the disc itself, it looks absolutely abhorrent with all of the artifacts. I\u2019ve never seen a DVD look this bad. I\u2019ve ripped, upscaled and converted some of my Korn and Nine Inch Nails DVD\u2019s and they did not look this bad. Is this normal with WWE/F DVD\u2019s?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok_Lack5978\"> /u/Ok_Lack5978 </a> <br/> <span><a href=\"https://i.redd.it/ii7udx5yxcqe1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comment",
        "id": 2386029,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhq4eb/do_wwe_dvds_usually_look_this_bad",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ii7udx5yxcqe1.jpeg?width=640&crop=smart&auto=webp&s=dbc5d3644f2956d32ae3538d2afcf0b090d6559a",
        "title": "Do WWE DVD\u2019s Usually Look This Bad?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T02:04:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi there,</p> <p>I have a niche special interest YouTuber with 300+ videos he has made over the years. I have every video he&#39;s ever made (Public, Removed, Membership only, etc). It is roughly 100GB. I wanted to torrent it when I first collected it 6 months ago or so, but I didn&#39;t want to hurt his business. His audience is not typically the typical level of nerdy to care about archiving or torrenting (no hate--he is a mindset / fitness youtuber so he tends to attract people like that more than us techy nerds). But yeah, what do you think about that? I guess this boils down to &quot;keeping data safe, in a way that doesn&#39;t hurt or infringe on creators&#39; profits&quot;</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok_Nail_4795\"> /u/Ok_Nail_4795 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhor82/question_archiving_in_a_way_that_does_not_hurt/\">[link]</a></span> &#32; <spa",
        "id": 2385894,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhor82/question_archiving_in_a_way_that_does_not_hurt",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Question: archiving in a way that does not hurt the copyright holder",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-23T01:50:26+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhoi47/china_unveils_a_powerful_deepsea_cable_cutter/\"> <img src=\"https://external-preview.redd.it/782FclSRo975cGvuYjtQNEAJI9IaGO5hq_DVOAmHP68.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=417a4d4f8fb6b1e3b76b590f0480b9e71405eca0\" alt=\"China unveils a powerful deep-sea cable cutter that could reset the world order \u2014 Beijing now has the power to disrupt global communications\" title=\"China unveils a powerful deep-sea cable cutter that could reset the world order \u2014 Beijing now has the power to disrupt global communications\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Traitor_Donald_Trump\"> /u/Traitor_Donald_Trump </a> <br/> <span><a href=\"https://www.scmp.com/news/china/science/article/3303246/china-unveils-powerful-deep-sea-cable-cutter-could-reset-world-order\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1jhoi47/china_unveils_a_powerfu",
        "id": 2385893,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1jhoi47/china_unveils_a_powerful_deepsea_cable_cutter",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/782FclSRo975cGvuYjtQNEAJI9IaGO5hq_DVOAmHP68.jpg?width=640&crop=smart&auto=webp&s=417a4d4f8fb6b1e3b76b590f0480b9e71405eca0",
        "title": "China unveils a powerful deep-sea cable cutter that could reset the world order \u2014 Beijing now has the power to disrupt global communications",
        "vote": 0
    }
]