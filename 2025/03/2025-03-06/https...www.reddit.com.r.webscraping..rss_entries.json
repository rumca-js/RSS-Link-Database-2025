[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-06T23:31:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all,</p> <p>Currently teaching myself how to scrape. I always try to find the API first before looking at other methods, however, all of the API tutorials on Youtube seem to show it on a super simple e-commerce website rather than something more challenging.</p> <p>If anyone knows of any helpful literature or youtube videos that would be greatly appreciated. </p> <p>Website I&#39;m currently trying to scrape: <a href=\"https://www.dnb.com/business-directory/company-information.commercial_and_industrial_machinery_and_equipment_rental_and_leasing.au.html\">https://www.dnb.com/business-directory/company-information.commercial_and_industrial_machinery_and_equipment_rental_and_leasing.au.html</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SlickGord\"> /u/SlickGord </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j59gsq/finding_the_api/\">[link]</a></span> &#32; <span><a href=\"https://www.",
        "id": 2264612,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j59gsq/finding_the_api",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Finding the API",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-06T20:25:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to scrape pricing data for Magic: the Gathering cards for a web app from <a href=\"https://www.tcgplayer.com/\">https://www.tcgplayer.com/</a> but can&#39;t figure out how to get all of the listing data quickly / reverse engineer their API. Any ideas? Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/r-r-reddit\"> /u/r-r-reddit </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j555c5/card_game_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j555c5/card_game_data/\">[comments]</a></span>",
        "id": 2263331,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j555c5/card_game_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Card Game Data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-06T11:10:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been scraping data for a while and the project has recently picked up some steam, so I&#39;m looking to provide better quality data.</p> <p>There&#39;s so much that can go wrong with webscraping. How do you verify that your data is correct/complete?</p> <p>I&#39;m mostly gathering product prices across the web for many regions. My plan to catch errors is as follows:</p> <ol> <li>Checking how many prices I collect per brand per region and comparing it to the previous time it got scraped <ul> <li>This catches most of the big errors, but won&#39;t catch smaller scale issues. There can be quite a few false positives.</li> </ul></li> <li>Throwing errors on requests that fail multiple times <ul> <li>This detects technical issues and website changes mostly. Not sure how to deal with discontinued products yet.</li> </ul></li> <li>Some manual checking from time to time <ul> <li>incredibly boring</li> </ul></li> </ol> <p>All these require extra manual",
        "id": 2259075,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j4t4uv/how_do_you_quality_check_your_scraped_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you quality check your scraped data?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-06T09:04:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I m Building a Tool for the website auto1.com , you have to log in to access the data. Does that mean it is illegal? Thanks in advance !</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ivo_Sa\"> /u/Ivo_Sa </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j4reof/legal/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j4reof/legal/\">[comments]</a></span>",
        "id": 2258236,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j4reof/legal",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Legal?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-06T05:14:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m struggling to scrape a site completely. This site (<a href=\"https://clerkshq.com/Newport-rit\">https://clerkshq.com/Newport-rit</a>) hosts municipal documents for various towns around the US. Link is to just one of their clients.</p> <p>I&#39;m new to scraping and until AI tools came out my coding ability wasn&#39;t the best. Now at first this was a fun personal puzzle, but not I&#39;m irked and stuck and am at a wall. I don&#39;t wanna give up cause but at this point I&#39;m just wasting time being stubborn.</p> <p>I&#39;m able to scrape a decent amount of the site using TOC pages as they have html links inside them. But a few of the TOC pages such as (<a href=\"http://www.clerkshq.com/toc/Newport-ri?path=Newport_Council\">www.clerkshq.com/toc/Newport-ri?path=Newport_Council</a>) dont (there&#39;s another folder as well). I believe its cause they are using &#39;data-toc-url&#39; + javascript. And unlike the other folders I can&#39;t just make a",
        "id": 2257178,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j4o53u/looking_for_pointersguidance",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for pointers/guidance",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-06T04:26:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, I&#39;ve been trying to get this book for my studies (it&#39;s not available on annas archive, zlibrary, etc etc) <a href=\"https://www.nxtbook.fr/lextenso-editions/Gualino/978-2-297-27726-6/index.php?ap=1\">https://www.nxtbook.fr/lextenso-editions/Gualino/978-2-297-27726-6/index.php?ap=1</a> (they let you see a few pages and then it gets all blurry). I&#39;m no expert on webscraping, but I&#39;ve already tried the typical technique of searching for .pdf in the elements, and when I search for Docs on the network section, the website goes a bit crazy, these things usually work for me, but in this case I&#39;ve tried everything that gpt has told me but anything works, if anyone could give me some advices or tell me if its actually possible to get the book it would be super helpful, thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Minimum-Alps7567\"> /u/Minimum-Alps7567 </a> <br/> <span><a href=\"ht",
        "id": 2256970,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j4nbtg/difficulties_trying_to_get_a_book",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Difficulties trying to get a book",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-06T01:52:06+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1j4kdrl/google_search_scraper_request_based/\"> <img src=\"https://external-preview.redd.it/VwWxuODDUqmXiJSg22p3DTWTlki3FWpK9HoP3clmRkc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9beced793e08423c76627806bdd2275b26ecca8a\" alt=\"Google search scraper ( request based )\" title=\"Google search scraper ( request based )\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I have seen multiple people ask in here how to automate Google search so I feel it may help to share this. No api keys needed. Just good ol request based scraping </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Excellent-Two1178\"> /u/Excellent-Two1178 </a> <br/> <span><a href=\"https://github.com/tkattkat/google-search-scraper\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1j4kdrl/google_search_scraper_request_based/\">[comments]</a></span> </td></tr></table>",
        "id": 2256571,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j4kdrl/google_search_scraper_request_based",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/VwWxuODDUqmXiJSg22p3DTWTlki3FWpK9HoP3clmRkc.jpg?width=640&crop=smart&auto=webp&s=9beced793e08423c76627806bdd2275b26ecca8a",
        "title": "Google search scraper ( request based )",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-03-06T01:35:21+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1j4k1lu/google_maps_scraping_different_results_logged_in/\"> <img src=\"https://a.thumbs.redditmedia.com/ZM7vV0WJWXP1iYB6sWs1qRw5BU_HoO6s9ife8LekME4.jpg\" alt=\"Google Maps scraping - different results logged in vs logged out\" title=\"Google Maps scraping - different results logged in vs logged out\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I\u2019m scraping Google Maps with Playwright, and I see different results when logged into my Google account vs logged out.</p> <p>I tried automating the login, but I hit a block (Google throws an error).</p> <p>Anyone faced this before? How do you handle login for scraping Google Maps?</p> <p><a href=\"https://preview.redd.it/ofgfvmgn3zme1.png?width=1107&amp;format=png&amp;auto=webp&amp;s=4e46cc78a376d9decbd1635c93b75e650266484c\">https://preview.redd.it/ofgfvmgn3zme1.png?width=1107&amp;format=png&amp;auto=webp&amp;s=4e46cc78a376d9decbd1635c93b75e650266484c</a></p> </div><!-- ",
        "id": 2256572,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1j4k1lu/google_maps_scraping_different_results_logged_in",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/ZM7vV0WJWXP1iYB6sWs1qRw5BU_HoO6s9ife8LekME4.jpg",
        "title": "Google Maps scraping - different results logged in vs logged out",
        "vote": 0
    }
]