[
    {
        "age": null,
        "album": "",
        "author": "/u/Wise_Feedback901",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T22:15:15.019377+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T21:56:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Will it let me know when i open the app or is there something I have to do manually for it to check? How often are they updated?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Wise_Feedback901\"> /u/Wise_Feedback901 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjlg2z/how_to_know_when_kiwix_archives_are_updated/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjlg2z/how_to_know_when_kiwix_archives_are_updated/\">[comments]</a></span>",
        "id": 2648591,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjlg2z/how_to_know_when_kiwix_archives_are_updated",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to know when kiwix archives are updated?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GoldenTrevor01",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T22:15:15.237954+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T21:26:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m new to the NAS\u2019s side of home lab\u2019s and recently purchased a Dell MD1000 it has been excellent so far, however I\u2019m only able to get about 30TB out of it with the EMM\u2019s installed. I do have 3 more array enclosures that house 24 drives a piece, but I have no drives for them as of yet and really don\u2019t know the best place to buy HBA\u2019s, good used or budget friendly new drives, or SAS cables. I know I can buy bulk used drives on eBay which is how I filled my MD1000, but I\u2019m just wondering if there are better places to look, thank you all! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GoldenTrevor01\"> /u/GoldenTrevor01 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjksqw/best_places_to_purchase/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjksqw/best_places_to_purchase/\">[comments]</a></span>",
        "id": 2648592,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjksqw/best_places_to_purchase",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best places to purchase",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Cojaro",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T22:15:15.427546+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T21:19:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Searching did not give results for my issue.</p> <p>I have a drive (drive D) with 1.81 TB total space. If I select all the folders, it returns 97,373 files totaling 1.19 TB. If I run chkdsk, it shows 104,631 files totaling 1.58 TB, which is the same used space that&#39;s shown in the This PC folder view. </p> <p>Where are these extra 7,000+ files totaling 0.39 TB? I should note that this is not my boot drive, I have my OneDrive on there with all files on device, hidden folders are shown. Restore Points are set to &lt;10% of C, so that&#39;s moot in my case. Drive is 100% allocated to storage per Disk Management.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Cojaro\"> /u/Cojaro </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjkn9j/data_usage_mismatch_between_drive_properties_and/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjkn9j/data_usage_mism",
        "id": 2648593,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjkn9j/data_usage_mismatch_between_drive_properties_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Data usage mismatch between drive properties and folder properties",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/evildad53",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T22:15:15.616343+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T21:10:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Running out of space on internal drives and external drives. Bought a TerraMaster D4-320 DAS and a couple of Exos 14TB drives. The internal files are already duplicated on the various externals, and backed up to Backblaze. If I want to get the internal files into the DAS (JBOD), can I just copy the folders over using Windows 10, or should I use backup software to make that initial transfer? Does the backup software have any extra error checking or anything? I&#39;m planning to use the 2nd Exos as a backup of the first for now, and add more drives next month or two. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/evildad53\"> /u/evildad53 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjkg52/copy_the_files_or_backup_the_files_first_time/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjkg52/copy_the_files_or_backup_the_files_first_time/\">[comments]<",
        "id": 2648594,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjkg52/copy_the_files_or_backup_the_files_first_time",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Copy the files or backup the files first time onto a clean disk?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jabberwockxeno",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T21:10:20.886416+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T20:15:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>On (or after?) May 15th, Flickr will be disabling large and original size image viewing and downloads for any photos uploaded by Free accounts</p> <p>As such, i&#39;m trying to archive and save a bunch of images before that happens, and from the research i&#39;ve done, gallery DL seems like the best option for this, and relatively simple</p> <p>However, I have a few questions and have run into issues doing small scale tests</p> <ul> <li><p>Both of the users I asked for their commands they used to do something similar had both <a href=\"https://github.com/mikf/gallery-dl/blob/master/docs/options.md#:%7E:text=%2D%2Dwrite%2Dmetadata%20%20%20%20%20%20%20%20%20%20%20%20Write%20metadata%20to%20separate%20JSON%20files%0A%2D%2Dwrite%2Dinfo%2Djson%20%20%20%20%20%20%20%20%20%20%20Write%20gallery%20metadata%20to%20a%20info.json%20file\">--write-metadata and --write-info-json</a> in their full command script, but as far as I can tell these output identical json fil",
        "id": 2648345,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjj9r8/trying_to_archive_flickr_content_before_most",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to archive Flickr content before most fullsize images are disabled this week, help with Gallery-DL?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/shiftdelete76",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T21:10:21.105354+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T19:02:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking for a program that lets me bulk download media from Booru sites and Twitter. </p> <p>I also need it to all downloaded media to be tagged with proper info.</p> <p>If possible, all booru downloads should have the character name in as the file name and also tags in metadata. For twitter, i need downloaded files named accordingly to the what original tweet/post was describing them as.</p> <p>Otherwise bulk downloading will be meaningless as files will be unorginazed mess and i have to go ahead and search for original posts to tag them properly.</p> <p>Is gallery-dl or img-brd capable of what i want? Which one is better? I read img-brd is much easier to use.</p> <p>Any other recommends?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/shiftdelete76\"> /u/shiftdelete76 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjho2s/gallerydl_vs_imgbrd_grabber_for_downloading_media/\">[link]",
        "id": 2648346,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjho2s/gallerydl_vs_imgbrd_grabber_for_downloading_media",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Gallery-dl vs img-brd grabber for downloading media from Booru sites and Twitter?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EthanColeK",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T18:57:10.418140+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T18:56:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have 10tb on a HDD on windows 10. Is there any software they I cns plug in let&#39;s say a 4Tb HDD copy as much as I can untill it&#39;s full.. Then I insert another one of a same size copy the next 4tb and so on untill everything is copied successfully. Even better if there is space left copy duplicates. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EthanColeK\"> /u/EthanColeK </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjhjd1/software_recommendation_backup_to_multiple/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjhjd1/software_recommendation_backup_to_multiple/\">[comments]</a></span>",
        "id": 2647683,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjhjd1/software_recommendation_backup_to_multiple",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Software recommendation backup to multiple smaller hard drives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ludespeedny",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T21:10:21.323648+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T18:50:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am looking at getting a nas for storage and self-hosting a few things like immich and google drive alternatives. Prob is I don&#39;t have many funds to work with. Any suggestions on what I should start looking at? I was thinking an older synology or qnap. I did find a qnap Ts-453be for 300 with 4x4tb drives. Do you think that is a good start or should I start elsewhere?</p> <p>I do already have 1 10tb drive and if I got a dual enclosure, I could pick up another and raid 1 it. My thing is I don&#39;t know what NAS&#39; run docker containers.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ludespeedny\"> /u/ludespeedny </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjhep3/nas_suggestions/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjhep3/nas_suggestions/\">[comments]</a></span>",
        "id": 2648347,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjhep3/nas_suggestions",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "NAS suggestions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EthanColeK",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T18:57:10.606444+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T18:48:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all I have 10tb of movies and photos and music on a windows 10 pc all sitting on a single HDD (I know big mistake). What are some budgets way to backup? I was thinking buying 2 14TB HDD and vacuum seal them with my sous vide machine put them on a dark place like a drawer and calling it a day. Store one here and one on my dad&#39;s place which is on a different continent. </p> <p>I know that there is the option of buying a NAS.. And M disk BkuRays and blackblaze as a service but I seriously don&#39;t want to loose my pictures they only exist right now in the icloud and on that hard drive and that bring me paranoia.. Also my movies which I riped and then threw the physical media away only live there. </p> <p>Best and sorry for being a newbie to this.. </p> <p>For a while I was using Bvckup 2 for windows and keeping my movies on another HDD inside the same windows computer but I feel it&#39;s a terrible idea becasue if I get a virus or a fire or somet",
        "id": 2647684,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjhcx7/store_extra_hard_drive_vacuum_sealed",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Store extra hard drive vacuum sealed?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/UltramarineOne",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T18:57:10.794981+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T18:34:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently brought a external ssd and I want to install windows on a part of it and keep the rest for normal data and use it on my PC and android, is there a way I can format half of it in NTFS and the other half as exFAT</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/UltramarineOne\"> /u/UltramarineOne </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjh1s8/need_help_with_external_ssd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjh1s8/need_help_with_external_ssd/\">[comments]</a></span>",
        "id": 2647685,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjh1s8/need_help_with_external_ssd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help with external ssd",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ezramay",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T18:57:10.982156+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T18:14:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;d like to download some videos from Tudum that Netflix don&#39;t put on their YouTube channel, le sigh.</p> <p>I&#39;ve tried just about everything and can&#39;t pull it off. I think my Macbook is too old...</p> <p>Happy for advice but would much prefer if someone is willing just to rip these for me?</p> <p><a href=\"https://www.netflix.com/tudum/videos/you-season-5-series-finale-table-read-script\">https://www.netflix.com/tudum/videos/you-season-5-series-finale-table-read-script</a><br/> <a href=\"https://www.netflix.com/tudum/videos/you-season-5-behind-the-scenes-penn-badgley\">https://www.netflix.com/tudum/videos/you-season-5-behind-the-scenes-penn-badgley</a><br/> <a href=\"https://www.netflix.com/tudum/videos/you-behind-the-scenes-set-secrets\">https://www.netflix.com/tudum/videos/you-behind-the-scenes-set-secrets</a><br/> <a href=\"https://www.netflix.com/tudum/videos/penn-badgley-thanks-you-fans\">https://www.netflix.com/tudum/videos/penn-badgley",
        "id": 2647686,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjglej/help_downloading_some_embedded_hidden_videos_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help downloading some embedded *hidden* videos from website.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/manzurfahim",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T18:57:11.172058+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T18:04:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone, I&#39;m trying to find an easy way to download all the contents of an IG account. I tried 4K Stogram and it works very well, but unfortunately it is not supported anymore, so I can&#39;t seem to buy a license for it.</p> <p>If you know of any good and easy way to download IG contents, please help me out. I wish I could get a license for 4K Stogram, but I can&#39;t.</p> <p>Many thanks everyone, much appreciated.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/manzurfahim\"> /u/manzurfahim </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjgdeb/best_way_to_download_all_contents_photos_videos/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjgdeb/best_way_to_download_all_contents_photos_videos/\">[comments]</a></span>",
        "id": 2647687,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjgdeb/best_way_to_download_all_contents_photos_videos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best way to download all contents (photos / videos) of an IG account?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BleedingXiko",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T18:57:10.199745+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T17:55:17+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjg5sj/updated_my_media_server_project_now_has_admin/\"> <img src=\"https://preview.redd.it/ot24apfjrzze1.gif?width=640&amp;crop=smart&amp;s=a818780736489813e88b7db312ea79f5a105c5fa\" alt=\"Updated my media server project: now has admin lock, sync passwords, and Pi support\" title=\"Updated my media server project: now has admin lock, sync passwords, and Pi support\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BleedingXiko\"> /u/BleedingXiko </a> <br/> <span><a href=\"https://i.redd.it/ot24apfjrzze1.gif\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjg5sj/updated_my_media_server_project_now_has_admin/\">[comments]</a></span> </td></tr></table>",
        "id": 2647682,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjg5sj/updated_my_media_server_project_now_has_admin",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ot24apfjrzze1.gif?width=640&crop=smart&s=a818780736489813e88b7db312ea79f5a105c5fa",
        "title": "Updated my media server project: now has admin lock, sync passwords, and Pi support",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MeepZero",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T17:52:22.825117+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T17:41:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve got a fair bit of compute and a few dozen terabytes of storage on my home lab. With all the insanity of data being wiped by the US Gov I want to put it all to good use. What initiatives and tools are out there right now that I can join to help?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MeepZero\"> /u/MeepZero </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjfui4/ive_got_a_home_lab_with_a_bunch_of_storage_how/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjfui4/ive_got_a_home_lab_with_a_bunch_of_storage_how/\">[comments]</a></span>",
        "id": 2647456,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjfui4/ive_got_a_home_lab_with_a_bunch_of_storage_how",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I've got a home lab with a bunch of storage, how can I help needy causes?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NatSpaghettiAgency",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T16:45:25.295243+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T16:42:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have three means of backup:</p> <ol> <li>A NTFS-formatted hard drive on which I <code>rsync</code> my phone, my partner&#39;s phone, my computer and other&#39;s people data. For this reason it must be a Windows-compatible file system</li> <li>A NTFS-formatted hard drive on which I perform <code>rdiff-backup</code> from the first hard disk</li> <li>A BTRFS-based NAS on which I perform <code>rdiff-backup</code> from the first hard disk</li> </ol> <p>My question is: I don&#39;t know whether this solution is nice, for example I have no bitrot protection on the second hard disk (I could format it as BTRFS as well but not being in RAID it can only detect, not fix bitrot) and I don&#39;t know if rdiff-backup is suitable for my use-case (mostly pictures and videos). Maybe borg or other solutions would be better? Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NatSpaghettiAgency\"> /u/NatSpaghettiAgency </a> <",
        "id": 2647106,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjejfm/how_do_i_make_an_efficient_backup_in_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do I make an efficient backup in this situation?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/calegendre",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T16:45:25.524509+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T16:42:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>First off, I run PMS &amp; everything off my Mac mini, because it&#39;s mounted under the desk and out of the way and it does a good job of handling my needs.</p> <p>I&#39;m housebound and disabled and I have a (at least I feel it&#39;s getting) large Plex library and growing. New episodes of shows and new things take up space, DVR takes up space, and I&#39;ve hit my first cap with a 10TB drive. I have another 20TB external here and a good number of DVDs and VHS tapes I&#39;d like to digitize that&#39;ll take up again, a good amount of space.</p> <p>All of these &quot;RAID&quot; option things confuse the crap outta me, no matter what I read, watch or otherwise. I can&#39;t afford to have multiple drives the same size for redundancy purposes, it just is what is with my situation...but I really need to find a way to make it think that folders are singular across drives, so media that is grabbed from *arr platforms do not stop because &quot;oh this is fu",
        "id": 2647107,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjej34/best_long_term_solution_on_extremely_low_budget",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best Long Term Solution on Extremely Low Budget?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/plpindc",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T16:45:25.719046+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T16:08:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi friends - can anyone help me figure out how to download this video from PBS? </p> <p><a href=\"https://www.pbs.org/wnet/gperf/next-to-normal-about/16693/\">https://www.pbs.org/wnet/gperf/next-to-normal-about/16693/</a></p> <p>I tried JDownloader2 and got the whole video to downlod but it had no audio. Is there an easy way to rip this video? Thanks! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/plpindc\"> /u/plpindc </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjdspe/help_downloading_this_pbs_video/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjdspe/help_downloading_this_pbs_video/\">[comments]</a></span>",
        "id": 2647108,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjdspe/help_downloading_this_pbs_video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help downloading this PBS Video",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/coldcathodes",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T16:45:25.908754+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T16:05:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Which do you think are more reliable for long term usage?</p> <p>The BarraCudas are on sale for a pretty decent price, but I&#39;m wary about Seagate drives. </p> <p><a href=\"https://www.seagate.com/products/hard-drives/barracuda-hard-drive/?sku=ST24000DM001\">https://www.seagate.com/products/hard-drives/barracuda-hard-drive/?sku=ST24000DM001</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/coldcathodes\"> /u/coldcathodes </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjdqhi/new_24gb_barracudas_vs_helium_wd_easystores/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjdqhi/new_24gb_barracudas_vs_helium_wd_easystores/\">[comments]</a></span>",
        "id": 2647109,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjdqhi/new_24gb_barracudas_vs_helium_wd_easystores",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New 24gb BarraCudas vs Helium WD Easystores",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/YellowTM",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T16:45:24.915269+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T15:58:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am planning on building my first NAS with Unraid in a Jonsbo N2 (so 5 HDD), I have purchased 2 WD Elements 20TB and 2 20TB Seagate Ironwolfs in recent sales.</p> <p>My current set up uses 1 12TB WD Elements attached to a small N5005 box and a 12TB WD My Book attached to a Raspberry Pi for the backups.</p> <p>My original plan was to shuck the new drives and one old one, so I would have 4 20TB and 1 12TB with 2 parity drives for 52TB, keeping my old 12TB Elements as a backup.</p> <p>But the new drives comes with a 2 year fresh warranty, which I assume would be voided by shucking, so my other option would be to keep one of the new 20TB drives as the new backup and instead have 3 20TB and 2 12 TB, for 44TB.</p> <p>I&#39;m pretty sure I won&#39;t need more storage than that until I can afford a bigger case - so my question is, is it more important to have a more reliable backup drive (scenario 2) or should I have more reliable actual data drives (scenari",
        "id": 2647105,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjdkhk/should_i_shuck_my_brand_new_20tb_wd_elements_or",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Should I shuck my brand new 20TB WD Elements or my old 12TB WD Elements that I am currently using?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/warbaque",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T15:40:26.696795+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T15:31:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Current setup is 2x16TB + 2x8TB, and once I need more room I&#39;ll add a new pair or replace smallest pair.</p> <p>Any opinions or recommendations? Most of the time I&#39;ll be running with 6 disks or fewer.</p> <p>I&#39;ve been using mdadm raid5 (with btrfs on top of it for checksums) on my homeserver for years, and I&#39;ve been mostly happy with it. It&#39;s been cost efficient and easy to use, but replacing array with larger disks have been pain in the ass.</p> <p>I am now rebuilding my setup, and I&#39;ve been thinking that maybe simplest setup would be to use one pool where I add mirrored disks under it so each pair of disks will have some redundancy and disks would be pretty simple to replace as pairs. Instead of rebuilding whole array, I could just manage few disks at a time.</p> <p>I would like to have a setup that I can easily extend with either by adding new disks or by replacing existing disks with larger ones. And if one disk dies and th",
        "id": 2646682,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjcys3/what_storage_setup_do_you_recommend_if_i_want_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What storage setup do you recommend, if I want to easily add and remove new mirrored pairs to my pool? Or alternative setup where I can increase storage 1 or 2 disks at a time",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fit_Question9360",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T21:10:21.660348+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T14:45:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>just got some really rare DVDs in, only wish to preserve them in .iso form and in mp4 form. there&#39;s this weird thing about them tho, where it also contains audio tracks stored as &quot;videos&quot;, trying to rip those those as well, but when using handbrake they don&#39;t show up at all. any help or pointers?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Fit_Question9360\"> /u/Fit_Question9360 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjbxtt/breaking_guy_who_knows_nothing_about_ripping_dvds/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjbxtt/breaking_guy_who_knows_nothing_about_ripping_dvds/\">[comments]</a></span>",
        "id": 2648348,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjbxtt/breaking_guy_who_knows_nothing_about_ripping_dvds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "BREAKING: Guy who knows nothing about ripping DVDs realizes he doesn't know how to rip DVDs.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LabPrior8506",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T14:33:53.811099+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T14:25:58+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjbih6/recived_my_hdd_like_this_from_amazon_there_is/\"> <img src=\"https://external-preview.redd.it/8PGEu-BOigr4jUiQjMO6Rs7YLml3ZRSo-YULKym7lFs.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=56ae517b038099fdb9d3bebd15264801f5a18de0\" alt=\"Recived my hdd like this from amazon there is even a small dent on the sata port should i return will it be fine\" title=\"Recived my hdd like this from amazon there is even a small dent on the sata port should i return will it be fine\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LabPrior8506\"> /u/LabPrior8506 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1kjbih6\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjbih6/recived_my_hdd_like_this_from_amazon_there_is/\">[comments]</a></span> </td></tr></table>",
        "id": 2646272,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjbih6/recived_my_hdd_like_this_from_amazon_there_is",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/8PGEu-BOigr4jUiQjMO6Rs7YLml3ZRSo-YULKym7lFs.jpeg?width=640&crop=smart&auto=webp&s=56ae517b038099fdb9d3bebd15264801f5a18de0",
        "title": "Recived my hdd like this from amazon there is even a small dent on the sata port should i return will it be fine",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ireun",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T11:16:55.806714+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T11:14:25+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kj7uet/wd_red_wd60efrx_high_power_draw/\"> <img src=\"https://external-preview.redd.it/j4aKbaEktk-EM89Jj6nkzd6JcGSNrPirdiGtQ6gXo1U.png?width=140&amp;height=73&amp;crop=140:73,smart&amp;auto=webp&amp;s=39991a1f38bc140db5d245a0ba314fe9b316444a\" alt=\"WD RED WD60EFRX - High power draw?\" title=\"WD RED WD60EFRX - High power draw?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi! </p> <p>I&#39;m building my first DIY-NAS, repurposing a Mini PC. The MiniPC runs proxmox, on which i&#39;ve set up TrueNAS Scale VM, PCI passthrough the SATA controller, and I&#39;ve got 1 Pool, with 1 VDEV, with 1 HDD - the WD60EFRX.<span class=\"md-spoiler-text\">redundancy will come later</span></p> <p>I&#39;ve got a separate PSU for the HDD, what is measured here is solely the 12V PSU + PicoPSU-80W + WD60EFRX.</p> <p>I&#39;ve found these specs online: </p> <ul> <li>Power Required (Seek): 5.3 W</li> <li>Power Required (Idle): 3.4 W</li> ",
        "id": 2645282,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kj7uet/wd_red_wd60efrx_high_power_draw",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/j4aKbaEktk-EM89Jj6nkzd6JcGSNrPirdiGtQ6gXo1U.png?width=140&height=73&crop=140:73,smart&auto=webp&s=39991a1f38bc140db5d245a0ba314fe9b316444a",
        "title": "WD RED WD60EFRX - High power draw?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Javidor44",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T11:16:55.994966+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T11:13:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, last summer when I visited my parents, I had the idea to backup all the games from my childhood consoles and bring them in a hard drive with me. Overall, the whole library is a bit over half a terabyte</p> <p>This hard drive contains both the backups and several games from various sources (Steam, GOG...) and recently I&#39;ve been running tight in space with installing some games on it, so I&#39;m looking into how to better manage the size of my backed-up games.</p> <p>I once managed to compress a single game into about half of its original size with some tweaking of the 7z settings, which is great because that&#39;d free up hundreds of GB from my disk, but it also took a LONG time. I&#39;m also worried about the decompression time afterwards, since it&#39;s gonna take a LONG time as well, although I am aware that compression algorithms often have asymmetric compression/decompression speed.</p> <p>I also have tons of Minecraft saves I preserve for",
        "id": 2645283,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kj7txq/how_to_better_manage_the_size_of_my_storage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to better manage the size of my storage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/tasic89",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T11:16:56.224964+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T10:28:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I would use it just to get data, large 4k files from torrents, etc etc. And keep them for some time or maybe forever. So it will not be used &quot;24/7&quot; or how long the PC is working. As a full working guy, unfortunately, I only have few hours a day to use PC. All data I would like to get and keep it there are &quot;recoverable&quot;.</p> <p>I have EXOS 16tb, and I am satisfied with that drive. But I saw that Barracuda and it seems &quot;Cheap&quot;... I also have some old old Baracuda 8tb from like 2012 and it still works like a clock, with 100% health. I plan to just use that Barracuda 8tb for putting somewhere and keep &quot;unrecoverable&quot; files.</p> <p>But, what do you guys think ? EXOS 20tb or Barracuda 24tb ?</p> <p>p.s. I have ssd m2 drive 2tb for regular gaming usage and stuff. This drive would be only a real data hoarder</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tasic89\"> /u/tasic89 </a> ",
        "id": 2645284,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kj75gy/exos_20tb_or_barracuda_24tb_for_ordinary_average",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "EXOS 20TB or Barracuda 24TB for \"ordinary, average PC\" usage ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/spamthroat",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T10:11:32.148106+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T09:30:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have been using dupeguru as it does exactly what I want but it is not been updated for a long time.</p> <p>I need</p> <p>1) Find duplicates<br/> 2) Delete them<br/> 3) Free</p> <p>No fancy moving, saving, replacing with links, renaming or anything like that.</p> <p>Background - Every month or so I copy the &quot;My PC&quot; directory (Documents, Videos, Music, Downloads...) in Windows to an external HD. Eventually HD gets full so I will search for the duplicates from the copies from a previous year and delete them.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/spamthroat\"> /u/spamthroat </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kj6bur/dupeguru_alternative/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kj6bur/dupeguru_alternative/\">[comments]</a></span>",
        "id": 2645016,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kj6bur/dupeguru_alternative",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dupeguru alternative.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/annsba",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T09:06:27.801513+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T08:20:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Other than WayBackMachine, what other free service is out there to look at an archived page? I just need to use it once and have never done it before. WayBackMachine just keeps trying to load and gives me nothing. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/annsba\"> /u/annsba </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kj5dej/site_before_the_edits/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kj5dej/site_before_the_edits/\">[comments]</a></span>",
        "id": 2644714,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kj5dej/site_before_the_edits",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Site before the edits",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jrjmun",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T06:56:24.413194+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T06:55:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have 8 x 28TB drives primarily for a media server containing many thousands of videos ranging from 2GB to 100GB. Secondary purposes of server is for hosting music, remote backup of phones and other PCs, minimal home automation, VMs, and much more.</p> <p>If anyone has any resources to help me best decide which OS and filesystem will best suit my needs please chime in. TrueNAS Scale, UnRAID, Proxmox and many more are certainly options, but I sure could use some resources to help me decide. I&#39;m not asking for specific advice on the OS/FS here now, though I&#39;m not opposed, but would more like a small list of where to go to help me make the best decision in a reasonable amount of time. Scouring search results can be quite tedious and confusing! Any help is appreciated. Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jrjmun\"> /u/jrjmun </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/",
        "id": 2644254,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kj45l2/i_have_8_x_28tb_drives_for_a_nas_where_do_i_start",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I have 8 x 28TB drives for a NAS - where do I start to guide me to the ideal OS and file system?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ceeesar",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T04:47:55.920078+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T04:44:57+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kj26fb/stumbled_upon_a_few_hard_drives/\"> <img src=\"https://preview.redd.it/iyeyqroqwvze1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c75f3da4bf76b2cdf77b8443d1595558f7afc88\" alt=\"stumbled upon a few hard drives\" title=\"stumbled upon a few hard drives\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>my original idea was wipe them and then sell them - but i had someone tell me to play around with them and do small projects. what do y\u2019all think?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ceeesar\"> /u/ceeesar </a> <br/> <span><a href=\"https://i.redd.it/iyeyqroqwvze1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kj26fb/stumbled_upon_a_few_hard_drives/\">[comments]</a></span> </td></tr></table>",
        "id": 2643876,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kj26fb/stumbled_upon_a_few_hard_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/iyeyqroqwvze1.jpeg?width=640&crop=smart&auto=webp&s=8c75f3da4bf76b2cdf77b8443d1595558f7afc88",
        "title": "stumbled upon a few hard drives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/boywithapplesauce",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T04:47:55.699764+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T04:07:59+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/boywithapplesauce\"> /u/boywithapplesauce </a> <br/> <span><a href=\"https://www.ign.com/articles/netflix-to-remove-black-mirror-bandersnatch-from-platform-in-an-effort-to-ditch-interactive-programming\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kj1kn0/netflix_to_remove_black_mirror_bandersnatch_and/\">[comments]</a></span>",
        "id": 2643875,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kj1kn0/netflix_to_remove_black_mirror_bandersnatch_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Netflix To Remove \u2018Black Mirror: Bandersnatch\u2019 and \u2018Unbreakable Kimmy Schmidt: Kimmy vs The Reverend\u2019 From Platform on May 12 In an Effort to Ditch Interactive Programming",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Trumba_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T03:41:08.809934+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T03:22:10+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kj0rq5/what_does_this_red_warning_mean/\"> <img src=\"https://preview.redd.it/kkxj6p30hvze1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b563edf7137f5aff5a23226700a461461a27d97\" alt=\"What does this red warning mean?\" title=\"What does this red warning mean?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>anyone know what this red sign mean in disk genius? it appeared when i had the windows popup saying &quot;Autoplay: Select what happens with removable disk&quot;, which I dont understand because its a SATA HDD. ever since this red triangle sign showed on my HDD, that windows pops up alawys show when ever I try to download games on steam and even files from sites, it just get cancelled at the same time with that windows Autoplay pop up. I even switched my SATA cables and changed the port locations and it still didn&#39;t change anything, I even tried changing the HDD drive to see if it was the drive itself ",
        "id": 2643694,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kj0rq5/what_does_this_red_warning_mean",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/kkxj6p30hvze1.png?width=216&crop=smart&auto=webp&s=9b563edf7137f5aff5a23226700a461461a27d97",
        "title": "What does this red warning mean?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/QualitySound96",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T03:41:08.446515+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T02:41:48+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kj02gu/is_this_a_safe_way_to_duplicate_a_drive/\"> <img src=\"https://preview.redd.it/l1i41q5eavze1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=64dd7bee4da3c698172dec018d47bc66bf16ae76\" alt=\"is this a safe way to duplicate a drive?\" title=\"is this a safe way to duplicate a drive?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>so i had to reformat an external so used the backup and am now mirroring onto the newly formatted drive. i was going to do the drag and drop method of folders and files but was told thats not the best way. ive never used anything like this before, my method has always been drag and drop but whats funny is i compared 2 other drives where i did the drag and dorp method and saw they didnt match up exactly until i did a mirror with this program. looked like maybe 100mb difference. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/QualitySound96\"> /u",
        "id": 2643693,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kj02gu/is_this_a_safe_way_to_duplicate_a_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/l1i41q5eavze1.png?width=640&crop=smart&auto=webp&s=64dd7bee4da3c698172dec018d47bc66bf16ae76",
        "title": "is this a safe way to duplicate a drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PricePerGig",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T02:36:15.008612+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T02:19:37+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PricePerGig\"> /u/PricePerGig </a> <br/> <span><a href=\"https://pricepergig.com/calculator\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kizo8o/i_fixed_the_disk_prices_calculator_on/\">[comments]</a></span>",
        "id": 2643507,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kizo8o/i_fixed_the_disk_prices_calculator_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I fixed the disk prices calculator on pricepergig.com as requested in this sub, but is it any use anyway?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DINOLOL569",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T02:36:14.760376+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T02:08:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to have a local backup of a few Wayback Machine pages mainly for old ARGs. If I try to download the page using just the browser the download then lacks most of the information on the page. I&#39;ve looked into Wayback Machine Downloader and Wget but I&#39;m fairly new to working with CLI and they require several other programs all of which come from websites that look less than secure.</p> <p>So is there a simple way that I could download pages from the Wayback Machine either through the Internet Archive itself or another piece of software that doesn&#39;t lead me down a rabbit hole?</p> <p>Cheers</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DINOLOL569\"> /u/DINOLOL569 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kizgwl/is_there_a_simple_way_to_backup_wayback_machine/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kizgwl/is_there_a_simpl",
        "id": 2643506,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kizgwl/is_there_a_simple_way_to_backup_wayback_machine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a simple way to backup Wayback Machine Pages",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TrueBenJAMin",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T01:31:09.783959+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T01:28:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I had an archived japanese page bookmarked for a while, only for it to somehow show up as a blank page, and the wayback machine saying the page doesn&#39;t exist despite it working on the archive before with multiple dates logging the page. Why is this happening? Here&#39;s the link btw <a href=\"http://www.party-tencho.com/tenchonobar/\">www.party-tencho.com</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TrueBenJAMin\"> /u/TrueBenJAMin </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kiyqhm/an_archived_page_from_the_wayback_machine_now/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kiyqhm/an_archived_page_from_the_wayback_machine_now/\">[comments]</a></span>",
        "id": 2643318,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kiyqhm/an_archived_page_from_the_wayback_machine_now",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "An archived page from the wayback machine now shows up blank, but it used to be a page full of info. Why is this?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fukushimafan",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T01:31:09.420703+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T00:40:49+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kixu6k/erm_i_put_sharpie_on_my_cdr_and_it_melted/\"> <img src=\"https://external-preview.redd.it/R8xzQpAvuf6kgNIRY6UovbbsmjTsn51W-8BtSgJUBW8.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=217ce1f37cdf50ca57c7b6577ea10538bff50055\" alt=\"Erm\u2026 I put sharpie on my CD-R and it melted!?\" title=\"Erm\u2026 I put sharpie on my CD-R and it melted!?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>This was a test CD-R. Don&#39;t worry there was no data on it. Also don&#39;t ask what I was doing with it.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Fukushimafan\"> /u/Fukushimafan </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1kixu6k\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kixu6k/erm_i_put_sharpie_on_my_cdr_and_it_melted/\">[comments]</a></span> </td></tr></table>",
        "id": 2643317,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kixu6k/erm_i_put_sharpie_on_my_cdr_and_it_melted",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/R8xzQpAvuf6kgNIRY6UovbbsmjTsn51W-8BtSgJUBW8.jpeg?width=640&crop=smart&auto=webp&s=217ce1f37cdf50ca57c7b6577ea10538bff50055",
        "title": "Erm\u2026 I put sharpie on my CD-R and it melted!?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/StandardIntern4169",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-10T00:26:12.531658+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-10T00:15:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I&#39;m looking for a budget 4TB NVMe SSD (PCIe Gen 3 \u00d74) to use in a Thunderbolt 3/4 USB-C enclosure. Since Thunderbolt maxes out around 3000 MB/s, I don\u2019t need a fast Gen 4 drive \u2014 just something reliable and affordable that can hit Gen 3 speeds.</p> <p>Any model recommendations with its price? I live in Japan.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/StandardIntern4169\"> /u/StandardIntern4169 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kixcav/best_budget_4tb_nvme_ssd_gen_3_x4/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kixcav/best_budget_4tb_nvme_ssd_gen_3_x4/\">[comments]</a></span>",
        "id": 2643110,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kixcav/best_budget_4tb_nvme_ssd_gen_3_x4",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best budget 4TB NVMe SSD (Gen 3 x4)?",
        "vote": 0
    }
]