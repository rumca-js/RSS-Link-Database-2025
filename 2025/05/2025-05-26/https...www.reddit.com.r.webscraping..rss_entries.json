[
    {
        "age": null,
        "album": "",
        "author": "/u/93bx",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-26T22:41:02.222371+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-26T22:18:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to scrape a streaming website for the m3u8 by intercepting the requests and fetching the m3u8 links, which is sent when the play button is clicked. The website has a turnstile Captcha which loads the iframe if passed. Otherwise it loads an empty iframe. I&#39;m using puppeteer and I tried all the modified versions and plugins, but still it doesn&#39;t work. Any tips on how to solve this challenge? Note: The captcha is invisible and works in the background, there&#39;s no click the button to verify you&#39;re human.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/93bx\"> /u/93bx </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kw78nd/looking_for_turnstile_captcha_bypass_tips/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kw78nd/looking_for_turnstile_captcha_bypass_tips/\">[comments]</a></span>",
        "id": 2777553,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kw78nd/looking_for_turnstile_captcha_bypass_tips",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for Turnstile Captcha bypass tips",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Designer_Athlete7286",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-26T23:46:05.821080+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-26T14:28:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m excited to share a project I&#39;ve been working on: <strong>Extract2MD</strong>. It&#39;s a client-side JavaScript library that converts PDFs into Markdown, but with a few powerful twists. The biggest feature is that it can use a local large language model (LLM) running entirely in the browser to enhance and reformat the output, so no data ever leaves your machine.</p> <p><strong><a href=\"https://www.google.com/search?q=https://github.com/hashangit/Extract2MD\">Link to GitHub Repo</a></strong></p> <p><strong>What makes it different?</strong></p> <p>Instead of a one-size-fits-all approach, I&#39;ve designed it around 5 specific &quot;scenarios&quot; depending on your needs:</p> <ol> <li> <strong>Quick Convert Only</strong>: This is for speed. It uses PDF.js to pull out selectable text and quickly convert it to Markdown. Best for simple, text-based PDFs.</li> <li> <strong>High Accuracy Convert Only</strong>: For the tough stuff like scanned docu",
        "id": 2777808,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kvvr5n/purely_clientside_pdf_to_markdown_library_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Purely client-side PDF to Markdown library with local AI rewrites",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Lupical712",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-26T15:05:18.932015+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-26T14:07:24+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1kvv8y5/need_help_web_scraping_kijiji/\"> <img src=\"https://b.thumbs.redditmedia.com/w9KZfO33J2aDvZy85befmkJRCN-0iIUFG09TISzcKiQ.jpg\" alt=\"Need help web scraping kijiji\" title=\"Need help web scraping kijiji\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Amateur programmer here.<br/> I&#39;m web scraping for basic data on housing prices, etc. However, I am struggling to find the information I need to get started. Where do I have to look? </p> <p><a href=\"https://preview.redd.it/wkaiwfd1v43f1.png?width=2942&amp;format=png&amp;auto=webp&amp;s=4ad732722bf19c3bf1c80fa3246cb4679e420de1\">https://preview.redd.it/wkaiwfd1v43f1.png?width=2942&amp;format=png&amp;auto=webp&amp;s=4ad732722bf19c3bf1c80fa3246cb4679e420de1</a></p> <p>This is another (failed) attempt by me, and I gave up because a friend told me that chromedriver is useless... I don&#39;t know if I could trust that, does anyone know if this code might have an",
        "id": 2774925,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kvv8y5/need_help_web_scraping_kijiji",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/w9KZfO33J2aDvZy85befmkJRCN-0iIUFG09TISzcKiQ.jpg",
        "title": "Need help web scraping kijiji",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Asleep-Patience-3686",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-26T14:00:44.984208+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-26T13:25:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone! Recently, I decided to develop a script with AI to help a friend with a tedious Google Maps data collection task. My friend needed to repeatedly search for information in specific areas on Google Maps and then manually copy and paste it into an Excel spreadsheet. This process was time-consuming and prone to errors, which was incredibly frustrating!</p> <p>So, I spent over a week using web automation techniques to write this userscript. It automatically <strong>accumulates</strong> all your search results on Google Maps, no matter if you scroll down to refresh, drag the map to different locations, or perform new searches. It automatically captures the key information and allows you to <strong>export everything in one click</strong> as an Excel (.xlsx) file. Say goodbye to the pain of manual copy-pasting and make data collection easy and efficient!</p> <p>Just want to share with others and hope that it can help more people in need. Totally",
        "id": 2774416,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kvub1r/free_userscript_for_google_map_scraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "free userscript for google map scraper",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/yshraj_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-26T05:11:48.351792+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-26T04:49:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Hi!</strong><br/> I\u2019m a freelance Python developer from India, offering fast and affordable <strong>web scraping, crawling, and discovery automation scripts</strong> for one-off tasks or ongoing projects.</p> <h1>\ud83d\udee0\ufe0f What I Can Do:</h1> <ul> <li>Web scraping using <strong>Python and Node.js (Requests, BeautifulSoup, Selenium, Scrapy, Playwright)</strong></li> <li>Handle <strong>dynamic websites</strong>, JavaScript rendering, login-required pages</li> <li>IP rotation, proxies, headless browsing support</li> <li>Extract data to <strong>CSV, JSON, Excel, or directly into databases</strong></li> <li>Sitemap discovery, recursive crawling</li> <li>Automate form submissions, filters, paginations, and more</li> </ul> <h1>\ud83d\udcc2 Some Past Projects:</h1> <ul> <li>Scraped 50k+ product listings from eCommerce platforms</li> <li>Built crawlers for real estate sites (listing + pricing history)</li> <li>Automated resume extraction from job boards</li> <li>Monitor",
        "id": 2771675,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kvlxcs/for_hire_need_data_scraped_freelance_web_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[For Hire] Need Data Scraped? Freelance Web Scraping Expert",
        "vote": 0
    }
]