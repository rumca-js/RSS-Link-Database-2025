[
    {
        "age": null,
        "album": "",
        "author": "/u/Exidos2468",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T22:36:50.898085+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T22:35:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, so for the last month I\u2019ve been toying with the idea of buying a NAS to store my files and backups, stream media and basically use as a cloud drive in and out of the house. My knowledge of NAS units is quite limited, I know that if you build them yourself it is both cheaper and it provides upgradeability, but I do not have the time to tinker right now and need a compact solution.</p> <p>Searching Amazon I have found two units that are in my budget and I am kind of torn between the two options, Synology DS223J vs QNAP TS-233</p> <p>Correct me if I\u2019m wrong, but QNAP appears to be a better choice in terms of specs, offering an additional 1 GB of RAM and being cheaper than the DS233J. However, I\u2019ve heard about the data protection issues the company has had in the past, and I\u2019ve also heard that the general user experience of Synology, with its ease of use, setup and app variety to be better than TS-233.</p> <p>So I am kind of in between these options, ",
        "id": 2811988,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kzhlax/what_nas_system_would_you_suggest_for_a_beginner",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What NAS system would you suggest for a beginner Synology DS223J vs QNAP TS-233",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fickle_Blackberry_64",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T22:36:51.074962+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T22:26:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i also know a hack to access a doc but i wanna actually have it as a PDF</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Fickle_Blackberry_64\"> /u/Fickle_Blackberry_64 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kzhdk2/can_one_download_scribd_files_as_an_pdf/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kzhdk2/can_one_download_scribd_files_as_an_pdf/\">[comments]</a></span>",
        "id": 2811989,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kzhdk2/can_one_download_scribd_files_as_an_pdf",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can one download Scribd files as an PDF",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/epic1772",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T22:36:51.223299+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T22:06:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Post the largest number you&#39;ve seen on a screen for storage in comments, I want my mind to be blown</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/epic1772\"> /u/epic1772 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kzgwyu/just_found_this_sib_i_want_to_be_amazed_by/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kzgwyu/just_found_this_sib_i_want_to_be_amazed_by/\">[comments]</a></span>",
        "id": 2811990,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kzgwyu/just_found_this_sib_i_want_to_be_amazed_by",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Just found this sib, I want to be amazed by storage amounts",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/photoby_tj",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T22:36:50.716776+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T21:58:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been a photographer for over a decade and have accumulated around 15TB of images, all spread across 12 external hard drives and dozens of Lightroom Classic catalogues. This includes everything: personal photos, professional shoots, travel, family, etc.</p> <p>It\u2019s been a bit of a \u201csave everything, sort it later\u201d approach, and now I\u2019m facing the \u201clater\u201d part.</p> <p>I&#39;ll have loads of catalogues (many need upgrading), with 10k\u201350k photos inside. Some are organised, 99% aren\u2019t. I do have exported favourites saved for my website, but there are thousands more that I\u2019ve forgotten about and would love to rediscover.</p> <p>But the idea of manually opening each catalogue and scrolling through dozens of 50,000 image catalogues makes my brain hurt.</p> <p>So what\u2019s the most efficient way to actually review and organise this? Merge catalogues? Use a tool like Photo Mechanic to batch preview?</p> <p>Would love to hear from anyone who\u2019s done large-scale ",
        "id": 2811987,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kzgqvx/ive_hoarded_15tb_of_lightroom_photos_over_13",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I\u2019ve hoarded 15TB of Lightroom photos over 13 years... how do I actually go through them now?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cwm9",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T21:31:47.213012+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T21:28:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have several 512e drives, and was considering converting to 4kn since several online references imply that converting from 512e to 4Kn results in an increase in capacity and error correction capability.</p> <p>But after thinking about it some more, I realized this claim doesn&#39;t make sense to me, so I wanted to check to see if anyone has <em>actually done it</em> and measured the capacity <em>before and after</em>. I don&#39;t want to waste my time only to find out I gained basically nothing.</p> <p>The reason it doesn&#39;t make sense to me is that according to what I read, 512e is <em>emulated</em> by the controller, but <em>stored</em> as 4kn. I would expect that to mean that, physically, on the drive, the sector is stored as a 4kn sector <em>with 4kn ECC data</em>, not as 512n sectors and <em>512n ECC</em>. Thus, any gain in density and error correction capability should apply to the 512e sectors just as much as 4kn sectors.</p> <p>Now, I can",
        "id": 2811553,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kzg1en/does_converting_from_512e_4kn_result_in_an_actual",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does converting from 512e -> 4Kn result in an actual measured increase in capacity? Because it seems like it shouldn't.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/xEvilL_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T19:24:24.471511+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T18:21:07+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kzbhg1/14tb_hdds_from_aliexpress/\"> <img src=\"https://preview.redd.it/8bhm2mxkoy3f1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d73a87b3cf3c6d5749f3764e8d3b95438fbd87fa\" alt=\"14TB HDD\u2019s from Aliexpress\" title=\"14TB HDD\u2019s from Aliexpress\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey Everyone,</p> <p>I host a media server and have been slowly growing my capacity, currently I have about 19TB consisting of 2x 8TB 1x2TB and 1x1TB,</p> <p>I\u2019m looking to expand my storage and found this great deal on aliexpress for new 14TB drives each for 175$ with 4.5 rating reviews,</p> <p>Any advice if these are worth getting or not ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/xEvilL_\"> /u/xEvilL_ </a> <br/> <span><a href=\"https://i.redd.it/8bhm2mxkoy3f1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kzbhg1/14tb_hdds_from_aliexp",
        "id": 2810614,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kzbhg1/14tb_hdds_from_aliexpress",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/8bhm2mxkoy3f1.jpeg?width=640&crop=smart&auto=webp&s=d73a87b3cf3c6d5749f3764e8d3b95438fbd87fa",
        "title": "14TB HDD\u2019s from Aliexpress",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Monoboy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T18:19:22.688663+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T17:59:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>Putting together a new server build, and I need a new case to replace my very old Antec case (that worked great, but I didn&#39;t care how the HDDs were laid out).</p> <p>I shouldn&#39;t need to put in more than 8 drives. Is the Fractal Design Define R5 still the case to go for? Is there something better out there? It just sits in a closet, so it doesn&#39;t have to look fancy.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Monoboy\"> /u/Monoboy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kzaxcm/fractal_design_define_r5_still_a_good_case_to_go/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kzaxcm/fractal_design_define_r5_still_a_good_case_to_go/\">[comments]</a></span>",
        "id": 2810074,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kzaxcm/fractal_design_define_r5_still_a_good_case_to_go",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Fractal Design Define R5 still a good case to go with?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AlanSlade",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T17:15:16.376358+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T16:52:37+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz98wq/raid_0_with_my_two_8_tb_drives_or_buy_a_single/\"> <img src=\"https://b.thumbs.redditmedia.com/4gzfl_FUhJdbPWwZ8NzjfocglGoqxmQpIPILWSgMB3w.jpg\" alt=\"Raid 0 with my two 8 tb drives, or buy a single 16\\18\\20 tb drive? Just bought a NAS.\" title=\"Raid 0 with my two 8 tb drives, or buy a single 16\\18\\20 tb drive? Just bought a NAS.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Good evening everyone. Just wanted to ask for suggestione regarding my drives. </p> <p>I&#39;m a photographer, all my pc is back upped with Backblaze so I don&#39;t fear to lose my work. I bought a NAS UGREEN DXP2800 primarily to work when I&#39;m not in my studio with all of my photos;</p> <p>they are stored in two external 8 tb WD Mybook. </p> <p><a href=\"https://preview.redd.it/r6btg28r4y3f1.jpg?width=799&amp;format=pjpg&amp;auto=webp&amp;s=93cd638058054356d6d7aebce3b3a14bda6e5e39\">https://preview.redd.it/r6btg28r4y3f1.jpg?width=7",
        "id": 2809486,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kz98wq/raid_0_with_my_two_8_tb_drives_or_buy_a_single",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/4gzfl_FUhJdbPWwZ8NzjfocglGoqxmQpIPILWSgMB3w.jpg",
        "title": "Raid 0 with my two 8 tb drives, or buy a single 16\\18\\20 tb drive? Just bought a NAS.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Neurrone",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T17:15:16.105296+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T16:28:00+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz8mgc/petabyteclass_e2_ssds_poised_to_disrupt_warm_data/\"> <img src=\"https://external-preview.redd.it/8PrvenERsShEbqUje3fBbKHprqT-ImAVFx8daU06Bf4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3315081084288c542a18e768c45a7b9b7abab0a9\" alt=\"Petabyte-Class E2 SSDs Poised to Disrupt Warm Data Storage\" title=\"Petabyte-Class E2 SSDs Poised to Disrupt Warm Data Storage\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Neurrone\"> /u/Neurrone </a> <br/> <span><a href=\"https://www.storagereview.com/news/e2-ssd-form-factor\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz8mgc/petabyteclass_e2_ssds_poised_to_disrupt_warm_data/\">[comments]</a></span> </td></tr></table>",
        "id": 2809485,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kz8mgc/petabyteclass_e2_ssds_poised_to_disrupt_warm_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/8PrvenERsShEbqUje3fBbKHprqT-ImAVFx8daU06Bf4.jpg?width=640&crop=smart&auto=webp&s=3315081084288c542a18e768c45a7b9b7abab0a9",
        "title": "Petabyte-Class E2 SSDs Poised to Disrupt Warm Data Storage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sea-Curve1871",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T15:01:28.057032+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T14:03:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have business idea wich requires searching discord servers for some specific stuff And I always wanted to search all discord servers in one go and when I found out about searchcord.io it was already shut down </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sea-Curve1871\"> /u/Sea-Curve1871 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz51jz/need_searchcordio_alt/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz51jz/need_searchcordio_alt/\">[comments]</a></span>",
        "id": 2808267,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kz51jz/need_searchcordio_alt",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need searchcord.io alt",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Grouchy_Rise2536",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T13:58:46.278649+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T13:46:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just wondering why companies sell drives in TB and not in TiB.</p> <p>The only reason I can imagine is bc marketing: 20TB are less bytes than 20TiB, and thus cheaper. But is that it?</p> <p>Let me know what you think</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Grouchy_Rise2536\"> /u/Grouchy_Rise2536 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz4mo1/why_tb_and_not_tib/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz4mo1/why_tb_and_not_tib/\">[comments]</a></span>",
        "id": 2807525,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kz4mo1/why_tb_and_not_tib",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Why TB and not TiB?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Shalliar",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T13:58:45.826903+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T13:07:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, after I started doubting DupeGuru and moved the duplicates it found back home, I said to myself that Ill do everything by hand but as usual I couldnt just stay on course and, remembering that some of you recommended to use czkawka instead, Ive decided to give it a chance as well. </p> <p>Currently it is removing the duplicates from the same folder DupeGuru worked on, and in the meantime I wanted to ask your opinion on czkawka trustworthiness. Can I be sure that it wont remove the best &quot;quality&quot; (size \\ dimensions) version of a given file and wont flag something 100% original as a duplicate of something else, given that I used its default settings (Hash \\ Blake3 \\ Recursive) and only selected the smallest files in each &quot;group&quot;? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Shalliar\"> /u/Shalliar </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz3s2i/question_abou",
        "id": 2807523,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kz3s2i/question_about_czkawka",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Question about czkawka",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Flimsy-Peak5633",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T13:58:45.981700+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T13:00:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It seems like the archive pricing of glacier but the retrieval costs of standard S3? </p> <p>I haven&#39;t used S3 in years and was wondering if anyone can share some insight. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Flimsy-Peak5633\"> /u/Flimsy-Peak5633 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz3lzs/am_i_missing_something_with_s3_intelligenttiering/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz3lzs/am_i_missing_something_with_s3_intelligenttiering/\">[comments]</a></span>",
        "id": 2807524,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kz3lzs/am_i_missing_something_with_s3_intelligenttiering",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Am I missing something with S3 Intelligent-Tiering?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PrinceTinyWeiner",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T13:58:46.634107+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T12:55:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, for years upon years I&#39;ve had RSS feeds running with studio-names - that way, I just gobbled every new scene up, and could vet it via jellyfin/plex - didn&#39;t give me an overview of scenes-available/scenes-owned, but the get-all-then-vet made sure I could sleep.</p> <p>Then I stumbled upon Whisparr, which got me an overview of available in text-format, great, let me go that route - untill I realised the V3 api issues - so I looked at ero&#39;s build, which at first glance had some irritating feats as the &quot;scene&quot; folder mandat for every file, but the IMAGE-overview made me reconfigure it all because that seemed like a God send, to vet all the things I didn&#39;t want by LOOKING at it, instead of going by a quick glance at the studio/name/performer (it&#39;s an ocd issue more than a watch issue).</p> <p>Then I started noticing that somethings weren&#39;t conneted to the right studios, but somehow was right in Whisparr - to realize th",
        "id": 2807526,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kz3igt/ive_messed_up_30tb_of_movies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I've messed up 30tb of movies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/notmichaelgood",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T09:59:51.353897+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T09:37:36+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz00ai/is_this_good_for_marking_my_discs_or_will_it/\"> <img src=\"https://preview.redd.it/tyr6t8n63w3f1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c002ebb1649434acaaf5255a0a0ec23560863b71\" alt=\"Is this good for marking my discs? Or will it cause some damage?\" title=\"Is this good for marking my discs? Or will it cause some damage?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://amzn.eu/d/hhE3Hbg\">https://amzn.eu/d/hhE3Hbg</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/notmichaelgood\"> /u/notmichaelgood </a> <br/> <span><a href=\"https://i.redd.it/tyr6t8n63w3f1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kz00ai/is_this_good_for_marking_my_discs_or_will_it/\">[comments]</a></span> </td></tr></table>",
        "id": 2806034,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kz00ai/is_this_good_for_marking_my_discs_or_will_it",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/tyr6t8n63w3f1.jpeg?width=640&crop=smart&auto=webp&s=c002ebb1649434acaaf5255a0a0ec23560863b71",
        "title": "Is this good for marking my discs? Or will it cause some damage?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/friendly-fiend",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T08:56:48.976265+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T07:57:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I currently have 2 x 14tb HDD&#39;s in a raid 1 array for a plex server, and I want to add a SSD to speed up the response time. Can this be done without formatting? </p> <p>I did search the net and wiki but I am very new to raid/linux. </p> <p>This is for ubuntu desktop but I am starting to use the terminal as well.</p> <p>Feel free to point me to a <strong>raid for</strong> <strong>Dummies</strong> resource.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/friendly-fiend\"> /u/friendly-fiend </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kyyl45/can_i_add_a_cache_drive_to_an_existing_raid_1/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kyyl45/can_i_add_a_cache_drive_to_an_existing_raid_1/\">[comments]</a></span>",
        "id": 2805664,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kyyl45/can_i_add_a_cache_drive_to_an_existing_raid_1",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can I add a cache drive to an existing Raid 1 without formatting it?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/JoeShtoops",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T06:45:48.237336+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T06:39:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Like the title says, I\u2019m looking for a jbod enclosure that uses a normal atx PSU. </p> <p>I\u2019m hoping to build a server in it with space for an eatx board, 5.25 hdd hot swappable drive caddies, and a backplane. </p> <p>Thanks in advance! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JoeShtoops\"> /u/JoeShtoops </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kyxg10/does_anyone_have_a_suggestion_for_a_jbod/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kyxg10/does_anyone_have_a_suggestion_for_a_jbod/\">[comments]</a></span>",
        "id": 2805028,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kyxg10/does_anyone_have_a_suggestion_for_a_jbod",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does anyone have a suggestion for a Jbod enclosure that uses an atx PSU?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NotSure-2020",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T05:38:01.959746+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T04:57:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey there, I finally purchased my first nas setup and have received everything except my drives which are seeming a bit delayed. I bought two of the Ironwolf pro 12tb model ST12000NT001. Well in my impatience I\u2019ve since found the same Ironwolf pro 12tb but model ST12000NE0008 for about $55 cheaper for the pair. While it\u2019s not huge it\u2019s enough to make me consider ordering the later since it\u2019s already taking forever to ship, but I can\u2019t seem to find anything comparing what(if any) the differences may be. Should I go for it and buy the cheaper ones? Is it possibly a typo on the model number? I did find an article comparing the two exact model numbers on jazzcybersheild but one of them is incorrect as they are reviewing an Ironwolf pro v a Skyhawk ai. Thanks for the help!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NotSure-2020\"> /u/NotSure-2020 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comme",
        "id": 2804768,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kyvuk7/help_comparing_models_of_same_hd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help comparing models of same hd",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/-Silver-Tongue-",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T04:33:00.906223+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T04:01:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Ok, I want to convert VHS to digital and am in a bind. I got a bit ahead of myself and bought a refurbished Panasonic Dmr-ez48v hoping I could use component out into a good quality HDMI converter like this: <a href=\"https://soundstores.net/products/component-to-hdmi-converter-with-scaling-function-resolution-and-frame-rate-conversion-ypbpr-to-hdmi-converter-for-component-devices-to-display-on-hdmi-tvsnot-compatible-with-240p-retro-games-component-to-hdmi?variant=44604049293465\">https://soundstores.net/products/component-to-hdmi-converter-with-scaling-function-resolution-and-frame-rate-conversion-ypbpr-to-hdmi-converter-for-component-devices-to-display-on-hdmi-tvsnot-compatible-with-240p-retro-games-component-to-hdmi?variant=44604049293465</a></p> <p>Then hdmi out into a video capture card like Elgato HD60 X. I know this isn&#39;t strictly the best approach, and I have later learnt that I should have purchased a VCR with a TBC built in. But I have the ",
        "id": 2804481,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kyuvzd/im_so_lost_any_advicerecommendations_desperately",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I'm so lost. Any advice/recommendations desperately needed for Panasonic DMR-EZ48V",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ArshiaTN",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T04:33:01.089141+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T03:36:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I know my setup is really bad because I am not using a dedicated NAS and honestly I am such a noob Idk if I am even on the right subreddit or not:</p> <p>I am gonna store anime, movies, personal pictures and movies on it. My current 1TB WD Blue is 10(?) years old so and I am gonna replace it with this 16TB MG09. That one is currently in one of these docking stations that is connected to my Router:</p> <p><a href=\"https://amzn.eu/d/gS3daIN\">https://amzn.eu/d/gS3daIN</a></p> <p>I really like my setup and with my router, the HDD goes to sleep after 3 minutes of not being used. I know HDDs are not silent when I am moving files to it (my Red Pro 4TB and my WD Blues are not silent). However I would like to know if MG09s are louder by comparison and if it matters? I am gonna just store my data to it and access it whenever I want to watch Anime for example. Is it still really loud when I am just accessing to my files?</p> <p>I could get one of the following i",
        "id": 2804482,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kyufky/toshiba_16tb_mg09_mg09aca16te_how_loud_is_it",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Toshiba 16TB MG09 MG09ACA16TE, How loud is it?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/tcameron22",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T02:24:02.621652+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T02:18:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Can I use a duplicator like the one in this video to procedurally rip DVD\u2019s?</p> <p><a href=\"https://m.youtube.com/watch?v=AqJ--cc2AR4&amp;pp=ygUJI3dlcmlkYXRh\">https://m.youtube.com/watch?v=AqJ--cc2AR4&amp;pp=ygUJI3dlcmlkYXRh</a></p> <p>Like fill every slot up with a DVD and rip them. Please correct me if I\u2019m using incorrect terminology. Thanks in advance</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tcameron22\"> /u/tcameron22 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kysxpd/rip_multiple_dvds_using_a_duplicator/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kysxpd/rip_multiple_dvds_using_a_duplicator/\">[comments]</a></span>",
        "id": 2803999,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kysxpd/rip_multiple_dvds_using_a_duplicator",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Rip multiple DVD\u2019s using a duplicator?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Platographer",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T02:24:02.772649+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T02:12:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have been using FreeFileSync to sync a 14 TB external HDD to a 16TB HDD of the same brand. Both are NTFS with 4KB cluster size. When comparing size through Windows Explorer, I noticed that one of my main folders has a different &quot;size on disk&quot; but the same size as its copy on the other hard drive. FreeFileSync says they are completely synced. In drilling down, it appears the slight discrepancy between the &quot;size on disk&quot; numbers comes from folders with zip files in them. How could that be possible when both HDDs are NTFS formatted with the same cluster size?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Platographer\"> /u/Platographer </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kystnt/discrepancy_between_size_and_size_on_disk_question/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kystnt/discrepancy_between_size_and_size_on",
        "id": 2804000,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kystnt/discrepancy_between_size_and_size_on_disk_question",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Discrepancy between size and size on disk question",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/hiroo916",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T01:19:03.040966+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T01:05:59+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hiroo916\"> /u/hiroo916 </a> <br/> <span><a href=\"/r/kpopthoughts/comments/1ks0c7n/soompi_forums_an_archive_of_kpop_history_19882025/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kyrhaq/soompi_kpop_forums_shutting_down_jun_16th_how_to/\">[comments]</a></span>",
        "id": 2803738,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kyrhaq/soompi_kpop_forums_shutting_down_jun_16th_how_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Soompi Kpop Forums Shutting Down Jun 16th? How to archive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/zawks",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-30T01:19:03.349376+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-30T00:58:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys,<br/> Do you guys know of an IT company in LA that can help a small video production company of around 10 editors with a server solution? I have some experience with QNAP NAS&#39; (A couple of TVS 6 Bay ones) and NAS&#39; in general but require a larger solution to backup years worth of projects from about the last 5-6 years. We are talking around 1 petabyte or 2 worth of footage/media. I would say we do around 100-200TB of content per year.<br/> Maybe we need 2 solutions, one for deep archive for projects that are 3+ years old that can be on colder storage (slower) and another for current projects that can house 1-2 years worth of projects if that makes sense.</p> <p>Is there anyone in LA that help? </p> <p>Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/zawks\"> /u/zawks </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kyrc0i/nas_server_solution_for_post_house_in_la/\">[li",
        "id": 2803739,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kyrc0i/nas_server_solution_for_post_house_in_la",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "NAS / Server solution for Post House in LA",
        "vote": 0
    }
]