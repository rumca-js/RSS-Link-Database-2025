[
    {
        "age": null,
        "album": "",
        "author": "/u/duckseasonfire",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T21:23:06.821715+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T20:55:27+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/duckseasonfire\"> /u/duckseasonfire </a> <br/> <span><a href=\"/r/kubernetes/comments/1ks8qpq/helm_chart_discovery_tool/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1ks8vk2/helm_chart_discovery_tool/\">[comments]</a></span>",
        "id": 2739162,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ks8vk2/helm_chart_discovery_tool",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Helm Chart Discovery Tool",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/xabugo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T19:12:28.372843+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T18:27:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>If i am to run Jenkins with Docker Swarm, should i have then jenkins installed directly on my distro, or should it be a Docker Swarm service? For production, of a real service, could Swarm handle everything fine or should i go all the way down the Kubernetes road? </p> <p>For context, i am talking about a real existing product serving real big industries. However as of now, things are getting a refactor on-premises from a windows desktop production environment (yes, you read it), to most likely a linux server running micro-services with docker, in the future everything will be on the cloud.</p> <p>ps: I&#39;m the intern, pls don&#39;t make me get fired.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/xabugo\"> /u/xabugo </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1ks57eb/i_just_need_a_quick_a_answer/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1ks57eb/i_j",
        "id": 2738193,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ks57eb/i_just_need_a_quick_a_answer",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I just need a quick a answer.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CrazyEyezKillah",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T18:07:31.039151+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T17:51:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have what I think is a pretty typical homelab setup. Here&#39;s an abridged version:</p> <pre><code>. \u251c\u2500\u2500 authentik \u2502 \u251c\u2500\u2500 docker-compose.yml \u2502 \u2514\u2500\u2500 .env \u251c\u2500\u2500 caddy \u2502 \u251c\u2500\u2500 docker-compose.yml \u2502 \u2514\u2500\u2500 .env \u2514\u2500\u2500 immich \u251c\u2500\u2500 docker-compose.yml \u2514\u2500\u2500 .env </code></pre> <p>I have an external network <code>reverse_proxy</code> that each of Caddy, Immich, and Authentik are on.</p> <p>In &quot;production&quot;, I have an actual domain name that I&#39;m using which I think will make things easier, but I&#39;m trying to figure out the best way to set things up on a <code>localhost</code> dev environment. Here&#39;s the Caddyfile:</p> <pre><code>{$SCHEME:&quot;http://&quot;}{$DOMAIN:localhost}, {$SCHEME:&quot;http://&quot;}*.{$DOMAIN:localhost} { @root host {$DOMAIN:localhost} handle @root { respond &quot;Hello, world!&quot; 200 } @authentik host authentik.{$DOMAIN:localhost} handle @authentik { reverse_proxy authentik-server:9000 } @immich host immich.{$DOMAIN:localhost",
        "id": 2737614,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ks4b00/networking_for_setting_up_immich_oauth_on_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Networking for setting up Immich Oauth on a localhost-based dev environment of my Homelab",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/adjlw",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T18:07:30.847757+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T17:21:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m looking for a new home Docker machine. A lot of the ARM processors have these big/little designs, with like 4 powerful cores and 4 low energy draw cores. Or Intel chips that have performance/efficiency/low power efficiency cores. </p> <p>Could I tell two containers to use performance cores, two more to use efficiency cores, so on and so forth? (I see no reason to try and assign one high power and one low power core to a machine.) If I have four performance cores, could I assign container one to performance cores 1 &amp; 2, and container two to performance cores 3 &amp; 4?</p> <p>Or should I ignore these types of processors, which is what I feel like I remember reading?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/adjlw\"> /u/adjlw </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1ks3k0o/how_do_you_manage_docker_containers_and/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/",
        "id": 2737613,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ks3k0o/how_do_you_manage_docker_containers_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you manage Docker containers and processors where the chips have different speeds?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Serious-Cow-4626",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T18:07:31.227475+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T17:10:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am using (want to use) Syncthing to allow me to upload files to my JellyFin server. They are both in Docker Containers on the same LXC. I have both containers running perfectly except on small thing. I cannot seem to share files between the two. I have change my docker-compose.yml file so that Syncthing has the volumes associated with JellyFin. It just isn&#39;t working.</p> <p>s<code>ervices:</code></p> <p><code>nginxproxymanager:</code></p> <p><code>image: &#39;jc21/nginx-proxy-manager:latest&#39;</code></p> <p><code>container_name: nginxproxymanager</code></p> <p><code>restart: unless-stopped</code></p> <p><code>ports:</code></p> <p><code>- &#39;80:80&#39;</code></p> <p><code>- &#39;81:81&#39;</code></p> <p><code>- &#39;443:443&#39;</code></p> <p><code>volumes:</code></p> <p><code>- ./nginx/data:/data</code></p> <p><code>- ./nginx/letsencrypt:/etc/letsencrypt</code></p> <p><code>audiobookshelf:</code></p> <p><code>image:</code> <a href=\"http://gh",
        "id": 2737615,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ks39q5/need_to_share_files_between_two_dockers",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need to share files between two dockers",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HouseMD221B",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T17:00:34.167177+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T16:29:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi.</p> <p>How can I use apt on the official Ubuntu image from Docker Hub?</p> <p>I want to use apt to install &quot;ubuntu-desktop&quot;.</p> <p>When I use the &quot;apt update&quot; command, I get an error &quot;public key&quot;, &quot;GPG error&quot;...</p> <p>Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HouseMD221B\"> /u/HouseMD221B </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1ks28ah/apt_on_official_ubuntu_image_from_docker_hub/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1ks28ah/apt_on_official_ubuntu_image_from_docker_hub/\">[comments]</a></span>",
        "id": 2736902,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ks28ah/apt_on_official_ubuntu_image_from_docker_hub",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "apt on official Ubuntu image from Docker Hub",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Hydra1721",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T15:55:15.109176+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T15:34:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m rather new to Docker but but I&#39;ve heard of various bugs being discovered over the years which has presented security concerns. I was wondering if it&#39;s both common practice as well as a good saftey precaution to run the entirety of docker in a custom LXC container? The idea being in the case of a new exploit being discovered it would add an extra layer of security. Would deeply appreciate clarity regarding this manner. Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hydra1721\"> /u/Hydra1721 </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1ks0ugz/running_docker_itself_in_lxc/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1ks0ugz/running_docker_itself_in_lxc/\">[comments]</a></span>",
        "id": 2736309,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ks0ugz/running_docker_itself_in_lxc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Running Docker Itself in LXC?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Front-Buyer3534",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T13:44:50.012326+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T13:12:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everybody. </p> <p>Maybe somebody know, how to run Docker on latest MacOS on ARM (I have MacBook Pro 14-inch, 2021 M1)</p> <p>Issue: <a href=\"https://github.com/docker/for-mac/issues/7664\">https://github.com/docker/for-mac/issues/7664</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Front-Buyer3534\"> /u/Front-Buyer3534 </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1krxhof/docker_didnt_work_on_macos_155/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1krxhof/docker_didnt_work_on_macos_155/\">[comments]</a></span>",
        "id": 2735088,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1krxhof/docker_didnt_work_on_macos_155",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Docker didn't work on MacOS 15.5",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Mother_Poem_Light",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T12:39:31.187969+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T11:24:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My question can be boiled down to why do <em>this</em>...</p> <pre><code>// ~/combined/docker-compose.yml services: flotsam: image: ghcr.io/example/flotsam:latest ports: - &quot;8080:8080&quot; jetsam: image: ghcr.io/example/jetsam:latest ports: - &quot;9090:9090&quot; </code></pre> <p>...instead of <em>this</em>?</p> <pre><code>// ~/flotsam/docker-compose.yml services: flotsam: image: ghcr.io/example/flotsam:latest ports: - &quot;8080:8080&quot; // ~/jetsam/docker-compose.yml services: jetsam: image: ghcr.io/example/jetsam:latest ports: - &quot;9090:9090&quot; </code></pre> <p>What are the advantages and drawbacks of bundling in this way?</p> <p>I&#39;m new to Docker and mostly interested in simple <a href=\"/r/selfhosted\">r/selfhosted</a> projects running other folk&#39;s images from Docker Hub if that&#39;s helpful context.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Mother_Poem_Light\"> /u/Mo",
        "id": 2734447,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1krve0x/when_to_combine_services_in_docker_compose",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "When to combine services in docker compose?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/gelomon",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T17:00:34.440199+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T09:54:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello I&#39;m setting up my homelab to use a NAS share to be used as bind mount for my docker containers.</p> <p>Current setup now is an SMB share. Share is mounted at /mnt/docker and I have used this directory for docker containers to use but I&#39;m having permission issues like when a container is using a different user for the mount.</p> <p>Is there any suggestion on what is the best practice on using a mounted NAS shared folder to use with docker?</p> <p>Currently the issue now I face is with postgresql container which creates bind mount with guid/gid 70 which I cannot assign in the smb share</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/gelomon\"> /u/gelomon </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1krtxvy/need_suggestion_nas_mounted_share_as_location_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1krtxvy/need_suggestion_nas_mounted_share_as_",
        "id": 2736903,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1krtxvy/need_suggestion_nas_mounted_share_as_location_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need Suggestion: NAS mounted share as location for docker files",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/romgo75",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T09:27:01.981830+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T08:24:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Dear community,</p> <p>I have a project which consist of deploying a swarm cluster. After reading the documentation I plan the following setup : </p> <p>- 3 worker nodes</p> <p>- 3 management nodes</p> <p>So far no issues. I am looking now on how to expose containers to the rest of the network.</p> <p>For this after reading this post : <a href=\"https://www.haproxy.com/blog/haproxy-on-docker-swarm-load-balancing-and-dns-service-discovery#one-haproxy-container-per-node\">https://www.haproxy.com/blog/haproxy-on-docker-swarm-load-balancing-and-dns-service-discovery#one-haproxy-container-per-node</a> </p> <p>- deploy keepalived </p> <p>- start LB on 3 nodes </p> <p>this way seems best from my point of view, because in case of node failure the failover would be very fast.</p> <p>I am looking for some feedback on how you do manage this ? </p> <p>thanks ! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/romgo75\"> /u/romgo",
        "id": 2733136,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1krsosa/docker_swarm_load_balancer",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "docker swarm - Load Balancer",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ERKO901YT",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T05:07:58.102153+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T04:56:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have set up my OVH VPS to redirect traffic to my Ubuntu server using WireGuard. I&#39;m using the OVH VPS because it has Anti-DDoS protection, so I redirect all traffic through this VPS.</p> <p>Here is configuration of my ubuntu server ```</p> <p>[Interface] Address = 10.1.1.2/24 PrivateKey = xxxxxxxxxxxxxxxxxxxxxxxx</p> <p>[Peer] PublicKey = xxxxxxxxxxxxxxxxxxxxxxxxx Endpoint = xxx.xxx.xxx.xxx:51820 AllowedIPs = 0.0.0.0/0 PersistentKeepalive = 25 <code> Here is vps configuration </code> [Interface] Address = 10.1.1.1/24 ListenPort = 51820 PrivateKey = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx</p> <p>[Peer] PublicKey = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx AllowedIPs = 10.1.1.2/32 ``` The WireGuard tunnel works correctly for the host system, but I&#39;m using Pterodactyl Panel which runs servers in Docker containers. These containers cannot access the internet, but the used to have the internet access:</p> <p>When creating a new server, Pterodactyl can&#39;t inst",
        "id": 2731906,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1krpn5b/pterodactyl_docker_containers_cant_access",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Pterodactyl Docker Containers Can't Access Internet Through WireGuard VPN Tunnel",
        "vote": 0
    }
]