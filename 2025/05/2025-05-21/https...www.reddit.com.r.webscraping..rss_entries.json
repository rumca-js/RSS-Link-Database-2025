[
    {
        "age": null,
        "album": "",
        "author": "/u/TroyXXIV",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T22:28:14.285460+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T21:24:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi there, essentially when I open up dev tools and switch to the redux panel I\u2019m able to see the state and live action dispatches of public websites that use redux for state management. </p> <p>This data is then usually displayed on the screen. Now my problem is, I\u2019m trying to scrape the data from a couple highly dynamic websites where data is updating constantly. I\u2019ve tried playwright, selenium etc but they are far too slow, also these sites don\u2019t have an easily accessible internal api that I can monitor (via dev tools) and call - in fact I don\u2019t really want to call undocumented apis due to potentially putting additional strain on their servers, aswell as ip bans. </p> <p>However, I have noticed with a lot of these sites they use redux and everything is visible via the redux dev tools. How could I potentially make the redux devtools a proxy that I could listen to in my own script or read from on updates to state. Or alternatively what methods could I",
        "id": 2739602,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ks9kyd/monitoring_a_stores_state_similar_to_redux_dev",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Monitoring a stores state similar to redux dev tools",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/_iamhamza_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T17:00:41.393330+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T16:40:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello all, I know some of you have already figured this out..I need some help!</p> <p>I&#39;m currently trying to automate a few processes on a website that has ArkoseLabs captcha, which I don&#39;t have a solver for; I thought about outsourcing it from a 3rd party API; but all APIs provide a solve token...do you guys have any idea how to integrate that token into my web automation application? Otherwise, I have a solver for Google&#39;s reCaptcha, and I simply load it as an extension into the browser I&#39;m using, is there a similar approach with ArkoseLabs as well?</p> <p>Thanks,<br/> Hamza</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/_iamhamza_\"> /u/_iamhamza_ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ks2ick/arkoselabs_captcha_solver/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ks2ick/arkoselabs_captcha_solver/\">[comments]</a></span>",
        "id": 2736904,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ks2ick/arkoselabs_captcha_solver",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "ArkoseLabs Captcha Solver?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ScraperWiz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T18:07:35.979754+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T16:12:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Especially the Search part where they provide answers by scraping hundreds of pages in real-time?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ScraperWiz\"> /u/ScraperWiz </a> <br/> <span><a href=\"https://www.youtube.com/live/o8NiE3XMPrM?si=gieZHs9xeeUw8cfr&amp;t=2766\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ks1sx9/how_do_you_see_the_future_of_scraping_after/\">[comments]</a></span>",
        "id": 2737616,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ks1sx9/how_do_you_see_the_future_of_scraping_after",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you see the future of scraping after Google's I/O keynote?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MayoJunge",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T15:55:32.640107+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T15:32:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am a student and live in Europe and started a part time job about a month ago. The description was clear, i just needed to do some price comparisons from some competing online shops selling the same product. I am a bit older as a student and my cv isnt great, i needed money so i was happy to get this. The pay is average but the working conditions are good. My department manages the online shop and I get tasks to do price comparisons on some products, make an excel with the prices, so my job is just 100% scraping, really easy. At the start it just seemed dumb to me to not somehow automate this but they told me they did that in the past, after a while the websites changed something and the whole automating script stopped working. I think they realized its just cheaper to get someone who can do this without any technical knowledge than getting a programmer to build a scraper, if i quit they can easily just get anyone else to do the job. But while i don",
        "id": 2736310,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ks0tf0/need_advice_on_negotiating_with_my_boss_after",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need advice on negotiating with my boss after automating my job",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LullzLullz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T13:45:34.378544+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T13:39:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I\u2019m trying to scrape some data from S A S but each time I just get bot detection sent back. I\u2019ve tried both puppeteer and playwright and using the stealth versions but to no success. </p> <p>Anyone have any tips on how I can tackle this? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LullzLullz\"> /u/LullzLullz </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kry36x/help_with_scraping_flights/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kry36x/help_with_scraping_flights/\">[comments]</a></span>",
        "id": 2735093,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kry36x/help_with_scraping_flights",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help with scraping flights",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SteakCalm5072",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T12:40:32.645067+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T08:50:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a list of startup/company leads (just names or domains for now), and I\u2019m trying to enrich this list with the following information:</p> <p>Funding details (e.g., investors, amount, funding type, round, dates)</p> <p>Merger &amp; acquisition activity (e.g., acquired by/merged with, date, amount if available)</p> <p>What\u2019s the best approach or tech stack to do this?</p> <p>Some specific questions:</p> <p>Are there public sources or APIs (like Crunchbase, PitchBook, CB Insights alternatives) that are free and easily scrappable</p> <p>Has anyone built a scraper for sites like Crunchbase, Dealroom, or TechCrunch? Are there any reliable open-source tools or libraries for this?</p> <p>How can I handle data quality and deduplication when scraping from multiple sources</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SteakCalm5072\"> /u/SteakCalm5072 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comm",
        "id": 2734448,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1krt1mj/scrape_funding_and_merger_for_leads",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scrape Funding and merger for leads",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Big_Decision5120",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-21T04:03:44.146621+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-21T03:57:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>any good ai that write the code for you, if you provide the prompt? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Big_Decision5120\"> /u/Big_Decision5120 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1krone5/ai_for_web_scraping_dynamic_site/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1krone5/ai_for_web_scraping_dynamic_site/\">[comments]</a></span>",
        "id": 2731661,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1krone5/ai_for_web_scraping_dynamic_site",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI For web scraping dynamic site",
        "vote": 0
    }
]