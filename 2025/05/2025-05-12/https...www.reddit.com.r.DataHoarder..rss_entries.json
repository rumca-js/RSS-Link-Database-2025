[
    {
        "age": null,
        "album": "",
        "author": "/u/HANEZ",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T23:46:47.501832+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T23:22:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Tagged as NSFW just in case. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HANEZ\"> /u/HANEZ </a> <br/> <span><a href=\"https://gizmodo.com/gop-senator-introduces-bill-to-make-all-porn-a-federal-crime-following-project-2025-playbook-2000600994\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kl76m3/senator_introduces_bill_to_make_all_porn_a/\">[comments]</a></span>",
        "id": 2663152,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kl76m3/senator_introduces_bill_to_make_all_porn_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Senator introduces Bill to make all Porn a Federal Crime.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Roarkindrake",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T21:34:52.757292+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T20:31:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Moving a older, barely used gaming pc to be my new unraid server and running into the problem that the current case just doesn&#39;t really hold any drives. Trying not to go nuts with it but have some expansion room. Have not had much luck finding anything that would fit both requirements.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Roarkindrake\"> /u/Roarkindrake </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kl35tz/anyone_know_a_good_atx_nas_case_with_360_aio/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kl35tz/anyone_know_a_good_atx_nas_case_with_360_aio/\">[comments]</a></span>",
        "id": 2662387,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kl35tz/anyone_know_a_good_atx_nas_case_with_360_aio",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone know a good ATX Nas Case with 360 AIO support?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Neo1881",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T20:28:43.786171+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T20:27:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a bunch of old 8mm video tapes taken with a Sony camcorder from the mid-1990&#39;s. Trying to convert them into digital format like dvds or MP4 using a DigitNow Video Grabber. Does anyone have experience using that grabber or any tips? Appreciate the feedback. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Neo1881\"> /u/Neo1881 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kl31lx/converting_old_hi8_8mm_tapes_onto_newer_digital/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kl31lx/converting_old_hi8_8mm_tapes_onto_newer_digital/\">[comments]</a></span>",
        "id": 2661623,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kl31lx/converting_old_hi8_8mm_tapes_onto_newer_digital",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Converting old Hi8 8mm tapes onto newer digital format using a DigitNow Video Grabber",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/gorcbor19",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T20:28:43.507390+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T19:45:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have maybe 600 GB of photos currently on an old Seagate hard drive that is no longer working, but was able to retrieve the images and they are currently on a 1TB hard drive. </p> <p>Last year sometime, I had been researching a new hard drive solution and many pointed me to a Synology 2-Bay DiskStation DS223j. It was a bit over my budget, but I bought it anyhow. It arrived today, and I only now realized that I also have to purchase the drives for it, which is going to be another $100/each (4TB WD NAS drives). </p> <p>Which got me thinking; why couldn&#39;t I just buy a second 1TB portable drive, have two backups, and then pay for cloud storage to also back up everything there? </p> <p>I do imagine I&#39;ll be taking more photos and backing up more images in the future, but I&#39;m not a photographer, these are just family cell phone photos and videos. I don&#39;t do much else with files, especially now that music and videos are streaming and any work",
        "id": 2661622,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kl1zba/why_shouldnt_i_just_use_a_couple_1tb_portable",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Why shouldn't I just use a couple 1TB portable hard drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Apart_Hovercraft_216",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T22:40:45.979576+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T18:22:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, I&#39;m new here so I&#39;m not sure if it is the right place to post. I&#39;m looking for a way to download all the individual wikipedia pages for national cuisines in PDF, without doing so manually. Does anyone know of a tool that could help me ?</p> <p>Specifically, I want all the national cuisines pages listed in the &quot;Regional and Ethnic Cuisines&quot; of the &quot;List of Cuisines&quot; page.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Apart_Hovercraft_216\"> /u/Apart_Hovercraft_216 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkzuxf/help_to_download_specific_wikipedia_pages/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkzuxf/help_to_download_specific_wikipedia_pages/\">[comments]</a></span>",
        "id": 2662804,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkzuxf/help_to_download_specific_wikipedia_pages",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help to download specific wikipedia pages",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lnvis",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T20:28:43.309317+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T18:02:26+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkzcjg/this_website_isnt_ever_going_to_finish/\"> <img src=\"https://preview.redd.it/xek5c69y3e0f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8cc6aaca735653016abd48a6804a47e47a978386\" alt=\"This website isn't ever going to finish downloading, is it?\" title=\"This website isn't ever going to finish downloading, is it?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lnvis\"> /u/lnvis </a> <br/> <span><a href=\"https://i.redd.it/xek5c69y3e0f1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkzcjg/this_website_isnt_ever_going_to_finish/\">[comments]</a></span> </td></tr></table>",
        "id": 2661621,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkzcjg/this_website_isnt_ever_going_to_finish",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/xek5c69y3e0f1.png?width=320&crop=smart&auto=webp&s=8cc6aaca735653016abd48a6804a47e47a978386",
        "title": "This website isn't ever going to finish downloading, is it?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/anakneemoose",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T22:40:46.227627+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T17:36:56+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/anakneemoose\"> /u/anakneemoose </a> <br/> <span><a href=\"https://www.amazon.com/s?k=seagate+expansion+22tb+hard+drive&amp;crid=2IKYGL7H1ZSUG&amp;sprefix=seagate+expansion+22tb+hard+drive+%2Caps%2C156&amp;ref=nb_sb_noss_2\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkyoko/the_posts_link_should_bring_you_to_an_amazon/\">[comments]</a></span>",
        "id": 2662805,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkyoko/the_posts_link_should_bring_you_to_an_amazon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The post's link should bring you to an Amazon search for 22TB drives, an external Seagate for $249 and an internal Seagate Exos (renewed) for $259. Which do you recommend?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Solmark",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T17:40:40.975173+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T16:43:18+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkxap1/seagate_12tb_errors/\"> <img src=\"https://preview.redd.it/hr9j0tqjqd0f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6f50b9eb3e398cadbdcb12ed9fca31c9d33af6d2\" alt=\"Seagate 12TB Errors\" title=\"Seagate 12TB Errors\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;ve got a Ugreen DXP4800 Plus with 4x 12TB Seagate 7200RPM drives running Raid 5.</p> <p>I&#39;ve noticed the drives seems to be always spinning, then noticed these errors. Does this mean the drive will likely fail soon?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Solmark\"> /u/Solmark </a> <br/> <span><a href=\"https://i.redd.it/hr9j0tqjqd0f1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkxap1/seagate_12tb_errors/\">[comments]</a></span> </td></tr></table>",
        "id": 2660774,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkxap1/seagate_12tb_errors",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/hr9j0tqjqd0f1.png?width=320&crop=smart&auto=webp&s=6f50b9eb3e398cadbdcb12ed9fca31c9d33af6d2",
        "title": "Seagate 12TB Errors",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/palepatriot76",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T16:34:31.065000+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T16:27:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>YT DLP seems to always give me fits so been suing &quot;Jdownloader&quot; but for some reason it hangs, and I always have to close and restart it. Disconnects, sign in, etc...</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/palepatriot76\"> /u/palepatriot76 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkww3g/whats_your_go_to_for_acquiring_yt_video/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkww3g/whats_your_go_to_for_acquiring_yt_video/\">[comments]</a></span>",
        "id": 2660195,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkww3g/whats_your_go_to_for_acquiring_yt_video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's your go to for acquiring YT video?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/smartymarty1234",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T16:34:31.579835+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T15:43:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, so I am relatively new to all of this. Right now I have an old gaming computer with a tenth gen intel, setup to run jf and some game servers as well as some other services like authentik and reverse proxy. Thats all fine and good and none of this data is important so its just on a 14tb drive plugged into the computer. </p> <p>I am wanting to expand capabilities so that I can have some storage backup options away from gdrive and onedrive as well as use immich. Now obviously this data is way more critical, but also less volume. So my plan was to have 3 2 tb drives, 2 in raid one together and then an offline weekly backup on the third. Mainly because i have those 3 2 tb drives alr. </p> <p>Now the problem I am now facing is that this old gamin computer is not equipped to even handle many drives. That 14tb is sitting at the bottom of the case lol. It also has only 3 sata ports and even if I could saturate them it has only 2 sata power connectors. This",
        "id": 2660197,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkvrhq/looking_for_some_advice_for_my_setup_thanks_in",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for some advice for my setup, thanks in advance.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/panxerox",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T16:34:30.719132+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T15:41:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.tomshardware.com/pc-components/storage/western-digital-is-investing-in-ceramic-hard-drive-pioneer-cerabyte-companys-nearly-indestructible-storage-device-gets-a-key-backer\">https://www.tomshardware.com/pc-components/storage/western-digital-is-investing-in-ceramic-hard-drive-pioneer-cerabyte-companys-nearly-indestructible-storage-device-gets-a-key-backer</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/panxerox\"> /u/panxerox </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkvq5v/western_digital_invests_in_ceramic_storage_firm/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkvq5v/western_digital_invests_in_ceramic_storage_firm/\">[comments]</a></span>",
        "id": 2660194,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkvq5v/western_digital_invests_in_ceramic_storage_firm",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Western Digital Invests in Ceramic Storage Firm That Claims 5,000-Year Data Retention",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/werexzenok",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T15:27:17.970919+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T15:15:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Let\u2019s leave the technical challenges out of this discussion\u2014let\u2019s assume it\u2019s perfectly feasible and easy to make such a time capsule.<br/> What data would you save?</p> <ul> <li>A favorite TV series or movie?</li> <li>Scans of famous paintings?</li> <li>Computer programs?</li> <li>Books?</li> <li>Photos and audio/video recordings showing what our time was like?</li> <li>A copy of the genomes of various species, humans included?</li> </ul> <p>The one thing I feel absolutely must be included is a copy of Wikipedia.<br/> I\u2019d love to hear your suggestions. :D</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/werexzenok\"> /u/werexzenok </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkv31p/if_you_were_going_to_build_a_timetravel_machine/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkv31p/if_you_were_going_to_build_a_timetravel_machine/\">[comments]</a><",
        "id": 2659426,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkv31p/if_you_were_going_to_build_a_timetravel_machine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "If you were going to build a time-travel machine to survive the end of human civilization and preserve our history, what data would you store?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PrimateOfGod",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T15:27:17.780731+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T14:50:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Yahoo answers is my place of origin when it comes to online forums. I spent most of my time in Mythology &amp; Folklore and Religion &amp; Spirituality</p> <p>I remember three of my usernames Dedicated To Evolution, Report Bigfoot, and Being Psychic SUCKS!!! (something along that line, don\u2019t judge me I was like 10)</p> <p>I\u2019d love to see my old questions and answers. Or questions and answers around this time period (2008-2012) in those Subs.</p> <p>Bonus points if anyone is familiar with the subs, and has joined the chat R&amp;S Chat (I believe it was called RandSplace)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PrimateOfGod\"> /u/PrimateOfGod </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkufyo/yahoo_answers_archives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkufyo/yahoo_answers_archives/\">[comments]</a></span>",
        "id": 2659425,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkufyo/yahoo_answers_archives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Yahoo answers archives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Brianstoiber",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T15:27:18.190008+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T14:32:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Long story short, I need to replace the drive in my server that is running Windows Server 2012 R2. I am using StableBit DrivePool v.2.3.5.1557 with 8 drives in the pool. The majority are not duplicated as the data is replaceable but one has data that is duplicated. </p> <p>I can&#39;t find the correct path to take to migrate to a new drive. I am going to install Windows 10 LTSC. I know I need to deactivate the license. But do I need to also remove each drive from the pool first and then install DrivePool on the new OS, activate it and then add each drive back? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Brianstoiber\"> /u/Brianstoiber </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kku0lw/stablebit_drivepool_migration_to_new_server/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kku0lw/stablebit_drivepool_migration_to_new_server/\">[comments]</a>",
        "id": 2659427,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kku0lw/stablebit_drivepool_migration_to_new_server",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "StableBit DrivePool migration to new server",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Tularis1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T15:27:18.378783+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T14:23:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey Guys,</p> <p>I need to copy around 38TB of data from one NAS to another, and I want to make sure the files are 100% identical by verifying their hashes. Ideally, I\u2019m looking for a lightweight Windows app that can:</p> <ul> <li>Let me specify a <strong>source directory</strong> (from the first NAS),</li> <li>A <strong>destination directory</strong> (on the second NAS),</li> <li>Then compare hashes (e.g., SHA256 or similar) for all files,</li> <li>And alert me if anything doesn\u2019t match.</li> </ul> <p>I\u2019d prefer a GUI tool if one exists, rather than writing scripts, but if there\u2019s no good app for it, I\u2019m open to scripting something if needed.</p> <p>Anyone got a good recommendation?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tularis1\"> /u/Tularis1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kktscs/looking_for_a_simple_windows_tool_to_verify_file/\">[link]</a></span> &#32; <span><",
        "id": 2659428,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kktscs/looking_for_a_simple_windows_tool_to_verify_file",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a simple Windows tool to verify file hashes between two NAS devices (38TB)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/axa8888",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T16:34:31.331569+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T14:20:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>In some of my work, I&#39;ve come across a number of .MDI (Microsoft Document Imaging) files. I realized that this is an outdated format for which no continuing support exists from Microsoft. Additionally, I&#39;ve seen that the range of tools available to convert this into something suitable for long term archival storage are lacking in various ways. Microsoft has a CLI tool but it is not actively maintained, and other tools to convert from .MDI are paid, discontinued, or not suitable for batch conversion. Digging further, I see that this format is listed in your Format Risk Matrix (NF00777) with a Moderate Risk classification. </p> <p>I was wondering if it would be helpful to anyone if I created an open source tool for this file conversion? My goal would be to have something that is free, open, can handle one-off and batch conversion, has both CLI and simple UI, is functional across different operating systems, and converts .MDI to the more archive-",
        "id": 2660196,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kktpf2/mdi_conversion_tool",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": ".MDI conversion tool",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/epvz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T16:34:31.769157+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T13:35:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a ton of old family photos with writing on the backs. I have a flatbed scanner and have scanned several albums in 300 dpi TIFF, but just learned my scanner can go up to 1200 dpi so I will likely be rescanning the fronts of each photo in ~600 dpi\ud83e\udd72. </p> <p>I\u2019ve seen several people say they just rename the files to front_0001 and back_0001. However, I was wanting to combine the fronts &amp; backs side by side in one TIFF, if that even makes sense. My goal is to have each photo be accompanied by the information on the back so it doesn\u2019t get lost or misconstrued. </p> <p>Also, should I keep two copies of the albums (one in TIFF for storage, another in jpeg for sharing)? Is there an optimal way to do this?</p> <p>I might not be asking this in the right place but thought I would give it a shot. Any advice is appreciated</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/epvz\"> /u/epvz </a> <br/> <span><a href=\"http",
        "id": 2660198,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkso9o/best_way_to_digitize_fronts_backs_of_antique",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best way to digitize fronts & backs of antique photos?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ok_Wolverine_4268",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T13:56:19.678890+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T13:14:16+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok_Wolverine_4268\"> /u/Ok_Wolverine_4268 </a> <br/> <span><a href=\"/r/dragonfable/comments/1kks615/is_there_a_way_to_download_dragonfable_locally/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kks7m5/is_there_a_way_to_download_dragonfable_locally/\">[comments]</a></span>",
        "id": 2658700,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kks7m5/is_there_a_way_to_download_dragonfable_locally",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a way to download Dragonfable locally, for preservation reasons?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/yonibloch",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T12:51:16.353782+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T11:53:50+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/yonibloch\"> /u/yonibloch </a> <br/> <span><a href=\"/r/blackmirror/comments/1kkpcr1/bandersnatch_is_still_alive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkql20/bandersnatch_is_still_alive/\">[comments]</a></span>",
        "id": 2658173,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkql20/bandersnatch_is_still_alive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Bandersnatch is still alive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jabberwockxeno",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T16:34:31.989346+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T11:31:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Previous post: <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjj9r8/trying_to_archive_flickr_content_before_most/\">https://www.reddit.com/r/DataHoarder/comments/1kjj9r8/trying_to_archive_flickr_content_before_most/</a></p> <p>On (after?) May 15th, fullsize images will be unavailable if uploaded by free uses/if not CC licensed</p> <p>Thanks to some help from other people, me and my friends trying to archive content ahead of the change have made progress in a gallery-dl workflow to back up content, but we still have a few roadblocks, including one huge one:</p> <p>If we use the url of a user&#39;s main photostream page (IE, the gallery of all their uploads), or of an album, then the json file that the --write-metadata, and/or the the extractor.flickr.metadata, extractor.flickr.exif, and extractor.flickr.contexts options generates is missing some of the metadata they create, compared to if the input url was a specific image page.</p> <p>We need",
        "id": 2660199,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkq6bw/using_gallerydl_to_archive_flickr_content_ahead",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Using Gallery-dl to archive Flickr content ahead of the purge: Metadata is excluded when ripping user's whole photostream or album vs individual images **WILL PAY MONEY FOR SOLUTION**",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/thermalzombie",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T09:23:10.099415+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T08:17:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was just looking for a 3.5&quot; enclosure and was wondering should I not be able to find one that requires a single cable with no power adapter?</p> <p>Thanks for the reply.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/thermalzombie\"> /u/thermalzombie </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkn93o/is_there_a_35_usb_enclosure_available_that_uses_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkn93o/is_there_a_35_usb_enclosure_available_that_uses_a/\">[comments]</a></span>",
        "id": 2656748,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkn93o/is_there_a_35_usb_enclosure_available_that_uses_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a 3.5\" usb enclosure available that uses a single cable?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/soowhatt1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T08:16:55.140559+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T07:25:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>\u200fHello everyone ,</p> <p>\u200fI\u2019m in a situation where I need to save some important educational videos from a private Telegram channel before the channel gets deleted. Unfortunately, the channel has restrictions that prevent me from downloading, forwarding, or saving the videos directly.</p> <p>\u200fI\u2019ve tried screen recording, but it\u2019s not very efficient due to the length of the videos. Does anyone know a reliable method to save these videos without losing quality? I\u2019m open to using any apps, bots, or methods you can recommend.</p> <p>\u200fThank you for your help.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/soowhatt1\"> /u/soowhatt1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkmjq0/how_can_i_save_videos_from_a_private_telegram/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkmjq0/how_can_i_save_videos_from_a_private_telegram/\">[comments]</a></span>",
        "id": 2656418,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkmjq0/how_can_i_save_videos_from_a_private_telegram",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "\u200fHow can I save videos from a private Telegram channel before they get deleted?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DarkThoughtsOfALoner",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T08:16:55.330673+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T07:12:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a Syba 8 bay enclosure stuffed with drives ranging from 10TB-16Tb. I&#39;ve only setup a two simple DrivePools. The top 4 are day to day usage. The bottom 4 are for archive mostly. </p> <p>The issue I have is that if all the drives are powered on, the enclosure will disconnect very soon randomly. If I&#39;ve moving files between the two DrivePools, it will definitely disconnect.</p> <p>I&#39;m not sure if it&#39;s a power limit issue when all or most of the drives are running at the same time or some kind of software/hardware issue. My only solution for now is to power off the bottom 4 most of the time.</p> <p>Is this a known issue? Anything I can do to fix the issue?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DarkThoughtsOfALoner\"> /u/DarkThoughtsOfALoner </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkmdep/drivepool_with_syba_8_bay_consistently/\">[link]</a></span> &#32; <s",
        "id": 2656419,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkmdep/drivepool_with_syba_8_bay_consistently",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "DrivePool with Syba 8 bay consistently disconnecting.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/orientpear",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T07:10:41.098158+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T06:35:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a bunch of data on JBOD atm. I&#39;d like to gather it all together and provide some redundancy via RAID5. I&#39;m open to NAS or DAS. I&#39;ll probably pass on Synology as I don&#39;t want to deal with their new policies. </p> <p>1) if I go DAS, it looks like SoftRaid is the only real solution. I don&#39;t love the subscription model. Is there something else that I am missing for RAID5 management on MacOS?</p> <p>2) If I choose NAS, and I don&#39;t want Synology, what are folks recommending for at least 5 bay. UnRaid/TrueNAS support is preferred.</p> <p>2a) I also have an old AMD motherboard and CPU (ASUS B550; Ryzen 5 3500; 600W PSU) plus a 20X0 Nvidia GPU; can I buy a big case and add drives to that or is a packaged NAS a better idea?</p> <p>3) is there a way to add some of the data on drives I already have to this new setup? Is there a way to start with 3 drives, then add the data from the drives I have already and add those drives to the p",
        "id": 2656124,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkltup/how_to_move_from_jbod_to_nas_or_das",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "how to move from JBOD to NAS or DAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DaddyDuck69420",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T06:05:47.222317+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T05:52:06+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkl6bh/brand_new_western_digital_performance_black_hdd/\"> <img src=\"https://external-preview.redd.it/djl6OHpqa2ppYTBmMYT2rx4ylWNr-2tpgRfDAto6iqciY0Jy122cNQWZtnfz.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ec9e5a1b92d3ae81b50c0b68e9ded3af8aa28a8\" alt=\"Brand new western digital performance black HDD making these noises.\" title=\"Brand new western digital performance black HDD making these noises.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>It doesn&#39;t just make them when it&#39;s reading/writing, it will just make them when it isnt. My windows C drive is an ssd, this is my secondary storage drive. It starts making the noise, and it eventually stops. But then at some point it will do it again. I was told that this was a good subreddit to ask this question in. What do you all think could be going on? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DaddyDuck694",
        "id": 2655872,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkl6bh/brand_new_western_digital_performance_black_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/djl6OHpqa2ppYTBmMYT2rx4ylWNr-2tpgRfDAto6iqciY0Jy122cNQWZtnfz.png?width=640&crop=smart&auto=webp&s=0ec9e5a1b92d3ae81b50c0b68e9ded3af8aa28a8",
        "title": "Brand new western digital performance black HDD making these noises.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Uncle-Drunkle",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T06:05:47.497358+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T05:26:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, I&#39;m looking to digitize some VHS tapes for my parents. I&#39;ve been through quite a few old posts but was wondering if there are some 2025 updates that have made things easier. I don&#39;t need the greatest quality but I&#39;d also like to avoid the $10 capture cards. I&#39;m somewhat computer literate but have zero experience with anything in this realm and would like to avoid any complicated hardware modifications if possible. Is the \u200eGV-USB2 and OBS solution something you would still stay away from? Any input would be greatly appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Uncle-Drunkle\"> /u/Uncle-Drunkle </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkks22/digitize_vhs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkks22/digitize_vhs/\">[comments]</a></span>",
        "id": 2655873,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkks22/digitize_vhs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Digitize VHS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Anotherlostvideo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T06:05:47.685370+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T05:10:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Im interested in a series of models like this one <a href=\"https://sketchfab.com/3d-models/bmw-sauber-f107-2007-49b35c0478bc4174a16e622bf3f7586b\">https://sketchfab.com/3d-models/bmw-sauber-f107-2007-49b35c0478bc4174a16e622bf3f7586b</a> and I need fo find a way to get these since they cant be downloaded normally, thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Anotherlostvideo\"> /u/Anotherlostvideo </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkkj98/how_to_extract_and_download_web_viewer_models/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkkj98/how_to_extract_and_download_web_viewer_models/\">[comments]</a></span>",
        "id": 2655874,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkkj98/how_to_extract_and_download_web_viewer_models",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to extract and download web viewer models?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Lit_Cap",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T16:34:32.411526+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T04:34:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I&#39;m looking to digitize about 100 old family DVDs. The original quality isn&#39;t the greatest, so I&#39;m not too worried about losing quality in the transfer, but I was wondering if there is a more modern/faster way to convert them into digital files other than using MakeMKV to rip the files off the DVDs and then using HandBrake to transcode into MP4s. (although, I&#39;ve seen lots of talk about how it might not be necessary to convert the MKV into an MP4 since it&#39;ll just make the quality worse, but I&#39;d love to hear any thoughts)</p> <p>The average length of each DVD is about an hour. Additionally, some DVDs have a more extensive menu covering many different &quot;chapters&quot; within the video, and I was wondering if that would alter how the video would be ripped off the DVD.</p> <p>I believe I already have all the necessary hardware to handle the transfer (a USB DVD burner that plugs into my PC and a portable USB ",
        "id": 2660200,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkjz8l/digitizing_about_100_family_dvds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Digitizing About 100 Family DVD's",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Proverbial_American",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T04:54:08.681509+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T03:51:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>If this is something already well known in the sub, I apologize. I was just curious how risky it is to plug up an external drive on a usb hub.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Proverbial_American\"> /u/Proverbial_American </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkj8z6/is_it_safe_to_transfer_data_between_drives_on_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkj8z6/is_it_safe_to_transfer_data_between_drives_on_a/\">[comments]</a></span>",
        "id": 2655632,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkj8z6/is_it_safe_to_transfer_data_between_drives_on_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is it safe to transfer data between drives on a usb expansion hub?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/National-Still3123",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T02:44:07.539501+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T02:43:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Advice/Help pls. And thanks because I\u2019m sure there\u2019s a couple thousand similar posts. </p> <p>For the nearly the same price of $110-ish, would the Seagate 6TB STKP6000400 be better than the WD 4TB WDBA3A0040BBK-WESN?</p> <p>All I need it for is just to backup my word docs, photos, videos.. random PDF files.. thanks to anyone answering me. I don\u2019t need speed. I don\u2019t access my current hard drive hardly at all. It\u2019s just a copy of my photos and docs in case my PC takes a dump and my 1TB drive is full. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/National-Still3123\"> /u/National-Still3123 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kki0zu/choosing_between_two_external_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kki0zu/choosing_between_two_external_drives/\">[comments]</a></span>",
        "id": 2655204,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kki0zu/choosing_between_two_external_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Choosing between two external drives.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Conti_2000",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-12T01:40:07.103476+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-12T01:26:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I&#39;ve grown tired of having to be online in order to enjoy movies, series, books or videos that i liked, and the fear that they will the removed or deleted one day haunts me every day.</p> <p>Besides that, I&#39;ve been trying to save a lot of pictures, videos and even downloading movies on my pc and phone in order to watch them later, but their storage is limited, and I would love to have more. How can I start saving and hoarding my own data? are cloud apps like mega and such good places to start? Or should I get external storages to start saving all that info? what about personal servers? (being honest I don&#39;t know anything about them but I heard they&#39;re good to keep everything conected) </p> <p>I also have places to download things like Internet Archive, Lucida for Music and bought a key from a downloading youtube page in order to save complete playlist if I wanted to, but I don&#39;t know if there are better places to get stuff from",
        "id": 2655030,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkgm86/how_can_i_start_hoarding",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can I start hoarding?",
        "vote": 0
    }
]