[
    {
        "age": null,
        "album": "",
        "author": "/u/tenclowns",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-19T18:27:47.570844+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-19T18:01:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Want to scrape and list all URLs from a webpage using GUI. Including posted links when say scraping a forum where posts include links. Id want some formatting options though if possible. To be able to see the directory of links. So all the links contained within a link should show the parent child relagionship. Also if possible each link could include the name that link would show in the browser when you visit that link (to get some more details about the particular link)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tenclowns\"> /u/tenclowns </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kqih28/rookie_question_scrape_urls_with_directory/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kqih28/rookie_question_scrape_urls_with_directory/\">[comments]</a></span>",
        "id": 2718870,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kqih28/rookie_question_scrape_urls_with_directory",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Rookie question - scrape URLs with directory relationship display",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Firstboy11",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-19T18:27:47.862838+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-19T17:37:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I am learning web scrapping and tried beautifulsoup and selenium to scrape. With bot detection and resources, I realized they aren&#39;t the most efficient ones and I can try using API calls instead to get the data. I, however, noticed that big companies like Amazon hide their API calls unlike small companies where I can see the JSON file from the request. </p> <p>I have looked at a few post, and some mentioned about encryption. How does it work? Is there any way to get around this? If so, how do I do that? I would appreciate if you could also point me out to any articles to improve my understanding on this matter.</p> <p>Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Firstboy11\"> /u/Firstboy11 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kqhucx/how_do_big_companies_like_amazon_hide_their_api/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/we",
        "id": 2718871,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kqhucx/how_do_big_companies_like_amazon_hide_their_api",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do big companies like Amazon hide their API calls",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/VitorMaGo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-19T17:23:50.385759+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-19T16:25:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Can I negotiate with a scraping bot, or offer a dedicated endpoint to download our data?</p> <p>I work in a library. We have large collections of public data. It&#39;s public and free to consult and even scrape. However, we have recently seen &quot;attacks&quot; from bots using distributed IPs with such spike in traffic that brings our servers down. So we had to resort to blocking all bots save for a few known &quot;good&quot; ones. Now the bots can&#39;t harvest our data and we have extra work and need to validate every user. We don&#39;t want to favor already giant AI companies, but so far we don&#39;t see an alternative.</p> <p>We believe this to be data harvesting for AI training. It seems silly to me because if the bots phased out their scraping, they could scrape all they want because it&#39;s public, and we kinda welcome it. I think, that they think, that we are blocking all bots, but we just want them to not abuse our servers. </p> <p>I&#39;ve",
        "id": 2718313,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kqg02r/can_i_negotiate_with_a_scraping_bot",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can I negotiate with a scraping bot?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DatakeeperFun7770",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-19T16:14:50.953690+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-19T16:02:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I want to scrape some competitor&#39;s ecom websites. I want to scrape every product details page and get all the relevant data from that page like title price variant sizes reviews etc and get a table out of it. Final goal is to get insights from LLM with these information of the products. </p> <p>How should I approach this problem?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DatakeeperFun7770\"> /u/DatakeeperFun7770 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kqffh8/how_would_you_approach_scraping_ecom_website/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kqffh8/how_would_you_approach_scraping_ecom_website/\">[comments]</a></span>",
        "id": 2717691,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kqffh8/how_would_you_approach_scraping_ecom_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How would you approach scraping Ecom website",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/carishmaa",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-19T15:09:55.862782+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-19T14:58:09+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1kqdtg0/scrape_websites_by_recording_your_actions_open/\"> <img src=\"https://external-preview.redd.it/xv6f3glOjAZa8rxE84PVJyS9GRyfDIkoaGTJ_yzxnJs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f58cd28cadb216d8de0b2e2f2d6e9b74435d6a2\" alt=\"Scrape websites by recording your actions. Open Source.\" title=\"Scrape websites by recording your actions. Open Source.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>6 months ago, we launched <strong>Maxun</strong>, an open-source free tool to scrape websites <strong>without writing code</strong>. You just:</p> <ol> <li><strong>Record</strong> your actions (click here, scroll there).</li> <li><strong>Save it as a robot</strong> (it repeats <em>exactly</em> what you did).</li> <li><strong>Get clean data</strong> (CSV/API/JSON).</li> </ol> <p>Today, we hit <strong>10M rows extracted</strong> and <strong>12.6K GitHub stars</strong>.</p> <p><strong>Why it works:</strong></p>",
        "id": 2716980,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kqdtg0/scrape_websites_by_recording_your_actions_open",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/xv6f3glOjAZa8rxE84PVJyS9GRyfDIkoaGTJ_yzxnJs.jpg?width=640&crop=smart&auto=webp&s=5f58cd28cadb216d8de0b2e2f2d6e9b74435d6a2",
        "title": "Scrape websites by recording your actions. Open Source.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/OkNeedleworker6500",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-19T14:01:25.658567+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-19T13:06:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>couldn\u2019t stop thinking about how 8 billion people are just out there doing stuff so i made this<br/> <a href=\"https://humans.maxcomperatore.com/\">https://humans.maxcomperatore.com/</a></p> <p>it <a href=\"https://www.reddit.com/r/webdev/comments/1ko1aht/wtf_are_8_billion_people_doing_right_now_i_made_a/\">blew up</a> so i:</p> <ul> <li>added a clock</li> <li>fixed the map</li> <li>nerfed the banging stats</li> <li>added war</li> <li>made it slightly less confusing</li> </ul> <p>still mostly vibes tho. lmk your thoughts lol</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/OkNeedleworker6500\"> /u/OkNeedleworker6500 </a> <br/> <span><a href=\"https://i.redd.it/hxsm3a3dfq1f1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kqb7ni/this_site_tells_you_what_8_billion_humans_are/\">[comments]</a></span>",
        "id": 2716354,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kqb7ni/this_site_tells_you_what_8_billion_humans_are",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "this site tells you what 8 billion humans are probably doing right now",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Few_Bet_9829",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-19T12:55:19.117779+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-19T12:14:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys, will appreciate some help. So I\u2019m scraping Reddit data (post titles, bodies, comments) to analyze with an LLM, but it\u2019s super inefficient. I export to JSON, and just 10 posts (+ comments) eat up ~400,000 tokens in the LLM. It\u2019s slow and burns through my token limit fast. Are there ways to:</p> <ol> <li>Scrape more efficently so that the token amount will be lower?</li> <li>Analyze the data without feeding massive JSON files into the LLM? </li> </ol> <p>I use a custom python script using PRAW for scraping and JSON for export. No fancy stuff like upvotes or timestamps\u2014just title, body, comments. Any tools, tricks, or approaches to make this leaner?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Few_Bet_9829\"> /u/Few_Bet_9829 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kqa5e5/smarter_way_to_scrape_andor_analyze_reddit_data/\">[link]</a></span> &#32; <span><a href=\"https://www.r",
        "id": 2715859,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kqa5e5/smarter_way_to_scrape_andor_analyze_reddit_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Smarter way to scrape and/or analyze reddit data?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/create_urself",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-19T05:20:03.228697+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-19T04:48:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is it possible to scrape perplexity responses from its web UI at scale across geographies? This need not be a logged in session. I have a list of queries,geolocation pairs that I want to scrape responses for and dump it on a db. </p> <p>Has anyone tried to build this? If you can point me to any resources that&#39;d be helpful. Thanks! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/create_urself\"> /u/create_urself </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kq3du6/scraping_perplexity/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kq3du6/scraping_perplexity/\">[comments]</a></span>",
        "id": 2713283,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kq3du6/scraping_perplexity",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Perplexity",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LeKaiWen",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-19T03:10:04.164327+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-19T02:52:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to scrape the content of a page, but it seems to require solving a captcha first in many cases.<br/> I&#39;m new to webscraping, so I&#39;m not familiar with the common techniques. Maybe for my case, there is an easy way around that I just can&#39;t see?</p> <p>Or is a captcha solver the only good solution to my problem?</p> <p>Here is the page I&#39;m trying to access (note: in some case, the page is accessed directly without captcha, and I don&#39;t know why, so maybe it won&#39;t show for you? no idea):</p> <p><a href=\"https://search.shopping.naver.com/search/all?pagingIndex=1&amp;pagingSize=40&amp;productSet=total&amp;query=%ED%9E%90%EB%A0%88%EB%B2%A0%EB%A5%B4%EA%B7%B8+%EC%95%8C%EB%9D%BD+%EA%B7%B8%EB%A6%B0&amp;sort=rel&amp;timestamp=&amp;viewType=list\">https://search.shopping.naver.com/search/all?pagingIndex=1&amp;pagingSize=40&amp;productSet=total&amp;query=%ED%9E%90%EB%A0%88%EB%B2%A0%EB%A5%B4%EA%B7%B8+%EC%95%8C%EB%9D%BD+%EA%B7%B8%",
        "id": 2712822,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kq1eg3/new_to_webscraping_is_a_captchasolver_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New to webscraping. Is a captcha-solver the solution to my situation?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/p3tanque",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-19T05:20:03.447687+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-19T02:12:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello! I am a beginner with next to zero experience looking to make a project that uses some webscraping. In my state of NSW (Australia), all traffic cameras are publicly accessible, <a href=\"https://www.livetraffic.com/traffic-cameras/all-nsw\">here</a>. The images update every 15 seconds, and I would like to somehow take each image as it updates (from a particular camera) and save them in a folder.</p> <p>In future, I think it would be cool to integrate some kind of image recognition into this, so that whenever my cars numberplate is visible on camera, it will save that image separately, or send it to me in a text.</p> <p>How feasible is this? Both the first part (just scraping and saving images automatically as they update) and the second part (image recognition, texting).</p> <p>I&#39;m mainly looking to gauge how difficult this would be for a beginner like myself. If you also have any info, tips, or pointers you could give me to helpful resources,",
        "id": 2713284,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kq0o2i/beginner_looking_for_tips_with_webscraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Beginner Looking for Tips with Webscraping",
        "vote": 0
    }
]