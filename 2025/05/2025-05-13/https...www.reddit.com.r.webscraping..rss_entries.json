[
    {
        "age": null,
        "album": "",
        "author": "/u/MayoJunge",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-13T19:46:11.125860+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-13T19:15:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I just need the product prices from some websites, I don&#39;t have a lot of knowledge about scraping or coding but I was successful in learning enough to set up a headless browser and using a python selenium script for one website, this one for example :<br/> <a href=\"https://www.wir-machen-druck.de/tragegriffverpackung-186-cm-x-125-cm-x-12-cm-einseitig-bedruckt-40farbig.html\">https://www.wir-machen-druck.de/tragegriffverpackung-186-cm-x-125-cm-x-12-cm-einseitig-bedruckt-40farbig.html</a><br/> This website doesn&#39;t have a lot of protection to prevent scraping but it uses dynamic java script to generate the prices, I tried looking in the source code but the prices weren&#39;t there. The specific product type needs to be selected from the drop down and than the amount, after some loading the price is displayed, also can&#39;t multiply the amount with the per item price because that is not the exact price. With my python script I added some wait time",
        "id": 2671045,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1klunqk/need_advice_on_efficiently_scraping_product",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need advice on efficiently scraping product prices from dynamic sites",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mickspillane",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-13T17:34:02.106974+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-13T16:37:20+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1klqlmb/advice_for_getting_past_amazon_captcha_on/\"> <img src=\"https://preview.redd.it/h01svmsttk0f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=38078429a643beb787478b6881b7959e339ab5e8\" alt=\"Advice for getting past Amazon captcha on Amazon.com\" title=\"Advice for getting past Amazon captcha on Amazon.com\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I see documentation on how to get past Amazon WAF captchas on other sites: <a href=\"https://docs.capmonster.cloud/docs/captchas/amazon-task/\">https://docs.capmonster.cloud/docs/captchas/amazon-task/</a></p> <p>But the captchas that appear on <a href=\"http://Amazon.com\">Amazon.com</a> don&#39;t provide the same information. For example, I don&#39;t see a challenge.js or captcha.js.</p> <p>Anyone been able to scrape around these captchas on <a href=\"http://Amazon.com\">Amazon.com</a> or is the game all about not getting hit with these captchas in the first pla",
        "id": 2669994,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1klqlmb/advice_for_getting_past_amazon_captcha_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/h01svmsttk0f1.png?width=320&crop=smart&auto=webp&s=38078429a643beb787478b6881b7959e339ab5e8",
        "title": "Advice for getting past Amazon captcha on Amazon.com",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Your-Ma",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-13T16:26:06.877002+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-13T16:10:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Ive tried all sorts of ways but can never fetch the profile picture image or a link to the image. Does anyone have any ideas?</p> <p><a href=\"https://ra.co/dj/tiesto\">https://ra.co/dj/tiesto</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Your-Ma\"> /u/Your-Ma </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1klpx7w/how_can_i_scrape_the_profile_image_from_this_site/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1klpx7w/how_can_i_scrape_the_profile_image_from_this_site/\">[comments]</a></span>",
        "id": 2669293,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1klpx7w/how_can_i_scrape_the_profile_image_from_this_site",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can i scrape the profile image from this site using imgproxy?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Infamous_Land_1220",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-13T14:12:44.173046+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-13T13:15:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>To elaborate a bit further, I read or heard somewhere that Amazon doesn\u2019t block its own AWS ips. And also because if you use lambda without vpc you get a new ip each time I figured it might be a good way to scrape Amazon. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Infamous_Land_1220\"> /u/Infamous_Land_1220 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kllnve/can_i_use_ec2_or_lambda_to_scrape_amazon_website/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kllnve/can_i_use_ec2_or_lambda_to_scrape_amazon_website/\">[comments]</a></span>",
        "id": 2667937,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kllnve/can_i_use_ec2_or_lambda_to_scrape_amazon_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can I use Ec2 or Lambda to scrape Amazon website?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-13T13:07:50.583970+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-13T13:01:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels\u2014whether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>If you&#39;re new to web scraping, make sure to check out the <a href=\"https://webscraping.fyi\">Beginners Guide</a> \ud83c\udf31</p> <p>Commercial products may be mentioned in replies. If you want to promote your own products and services, continue to use the <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">monthly thread</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 2667361,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kllck7/weekly_webscrapers_hiring_faqs_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weekly Webscrapers - Hiring, FAQs, etc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/antvas",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-13T10:57:08.892942+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-13T09:57:39+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1kli144/detecting_hidemium_fingerprinting_inconsistencies/\"> <img src=\"https://external-preview.redd.it/_FR58CPbqMcMYiLcjCMzD1jExf8v29S4GMtAYFvsQcI.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bbca6f5f0f36bf0428dda37f9c6e7c6962bd1e6d\" alt=\"Detecting Hidemium: Fingerprinting inconsistencies in anti-detect browsers\" title=\"Detecting Hidemium: Fingerprinting inconsistencies in anti-detect browsers\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi, author here \ud83d\udc4b This post is about <strong>detection</strong>, not evasion, but if you&#39;re defending against bots, understanding how anti-detect tools work (and where they fail) is critical.</p> <p>In this blog, I take a close look at <strong>Hidemium</strong>, a popular anti-detect browser. I break down the techniques it uses to spoof fingerprints and show how <strong>JavaScript feature inconsistencies</strong> can reveal its presence.</p> <p>Of course, JS featu",
        "id": 2666262,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kli144/detecting_hidemium_fingerprinting_inconsistencies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/_FR58CPbqMcMYiLcjCMzD1jExf8v29S4GMtAYFvsQcI.png?width=640&crop=smart&auto=webp&s=bbca6f5f0f36bf0428dda37f9c6e7c6962bd1e6d",
        "title": "Detecting Hidemium: Fingerprinting inconsistencies in anti-detect browsers",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Kindly_Object7076",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-13T10:57:09.083012+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-13T09:52:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>For context: Im writing a program that scrapes off google, Scrapes one google page (returns 100ish google links that are linked to the main one) Scrapes each of the resulting pages(returns data) </p> <p>I suppose a good example of what im doing without giving it away could be maps, first task finds a list of places second takes data from the page of the place</p> <p>For each page i plan on using a hit and run scraping style and a different residential proxy, what im wondering is, since the pages are interlinked would using random proxies for each page still be a viable strategy for remaining undetected (i.e. searching for places in a similar region within a relatively small timeframe from various regions of the world)?</p> <p>Some follow ups: Since i am using a different proxy each time is there any point in setting large delays or could i get away with a smaller/no delay? How important is it to switch UA and how much does it have to be switched (atm ",
        "id": 2666263,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1klhyom/proxy_rotation_effectiveness",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Proxy rotation effectiveness",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/urgetobe",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-13T06:36:45.979445+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-13T06:12:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi there,<br/> I&#39;ve developed an app that scrapes data from a given URL. To avoid getting banned, I decided to use residential proxies \u2014 which seem to be the only viable solution. However, each page load consumes about <strong>600 KB</strong> of data. Since I need the app to process <strong>at least 50,000-60,000 pages per day</strong>, the total data usage adds up quickly.</p> <p>I&#39;m currently testing a services residential proxies, but even their highest plan offers only <strong>50 GB per month</strong>, which is far from enough.</p> <p>I also came across something called <strong>static residential proxies (ISP)</strong>, but I\u2019m not sure how they differ from regular residential proxies. They seem to have a 250 GB monthly cap, which still feels limiting.</p> <p>I\u2019m quite new to all of this and feeling stuck. I&#39;d really appreciate any help or advice. Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www",
        "id": 2664885,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kleu8j/residental_proxies_vs_isp",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Residental Proxies vs ISP",
        "vote": 0
    }
]