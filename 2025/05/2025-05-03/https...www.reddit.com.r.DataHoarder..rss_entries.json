[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T23:06:35.053181+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T23:01:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I keep trying to view a site on Wayback machine but its just a white screen and nothing else, anyone know why this happens?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Severe_Citron768\"> /u/Severe_Citron768 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ke5l0f/sites_refuse_to_show_up_on_wayback_machine/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ke5l0f/sites_refuse_to_show_up_on_wayback_machine/\">[comments]</a></span>",
        "id": 2592900,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ke5l0f/sites_refuse_to_show_up_on_wayback_machine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Sites refuse to show up on Wayback Machine",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T23:06:35.183088+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T22:48:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Any input would be appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Electrical-Reveal-25\"> /u/Electrical-Reveal-25 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ke5bni/free_file_sync_users_does_ffs_copy_data_faster/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ke5bni/free_file_sync_users_does_ffs_copy_data_faster/\">[comments]</a></span>",
        "id": 2592901,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ke5bni/free_file_sync_users_does_ffs_copy_data_faster",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Free file sync users: does ffs copy data faster when synchronizing than if I were to copy from one file to another manually (i.e. copying and pasting a file on my desktop). It seems like data is being copied faster using ffs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T23:06:35.313999+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T22:18:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Yes, they actually made VHS Players, playback only devices that didn&#39;t record. They were mostly used in the back of limousines and camper setups because even if you had live TV OTA, the signal wasn&#39;t worth recording with a small antenna. Anyway, would models that take in 12V DC help with noise reduction? Is there a 60/50hz noise hum in in the test points? Also will a PAL VHS tape work on a NTSC VCR and I just won&#39;t see it on a NTSC TV?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/commodore512\"> /u/commodore512 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ke4pjh/would_a_vcr_or_vcp_that_can_take_12v_dc_help_with/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ke4pjh/would_a_vcr_or_vcp_that_can_take_12v_dc_help_with/\">[comments]</a></span>",
        "id": 2592902,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ke4pjh/would_a_vcr_or_vcp_that_can_take_12v_dc_help_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Would a VCR or VCP that can take 12V DC help with noise reduction with the Domesday Duplicator?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T22:02:33.935437+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T21:54:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>I&#39;m new to data hoarding. Actually, i&#39;ve just learned about raid technology (i knew that existed, but never knew how it actually worked). The thing that has always annoyed me is how much space we have to sacrifice to insure data. 50% of total space for raid 1, and even though for it&#39;s only 25% of total for Raid 5 which seem the best one from have i&#39;ve read, it&#39;s still a lot.</p> <p>So, i imagined this configuration. What about a raid 0 + another disk that will regularly (once a week/day/couple of hours depending on what we like) lossless compress the data from the raid 0 to act as redundancy (even as backup actually) while saving a lot of space (50% gain on average maybe more? smth like that). And if we&#39;re really paranoid on the data loss from that back up, we can use a raid 1 array for that back up disk, it would still be more efficient than a plain raid 5 (which also has no real back up).</p> <p>Example :</p> <p>We",
        "id": 2592657,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ke47zg/raid_0_compression_on_another_disk_best_use_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Raid 0 + Compression on another disk = best use of space for hoarding ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T22:02:33.695623+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T21:41:16+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ke3xqf/huntarr_v62_history_tracking_stateful_management/\"> <img src=\"https://external-preview.redd.it/yHlEvWmSuDCQNbu2iSfYp6bR8C-i9bZWpKx9O3y5R_M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=20b8f563fb72f4d394d06c1db4c045d41a61cdf0\" alt=\"Huntarr v6.2 - History Tracking, Stateful Management and Whisparr v2 Support\" title=\"Huntarr v6.2 - History Tracking, Stateful Management and Whisparr v2 Support\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Good Afternoon Fellow Data Hoarders</p> <p>Released Huntarr 6.2 with what many features that have been asked for. Check out the details below! Keep in mind the app is unraid store. Visit us over at <a href=\"/r/huntarr\">r/huntarr</a> on reddit! So far 80TBs of missing content on my end has been downloaded soley due to Huntarr.</p> <p><strong>GITHUB:</strong> <a href=\"https://github.com/plexguide/Huntarr.io\">https://github.com/plexguide/Huntarr.io</a></p> <p><strong>",
        "id": 2592656,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ke3xqf/huntarr_v62_history_tracking_stateful_management",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/yHlEvWmSuDCQNbu2iSfYp6bR8C-i9bZWpKx9O3y5R_M.jpg?width=640&crop=smart&auto=webp&s=20b8f563fb72f4d394d06c1db4c045d41a61cdf0",
        "title": "Huntarr v6.2 - History Tracking, Stateful Management and Whisparr v2 Support",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T20:57:35.486998+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T19:52:52+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ke1ky1/setup_my_nas_running_asrock_n100dcitx_16_gig_ram/\"> <img src=\"https://a.thumbs.redditmedia.com/V7gGjR4TagJejXIXiMVhBN21PmimDdVEaHKVx-G2iA8.jpg\" alt=\"Setup my nas, running asrock n100dc-itx 16 gig ram, 60 terabytes\" title=\"Setup my nas, running asrock n100dc-itx 16 gig ram, 60 terabytes\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Just my setup I have an 18 terabyte ironwolf pro for my parity drive using unraid, another 18 tb for data (ironwolf pro), and 14 tb ironwolf pro, a wd red plus 10 tb for data, ordered another 18 tb wd gold not sure if i will use for second parity drive or more data</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/local-host\"> /u/local-host </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1ke1ky1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ke1ky1/setup_my_nas_running_asrock_n100dcitx_16",
        "id": 2592345,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ke1ky1/setup_my_nas_running_asrock_n100dcitx_16_gig_ram",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/V7gGjR4TagJejXIXiMVhBN21PmimDdVEaHKVx-G2iA8.jpg",
        "title": "Setup my nas, running asrock n100dc-itx 16 gig ram, 60 terabytes",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T19:52:35.213132+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T19:42:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone. I&#39;ve got a decent collection of manga books from the 70&#39;s/80&#39;s and I was looking for a non-destructive way to scan and digitalize them. Flatbed scanners are, of course, not what I&#39;m looking for, and mobile scanning apps are a bit tricky to deal with (besides, my camera is pretty bad). I&#39;m actually looking to sell some of my pieces for other people to enjoy, which is why it is important that they remain unharmed. Thanks in advance for all the advice. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sa-_-m\"> /u/Sa-_-m </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ke1cgy/bestleast_destructive_way_to_scan_and_digitalize/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ke1cgy/bestleast_destructive_way_to_scan_and_digitalize/\">[comments]</a></span>",
        "id": 2592093,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ke1cgy/bestleast_destructive_way_to_scan_and_digitalize",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best/least destructive way to scan and digitalize comics.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T18:47:34.196253+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T18:22:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi. I would like help/ advice to setup a NAS (about 10TB) so my family (4 people) can connect their computers to store files (homework, documents, excel, photos, family video, etc). That&#39;s it for now. And I would like to set up another NAS (?) or maybe just an external drive (?) to back up the files in the family NAS automatically, like nightly. Lastly, setting up another NAS at my parents&#39; house to backup regularly what&#39;s in the family NAS automatically, weekly (?).</p> <p>We don&#39;t plan to stream video like Plex or Jellyfin. We don&#39;t plan to upload trip photos while vacation. I don&#39;t know if an old PC build (OMV, TrueNas, UnRaid but I have never used any of them before) or a prebuilt system like Terra Master, Qnap, UGreen is better. Synology with the propriety hard drive is a turn off. I don&#39;t mind spending sometime to learn and build my own, but if there is a reasonably priced prebuilt option, I am also open to it. </p> <",
        "id": 2591764,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdzjey/seeking_advice_for_a_setup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seeking advice for a setup",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T18:47:34.326766+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T18:20:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I have quite a lot of media files (mainly video and audio) and have over the years bought multiple 5TB Seagate One Touch external HDDs. This has been fine but I&#39;ve already maxed out 4 of them, and am filling up some of my smaller external drives as well.</p> <p>Could anyone give me some recommendations for short term options and long term options (where I&#39;m able to save more and have more storage - ~50TB) on what the best way to manage things? Currently, I have a spreadsheet that just has a list of things on each drive and if I need something, I&#39;ll check the spreadsheet, then plug in the appropriate drive.</p> <p>I&#39;m on Windows and I do want to note that I am considering building a new PC at some point in the next year or two as mine is quite old. If there&#39;s any way for me to reuse any parts to create some sort of media storage device, please let me know.</p> <p>Thanks in advance!</p> </div><!-- SC_ON --> &#32; submit",
        "id": 2591765,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdzi0z/advice_on_storing_large_amounts_of_media_content",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Advice on storing large amounts of media content",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T18:47:33.923024+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T17:59:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m on the hunt for a +18 TB desktop HDD to stash all my video projects and do a bit of editing now and then. A couple of things: </p> <p><strong>Use case:</strong> Mainly cold storage, occasional editing.<br/> <strong>Power:</strong> Won\u2019t be running 24/7\u2014only plugged in when I need it.<br/> <strong>Warranties:</strong> Don\u2019t care\u2014can\u2019t really use them where I live. :(<br/> <strong>No NAS:</strong> Just a plug-and-play USB drive on my desk. (I am not ready financially for it)<br/> <strong>Budget:</strong> Mid-range, aiming for solid bang-for-buck and decent speeds.</p> <p>Any recommendations? Seagate, WD, Toshiba\u2026 any specific series? Seagate Expansion VS WD Elements? </p> <p>So basically something that will be up for years, as I can&#39;t use the warranty.</p> <p>Thanks a ton! \ud83d\ude4f</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JuanLuisBst\"> /u/JuanLuisBst </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHo",
        "id": 2591763,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdyzmm/which_external_desktop_hdd_18_tb_do_you_recommend",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Which external desktop HDD (\u224818 TB) do you recommend for storage and occasional editing (no NAS or warranties)?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T18:47:34.458795+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T17:52:25+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdyu5v/best_nvme_10gbps_enclosure_setup_for_m2_max_mac/\"> <img src=\"https://preview.redd.it/zsn6814rulye1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aaf9c0bb811a3040376280d0f3581bb0b1839878\" alt=\"Best NVMe + 10Gbps enclosure setup for M2 Max Mac in decent budget\" title=\"Best NVMe + 10Gbps enclosure setup for M2 Max Mac in decent budget\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey all,</p> <p>I\u2019m looking to build a fast external SSD setup using an M.2 NVMe drive with a 10 Gbps USB 3.2 Gen2 enclosure (supports M-Key and B+M Key NVMe SSDs) for my M2 Max MacBook Pro. My main uses include:</p> <ol> <li>Fast file transfers temporarily for the current projects to run ArriRaw, R3D and similar formats.</li> <li>Running DaVinci Resolve projects (media, cache, renders, etc)</li> </ol> <p>A few questions before I buy the parts:</p> <p>1.\u2060 \u2060Will this give me real-world speeds close to 900\u20131000 MB/s on macOS",
        "id": 2591766,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdyu5v/best_nvme_10gbps_enclosure_setup_for_m2_max_mac",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/zsn6814rulye1.jpeg?width=640&crop=smart&auto=webp&s=aaf9c0bb811a3040376280d0f3581bb0b1839878",
        "title": "Best NVMe + 10Gbps enclosure setup for M2 Max Mac in decent budget",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T17:42:33.680190+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T16:40:25+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdx6wa/i_can_only_use_83_gb_out_960_gb_why/\"> <img src=\"https://preview.redd.it/59zk2m0zhlye1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1729078a836d19908b94d6e140ad60993aa3851\" alt=\"I can only use 83 GB out 960 GB, WHY!?\" title=\"I can only use 83 GB out 960 GB, WHY!?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>The SSD shows 937 GB, but I&#39;m only able to use 83 GB</p> <p>Why you ask, Because when it exceeds 83 GB The activity on the drive reaches 100% With 0% Read/Write activity and becomes unresponsive </p> <p>As you can see in the image that I have a Kingston SSD 960 GB</p> <p>I checked the whole drive sector for errors I deleted it, formated it, change between NTFS/Fat32, MBR/GPT, checked the firmware </p> <p>I used different drive softwares All of them showed no errors and checks 937 GBs</p> <p>At this point I&#39;m lost Please help me guys </p> <p>How can i unlock the other 854 GBs</p> </",
        "id": 2591396,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdx6wa/i_can_only_use_83_gb_out_960_gb_why",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/59zk2m0zhlye1.jpeg?width=640&crop=smart&auto=webp&s=c1729078a836d19908b94d6e140ad60993aa3851",
        "title": "I can only use 83 GB out 960 GB, WHY!?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T16:37:47.997206+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T16:05:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>im using goojara and theyre missing it. ive tried looking elsewhere online but im not getting far</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AggravatingTear4919\"> /u/AggravatingTear4919 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdwfgp/anyone_know_where_to_find_season_3_episode_9/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdwfgp/anyone_know_where_to_find_season_3_episode_9/\">[comments]</a></span>",
        "id": 2591141,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdwfgp/anyone_know_where_to_find_season_3_episode_9",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "anyone know where to find season 3 episode 9 hydes christmas rager of that 70s show?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T16:37:47.809019+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T15:53:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Title says everything. i looked at a few things from github but dont understand how they work and i dont wanna download videos one at a time</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LustingForErotica\"> /u/LustingForErotica </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdw57w/simple_to_use_program_to_bulk_download_files_from/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdw57w/simple_to_use_program_to_bulk_download_files_from/\">[comments]</a></span>",
        "id": 2591140,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdw57w/simple_to_use_program_to_bulk_download_files_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Simple to use program to bulk download files from a private telegram channel?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T15:32:31.335364+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T15:32:17+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdvntb/can_i_see_what_i_uploaded_without_an_account_on/\"> <img src=\"https://preview.redd.it/h9tylnnu5lye1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1c785c38caeca0c336fd798620ea2753b6c3fda2\" alt=\"Can I see what I uploaded without an account on imgur?\" title=\"Can I see what I uploaded without an account on imgur?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I don&#39;t know why putting i.imgur today showed up 3 images I uploaded in 2016. I never had an imgur account and I have new phone since 2023. My question is. Can I access what I uploaded in the past without having an account? Why was saved the url a pic from 2016? \ud83d\ude35\u200d\ud83d\udcab</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hitthegymsis\"> /u/Hitthegymsis </a> <br/> <span><a href=\"https://i.redd.it/h9tylnnu5lye1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdvntb/can_i_",
        "id": 2590762,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdvntb/can_i_see_what_i_uploaded_without_an_account_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/h9tylnnu5lye1.jpeg?width=640&crop=smart&auto=webp&s=1c785c38caeca0c336fd798620ea2753b6c3fda2",
        "title": "Can I see what I uploaded without an account on imgur?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T15:32:31.466280+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T15:18:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Ok so I have two computers laying around basically unused. I have an m4 Mac Mini that I have hooked up to my large external drives and use that + VidHub or infuse to stream my library to my apple tv&#39;s. Works terrifically, and is also extremely easy to add media from my personal (Mac) over the network to the main storage drives.</p> <p>I also recently purchased a $170 &quot;mini PC&quot; from amazon so I can use some windows specific programs, and for a pretty similar price made more sense to me to invest in rather than using something like parallels. I&#39;ve found that I really dont use this PC as much as I thought I would, and would like to make the mini PC my personal media server and repurpose the more powerful/expensive mac to either use more or just sell. </p> <p>The other day I downloaded Emby to my PC and tried to run it as I do VidHub. I was not impressed with the performance on Apple TV, would only play an episode or two and then just st",
        "id": 2590763,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdvcyd/wanting_to_switch_my_home_media_server_from_mac",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Wanting to switch my home media server from Mac to PC, Need Recomendations",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T15:32:31.145830+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T14:35:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi! I do video editing and I\u2019m looking to upgrade my storage for past projects. I currently have around 70TB backed across various smaller 4-8tb WD externals (they\u2019re getting old!). I\u2019d like to consolidate these into some bigger drives and have enough space left for a few years (10TB/year).</p> <p>Are the 28TB Seagate Expansions any good?</p> <p>I rarely ever pull from my current drives, it\u2019s more of a safety net. If I do pull from them, it\u2019s copying files to my SSD for editing.</p> <p>I also have a couple OWC Dual Elite Pros - would it better to throw some bigger drives in these?</p> <p>Everything is also backed up to the cloud.</p> <p>Thanks for any advice</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DIYDLH\"> /u/DIYDLH </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdueje/storing_70tb_of_video/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kd",
        "id": 2590761,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdueje/storing_70tb_of_video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Storing 70TB of Video?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T15:32:31.654845+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T14:35:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to be able to archive and use the [Feynman lectures](<a href=\"https://www.feynmanlectures.caltech.edu/\">https://www.feynmanlectures.caltech.edu/</a>) website, and I tried using HTTrack for that but it didn&#39;t seem to work since it uses Javascript to navigate throughout the website. The website itself is rather simple and I doubt there&#39;s any machinery that will make it too difficult to download the entirety of the website.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hattapliktir\"> /u/hattapliktir </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdueci/how_to_archive_a_website_that_uses_javascript/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdueci/how_to_archive_a_website_that_uses_javascript/\">[comments]</a></span>",
        "id": 2590764,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdueci/how_to_archive_a_website_that_uses_javascript",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to archive a website that uses Javascript links?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T14:26:53.531386+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T13:51:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I&#39;m using Robocopy to back up my Dragon Ball Blu-ray ISO rips (full 1:1 copies) onto a Western Digital HDD (Gold Enterprise).My priority is data integrity and reliability over speed.</p> <p>These are the Robocopy parameters I&#39;m currently using:</p> <p>robocopy &lt;src&gt; &lt;dest&gt; /COPY:DAT /DCOPY:T /ZB /J /R:3 /W:5</p> <p>/COPY:DAT (copies data, attributes, timestamps)</p> <p>/DCOPY:T (preserves directory timestamps)</p> <p>/ZB (restartable mode with backup privileges if needed)</p> <p>/J (copies using unbuffered I/O for large files)</p> <p>/R:3 /W:5 (retries 3 times, waits 5 seconds between retries)</p> <p>Do these parameters look suitable and reliable enough for ensuring integrity during transfer, especially for large ISO files?</p> <p>Any suggestions or additional flags recommended for preserving long-term data integrity on cold storage disks?</p> <p>Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#3",
        "id": 2590365,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdtgta/are_these_robocopy_parameters_suitable_for_safely",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are these Robocopy parameters suitable for safely copying Blu-ray ISO rips of Dragon Ball to a WD Cold Storage HDD?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T14:26:53.276378+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T13:23:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Anyone know any info regarding these two blurays? Sorry for the Norwegian information, don&#39;t know enough to find English site that sells identical one.</p> <p><a href=\"https://www.multicom.no/verbatim-datalifeplus-bd-r-dl-x/cat-p/c/p3755132\">https://www.multicom.no/verbatim-datalifeplus-bd-r-dl-x/cat-p/c/p3755132</a> 218.40$</p> <p><a href=\"https://www.multicom.no/mediarange-bd-r-x-25-50/cat-p/c/p8584898\">https://www.multicom.no/mediarange-bd-r-x-25-50/cat-p/c/p8584898</a> 67.82$</p> <p>I bought the bottom one a while back but had it in my room at summer where it ended up being 40c at times which might have killed them? But packaging was also slightly cracked when I got them, so I tried like 4 of them and 3 just failed to burn randomly or failed to verify after burning. Burnt at 4x speed rather than 6x as I read that&#39;s better? Also tried 2x just to make sure but it still failed. I used ImgBurn to burn them.</p> <p>The errors I got were like th",
        "id": 2590364,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdsvkj/bluray_choice_cheap_vs_expensive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Bluray choice, cheap vs expensive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T13:22:34.426751+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T12:48:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all</p> <p>Any thought on the most economical way to build a 200 TB storage</p> <p>Looking for an appliance that can also handle some m.2 or ssd storage for cache to speed things up </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Itsme809\"> /u/Itsme809 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kds6s3/economical_200tb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kds6s3/economical_200tb/\">[comments]</a></span>",
        "id": 2590041,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kds6s3/economical_200tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Economical 200TB",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T12:17:58.622797+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T11:44:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Does anybody have experience with keeping an off-site-mirror or backup with friends or family?</p> <p>Not sure how welcoming my friends and family would be, if I ask them, if I could plug a raspberry pi with an external harddrive into their router. But I think it would be a nice idea and also not a bad deal for them. They would get, let&#39;s say 2 TB of managed (by me) NAS storage, with off-site-mirror (at my place), and in exchange, I can mirror my stuff to that pi.</p> <p>I guess simply paying for cloud-storage is less cumbersome, but I kind of like the idea.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/leopard-monch\"> /u/leopard-monch </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdr1jd/offsitemirror_with_friends_or_family/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdr1jd/offsitemirror_with_friends_or_family/\">[comments]</a></span>",
        "id": 2589675,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdr1jd/offsitemirror_with_friends_or_family",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Off-Site-Mirror with friends or family",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T10:07:33.588941+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T09:48:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m upgrading my Plex server and debating between the WD Red Pro or Segate Ironwolf series 24TB. I will be seeing up 4 drives in RAID. </p> <p>I&#39;ve been using 4x 18TB Segate Ironwolf Pros for 3yrs with no issues, but they can be noisy at times. I&#39;ve heard mixed anecdotes about the WD Reds being noisy or quiet. </p> <p>I&#39;m leaning towards the WD drives due to the lower power consumption at idle.</p> <p>What has been everyone&#39;s experience with either? (The 18TB-24TB models are built differently than the lower capacity drives so a 1 to 1 isn&#39;t as relevant of lower ones)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/itsthewolfe\"> /u/itsthewolfe </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdp9nb/wd_red_pro_or_segate_ironwolf_pro_for_plex_server/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdp9nb/wd_red_pro_or_segate_ironw",
        "id": 2589059,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdp9nb/wd_red_pro_or_segate_ironwolf_pro_for_plex_server",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WD Red Pro or Segate Ironwolf Pro for Plex server? (24TB model)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T10:07:33.375151+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T09:09:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I installed a 1GB WD My Passport disk as backup disk for Time Machine on my Mac Mini.</p> <p>The first days all good, but after about a week it seems to have died completely. Did I do something wrong by using this disk as a backup disk?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Jeff_Florida\"> /u/Jeff_Florida </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdoqlx/wd_my_passport_disk_as_backup_disk_for_time/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdoqlx/wd_my_passport_disk_as_backup_disk_for_time/\">[comments]</a></span>",
        "id": 2589058,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdoqlx/wd_my_passport_disk_as_backup_disk_for_time",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WD My Passport disk as backup disk for Time Machine?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T07:57:50.116413+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T07:24:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking at SSDs with crazy high TBW, something like 70 years to reach TBW under normal circumstances, and can&#39;t help but wonder when will it fail? Because nothing lasts forever and everything eventually fails. The controller is far more likely to fail before reaching TBW, is this correct?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BringerOfNuance\"> /u/BringerOfNuance </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdn9rh/does_nand_and_controller_effect_ssd_reliability/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdn9rh/does_nand_and_controller_effect_ssd_reliability/\">[comments]</a></span>",
        "id": 2588574,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdn9rh/does_nand_and_controller_effect_ssd_reliability",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does NAND and controller effect SSD reliability? Or is TBW all there is?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T07:57:50.249946+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T07:06:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a phanteks entho 719 for my home desktop. Its my gaming pc, but it also has a decent amount of storage, and I use it for a as-needed Plex server. Its not always on, just as needed. I don&#39;t really remote stream from it. </p> <p>I my oldest two HDDS are 10TB HGSTs, and I have been thinking about upgrading those two to two ST28000NM000Cs. </p> <p>I have the space in the Entho, the drive cages will be stacked on two others I have, and its mounting system is fairly quiet, but I assume the drives are going to be louder than most standard hard drives? Is it only on access? </p> <p>What about the PWDIS function? Will I need to use a molex connector if I dont want to tape a pin? </p> <p>And what is the best solution to stop the heads from parking/cycling on the regular? I know that was a thing with older exos drives, is it still a thing with these?</p> <p>Anything else I should be aware of before dropping $680 on two of these? thanks!</p> </div><!--",
        "id": 2588575,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdn04d/thinking_of_grabbing_a_couple_of_seagate_exos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Thinking of grabbing a couple of Seagate Exos ST28000NM000C 28TBs for home desktop, part time plex server. Pros and Cons? Noise issues? PWDIS? Drive Sleep, load/unload cycles, etc?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T07:57:50.438164+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T07:02:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Please somebody archive everything on there or most of this will become lost media and o can&#39;t have that happen to my favourite artist</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Recent_Selection1945\"> /u/Recent_Selection1945 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdmxuj/save_ayeshapedia/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdmxuj/save_ayeshapedia/\">[comments]</a></span>",
        "id": 2588576,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdmxuj/save_ayeshapedia",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SAVE AYESHAPEDIA!!!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T04:41:14.339371+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T04:22:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>There are some that I remember fondly but were deleted by their uploaders so I can&#39;t watch them again. Does anyone have any ideas on how to find them?</p> <p>Examples are The Super Smash Bros Brawl Show (a machinima comedy series based on the 2010 Smash video game) and the TF2 <a href=\"http://15.ai\">15.ai</a> Team Degeneracy 2 Part 1 and 2 videos.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Expensive-Baby-1391\"> /u/Expensive-Baby-1391 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdkha0/does_anyone_know_how_to_find_deleted_youtube/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdkha0/does_anyone_know_how_to_find_deleted_youtube/\">[comments]</a></span>",
        "id": 2588000,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdkha0/does_anyone_know_how_to_find_deleted_youtube",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does anyone know how to find deleted youtube videos?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T04:41:14.122639+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T04:18:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have tons of videos stored on these USB&#39;s. I bought them maybe less than a year ago. Probably 6 - 8 months ago. All the images on the device still seem to be fine. But I&#39;m noticing going through everything. I&#39;m seeing some videos still working but tons of them just have the blue play icon and when I try playing them they wont play. </p> <p>Is there a way for me to recover them maybe? A lot of them still have the danbooru/gelbooru tags in them so is it still possible to copy and paste the tags and find the original image some how?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mil0wCS\"> /u/mil0wCS </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdkeom/my_usbs_arent_even_that_old_and_are_already/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdkeom/my_usbs_arent_even_that_old_and_are_already/\">[comments]</a></span>",
        "id": 2587999,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdkeom/my_usbs_arent_even_that_old_and_are_already",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "My usb's aren't even that old and are already facing corrupted files? how do I fix them?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T04:41:13.963233+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T03:54:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone. As someone who have a not so small media library myself, I needed a solution for keeping all my family media organized. After some search many years ago I have decided to write a small utility for myself, which I have polished over the years and it was solving a real problem I had for many years.</p> <p>Recently, I came across a thread in this community from someone looking for a similar solution, and have decided to share that tool with everyone. So I have open sources my app and also published it to Microsoft Store for free.</p> <p>I hope it will help many of you if you are still looking for something like this or ended up coming up with your own custom solution.</p> <p><a href=\"https://GitHub.com/mkArtak/MediaOrganizer\">Media Organizer GitHub repo</a></p> <p>Give it a try, I hope you will like it. I still use it for sorting my media on a weekly basis.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/use",
        "id": 2587998,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdjzxk/i_have_open_sources_my_media_organizer_app_and_i",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I have open sources my media organizer app and I hope it will help many of you",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T04:41:13.686449+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T03:42:05+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdjs1w/sim0n00ps_ofdl_has_been_dmcad/\"> <img src=\"https://preview.redd.it/mduiui85nhye1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=452d12c92d595eda9f531dc3a21a9e170e82c0bd\" alt=\"sim0n00ps OFDL has been DMCA\u2019d\" title=\"sim0n00ps OFDL has been DMCA\u2019d\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HANEZ\"> /u/HANEZ </a> <br/> <span><a href=\"https://i.redd.it/mduiui85nhye1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdjs1w/sim0n00ps_ofdl_has_been_dmcad/\">[comments]</a></span> </td></tr></table>",
        "id": 2587997,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdjs1w/sim0n00ps_ofdl_has_been_dmcad",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/mduiui85nhye1.jpeg?width=640&crop=smart&auto=webp&s=452d12c92d595eda9f531dc3a21a9e170e82c0bd",
        "title": "sim0n00ps OFDL has been DMCA\u2019d",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T03:36:13.845422+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T03:05:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>As the title says I want to download all the videos, gifs and pictures I saved on bookmarks at once. I save them to dowload them later and use them as Wallpaper, Screensavers and Widgets but I am tired of going post by post and copy link, use Twitter video downloader app, download repeat cycle. I want a solution that downloads all of them in just some clicks. If someone knows a easy solution like a chrome add-on/extensions I would be glad to hear it.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EdwinON\"> /u/EdwinON </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdj54m/download_all_the_videos_gifs_and_pics_media_from/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kdj54m/download_all_the_videos_gifs_and_pics_media_from/\">[comments]</a></span>",
        "id": 2587824,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdj54m/download_all_the_videos_gifs_and_pics_media_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Download all the videos, gifs and pics (media) from my bookmarks of Twitter/X at once?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T02:31:14.544901+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T02:20:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently (okay, yesterday) loaded Ubuntu onto my late 2012 Mac Mini to repurpose as a home server, including file server (NAS), some lightweight media serving, and hopefully media backups as well. My biggest question is how to best use the Thunderbolt (mini DisplayPort) port on the system (Mac says it\u2019s TB1, but Ubuntu seems to think it is TB2??)</p> <p>What kind of options are still available for this outdated interface? Best option for reasonable Blu-ray drive?</p> <p>An NVMe SSD would be sweet, but I haven\u2019t seen anything with other than USB-C interfaces, with one very expensive option. Honestly, 6-10 TB of storage would work for a while, though I suspect I\u2019ll eventually outgrow it. </p> <p>Just beginning to research what\u2019s out there, but have lurked in this sub long enough to know I\u2019ll get better suggestions here than I will find on my own. </p> <p>TIA</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No_Viol",
        "id": 2587685,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdibq2/external_expansion_advice",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "External expansion advice",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T01:26:15.263197+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T01:22:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Disclaimer:</strong> I&#39;d like to keep this as a serious discussion, so right off the bat, I feel that &quot;<em>I don&#39;t use / will never use AI</em>&quot; type of responses add little to the conversation. Let&#39;s keep it productive!</p> <p>I&#39;d like to share my bet on AI and how it affected my datahoarding, as the amount of data I was keeping started to climb far past what I&#39;m comfortable with. &quot;3-2-1&quot; is great when we&#39;re discussing how to keep things, but it doesn&#39;t necessarily facilitate access to our data in an affordable and convenient way.</p> <p>I&#39;ve been through the pain of downloading several terabytes worth of my data from the cloud and it&#39;s a painful exercise on the shoddy internet connection that I have to deal with. Put simply, I just have too much data. Most of it are my own remuxes of DVDs and Blu-rays and I&#39;ve now made a bet on AI to help with that.</p> <p>No longer do I buy 4K UHD ",
        "id": 2587517,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdh9nh/how_has_ai_affected_your_datahoarding_if_it_hasnt",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How has AI affected your datahoarding? If it hasn't, how would you like to use AI in the context of datahoarding?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-03T01:26:15.015513+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-03T00:49:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I know how to download the files using</p> <pre><code>ia download &#39;Collection Identifier Here&#39; </code></pre> <p>but I don&#39;t know how to save it to a separate drive.</p> <p>I found that you can use --glob to save to a different folder in a directory, but I don&#39;t know how to use it and if it works for drives, let alone where it saves without --glob.</p> <p>I haven&#39;t found a solution yet (yes, I&#39;ve tried to find the solution myself). If there&#39;s already someone who posted a solution, please send the link or tell me the solution.</p> <p>If it helps, I&#39;m using python on Windows and followed the installation guide in Internet Archive&#39;s documentations. I&#39;ve installed pipx. I don&#39;t want to download the files to my main drive (C:/). The collection is ~250GB (they&#39;re videos along with their thumbnails).</p> <p>I&#39;ve only installed it ~2 hours ago. Yes I&#39;m new</p> </div><!-- SC_ON --> &#32; submitted by &#32;",
        "id": 2587516,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kdgn03/is_there_a_way_for_ia_internet_archives_command",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a way for ia (Internet Archive's command line utility) to download a collection to a separate drive?",
        "vote": 0
    }
]