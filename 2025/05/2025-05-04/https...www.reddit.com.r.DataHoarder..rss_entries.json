[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T21:53:00.469055+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T21:25:38+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sepffuzzball\"> /u/sepffuzzball </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1keutuk\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keuvif/got_my_hakocore_rev_2/\">[comments]</a></span>",
        "id": 2598396,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1keuvif/got_my_hakocore_rev_2",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Got my Hako-Core Rev 2!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T21:53:00.802519+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T20:50:21+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lflondonol\"> /u/lflondonol </a> <br/> <span><a href=\"/r/homelab/comments/1keu27w/planning_my_first_nas_ecc_ram_support_with_amd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keu2jt/planning_my_first_nas_ecc_ram_support_with_amd/\">[comments]</a></span>",
        "id": 2598397,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1keu2jt/planning_my_first_nas_ecc_ram_support_with_amd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Planning My First NAS \u2014 ECC RAM Support with AMD 5650GE + B550M?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T19:44:35.284304+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T19:43:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello data hoarders,</p> <p>I&#39;m planning a large-scale archival project and would appreciate your recommendations on reliable HDDs for storing approximately 2PB of data. The key requirement is that this data needs to remain intact and recoverable after 5 vears, but will have minimal read operations during this time period, it&#39;s basicxally a cold storage.</p> <p>I initially considered LTO tape storage, but decided against it for various reasons, so I&#39;m specifically looking for HDD-based solutions.</p> <p>Which HDD models would you recommend for this long-term, low-access archival solution? I&#39;m particularly interested in reliability, data retention capabilities, and cost-effectiveness for drives that will mostly sit idle.</p> <p>Additionally, I&#39;m considering implementing RAID 10 for this setup. Would this be worth the investment for my specific cold storage use case, or would you suggest alternative RAID configurations or storage str",
        "id": 2597811,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1keshrw/best_hdds_for_2pb_longterm_cold_storage_raid_10",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best HDDs for 2PB long-term cold storage? RAID 10 worth it?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T19:44:34.819810+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T19:24:38+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kes25p/black_friday_2018_was_a_good_time/\"> <img src=\"https://b.thumbs.redditmedia.com/PF-ePSPuw9G1Vb4RC2ghKWYuaNjtxh3Y0aEkQsQSrvk.jpg\" alt=\"Black Friday 2018 was a Good Time\" title=\"Black Friday 2018 was a Good Time\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Getting ready for a move going through boxes and for the bad boys. Around Black Friday 2018 these went on sale for like $129 at Best Buy and bought 8 of them. Shucked them all the same night had had them running the next day. Over the years my setup has changed but these drives are still kicking. Was good time. Using 5\u2026 2 for cold storage and gave one to a friend was is starting out. </p> <p>Showing current setup not to violate any rules. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dreadrockstar\"> /u/dreadrockstar </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1kes25p\">[link]</a></span> &#32; <s",
        "id": 2597809,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kes25p/black_friday_2018_was_a_good_time",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/PF-ePSPuw9G1Vb4RC2ghKWYuaNjtxh3Y0aEkQsQSrvk.jpg",
        "title": "Black Friday 2018 was a Good Time",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T19:44:35.447132+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T19:20:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The videos are protected somehow when I try to download them. It will just show the name of the site. Any way to download them?</p> <p>Here is an example:</p> <p><a href=\"https://kisskh.do/Drama/Ang-Mutya-ng-Section-E/Episode-1?id=9987&amp;ep=172365&amp;page=0&amp;pageSize=100\">https://kisskh.do/Drama/Ang-Mutya-ng-Section-E/Episode-1?id=9987&amp;ep=172365&amp;page=0&amp;pageSize=100</a></p> <p>Video download link but only shows the site name when you open the video:</p> <p><a href=\"https://hls.streamsub.top/hls07/9987/Ep1_index.m3u8\">https://hls.streamsub.top/hls07/9987/Ep1_index.m3u8</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lostoompa\"> /u/lostoompa </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kerym4/help_downloading_videos_from_a_site/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kerym4/help_downloading_videos_from_a_site/\">[comment",
        "id": 2597812,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kerym4/help_downloading_videos_from_a_site",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help downloading videos from a site",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T20:48:18.354459+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T19:01:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I remember there used to be a lot of cool stuff on the-eye i was looking at the way back machine and saw that a lot of directories and files have been deleted: <a href=\"https://web.archive.org/web/20180403123723/https://the-eye.eu/public/\">https://web.archive.org/web/20180403123723/https://the-eye.eu/public/</a> </p> <p><a href=\"https://the-eye.eu/public/\">https://the-eye.eu/public/</a><br/> heres the comparison. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Puzzleheaded-Option8\"> /u/Puzzleheaded-Option8 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kerivu/what_happened_to_theeyeeu/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kerivu/what_happened_to_theeyeeu/\">[comments]</a></span>",
        "id": 2598101,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kerivu/what_happened_to_theeyeeu",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "what happened to the-eye.eu?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T19:44:35.124841+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T18:47:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is there any way to download videos from these websites? A lot of size fetish people are moving their content to this website since either Patreon is becoming a pain or Vimeo is taking their videos down. Internet download manager doesn&#39;t seem to have a way yet.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Pkemr7\"> /u/Pkemr7 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ker6zc/mymembersite_video_downloaded/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ker6zc/mymembersite_video_downloaded/\">[comments]</a></span>",
        "id": 2597810,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ker6zc/mymembersite_video_downloaded",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Mymember.site video downloaded?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T18:38:37.895143+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T18:31:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I don&#39;t know anything about anything and i&#39;m looking for the cheapest possible solution</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/_Argsy\"> /u/_Argsy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keqtmz/should_i_buy_a_1tb_hard_drive_from_facebook/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keqtmz/should_i_buy_a_1tb_hard_drive_from_facebook/\">[comments]</a></span>",
        "id": 2597489,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1keqtmz/should_i_buy_a_1tb_hard_drive_from_facebook",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Should i buy a 1tb hard drive from facebook marketplace?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T18:38:38.548934+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T17:35:47+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kephim/why_does_one_of_these_movies_have_black_bars_on/\"> <img src=\"https://b.thumbs.redditmedia.com/Tg_u5OEhE4BRv9e9afaL-vQrqMn1hMMcsP7d4CVoCLE.jpg\" alt=\"Why does one of these movies have black bars on all side, and the other doesn\u2019t?\" title=\"Why does one of these movies have black bars on all side, and the other doesn\u2019t?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Both these mkv\u2019s clock in over 50gb\u2019s. And both are listed as 4k. But I can\u2019t help but think the one with black bars is somehow less quality. Now admittedly, I\u2019m a video novice. And VLC can certainly expand the one with black bars to full screen, but if I\u2019m gonna have a 50gb+ video file, I\u2019m gonna expect the best. Even if I can\u2019t tell the difference.</p> <p>Can anyone tell me what\u2019s going on with the video with black bars on all sides? Is it someone\u2019s lazy or bad encoding? Btw, these were not obtained through any official sources.</p> </div><",
        "id": 2597490,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kephim/why_does_one_of_these_movies_have_black_bars_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/Tg_u5OEhE4BRv9e9afaL-vQrqMn1hMMcsP7d4CVoCLE.jpg",
        "title": "Why does one of these movies have black bars on all side, and the other doesn\u2019t?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T17:32:33.587372+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T17:05:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking at a Terramaster F4-210 (diskless)that I can get for $170. Is this a good deal for a first NAS?</p> <p>If there are better alternatives, what would you recommend?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No_Violinist_6736\"> /u/No_Violinist_6736 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keorp0/good_deal_for_nas_n00b/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keorp0/good_deal_for_nas_n00b/\">[comments]</a></span>",
        "id": 2597122,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1keorp0/good_deal_for_nas_n00b",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Good deal for NAS n00b?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T17:32:33.717735+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T16:30:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hiya, </p> <p>I&#39;ve been trying to transfer some files to my LaCie SSD from my mac. It&#39;s 90gb-ish and its a ton of smaller files inside one folder. It&#39;s stuck on &#39;calculating time left&#39; and never progress from there. I tried compressing them to .zip and then extracting them when they were inside the SSD, but there&#39;s an error when unfolding/extracting the files inside the SSD. </p> <p>How do I deal with this, and why is it so insanely slow. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Environmental_Gap_65\"> /u/Environmental_Gap_65 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keny9m/unable_to_transfer_many_files_to_ssd_lacie/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keny9m/unable_to_transfer_many_files_to_ssd_lacie/\">[comments]</a></span>",
        "id": 2597123,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1keny9m/unable_to_transfer_many_files_to_ssd_lacie",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Unable to transfer many files to SSD LaCie",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T20:48:18.833211+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T16:09:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking for the most suited NAS OS, for RAID6 pools and low ECC memory requirements, no matter how many pools are connected.</p> <p>I&#39;ll start with 1 pool, but later I might add temporarily more pools or even keep them disconnected for a while, in case I don&#39;t need access to that data.</p> <p>I value the checksum functionality of ZFS, but I&#39;m afraid of the possibility of losing all your data if the hardware(especially RAM) is not properly sized to the total connected storage.</p> <p>Currently I&#39;m a Synology owner and I totally dislike their restrictions(software and physical) when it comes to migrating your data from one NAS to the other.</p> <p>I&#39;m not interested in fancy features, like running all kinds of services, docker stuff, etc. I just need plain dumb storage, that is transferring as fast as possible and as reliable as possible, when it comes to data corruption.</p> <p>The only fancy feature that I might need would ",
        "id": 2598102,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kenftu/nas_os_recommendation_raid6_pools_but_no",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "NAS OS recommendation - RAID6 pools, but no ZFS(afraid of HW requirements)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T20:48:18.963590+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T15:24:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Going to be building my NAS soon directly from Seagate and will be ordering a few hard drives to start, eventually adding more to the pool in the future. </p> <p>Looking for advice on how to go about ensuring these aren\u2019t damaged during shipping.</p> <p>I\u2019m familiar with looking into SMART stats, although that\u2019s a lower concern here being they\u2019re coming directly from the manufacturer. I\u2019ve seen some talk about FARM stats, but again, doesn\u2019t seem to be largely applicable here.</p> <p>Mostly wondering about testing, as I\u2019ve seen folks here talk about running tests against HDDs, and I\u2019m not familiar whatsoever with those. Would love any advice you all can provide around ensuring the drives weren\u2019t wrecked during the shipping process</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/0biwan-Kenobi\"> /u/0biwan-Kenobi </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keme3j/validating_hdd_integrity_",
        "id": 2598103,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1keme3j/validating_hdd_integrity_upon_receipt",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Validating HDD Integrity Upon Receipt",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T15:22:35.228140+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T15:12:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m going to be building a small storage server based on a Ryzen 5700G and a Gigabyte A520I AC motherboard. I&#39;m hoping to get some ECC RAM, and I&#39;m starting with the compatibility list provided by Gigabyte, but it&#39;s of course not exhaustive and the products I can find for reasonable money on eBay are not specifically listed.</p> <p>There are two options that particularly stand out to me. There&#39;s some Samsung 2133mhz memory, but it&#39;s 4DRx4 and there are no 4DRxx items on the compatibility list. There&#39;s also some Samsung 2400T memory that is 2Rx4, which there are plenty of 2Rxx items on the compatibility list, though not specifically x4, mostly x8. Also, I&#39;m not sure what &quot;2400T&quot; indicates versus a traditional 2400mhz label.</p> <p>I&#39;m leaning towards the 2Rx4 memory instead of the 4DRx4 memory, because there is no 4DRxx memory on the compatibility list, but I want to double-check here to see if I&#39;m on t",
        "id": 2596400,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kem45p/buiding_a_small_storage_server_am4_ddr4_ecc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Buiding a small storage server, AM4 DDR4 ECC compatibility?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T15:22:35.038668+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T15:08:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m archiving comics, and I&#39;ve started to learn towards naming them with a YYYY.MM.DD at the beginning of their file, to make sorting and reading orders simpler and more efficient. So I was wondering if there was a program that did that, because typing them in manually for hundreds and hundreds of comics is.... not ideal.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sludge_Punk\"> /u/Sludge_Punk </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kem0pc/filebot_but_for_comics/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kem0pc/filebot_but_for_comics/\">[comments]</a></span>",
        "id": 2596399,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kem0pc/filebot_but_for_comics",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Filebot but for comics?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T15:22:35.359501+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T15:08:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It&#39;s a kingston SSD, and transfers at about 40MB/s (not sure if it&#39;s because of my USB enclosure)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TriedWharf\"> /u/TriedWharf </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kem0ii/is_60_a_good_price_for_a_1tb_ssd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kem0ii/is_60_a_good_price_for_a_1tb_ssd/\">[comments]</a></span>",
        "id": 2596401,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kem0ii/is_60_a_good_price_for_a_1tb_ssd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is 60\u20ac a good price for a 1TB SSD?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T20:48:19.123168+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T15:03:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, sorry. I heard that a quicker method to download such is by using the Inspect Element and get the M3U file, but even though I was able to get the playlist file, and download it successfully with yt-dlp, with the resulting file being an m4a, I can&#39;t seem to open it in MPV. And ffmpeg spits out the following warning and error:</p> <pre><code>[mov,mp4,m4a,3gp,3g2,mj2 @ 0xcff3133f700] Format mov,mp4,m4a,3gp,3g2,mj2 detected only with low score of 1, misdetection possible! [mov,mp4,m4a,3gp,3g2,mj2 @ 0xcff3133f700] moov atom not found </code></pre> <p>./playlist_16701443375057698887 [playlist_16701443375057698887].mov: Invalid data found when processing input</p> <p>Is there a way I can fix this file I have here? Or would anyone know of a Twitter Space downloader that won&#39;t ask me to register, or anything like that?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PuppyFromLosAndes\"> /u/PuppyFromLosAndes ",
        "id": 2598104,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kelwxu/how_do_i_download_a_twitter_space",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do I download a Twitter Space?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T15:22:35.491462+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T14:48:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Not really a serious data hoarder but thanks to Amazon purchase history which goes back to the beginning. Between 2016 and 2021 I purchased an number of 2.5 inch external USB 3 and 3.5 inch SATA HDD 2TB to 5TB drives. Of the ones that are still available or their cousins prices are up about 2.2X since then.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/redd-or45\"> /u/redd-or45 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kelk8k/prices_not_just_anecdotal/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kelk8k/prices_not_just_anecdotal/\">[comments]</a></span>",
        "id": 2596402,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kelk8k/prices_not_just_anecdotal",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Prices not just anecdotal",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T14:17:36.634129+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T14:10:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Been deep in the weeds of marketing automation and AI for over a year now. Recently wrapped up building a large-scale system that scraped and enriched over <strong>300 million LinkedIn leads</strong>. It involved:</p> <ul> <li>Multiple Sales Navigator accounts</li> <li>Rotating proxies + headless browser automation</li> <li>Queue-based architecture to avoid bans</li> <li>ChatGPT and DeepSeek used for enrichment and parsing</li> <li>Custom JavaScript for data cleanup + deduplication</li> </ul> <p>LinkedIn really doesn&#39;t make it easy (lots of anti-bot mechanisms), but with enough retries and tweaks, it started flowing. The data pipelines, retry queues, and proxy rotation logic were the toughest parts.</p> <p> If you&#39;re into large-scale scraping, lead gen, or just curious how this stuff works under the hood, happy to chat.</p> <p>I packaged everything into a cleaned database way cheaper than ZoomInfo/Apollo if anyone ever needs it. It\u2019s up at Lea",
        "id": 2596046,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kekpk9/built_a_300_million_linkedin_lead_gen_data_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Built a 300 million LinkedIn lead gen data with automation + AI scraped (painful but worth it)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T14:17:36.285341+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T13:26:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Questions:</strong></p> <ol> <li>Does this issue also apply for hard desks in PCs? I ask because I still have an old computer with a 1080 sitting next to me whose drives still work perfectly fine. I still use that computer for storage (but I am taking steps now to clean out its contents and store it elsewhere).</li> <li>Does this issue also apply to USB sticks? I keep some USB sandesks with encrypted storage for stuff I really do not want to lose (same data on 3 sticks, so I won&#39;t lose it even if the house burns down).</li> <li>Is my current plan good?</li> </ol> <p>My plan as of right now is to buy a 2TB external drive and a 2nd one 1,5 years from now and keep all data duplicated on 2 drives at any one time. When/if one drive fails I will buy 2 new ones, so there is always an overlap. Replace drives every 3 years regardless of signs of failure.</p> <p>4) Is there a good / easy encryption method for external hard drives? My USBs are encryp",
        "id": 2596045,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kejs0m/i_recently_today_learned_that_external_hard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I recently (today) learned that external hard drives on average die every 3-4 years. Questions on how to proceed.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T14:17:36.794537+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T13:14:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>(hope I&#39;m the first one to ask this kind of question around here, may or may not have seen some posts that are similar or exactly like this)</p> <p>My 2.5 and my 3.5 were both got dropped on the floor. They&#39;ve just dropped flat and didn&#39;t bounce or whatever, but I&#39;m not sure whether or which side of the drive were they got dropped. Probably from behind as one was wrapped in a bubble wrap (3.5) and the 2.5 was just on top of it. When they got dropped they&#39;ve landed both flat and the 2.5 were still on top of 3.5 and as of now, the 2.5 only rattles when is shaking vertically but isn&#39;t horizontally. The 3.5 weren&#39;t rattling vertically but I think I could hear a swooshing high pitched sound when you&#39;d shake it horizontally. Kind of like when you swing a very thin stick, you&#39;ll get that high pitch sound. </p> <p>I&#39;m not sure if I should plug it in then see if it boots or just let a professional check the internal part",
        "id": 2596047,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kejir3/what_does_it_mean_when_you_shake_a_25_hard_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "what does it mean when you shake a 2.5 Hard Drive and there's rattling vertically only?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T16:27:35.827409+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T12:47:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Couple of years ago, I got GIGABYTE BRIX mini PC with Celeron Processor J4105. The machine details can be found on its <a href=\"https://www.gigabyte.com/Mini-PcBarebone/GB-BLCE-4105-rev-10#ov\">home page here</a>.</p> <p>It basically has following relevant specifications:</p> <ul> <li>Front IO: <ul> <li>1 x USB3.0</li> <li>1 x USB3.0 type C</li> </ul></li> <li>Rear IO: 2 x USB 3.0</li> <li>Storage: Supports 2.5&quot; HDD/SSD, 7.0/9.5 mm thick (1 x 6 Gbps SATA 3)</li> <li>Expansion slots <ul> <li>1 x M.2 slot (2280_storage) PCIe x2/SATA</li> <li>1 x PCIe M.2 NGFF 2230 A-E key slot occupied by the WiFi+BT card</li> </ul></li> </ul> <p>Currently I have following things installed:</p> <ul> <li>Samsung SSD 850 EVO 500GB</li> <li>8 GB DDR4 RAM.</li> </ul> <p>CPU-Z says following for the RAM:</p> <ul> <li>Total Size: 8192 MB</li> <li>Type: DDR4-SDRAM</li> <li>Frequency: 1197.4 MHz (DDR4-2394) - Ratio 1:12</li> <li>Slot #1 Module - P/N: CB8GS2400.C8JT</li> </u",
        "id": 2596802,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kej0e0/setting_up_media_center_and_backup_server_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Setting up media center and backup server with mini PC",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T13:12:33.660998+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T12:46:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My budget is not that much, so I am considering Epson Perfection V19 and Canon LiDE 400. I will use it to scan old photos. As far as I have researched, the features are very similar, but they say that Epson is better. unfortunately, there are not many scanner models in the country where I live. (apart from these, Epson Perfection V39II is also possible, but if the others are good, I don&#39;t want to exceed my budget)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/firatlql\"> /u/firatlql </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keiz97/flatbed_scanner_advice/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keiz97/flatbed_scanner_advice/\">[comments]</a></span>",
        "id": 2595733,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1keiz97/flatbed_scanner_advice",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Flatbed scanner advice",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T13:12:33.411521+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T12:28:12+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1keinkc/best_10gb_based_nas_i_found_so_far_ugreen_dxp4800/\"> <img src=\"https://external-preview.redd.it/qgGdt9aoJPAwEsz09Gy9NefkdIaBTiRgm-g6h6yR_jU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a9b52710454cf0cafb5a0def6b50bc06425bdfee\" alt=\"Best 10Gb based NAS I found so far! UGREEN DXP4800 Plus\" title=\"Best 10Gb based NAS I found so far! UGREEN DXP4800 Plus\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>This NAS has one particular feature I really like! 2 Network Cards - 2.5 and 10Gb. It has a lot of other bells and whistles like a a nice Pentium gold 8505 with 5 cores and 6 threads and expandable RAM slots up to 64GB. But for me it was the network design that got me! 10Gb switches are expensive, which is why most of us opt for 2.5Gb switches. You can get them for as little as 30 quid, especially if they are basic ones (no POE and unmanaged) </p> <p>Which is why I really dig this network NiC setup on thi",
        "id": 2595732,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1keinkc/best_10gb_based_nas_i_found_so_far_ugreen_dxp4800",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/qgGdt9aoJPAwEsz09Gy9NefkdIaBTiRgm-g6h6yR_jU.jpg?width=320&crop=smart&auto=webp&s=a9b52710454cf0cafb5a0def6b50bc06425bdfee",
        "title": "Best 10Gb based NAS I found so far! UGREEN DXP4800 Plus",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T13:12:33.820425+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T12:13:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi!</p> <p>I&#39;ve recently bought a new/bigger HDD for my Synology DS218+.</p> <p>I slapped it into the NAS, formatted it to ext4/jbod and copied all the shared folders onto the new drive.</p> <p>Now I have totally 3 HDD&#39;s for the NAS. The first one is from a few years back with 10TB, the second 16TB and the new one 24TB.</p> <p>The 16TB and 24TB are currently inside the DS218+, but the 16TB should be removed and stored as backup.</p> <p>My plan is, to slap the 10TB into a HDD enclosure and backup every new copied stuff that gets copied over to the NAS also on this drive.</p> <p>So in total that would make 1x24TB inside = 1x16TB + 1x10TB as backup.</p> <p>But what is, if the NAS itself dies? Is it easy to access the ext4/jbod data and recover it from a normal windows/linux PC?</p> <p>Is it a good Idea to take out the 16TB and store it as it comes out from the Synology without any formatting/copying?</p> <p>Thank you for your help!</p> </div><!--",
        "id": 2595734,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1keie3p/backup_strategy_needed",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Backup strategy needed",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T12:07:34.889191+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T11:26:04+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kehlai/powerdirhasher_a_windows_data_integrity_tool_to/\"> <img src=\"https://preview.redd.it/079sap9g2rye1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2a1dbf7ecb82bab7242780a3e96fa05241ea08d\" alt=\"PowerDirHasher. A Windows data integrity tool to hash, verify and sync hashes for your files, keeping a history of all file changes\" title=\"PowerDirHasher. A Windows data integrity tool to hash, verify and sync hashes for your files, keeping a history of all file changes\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://github.com/diegopau/PowerDirHasher\">PowerDirHasher repo in GitHub</a> </p> <p>Hi everyone.</p> <p>I have recently published this GitHub repo with a PowerShell based tool that I named &quot;PowerDirHasher&quot; that allows you to hash, verify and sync hashes for your files, keeping a history of any file modifications for a given folder or set of folders.</p> <p>It doesn&#39;t have",
        "id": 2595413,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kehlai/powerdirhasher_a_windows_data_integrity_tool_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/079sap9g2rye1.png?width=640&crop=smart&auto=webp&s=f2a1dbf7ecb82bab7242780a3e96fa05241ea08d",
        "title": "PowerDirHasher. A Windows data integrity tool to hash, verify and sync hashes for your files, keeping a history of all file changes",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T11:02:45.847207+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T10:03:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, A quick overview before the question comes: I started with a Synology 4-bay NAS, then added an Optiplex with an ARC A310 for transcoding. Soon I&#39;ll be running out of space and I want to get out of Synology&#39;s ecosystem. The Plex server is already running on the Optiplex so I only need to move the media somewhere else. </p> <p>I came across Terramaster (D6-320) that I could attach to the Optiplex. </p> <p>Is it a good idea to run software raid 5 (even 6) on a windows pc with the Terramaster? How high is the CPU load nowadays really running software raid? If the PC crashes for some reason (behind UPS), is the data safe? Is it scalable? I ask because I see different opinions when searching the web. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DigitalDustOne\"> /u/DigitalDustOne </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kegbzw/software_raid/\">[link]</a></span> &#3",
        "id": 2595101,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kegbzw/software_raid",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Software RAID",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T11:02:45.978458+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T10:02:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, as Flickr changes it&#39;s way of usability on 16th May 2025 (limit file size downloads via free accounts), I wanted to know what important oder notable account are to save (including URL). Thanks :3</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hungry-Wealth-6132\"> /u/Hungry-Wealth-6132 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kegbhp/notableimportant_flickr_accounts/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kegbhp/notableimportant_flickr_accounts/\">[comments]</a></span>",
        "id": 2595102,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kegbhp/notableimportant_flickr_accounts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Notable/important flickr accounts",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T09:57:34.043751+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T09:06:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all. As per the title, what do you think are the odds of finding RED Plus over Ultrastar in My Book 12TB? All white label obviously. I don\u2019t want the HC530 due to noise thus avoiding My Book 14TB as Red Plus are no longer manufactured in this configuration.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Snickrrr\"> /u/Snickrrr </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kefj3f/odds_of_finding_12tb_red_vs_ultrastar_in_my_book/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kefj3f/odds_of_finding_12tb_red_vs_ultrastar_in_my_book/\">[comments]</a></span>",
        "id": 2594828,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kefj3f/odds_of_finding_12tb_red_vs_ultrastar_in_my_book",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Odds of finding 12TB RED+ vs Ultrastar in My Book in 2025?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T09:57:34.174474+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T08:53:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I&#39;ve got an 8-bay NAS with 4*20TB and 4*16TB drives in (two RAID 5 arrays). I started with the 20TB drives configured in RAID 5 and I have used 28.3TB of the 54.5TB. I had two 16TB drives laying around from a previous build so I bought two more and added them and configured another RAID 5. I have not added any files so I have 43.6TB of space on the second RAID 5 array.</p> <p>The reality of my storage needs are that I don&#39;t foresee needing much more than 50TB total in the near future so I am researching options to utilize the second array to provide more fault tolerance, or creating one RAID array with different size drives.</p> <p>Keeping the two array configuration, one option I&#39;ve come across is to have some rsync that automates backing up folders from the two arrays. I know nothing about this so there&#39;s a learning curve.</p> <p>Another option is to delete the 4*16TB RAID 5 array and create one RAID 6 array with all 8 ",
        "id": 2594829,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kefc8g/options_for_8_bay_nas_array_config",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Options for 8 bay NAS array config",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T08:52:33.256923+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T08:06:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi All.</p> <p>I hope people can help.</p> <p>I don&#39;t haver a NAS or anything like that, so i&#39;m looking for a mass storage disk that I can put in my stationary PC (it&#39;s 6 moths old).</p> <p>EXOS seem to be the most popular choice, but there are so many different types, so I can&#39;t figure out what to go for.</p> <p>There is also Toshiba and Western Digital Ultrastar among others.</p> <p>I&#39;m looking for at least 16 TB.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lactoo\"> /u/Lactoo </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keep31/looking_for_a_16tb_capacity_storage_disk_for_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1keep31/looking_for_a_16tb_capacity_storage_disk_for_a/\">[comments]</a></span>",
        "id": 2594586,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1keep31/looking_for_a_16tb_capacity_storage_disk_for_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a 16+TB capacity storage disk for a desktop",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T07:47:10.175826+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T07:15:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey hoarders\u2014<br/> I&#39;m looking for anyone who recorded <strong>TV news broadcasts</strong> (OTA, cable, or streaming) from around <strong>early 2024</strong>.<br/> There was a specific incident I saw live on the news that has <strong>completely vanished</strong> online. No trace on search engines, no clips, no mentions\u2014just gone.</p> <p>I won&#39;t go into detail here, but I\u2019d really appreciate if anyone has full DVR dumps, <strong>network rips (CNN, Fox, MSNBC, NY1, etc.)</strong>, or even partial captures from that timeframe.<br/> Could be from <strong>Plex libraries, NAS archives, livestream tools, even raw transport streams.</strong></p> <p>If you have anything recorded\u2014especially from <strong>March to May 2024</strong>\u2014please <strong>PM me</strong>. I can give more details privately. Even a few minutes of a nightly newscast might be enough.</p> <p>Thanks in advance to any fellow hoarders who&#39;ve got the good</p> </div><!-- SC_ON --> &#32; ",
        "id": 2594343,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kedz51/does_anyone_here_archive_tv_news_broadcasts_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does anyone here archive TV news broadcasts from early 2024?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T05:37:29.763615+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T05:10:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I saw the recent announcement that Facebook is going to be deleting all live stream videos. At first, when I saw this announcement, I didn\u2019t care cause I never go live. However, I remembered that my dad who passed away in 2021 used to go live daily in post 10 to 15 minute videos of inspirational content. I think the hardest part about somebody passing away is not being able to remember their voice the days and I\u2019m really missing him. I\u2019ll scroll through his Facebook and watch his old live stream videos but now they\u2019re gonna be deleted in 30 days, what is the easiest and quickest way to save a mass amount of Facebook live videos from somebody else else\u2019s account? I\u2019m so stressed and upset over this. I always had the backup of being able to just go on his profile and watch a few videos when I was missing him, but now they\u2019ll be gone forever. Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/justsad95\"> /u/jus",
        "id": 2593972,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kec5e9/whats_the_easiest_way_to_save_somebody_elses",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What\u2019s the easiest way to save somebody else\u2019s Facebook live videos before they\u2019re all deleted? My dad who passed away.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T04:32:50.843947+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T03:45:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>I&#39;ve got an always on Mac mini m4 running Plex server with a 128gb SSD attached containing some tv series and movies I watch on Plex on my TV and sometimes on my phone when I am at work via Tailscale. I also have 3 different old 2.5 HDD 500gb each one with photos, one with music and some files/apps and one as backup for my documents folders on Mac mini and MacBook. </p> <p>I would like to consolidate those several small HDDs into 1 or 2 3.5 HDDs maybe. Wanting to put them in raid so the second drive would always be a copy of the first one in case it fails and will have another one external as a backup for most important files which will only be plugged in once a week as a backup. I mainly need those drives to always be accessible for photos and movies (as storage). </p> <p>Am I better off with a DAS or just 2 external HDD attached all time to my Mac? Would love Synology but don&#39;t really have funds available to spend $AUD500 just for",
        "id": 2593782,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kearzn/would_i_benefit_from_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Would I benefit from NAS?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-04T02:22:55.085482+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-04T01:20:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I&#39;ve been trying to get some physical media (old photos, family videos) and stuff into the cloud, and decided on using Wasabi.</p> <p>I&#39;ve successfully put some things in the cloud, but now I cannot for the life of me figure out how to grant access to the sub user accounts I&#39;m making for my family. I have tried adding just about all the default admin and full access policies to a test account, yet when I try to access my bucket from Cyberduck, it fails because of an explicit deny policy (no idea where or why this is happening?)</p> <p>I don&#39;t want to make it &quot;public&quot; I just want to be able to help my family use Cyberduck to download things I am putting in my Wasabi bucket. I&#39;ve been going through the Wasabi documentation for a few hours now and nothing is making sense, no tutorials are helping me. Whatever I do Cyberduck won&#39;t connect to my Wasabi bucket on any sub user account. I do not want to give out root acces",
        "id": 2593475,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ke88mo/help_with_wasabi_and_giving_family_members_read",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help with Wasabi and giving family members read only access",
        "vote": 0
    }
]