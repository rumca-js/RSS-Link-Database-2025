[
    {
        "age": null,
        "album": "",
        "author": "/u/Diligent-Tea-9219",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-18T23:55:01.890701+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-18T22:46:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to scrape lease data from <a href=\"http://costar.com\">costar.com</a>, which requires me to sign in using credentials and attach received cookies onto request headers to make further valid requests for web scraping. However, when trying to get cookies by submitting a login form (form can be accessed here: <a href=\"http://product.costar.com\">product.costar.com</a>) as POST request, my submission quests fails and receives a non-200-response.</p> <p>I noticed that the login submission action attaches a <code>signin</code> param to the login POST request. Is there any way for me to find the <code>signin</code> value from costar website? Or is it an application-generated code challenge that is very hard for me to find?</p> <p>Maybe browser automation is the only way for me submit a login and receive cookies?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Diligent-Tea-9219\"> /u/Diligent-Tea-9219 </a> <br",
        "id": 2712220,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kpwou5/login_form_questions",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Login Form Questions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Lazy-Masterpiece8903",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-18T22:50:03.180996+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-18T22:33:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I&#39;m pretty new to scraping so need some advice for a newbie. </p> <p>I&#39;m working on some personal tasks trying to learn what I can. </p> <p>I&#39;ve attempted to scrape a free web tool and everything goes well I run a script to fill out the fields click submit and it brings back a recaptcha error. </p> <p>The problem is I don&#39;t see any recaptcha show up when the script runs. </p> <p>I&#39;m using playwrite and I tested patchright with a rotating proxy pool but never seem to pass this invisible bot detection. </p> <p>Should I test another library or should I get a captcha solver to bypass it ? </p> <p>TIA</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lazy-Masterpiece8903\"> /u/Lazy-Masterpiece8903 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpwfha/im_trying_to_scrape_need_advice/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpwf",
        "id": 2711897,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kpwfha/im_trying_to_scrape_need_advice",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I'm Trying to Scrape Need Advice",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NoPin618",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-18T17:24:54.171817+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-18T16:54:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Do you guys know about ssyoutube it is a youtube video downloading site and it has been there since a decade as far as i remember. And its domain name also stays the same without any extention change it still uses .com.</p> <p>So how does it manage to stay in the google search history and not get taken down by dmca or anything? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NoPin618\"> /u/NoPin618 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpokfj/how_does_ssyoutube_manage_to_not_get_down_by/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpokfj/how_does_ssyoutube_manage_to_not_get_down_by/\">[comments]</a></span>",
        "id": 2710161,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kpokfj/how_does_ssyoutube_manage_to_not_get_down_by",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How does ssyoutube manage to not get down by google search results?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/eliadkid",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-18T17:24:54.412143+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-18T16:47:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>been trying different api&#39;s and ideas for the last two days didn&#39;t manage to get around this issue, i can scrape a page but it won&#39;t have all the data if im not logged in. but i didnt&#39; manage to make a bot that can log in to the user and bypass the cloudflare. any ideas ? thx</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/eliadkid\"> /u/eliadkid </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpof47/any_ideas_how_to_get_passed_cloudflare/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpof47/any_ideas_how_to_get_passed_cloudflare/\">[comments]</a></span>",
        "id": 2710162,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kpof47/any_ideas_how_to_get_passed_cloudflare",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "any ideas how to get passed cloudflare ? propertyshark.com",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/No_Pickle_2048",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-18T19:34:54.634880+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-18T16:47:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys, i am new to the wold of scraping and this is the first time i am playing with proxies.</p> <p>Right now i am facing some problems.</p> <p>I think i made my proxy worked as everytime i request in <a href=\"https://api.ipify.org/?format=json\">https://api.ipify.org/?format=json</a> i get a different ip. But when i am trying to scrape real data (Booking.com) i get 402 error. The problem disapears if i remove the proxy from my script.</p> <p>ps i am using residential proxies but i have also tried mobile ones. does anyone have a clue? </p> <p>Thank you in advance </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No_Pickle_2048\"> /u/No_Pickle_2048 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpoemb/problems_with_proxies/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpoemb/problems_with_proxies/\">[comments]</a></span>",
        "id": 2710841,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kpoemb/problems_with_proxies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Problems with proxies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Infinity-artist",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-18T11:59:55.560169+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-18T11:52:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i have 3 years+ experience in web scraping and already scraped 600+ websites . I want to work on fresh or ongoing projects with single person or as part of team. can do multithreading beyond python current speed limits . security bypass as its casual day thing. if you have some work dm me . ( i don&#39;t want any payment , just learning &amp; experience.)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Infinity-artist\"> /u/Infinity-artist </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpi6de/want_to_work_on_web_scraping_projects/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpi6de/want_to_work_on_web_scraping_projects/\">[comments]</a></span>",
        "id": 2708368,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kpi6de/want_to_work_on_web_scraping_projects",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Want to work on web scraping projects",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Imaginary-Fact3763",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-18T09:49:49.120278+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-18T09:08:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What\u2019s the easiest way of crawling/scraping a website, and finding / downloading all PDFs they\u2019re hyperlinked?</p> <p>I\u2019m new to scraping.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Imaginary-Fact3763\"> /u/Imaginary-Fact3763 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpfqck/crawling_domain_and_findsdownloads_all_pdfs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kpfqck/crawling_domain_and_findsdownloads_all_pdfs/\">[comments]</a></span>",
        "id": 2707788,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kpfqck/crawling_domain_and_findsdownloads_all_pdfs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Crawling domain and finds/downloads all PDFs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/albert_in_vine",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-18T09:49:49.376443+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-18T08:54:57+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1kpfju3/pagination_in_offerup_graphql_api/\"> <img src=\"https://preview.redd.it/gyloljrf7i1f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9f191b8602e4025ac7652afae60e09fab3be5b1a\" alt=\"Pagination in Offerup Graphql API\" title=\"Pagination in Offerup Graphql API\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>In this <a href=\"https://offerup.com/api/graphql\">GraphQL</a> API for OfferUp, the <strong>pageCursor</strong> value is random and appears to be encrypted. The main category page of the website uses endless scrolling, so you won&#39;t find pagination URLs. However, in the API, the <strong>pageCursor</strong> value changes randomly. How can I capture these values with each scroll? I would greatly appreciate any guidance on this. Also, I&#39;ve noticed that the initial value starting with <strong>H4sIAAAAAAAAA</strong> remains the same, but it changes after that.</p> </div><!-- SC_ON --> &#32; submitted ",
        "id": 2707789,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kpfju3/pagination_in_offerup_graphql_api",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/gyloljrf7i1f1.png?width=320&crop=smart&auto=webp&s=9f191b8602e4025ac7652afae60e09fab3be5b1a",
        "title": "Pagination in Offerup Graphql API",
        "vote": 0
    }
]