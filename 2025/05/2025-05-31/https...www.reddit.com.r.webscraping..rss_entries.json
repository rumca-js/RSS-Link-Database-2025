[
    {
        "age": null,
        "album": "",
        "author": "/u/LKS7000",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-31T18:48:13.461627+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-31T18:39:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1l049nw/need_some_architecture_device_to_automate_scraping/\"> <img src=\"https://b.thumbs.redditmedia.com/QgO65GqmvOprINI0N2KSQj811kmEgq0qfu97qXn-7wI.jpg\" alt=\"Need some architecture device to automate scraping\" title=\"Need some architecture device to automate scraping\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi all, I have been doing webscraping and some API calls on a few websites using simple python scripts - but I really need some advice on which tools to use for automating this. Currently I just manually run the script once every few days - it takes 2-3 hours each time.</p> <p><a href=\"https://preview.redd.it/n6e8ru5ow54f1.png?width=2056&amp;format=png&amp;auto=webp&amp;s=bb0676602f0f04e9069a2ef838247ae4386c10c6\">https://preview.redd.it/n6e8ru5ow54f1.png?width=2056&amp;format=png&amp;auto=webp&amp;s=bb0676602f0f04e9069a2ef838247ae4386c10c6</a></p> <p>I have included a diagram of how my flow works a",
        "id": 2817158,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l049nw/need_some_architecture_device_to_automate_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/QgO65GqmvOprINI0N2KSQj811kmEgq0qfu97qXn-7wI.jpg",
        "title": "Need some architecture device to automate scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Diligent-Resort5851",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-31T19:54:21.554584+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-31T15:29:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been trying to scrape the project listings from <a href=\"http://Codeur.com\">Codeur.com</a> using Python, but I&#39;m hitting a wall \u2014 I just can\u2019t seem to extract the project links or titles.</p> <p>Here\u2019s what I\u2019m after: links like this one (with the title inside):</p> <p>Acquisition de leads</p> <p>Pretty straightforward, right? But nothing I try seems to work.</p> <p>So what\u2019s going on? At this point, I have a few theories:</p> <p>JavaScript rendering: maybe the content is injected after the page loads, and I&#39;m not waiting long enough or triggering the right actions.</p> <p>Bot protection: maybe the site is hiding parts of the page if it suspects you&#39;re a bot (headless browser, no mouse movement, etc.).</p> <p>Something Colab-related: could running this from Google Colab be causing issues with rendering or network behavior?</p> <p>Missing headers/cookies: maybe there\u2019s some session or token-based check that I\u2019m not replicating properly",
        "id": 2817419,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kzzt01/trouble_scraping_codeurcom_are_javascript_or",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trouble Scraping Codeur.com \u2014 Are JavaScript or Anti-Bot Measures ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MafiaAccountant",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-31T13:24:19.852682+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-31T10:35:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to scrape news headlines for a single stock from Yahoo Finance using R, from this page for example: <a href=\"https://finance.yahoo.com/quote/AAPL/news/\">https://finance.yahoo.com/quote/AAPL/news/</a></p> <p>Need something that grabs Date + Headline for the last 30 days. Could someone help with a working code or tips?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MafiaAccountant\"> /u/MafiaAccountant </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kzu0rr/scraping_news_from_yahoo_finance_with_r/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kzu0rr/scraping_news_from_yahoo_finance_with_r/\">[comments]</a></span>",
        "id": 2815371,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kzu0rr/scraping_news_from_yahoo_finance_with_r",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping news from Yahoo Finance with R",
        "vote": 0
    }
]