[
    {
        "age": null,
        "album": "",
        "author": "/u/Kris_Krispy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T13:58:24.125229+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T13:36:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Specifically I&#39;m looking for a salary. However its inconsistently inside a p tag or inside its own section. My current idea is dump all the text together, use a find for the word salary, then parse that line for a number. Are there libraries that can do this better for me?</p> <p>Additionally, I need advice on this: a div renders with multiple section children, usually 0 - 3, from a given pool. Afaik, the class names are consistent. I was thinking abt writing a parsing function for each section class, then calling the corresponding parsing function when encountering the specific section. Any ideas on making this simpler?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kris_Krispy\"> /u/Kris_Krispy </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kr51ri/how_to_parse_a_specific_number_from_a_paragraph/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1",
        "id": 2725519,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kr51ri/how_to_parse_a_specific_number_from_a_paragraph",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to parse a specific number from a paragraph of text",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T13:58:23.848347+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T13:01:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels\u2014whether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>If you&#39;re new to web scraping, make sure to check out the <a href=\"https://webscraping.fyi\">Beginners Guide</a> \ud83c\udf31</p> <p>Commercial products may be mentioned in replies. If you want to promote your own products and services, continue to use the <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">monthly thread</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 2725518,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kr4afp/weekly_webscrapers_hiring_faqs_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weekly Webscrapers - Hiring, FAQs, etc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/antvas",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T08:31:23.111699+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T07:28:04+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1kqyyd5/what_a_binance_captcha_solver_tells_us_about/\"> <img src=\"https://external-preview.redd.it/zpEVp8fygFWuh73girG3CuWt3tbyL4vQxLhzy4kwcPM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eb27398b2c766c20b0b52a003f73905ac42ba0cd\" alt=\"What a Binance CAPTCHA solver tells us about today\u2019s bot threats\" title=\"What a Binance CAPTCHA solver tells us about today\u2019s bot threats\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi, author here. A few weeks ago, someone shared an open-source Binance CAPTCHA solver in this subreddit. It\u2019s a Python tool that bypasses Binance\u2019s custom slider CAPTCHA. No browser involved. Just a custom HTTP client, image matching, and some light reverse engineering.</p> <p>I decided to take a closer look and break down how it works under the hood. It\u2019s pretty rare to find a public, non-trivial solver targeting a real-world CAPTCHA, especially one that doesn\u2019t rely on browser automation. ",
        "id": 2723046,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kqyyd5/what_a_binance_captcha_solver_tells_us_about",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/zpEVp8fygFWuh73girG3CuWt3tbyL4vQxLhzy4kwcPM.jpg?width=640&crop=smart&auto=webp&s=eb27398b2c766c20b0b52a003f73905ac42ba0cd",
        "title": "What a Binance CAPTCHA solver tells us about today\u2019s bot threats",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/bluesanoo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T03:06:22.783461+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T02:03:21+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1kqtl0e/scraperr_v110_basic_agent_mode/\"> <img src=\"https://external-preview.redd.it/2OMkeo1ndSfjf7Dz1cA0Ijw3HL_2vXFck_vEFkksSu0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=970a2fefebf440ae8833f21605f057f32cf4b7d8\" alt=\"\ud83d\udd77\ufe0f Scraperr - v1.1.0 - Basic Agent Mode \ud83d\udd77\ufe0f\" title=\"\ud83d\udd77\ufe0f Scraperr - v1.1.0 - Basic Agent Mode \ud83d\udd77\ufe0f\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Scraperr, the open-source, self-hosted web scraper, has been updated to 1.1.0, which brings basic agent mode to the app.</p> <p>Not sure how to construct xpaths to scrape what you want out of a site? Just ask AI to scrape what you want, and receive a structured output of your response, available to download in <strong>Markdown</strong> or <strong>CSV</strong>.</p> <p>Basic agent mode can only download information off of a single page at the moment, but iterations are coming to allow the agent to control the browser, allowing you to collect structure",
        "id": 2721804,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kqtl0e/scraperr_v110_basic_agent_mode",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/2OMkeo1ndSfjf7Dz1cA0Ijw3HL_2vXFck_vEFkksSu0.jpg?width=640&crop=smart&auto=webp&s=970a2fefebf440ae8833f21605f057f32cf4b7d8",
        "title": "\ud83d\udd77\ufe0f Scraperr - v1.1.0 - Basic Agent Mode \ud83d\udd77\ufe0f",
        "vote": 0
    }
]