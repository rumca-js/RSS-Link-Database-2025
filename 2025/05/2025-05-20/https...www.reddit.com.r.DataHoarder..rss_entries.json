[
    {
        "age": null,
        "album": "",
        "author": "/u/Novaa_49",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T23:26:55.578672+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T22:53:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Which would be more worth it for big data transfer use once and then I\u2019m just gonna retrieve it once in a while and It\u2019s gonna be installed into a usb enclosure so which would be better for sustain use as sometimes I would write lots of files to the SSD.</p> <p>Edit: both about same price lol like 1usd difference in my place, but maybe I want to hear on reliability.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Novaa_49\"> /u/Novaa_49 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kriomh/wd_black_sn850x_vs_samsung_990980pro/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kriomh/wd_black_sn850x_vs_samsung_990980pro/\">[comments]</a></span>",
        "id": 2730474,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kriomh/wd_black_sn850x_vs_samsung_990980pro",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Wd black sn850x vs Samsung 990/980pro",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LightDarkCloud",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T23:26:55.803024+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T22:47:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>24-26GB each</p> <p>WD preferably.</p> <p>Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LightDarkCloud\"> /u/LightDarkCloud </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krik5n/i_just_purchased_a_new_nas_and_i_need_to_purchase/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krik5n/i_just_purchased_a_new_nas_and_i_need_to_purchase/\">[comments]</a></span>",
        "id": 2730475,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1krik5n/i_just_purchased_a_new_nas_and_i_need_to_purchase",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I just purchased a new NAS and I need to purchase 5 very large 3.5\" HDDs. What are your go to places for large HDDs on sale? TiA",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Snoo_60803",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T23:26:55.272246+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T22:41:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I know it&#39;s probably very naive to ask, but I see so many videos, articles and informations about the genocide, that I fear one day, when the dust will settle, will all be lost or deleted, and the people who committed those atrocities never pay a dime for their actions. I was wondering if it&#39;s possible to do something like this, and how to do it Sorry for the very heated post, I just feel distraught by this all situation </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Snoo_60803\"> /u/Snoo_60803 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krif5o/is_possible_to_create_a_data_collector_for_all/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krif5o/is_possible_to_create_a_data_collector_for_all/\">[comments]</a></span>",
        "id": 2730473,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1krif5o/is_possible_to_create_a_data_collector_for_all",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is possible to create a data collector for all the crimes committed by Israel?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/briko3",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T22:21:51.522282+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T21:33:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need a good scanner that can scan directly to a USB flash drive. I&#39;m looking at the ES-580W, but not sure if I&#39;m overlooking a better option. I&#39;ve looked at the ix1600, but it doesn&#39;t scan to USB. Any thoughts, ideas or recommendations?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/briko3\"> /u/briko3 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krgv87/scanner_that_scans_to_usb_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krgv87/scanner_that_scans_to_usb_drive/\">[comments]</a></span>",
        "id": 2730036,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1krgv87/scanner_that_scans_to_usb_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scanner that scans to USB drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/pcookie95",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T22:21:51.796427+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T21:27:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am visiting my parents in a few weeks and was hoping to set up some backup storage at their house. Originally I was just going to use a Raspberry Pi and a USB HDD bay, but I&#39;ve read on a few different threads on Reddit that USB bays have some reliability problems that can cause data corruption.</p> <p>What is the best/cheapest alternative to a USB HDD bay? One of the reasons I wanted to use an RPi was the small footprint it offered (both in size and in power). Is there a solution for a similar price point (~100 USD) that doesn&#39;t take up too much space?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/pcookie95\"> /u/pcookie95 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krgpp9/usb_hdd_bay_backup_alternatives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krgpp9/usb_hdd_bay_backup_alternatives/\">[comments]</a></span>",
        "id": 2730037,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1krgpp9/usb_hdd_bay_backup_alternatives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "USB HDD Bay Backup Alternatives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/fungusfromamongus",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T21:17:58.563077+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T21:02:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys,</p> <p>I thought I&#39;d ask the experts in this sub about what is the best and cost effective way to store videos and photos for the purpose of ownership and have a cloud backup available of these assets.</p> <p>We are a local non profit org who often hosts international scholars and events that we record in RAW and capture photos from. We need to often share these assets with external vendors who do content creation etc work for us. </p> <p>I was thinking of getting a NAS with 20TB disks for redundancy <a href=\"https://pricespy.co.nz/search?query=20tb\">https://pricespy.co.nz/search?query=20tb</a></p> <p>Can you recommend a NAS that will allow me to also share files with external parties with READ only permissions etc?</p> <p>We dont require the NAS to host any docker images or other content.</p> <p>We would also like the NAS to orchestrate backups to Azure Storage Accounts for &quot;offsite&quot; backups stored as cool storage.</p> <p>Than",
        "id": 2729583,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1krg4av/saving_raw_videos_and_photos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Saving RAW videos and photos",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Nathaniel820",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T21:17:58.344360+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T20:24:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I have a couple of old internal 3.5in HDDs that I want to use as external harddrives, so I need to get an adaptor. I looked it up and I found some sources saying that an enclosure (<a href=\"https://www.amazon.com/Enclosure-CLAVOOP-External-SATA-Recovery/dp/B0D6RH6JBH?s=electronics\">example</a>) was better than a simple SATA to USB cable (<a href=\"https://www.amazon.com/Goldnest-Adapter%EF%BC%8CSATA-Superspeed-Compatible-Connector/dp/B0CQNYTMNQ?s=industrial&amp;th=1\">example</a>), but the reasons given as to why they were better seemed to be related to protection rather than speed/usability/etc. So if I were to just 3D print an enclosure to securely hold the HDD and cord in place, would it be any worse than an &quot;actual enclosure&quot;? Or do the boards in actual enclosures provide some benefit that makes them inherently better than a simple cable (of equal quality)?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.co",
        "id": 2729582,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1krf7r1/when_converting_internal_drives_into_external",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "When converting internal drives into external ones, is there any benefit to using a pre-made hard drive enclosure VS just using a SATA-to-USB cable and 3D printing an enclosure to fit it?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sega_CD32x",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T20:13:01.720385+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T19:08:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m hoping that some of us data hoarders hoard notes too!</p> <p>I&#39;m currently researching and attempting to create a massive timeline of historical events related to a specific subject. I&#39;m starting to hit a point where it is very hard to keep track of the hundreds of dates/events &amp; tons of media/documents/general files related to this subject...and, being a visual learner, I would really like a way to visualize such a timeline so that if I discover a new fact or event, it will &quot;click into place&quot; with other data I&#39;ve found. That way it will be easier for me to mentally associate related things together.</p> <p>So I&#39;m looking for a software that can help organize my research and I&#39;m imagining something that could at least implement some of the following:</p> <ul> <li>Create a visualization of a list of events (&quot;pages of data&quot;) based on time</li> <li>All events can be searched by tags or keywords (hopeful",
        "id": 2729144,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1krdbeo/best_way_to_make_a_large_timeline_of_information",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best Way to Make a Large Timeline of Information & Data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/myprettygaythrowaway",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T18:03:17.687072+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T17:46:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Reposting in the hopes that I got buried for posting at 3am or something on a Saturday.</p> <p>About me: not a techie, into Linux more out of principle and practicality - it&#39;s free, I&#39;m broke.</p> <p>My current setup:</p> <ul> <li>One refurbished ThinkPad running Linux that doesn&#39;t really work anymore. If I have a browser with a handful of tabs, and LibreOffice Writer open at the same time, it&#39;ll be sluggish at best, freeze and need a forced shutdown to get out of it. It&#39;s basically an external hard drive at this point, just storing stuff for me and rarely getting turned on.</li> <li>The refurbished ThinkPad running Linux I&#39;m writing this on! Holding up, but it&#39;s been through hell. It&#39;s had its share of forced shutdowns, power outages, so on, so forth.</li> <li>One external HDD of about 3.6TB that has all my oldest files, formatted in NTFS cause I didn&#39;t know better. <code>fsck</code> shows some serious problems wit",
        "id": 2727866,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1krb8rl/need_advice_on_what_to_work_toward_when_it_comes",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need advice on what to work toward, when it comes to fixing my current setup and going from there",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Geode890",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T18:03:17.878032+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T17:40:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking for a 4TB external hard drive to backup my PC to. Originally I was going to go for just a 2TB one, but finally got enough to cover a 4TB one (despite the apparent recent price increases). I currently have a 2TB version of the Toshiba Canvio Basics, which seems to have worked fine over the last decent few years, and I&#39;m wondering if I should just get the 4TB version of it (product number HDTB540XK3CA). Alternatively, I read that Seagate actually decouples the internal drive from the port, meaning you can remove it if the port breaks, which would be great. I found an almost suspiciously cheap, albeit official, one selling on Amazon called the Backup Plus Portable (product number STHP4000400).</p> <p>Anybody have any horror stories or praise for either of these? I&#39;m also open to other recommendations so long as they&#39;re right around $100 or so. I can&#39;t really spring for an external SSD, and couldn&#39;t really find a great ",
        "id": 2727867,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1krb3hh/any_recommendations_between_these_two_drives_or",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any Recommendations Between These Two Drives? (or alternatives)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/leftunreadit",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T18:03:18.066904+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T17:38:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"http://archive.ph\">archive.ph</a> - doesnt work anymore? are there any good alternatives? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/leftunreadit\"> /u/leftunreadit </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krb13k/archiveph_doesnt_work_anymore_are_there_any_good/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krb13k/archiveph_doesnt_work_anymore_are_there_any_good/\">[comments]</a></span>",
        "id": 2727868,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1krb13k/archiveph_doesnt_work_anymore_are_there_any_good",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "archive.ph - doesnt work anymore? are there any good alternatives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Surealistic_Sight",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T18:03:18.254530+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T17:17:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello and I am ripping my DVD collection to an external HDD and I have an issue with a bootleg DVD I own.</p> <p>I have a bootleg DVD, which has no copy protection. I tried it with MakeMKV, Imgburn, DVD Decrypter and DDrescue on Linux, since I am both a Windows and Linux user and it doesn\u2019t work.</p> <p>The dvd plays fine without any issues and other bootleg DVDs I own have been ripped without any issues.</p> <p>I am archiving my DVD collection as ISO files, to have everything on those DVDs.</p> <p>So yeah what can I do?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Surealistic_Sight\"> /u/Surealistic_Sight </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krai5i/i_have_an_issue_of_an_dvd_of_mine/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1krai5i/i_have_an_issue_of_an_dvd_of_mine/\">[comments]</a></span>",
        "id": 2727869,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1krai5i/i_have_an_issue_of_an_dvd_of_mine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I have an issue of an DVD of mine",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ElMostaza",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T16:58:29.611348+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T16:42:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to help a friend figure out the best way to keep their DVR&#39;ed content from YouTube TV.</p> <p>I honestly thought it would be pretty easy to either download the files directly or at least capture it with OBS. </p> <p>I can&#39;t find anything on the former. I&#39;ve found some comments in threads where people mention using ytdll to download the files, but no details or instructions are given. </p> <p>With OBS, I&#39;ve found several videos showing how to do it, but none of them worked for me. </p> <p>The best work around I could come up with us to have her setup two computers, with the first playing the content and the second taking it in via HDMI capture card and recording with OBS. Unfortunately, she doesn&#39;t have two computers. </p> <p>&nbsp;</p> <p>I&#39;ve seen enough comments on Reddit and other sites&#39; threads that I&#39;m certain there&#39;s a workable solution, but I haven&#39;t found anywhere that someone lays out exa",
        "id": 2727170,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr9lkb/whats_the_best_way_to_download_or_record_live",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's the best way to download or record live content from YouTube TV?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ConfusedHomelabber",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T16:58:29.800088+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T16:37:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><h2>\ud83d\udd0d Looking for the Best Option to Run SATA SSDs + SATA/SAS HDDs in a Small Form Factor (Newer than 9200-8i)</h2> <p>I&#39;m on the hunt for a <strong>modern, compact HBA or RAID card</strong> that supports:</p> <ul> <li>\u2705 <strong>SATA SSDs</strong></li> <li>\u2705 <strong>SATA and SAS HDDs</strong></li> <li>\u2705 <strong>Small form factor (SFF) friendly</strong></li> <li>\u2705 <strong>Newer than the LSI 9200-8i</strong></li> </ul> <p>The <strong>9200-8i</strong> is solid, but I\u2019m hoping to find something with: - <strong>Better power efficiency</strong> - <strong>Improved performance or newer firmware support</strong> - Possibly <strong>PCIe 3.0 or 4.0 compatibility</strong></p> <p>This is for a <strong>compact build</strong>, so <strong>low-profile cards</strong> or <strong>external cabling options</strong> would be ideal.</p> <p>If you\u2019ve had success with a more recent setup, I&#39;d love to hear your recommendations!</p> </div><!-- SC_ON --> &#32; submitted by &",
        "id": 2727171,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr9hcz/best_hba_card_for_a_fractal_node_304",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best HBA card for a Fractal Node 304?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lyrebird2",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T15:53:34.034416+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T15:18:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><h1>I\u2019m a videographer and I&#39;m using the OWC u2 shuttle with 3 8TB NVME cards to handle my working files. I have two additional storage drives that I back up to. I have an owc enclosure so I can just pop the shuttle in and out between work and home which is very convenient. There are times when I\u2019m on the road, however, and would like to use the shuttle with my Mac laptop. All the 3.5\u201d enclosures I\u2019ve found are large and not really portable. I\u2019m wondering if there are cables that would let me connect the shuttle to a port on my laptop relatively directly without an enclosure. I\u2019m not sure how much processing goes on in the shuttle vs the enclosure, so I\u2019m not sure how possible this is. I don\u2019t think heat would really be an issue given the shuttle has good heat sinks. I also don\u2019t know if this can be bus powered. I know there are dedicated enclosures - I actually have the Acasis 40gbps 4 nvme enclosure - but I\u2019d just really like to use the u2 shuttle ",
        "id": 2726594,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr7hsa/owc_u2_shuttle_connection",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "OWC U2 Shuttle connection",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cobalt_ss1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T14:47:55.482892+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T14:36:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Does anyone know of a tool, preferably in a docker, that can monitor and download any new images/videos that are posted by a Reddit user?..... For research purposes..... Getting past posts is easy but I want an automated method to keep up with new stuff.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cobalt_ss1\"> /u/cobalt_ss1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr6g0u/tool_to_download_user_posts_from_reddit/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr6g0u/tool_to_download_user_posts_from_reddit/\">[comments]</a></span>",
        "id": 2725856,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr6g0u/tool_to_download_user_posts_from_reddit",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tool to download user posts from reddit",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/hwayu_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T14:47:55.880783+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T14:31:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a beginner&#39;s question, but I couldn&#39;t find answers online. Only some user experiences with different results and too many &quot;should&quot; and &quot;could&quot;.</p> <p>My PC is running in RAID mode, with one SSD running Windows and two HDDs in a RAID 1 array. BIOS updates always reset the BIOS settings, so what happens to my drives? Will simply changing from AHCI mode to RAID mode get the drives working normally again without losing data?</p> <p>(I use the raid controller built into the mainboard, MSI MAG B650 TOMAHAWK WIFI)</p> <p>Edit: typo</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hwayu_\"> /u/hwayu_ </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr6bx5/bios_update_while_using_raid_mode/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr6bx5/bios_update_while_using_raid_mode/\">[comments]</a></span>",
        "id": 2725857,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr6bx5/bios_update_while_using_raid_mode",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "BIOS update while using RAID mode",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/thomas001le",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T14:47:56.116442+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T14:06:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was browsing cloud providers for cold storage and came across OVHcloud. They charge 0.0013797 $ per GB and Month. This makes them more expensive than AWS, GCS and Azure, but apparently they do not charge for ingress and egress traffic?!? This means the excessive costs of a restore (or even backup testing) would be removed.</p> <p>Granted OVHcloud doesn&#39;t have the best track record of success, but I only consider them as a second layer of defense and have all data also locally.</p> <p>Can that be true? Anybody have any experience?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/thomas001le\"> /u/thomas001le </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr5qpg/ovhcloud_with_free_ingressegress_traffic_really/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr5qpg/ovhcloud_with_free_ingressegress_traffic_really/\">[comments]</a></span>",
        "id": 2725858,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr5qpg/ovhcloud_with_free_ingressegress_traffic_really",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "OVHcloud with free ingress+egress traffic? really?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CautiousSize5143",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T13:41:47.258489+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T13:24:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all</p> <p>I currently am using storage spaces and wish to eventually get rid of it. I have 5x16tb drives using 4 for data and 1 for parity. I think I have a failing drive, so wanted to remove it without replacing it, and I have enough free space for this to happen, however, the option to remove disk is not present. I assumed this is because the virtual drive size covers 99.9% capacity of 4 drives, so I was thinking I could resize this to under 3 disks and be able to remove the drive.</p> <p>I know of the command <strong>Resize-VirtualDisk</strong> but I am unsure if this is the correct way to go about this. Or if column count may be the issue too?</p> <p>Provisioning is fixed type, any help will be greatly appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CautiousSize5143\"> /u/CautiousSize5143 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr4sdq/resize_storage_spaces_to_r",
        "id": 2725177,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr4sdq/resize_storage_spaces_to_remove_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Resize Storage Spaces to remove hdd",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Late_Coconut1877",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T16:58:29.422782+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T12:59:30+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr48q7/possible_doctored_seagate_with_weird_farm_values/\"> <img src=\"https://b.thumbs.redditmedia.com/GZNy4EuQrSjExnipXRYrGmPzSPSyW_zm-S9jErtS-7w.jpg\" alt=\"Possible Doctored Seagate with weird farm values\" title=\"Possible Doctored Seagate with weird farm values\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey I recently bought a Seagate Exos 16TB from a reputable german vendor where I clearly saw that it had reset smart values.</p> <p>I&#39;ve now purchased a replacement from Cyberport and I suspect it is also altered but:</p> <p><a href=\"https://preview.redd.it/sgz0ya0ejx1f1.png?width=986&amp;format=png&amp;auto=webp&amp;s=7d6113556e5e5c5d50bf040bae1a4094e21a3973\">https://preview.redd.it/sgz0ya0ejx1f1.png?width=986&amp;format=png&amp;auto=webp&amp;s=7d6113556e5e5c5d50bf040bae1a4094e21a3973</a></p> <p>Checking the Smart values returns 0 read hours and more curcialy no performed self test which according t",
        "id": 2727169,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr48q7/possible_doctored_seagate_with_weird_farm_values",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/GZNy4EuQrSjExnipXRYrGmPzSPSyW_zm-S9jErtS-7w.jpg",
        "title": "Possible Doctored Seagate with weird farm values",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fran314",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T16:58:30.089000+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T11:50:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have some small sensitive data (such as SSH keys, AGE keys and similar stuff) and I&#39;m trying to solve the problem of how to store this data in a way that is secure, convenient and long-term-safe.</p> <p>I was thinking of buying some (not cheap) 16GB USB sticks (probably SanDisk based on some quick google search on quality) and use them with the 3-2-1 strategy (2 locally, 1 off-site)</p> <p>I&#39;ve also noticed that USB stick are not considered reliable, so I was wondering if there was some better media that fits my usecase, in particular with the following &quot;requirements&quot;:</p> <ul> <li>small size (&lt;= 16GB), as I don&#39;t need to store that much information (I don&#39;t think I would even fill 1GB)</li> <li>reliable for long-term storage (with reliable here I mean that the chance that after 1 year of not using it, it still works. I have no issue with rotating the off-site stick once per year and I would probably do it anyway just to",
        "id": 2727172,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr2w9c/best_option_for_small_longterm_occasionalusage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best option for small, long-term, occasional-usage storage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Space_Eagle9990",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T16:58:30.327789+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T10:27:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been out of the game for a while now, but back in the day like 8 years ago there were a few tools you could use to mass download entire profiles from Instagram without getting caught. Now all I ever hear about in these downloading circles is that if you use 4K Stogram or other apps, you&#39;ll get banned, shadow banned, or IP Ban. I&#39;ve had my IG account for many years and I really don&#39;t want to lose it, but I still need to find a way to mass download accounts since my current way is very slow and takes too much time. I&#39;m currently downloading each individual photo and video. </p> <p>Is there a quicker more efficient workaround for this? Are they any apps that allow you to mass download from IG without getting caught? If there are, what precautions should I take to avoid being detected as a bot and getting banned? Do I need to use a different PC or Laptop? Use a VPN? If I just create a new account on another browser IG&#39;s system",
        "id": 2727173,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr1hat/mass_download_from_instagram_without_getting",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Mass Download from Instagram without getting banned, help?!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Liya_Yip",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T10:26:43.618538+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T10:00:44+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr12kr/whats_the_most_appropriate_file_system_for_a_d8/\"> <img src=\"https://preview.redd.it/xd3vu1p6uw1f1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3b771708bd6278f3d2bfa939243b87da3976cc20\" alt=\"What's the most appropriate file system for a D8 Hybrid expanded via USB??\" title=\"What's the most appropriate file system for a D8 Hybrid expanded via USB??\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;m setting up a a TERRAMASTER DAS D8 hybrid using USB expansion for extra capacity. The D8 will mainly store media files (videos, photos) and serve as a backup for multiple Windows and macOS machines. </p> <p>What&#39;s the most appropriate file system for a DAS expanded via USB? I&#39;m considering NTFS, exFAT, or even ZFS, but I&#39;m unsure about compatibility and performance trade-offs.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Liya_Yip\"> /u/Liya_Yip </a",
        "id": 2723630,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr12kr/whats_the_most_appropriate_file_system_for_a_d8",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/xd3vu1p6uw1f1.jpeg?width=640&crop=smart&auto=webp&s=3b771708bd6278f3d2bfa939243b87da3976cc20",
        "title": "What's the most appropriate file system for a D8 Hybrid expanded via USB??",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Mochila-Mochila",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T10:26:43.400655+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T09:28:59+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr0m45/new_case_fsp_u660_18_x_35_hdd_bays_9_pci/\"> <img src=\"https://external-preview.redd.it/Qi49gaMeo7ER4d6pSfpljE_HXnYNSw6EtkaZ1dqhjr0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cb9111f8b96f1a73b21a1c6f8adc2af8d2f8bb27\" alt=\"[New case] FSP U660 : 18 x 3.5&quot; HDD bays, 9 PCI expansion slots, BTF mobo support. 451 mm x 258 mm x 568 mm.\" title=\"[New case] FSP U660 : 18 x 3.5&quot; HDD bays, 9 PCI expansion slots, BTF mobo support. 451 mm x 258 mm x 568 mm.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Mochila-Mochila\"> /u/Mochila-Mochila </a> <br/> <span><a href=\"https://www.techpowerup.com/337024/fsp-at-2025-computex-air-and-liquid-cpu-coolers-specialist-psus-and-cases\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr0m45/new_case_fsp_u660_18_x_35_hdd_bays_9_pci/\">[comments]</a></span> </td></tr></table>",
        "id": 2723629,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr0m45/new_case_fsp_u660_18_x_35_hdd_bays_9_pci",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/Qi49gaMeo7ER4d6pSfpljE_HXnYNSw6EtkaZ1dqhjr0.jpg?width=640&crop=smart&auto=webp&s=cb9111f8b96f1a73b21a1c6f8adc2af8d2f8bb27",
        "title": "[New case] FSP U660 : 18 x 3.5\" HDD bays, 9 PCI expansion slots, BTF mobo support. 451 mm x 258 mm x 568 mm.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ufokid",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T09:21:50.714857+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T09:10:24+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr0cuk/are_all_these_scans_for_the_same_drive/\"> <img src=\"https://preview.redd.it/u2t6hiszkw1f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=681e260c01f4aca521c741d23cd32edf1f7fe01b\" alt=\"are all these scans for the same drive?\" title=\"are all these scans for the same drive?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ufokid\"> /u/ufokid </a> <br/> <span><a href=\"https://i.redd.it/u2t6hiszkw1f1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kr0cuk/are_all_these_scans_for_the_same_drive/\">[comments]</a></span> </td></tr></table>",
        "id": 2723257,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kr0cuk/are_all_these_scans_for_the_same_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/u2t6hiszkw1f1.png?width=640&crop=smart&auto=webp&s=681e260c01f4aca521c741d23cd32edf1f7fe01b",
        "title": "are all these scans for the same drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mobiliakas1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T09:21:50.417054+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T08:37:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, anybody knows where to get cheap drives in the EU? Most people recommended here US based sellers, but it won&#39;t make sense to ship it here.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mobiliakas1\"> /u/mobiliakas1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqzwno/cheap_drives_in_europe/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqzwno/cheap_drives_in_europe/\">[comments]</a></span>",
        "id": 2723256,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kqzwno/cheap_drives_in_europe",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cheap drives in Europe?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Tywin____Lannister",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T06:06:43.030072+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T05:13:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to backup my Windows 10 laptop that is starting to randomly shut off after 30 mins - 1 hr to an external hard drive connected through another computer via ethernet.</p> <p>Is there any software that can resume if the backup process is interrupted? Windows 7 Image can only backup abut 5 GB / 1 TB before shutting down.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tywin____Lannister\"> /u/Tywin____Lannister </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqwzzs/software_recommendations_for_backing_up_1tb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqwzzs/software_recommendations_for_backing_up_1tb/\">[comments]</a></span>",
        "id": 2722413,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kqwzzs/software_recommendations_for_backing_up_1tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Software recommendations for backing up 1TB Windows 10 laptop that randomly shuts off?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AccomplishedBee857",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T05:01:40.980667+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T04:52:48+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqwnst/best_way_to_scan_recessed_old_photos/\"> <img src=\"https://b.thumbs.redditmedia.com/nv3eFz3MC-FLaq2VcF93Ey-JEeqmswo8nAzRCa8nR6g.jpg\" alt=\"Best way to scan recessed old photos\" title=\"Best way to scan recessed old photos\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I have about 3 dozen old pictures that are affixed into frames that I cannot get the picture out of, they are not behind a glass frame it is a matte frame from the late 1800\u2019s early 1900\u2019s. I tried scanning them with an Epson V39II and they all turn out blurry even though the original picture is very detailed.</p> <p>The pictures are recessed into the frame about 1-3mm so there is a gap between the picture and the scanner bed itself. Is there a specific setting I might need on this scanner or would I need a ccd type scanner since the actual image I want to scan is not physically touching the glass?</p> <p>I have attached an example of one ",
        "id": 2722134,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kqwnst/best_way_to_scan_recessed_old_photos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/nv3eFz3MC-FLaq2VcF93Ey-JEeqmswo8nAzRCa8nR6g.jpg",
        "title": "Best way to scan recessed old photos",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MontyPontyy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T03:56:40.610188+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T03:19:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>so as i\u2019m writing this i tried to play a bunch of new vegas. out of nowhere my pc freezes and starts making a \u201cclicking\u201d sound. i\u2019ve had these parts for four years going and my fan(s) normally make a lot of noise. though i\u2019m not sure how bad its supposed to be, it\u2019s very clear my pc can no longer keep up with its current parts. i\u2019ve never had a freeze like this and if what im reading is right, i most likely don\u2019t have more then a week with this hard drive.</p> <p>in short, how do i transfer everything as best as possible? </p> <p>edit: okay wait, i might be on a slightly wrong subreddit. i\u2019m using SSD, and while that could also be a problem, it was a clicking noise, i think it\u2019s a fan issue either with my GPU or cooling fan.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MontyPontyy\"> /u/MontyPontyy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqv1dc/my_pc_hard_drive_seems_to_be_final",
        "id": 2721899,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kqv1dc/my_pc_hard_drive_seems_to_be_finally_giving_out",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "my pc hard drive seems to be finally giving out after four years. how can i best transfer things from my hard drive too my new hard drive im trying to get?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Shalliar",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T03:56:40.827729+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T02:52:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Since files can get corrupted or maybe got marked as duplicates by mistake (not confirmed yet though), do you think its reasonable to not delete duplicates at all and just let them sit in a separate folder in case I need them? How do you guys deal with this problem and duplicates in general?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Shalliar\"> /u/Shalliar </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqujbz/regarding_my_previous_post_about_duplicate/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqujbz/regarding_my_previous_post_about_duplicate/\">[comments]</a></span>",
        "id": 2721900,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kqujbz/regarding_my_previous_post_about_duplicate",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Regarding my previous post about duplicate pictures",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Shalliar",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T02:52:48.420906+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T02:10:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, Ive been trying this program out, scanned a HUGE folder containing various pics, found a bunch of duplicates, moved them to a different folder and on a quick inspection found out that one seemingly original picture got moved alongside with the dupes. </p> <p>Does it mean that theres another picture with better quality that stayed in the original folder, and its actually safe to delete the duplicates, or its a false positive? Does DupeGuru make mistakes of this kind? I dont want to delete something by mistake but its not really feasible to check everything manually.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Shalliar\"> /u/Shalliar </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqtps8/issue_with_dupeguru/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqtps8/issue_with_dupeguru/\">[comments]</a></span>",
        "id": 2721732,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kqtps8/issue_with_dupeguru",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Issue with DupeGuru",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jdwusami",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T01:46:44.457493+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T01:38:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just a heads up for anyone doing data recovery or configuring their RAID setup with the OWC Mercury Elite Pro Dual USB-C enclosure (model OWCMEDCH7T00):</p> <p>The default RAID chunk/stripe size, when set using the hardware switch on the back of the enclosure, is 64KB.</p> <p>I couldn\u2019t find this documented anywhere publicly and had to reach out to OWC support to confirm. Posting here in case it helps anyone else running into the same question.</p> <p>Hope this saves someone time!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jdwusami\"> /u/jdwusami </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqt2vp/owc_mercury_elite_pro_dual_with_3port_hub_raid/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqt2vp/owc_mercury_elite_pro_dual_with_3port_hub_raid/\">[comments]</a></span>",
        "id": 2721446,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kqt2vp/owc_mercury_elite_pro_dual_with_3port_hub_raid",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "OWC Mercury Elite Pro Dual with 3-Port Hub - RAID Chunk Size",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Broad_Sheepherder593",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T01:46:44.646578+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T00:44:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, </p> <p>I live in asia and average temp here is 32-34 deg celcius. My nas drives are ok, doing 43 deg but the nas system temp is around 45. Based on the nas specs, operating temp is only 0-40 deg. Should i be worried about this? Thinking of placing a fan but its not sustainable as i wouldn&#39;t want to leave a fan unattended.</p> <p>Using DS423+ </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Broad_Sheepherder593\"> /u/Broad_Sheepherder593 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqs0ey/nas_ambient_and_operating_temp/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqs0ey/nas_ambient_and_operating_temp/\">[comments]</a></span>",
        "id": 2721447,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kqs0ey/nas_ambient_and_operating_temp",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Nas ambient and operating temp",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Single-Rich-Bear",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-20T00:41:44.153248+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-20T00:05:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What would be the best setup? Occasional video editing Torrents Media library Data backup</p> <p>Thinking 1 SSD for read cache, 1 for active torrents and docker containers, apps etc., 3 HDD as raid5 and 1 HDD for backup </p> <p>SSD are 2TB each HHD are 16TB each </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Single-Rich-Bear\"> /u/Single-Rich-Bear </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqr8n7/best_setup_4bay_hdd_2_ssd_nas/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kqr8n7/best_setup_4bay_hdd_2_ssd_nas/\">[comments]</a></span>",
        "id": 2721151,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kqr8n7/best_setup_4bay_hdd_2_ssd_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best setup: 4bay HDD +2 SSD NAS",
        "vote": 0
    }
]