[
    {
        "age": null,
        "album": "",
        "author": "/u/Eastern-Idea-5097",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-15T20:53:59.864342+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-15T20:32:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I am currently creating a software that needs to basically go to any IG profile, scrape post links and then download the content. after multiple days of debugging I have everything working accept I haven&#39;t been able to get around the following error: JSON Query to graphql/query: 401 Unauthorized - &quot;fail&quot; status, message &quot;Please wait a few minutes before you try again.&quot;</p> <p>I just set up residential proxies through Brightspace which seemed to work a little better but it seems to now maybe shadow ban the account itself?</p> <p>Should I just get a bunch of accounts and maybe try to limit the requests as much as possible? I am currently using 8 different accounts, although originally they were all on the same IP address which might be a big reason why this is happening. should I just make a bunch of new accounts or maybe even if I can buy a bunch online? Any advice would be appreciated.</p> </div><!-- SC_ON --> &#3",
        "id": 2690446,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1knil5v/ig_content_scraping_getting_graphqlquery_401",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "IG content scraping (getting graphql/query 401 errors)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/No_Mam_Sam",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-15T15:29:11.255208+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-15T15:10:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi Friends,</p> <p>There are numerous sites that list Medical practices and specialties. I want to compile a list of Doctors (name, practice, address, etc) from these sites.</p> <p>I&#39;m not looking for anything &#39;Medical Sensitive&#39; that would violate HIPAA laws,... just want to have a contact list of Doctor offices, and whatever information they list on sites like &#39;healthgrades, Healthline, etc.&#39;</p> <p>I want doctors who are actively promoting their practices (not just a list that I can get from a list company or state gov.).</p> <p>* What&#39;s the easiest way to achieve this task?</p> <p>Thanks very much!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No_Mam_Sam\"> /u/No_Mam_Sam </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1knanab/compiling_a_list_of_doctors_how_difficult_would/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1k",
        "id": 2687513,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1knanab/compiling_a_list_of_doctors_how_difficult_would",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Compiling a list of Doctors --- How difficult would this be?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/hafi51",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-15T12:14:08.528258+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-15T11:13:55+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1kn5kfg/solving_captcha/\"> <img src=\"https://a.thumbs.redditmedia.com/_LdqOgmuicxNnPX5fJdgrZb0pY2BK2kfw3xuuajfsc8.jpg\" alt=\"solving captcha\" title=\"solving captcha\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>i&#39;m automating task on website(checking for appointment) and i need to solve or bypass this captcha. sometime they are hard to spot like 1st block. is there any reliable api for this?<br/> i know it&#39;s webscraping sub but since you guys probably deal with captcha more than anyone else, kindly help me out. </p> <p><a href=\"https://preview.redd.it/3k1pi2cfix0f1.png?width=419&amp;format=png&amp;auto=webp&amp;s=3830139c7b8368263ca9d00b8a207cd936ac4c4f\">https://preview.redd.it/3k1pi2cfix0f1.png?width=419&amp;format=png&amp;auto=webp&amp;s=3830139c7b8368263ca9d00b8a207cd936ac4c4f</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hafi51\"> /u/hafi51 </a> <br/> <",
        "id": 2685715,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kn5kfg/solving_captcha",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/_LdqOgmuicxNnPX5fJdgrZb0pY2BK2kfw3xuuajfsc8.jpg",
        "title": "solving captcha",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/danielecr",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-15T11:10:03.598100+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-15T10:18:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I wanna share this code for scraping data from html page. Initially the feature list included to grab data from web with guzzle, but that part was moved in another class. It is old code staling from 2016, it is PHP, and maybe of some use for someone.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/danielecr\"> /u/danielecr </a> <br/> <span><a href=\"https://smartango.com/2025/05/scraping-html-page-by-dom-and-xpath/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kn4ovi/scraping_html_page_by_dom_and_xpath/\">[comments]</a></span>",
        "id": 2685254,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kn4ovi/scraping_html_page_by_dom_and_xpath",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping HTML page by DOM and XPath",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ok-Ship812",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-15T10:04:04.252399+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-15T08:59:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Up to now my scraping needs have been very focussed, specific sites, known links, known selectors and/or APIs.</p> <p>Now I need to build a process that</p> <ol> <li>Takes a URL from a DB of about 5,000 online casino sites</li> <li>Searches for specific product links on the site</li> <li>Follows those links</li> <li>Captures the target info</li> </ol> <p>I&#39;m leaning towards using a Playwright / Python code base using Camoufox (and residential proxies).<br/> For the initial pass though the site I look for the relevent links, then pass the DOM to a LLM to search for the target content and then record the target selectors in a JSON file for a later scraping process to utilise. I have the processing power to do all this locally without LLM API costs.</p> <p>Ideally the daily scraping process will have uniform JSON input and output regardless of the layout and selectors of the site in question.</p> <p>I&#39;ve been playing with different ideas and solu",
        "id": 2684749,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kn3jjd/5000_sites_to_scrape_daily_wondering_about_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "5000+ sites to scrape daily. Wondering about the tools to use.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Odd-Ad-5096",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-15T06:48:55.117159+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-15T06:37:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey folks,</p> <p>just wanted to share a small update for those interested in web scraping and automation around real estate data.</p> <p>I&#39;m the maintainer of <a href=\"https://github.com/orangecoding/fredy\">Fredy</a>, an open-source tool that helps monitor real estate portals and automate searches. Until now, it mainly supported platforms like Kleinanzeigen, Immowelt, Immonet and alike.</p> <p>Recently, we\u2019ve reverse engineered the <strong>mobile API of ImmoScout24</strong> (Germany&#39;s biggest real estate portal). Unlike their website, the mobile API is not protected by bot detection tools like Cloudflare or Akamai. The mobile app communicates via JSON over HTTPS, which made it possible to integrate cleanly into Fredy.</p> <p>What can you do with it?</p> <ul> <li>Run automated searches on ImmoScout24 (geo-coordinates, radius search, filters, etc.)</li> <li>Parse clean JSON results without HTML scraping hacks</li> <li>Combine it with alerts, au",
        "id": 2683784,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kn1jod/reverse_engineered_immoscouts_mobile_api_to_avoid",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Reverse engineered Immoscout's mobile API to avoid bot detection",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/External_Ask_5867",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-15T07:53:53.280901+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-15T05:38:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m new to this space and am mostly interested in finding ways to monitor news content (from media, companies, regulators, etc.) from sites that don&#39;t offer native RSS.</p> <p>I assumed that this will involve scraping techniques, but I have also come across feed generation systems such as <a href=\"http://morss.it\">morss.it</a>, RSSHub that claim to convert anything into an RSS feed.</p> <p>How should I think about the merits of one approach vs. the other?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/External_Ask_5867\"> /u/External_Ask_5867 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kn0n6w/web_scraping_vs_feed_generators/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kn0n6w/web_scraping_vs_feed_generators/\">[comments]</a></span>",
        "id": 2684048,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kn0n6w/web_scraping_vs_feed_generators",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Web scraping vs. feed generators",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheWigglerSpot",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-15T02:29:49.479343+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-15T01:44:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I just want to scrape a <a href=\"http://debank.com\">debank.com</a> page 1x a day and save it as a pdf. Standard Curl won&#39;t work bc the page requires JS - I tried Scrapingninja but the setup is convulted imo. I realize I can write this in python and self host it but would rather just use a service that can grab it 1x a day and save as a pdf.</p> <p>I know this there are alot of different ways to solve this - but would prefer to use a scraping service somehow.</p> <p>thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheWigglerSpot\"> /u/TheWigglerSpot </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kmwgsz/simple_scraping_project_best_service/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kmwgsz/simple_scraping_project_best_service/\">[comments]</a></span>",
        "id": 2682743,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kmwgsz/simple_scraping_project_best_service",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Simple scraping project - best service?",
        "vote": 0
    }
]