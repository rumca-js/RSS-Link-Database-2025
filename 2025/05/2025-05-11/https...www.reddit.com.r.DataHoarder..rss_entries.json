[
    {
        "age": null,
        "album": "",
        "author": "/u/erdenflamme",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T23:29:06.977507+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T23:09:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I went the MiniPC route with a Beelink MiniS13 Pro for the server and a TerraMaster D430 for storage. For disks I have an 8TB WD White on hand, and am looking at buying 3x8TB WD Red or Blue drives to fill the DAS. </p> <p>On the software side I&#39;m planning to use mergerFS + SnapRAID. Then I&#39;ll use NFS to make it accessible on my network.</p> <p>Is there anything obviously wrong with this plan, or something I ought to change before the money leaves my pocket? Maybe it&#39;s overkill, but I&#39;m firmly on team prefer to have it and not need it. My main use-case is archiving YouTube channels and torrenting.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/erdenflamme\"> /u/erdenflamme </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kke04q/is_this_a_good_setup_das_minipc/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kke04q/is_this_a_good_setup_d",
        "id": 2654583,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kke04q/is_this_a_good_setup_das_minipc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is this a good setup? (DAS + MiniPC)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Competitive_Cake_925",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T23:29:07.247601+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T22:53:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, first time posting here. I have lots of data I&#39;ve saved over the years that has been eating away my storage, and with switching PCs and USBs, lots of them have duplicated. Since I don&#39;t have that much time to go through every folder and file to check for duplicates, especially with photos, and my memory is getting slowly critical, I am considering compressing files into some format until I either find time to go through all files, or until I get myself another bigger drive to unpack those files. I don&#39;t need to pack all files, just enough to be comfortable for some time.</p> <p>I&#39;ve read a few posts here but those were relatively case specific, and in all of them the verdict was to avoid compressing. I don&#39;t mind compressing files and maybe backing them up on cloud or something, I just don&#39;t want to delete a folder, and then when I&#39;ll be unpacking those files I encounter some kind of failure which would result in stu",
        "id": 2654584,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkdo8l/compressing_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Compressing files",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/gottago_gottago",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T22:25:39.630609+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T22:13:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>LLMs are ruining everything. Their aggressive crawling is causing more and more sites to put up captchas or use things like <a href=\"https://anubis.techaro.lol/\">Anubis</a>. Understandable.</p> <p>But, this also means that archive.today and other web archiving services are increasingly getting stuck or unable to archive particular pages. (I&#39;m currently unable to submit StackOverflow pages to archive.today, for example.)</p> <p>I&#39;d like to get an archive.today-style &quot;snapshot&quot; of a page, but using a tool that&#39;s integrated into my browser, so I can handle any captchas and block popup elements and other nonsense.</p> <p>I found <a href=\"https://github.com/danny0838/webscrapbook\">https://github.com/danny0838/webscrapbook</a>. Anybody here have other recommendations?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/gottago_gottago\"> /u/gottago_gottago </a> <br/> <span><a href=\"https://www.reddit.c",
        "id": 2654341,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkcvgd/recommendations_for_a_firefox_extension_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Recommendations for a Firefox extension for archiving pages locally?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Orii21",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T22:25:39.849547+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T21:44:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve bought this <a href=\"https://www.amazon.es/gp/product/B0BLFDRWN3?smid=A3DXORUL1A74U\">HC560</a> drive on amazon.es from &quot;Digital Emporium GmbH&quot;. What happend is that I purchased the WUH722020BLE6L4/0F38785 model but they sent the WUH722020ALE6L4/0F38755 model instead which is, acording to the <a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/data-center-drives/ultrastar-dc-hc500-series/data-sheet-ultrastar-dc-hc560.pdf\">datasheet</a>, the previous generation model.</p> <p>The only difference I see on the datasheet is that the second generation has faster random write speeds, matching them to the SAS models.</p> <p>Here&#39;s <a href=\"https://imgur.com/a/wd-dc-hc560-yjWk834\">images</a> (imgur.com) of the drive which I haven&#39;t unsealed yet. What are your insights about the generations of these WD disks? Do you think I should ask the seller for a solution or forget abou",
        "id": 2654342,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkc8so/hgst_wd_ultrastar_dc_hc560_its_worth_returning_it",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "HGST WD Ultrastar DC HC560. It's worth returning it?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GlacialFire",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T21:19:57.375228+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T20:57:41+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkb6l2/bought_seagate_expansion_off_seagates_estore_came/\"> <img src=\"https://external-preview.redd.it/COCNK7BBo6Vi4z_pwRedbuKvKdALNoQJS2CmmispRKY.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=08308395031f9f9fe7343eeb3578bc45f6362628\" alt=\"Bought Seagate Expansion off Seagate\u2019s estore. Came in a brown envelop with no protection. Return?\" title=\"Bought Seagate Expansion off Seagate\u2019s estore. Came in a brown envelop with no protection. Return?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I saw the deal on this subreddit about the expansion hard drives and ordered one off Seagates own e-commerce store. </p> <p>It came in a brown envelop with 0 protection, and a hole in the envelope. Just the retail box inside. I haven\u2019t opened the box yet. </p> <p>I should return this and demand a new one right? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GlacialFire\"> /u/Glaci",
        "id": 2654074,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkb6l2/bought_seagate_expansion_off_seagates_estore_came",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/COCNK7BBo6Vi4z_pwRedbuKvKdALNoQJS2CmmispRKY.jpeg?width=640&crop=smart&auto=webp&s=08308395031f9f9fe7343eeb3578bc45f6362628",
        "title": "Bought Seagate Expansion off Seagate\u2019s estore. Came in a brown envelop with no protection. Return?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/epictoyseries02",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T21:19:56.819827+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T20:23:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to extract menus from a DVD/Blu-ray on my Mac so I can import them into an Adobe Encore project (which I&#39;m running through a virtual machine). What methods/software would you recommend for this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/epictoyseries02\"> /u/epictoyseries02 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkaehv/help_extracting_dvdbluray_menus_on_mac/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kkaehv/help_extracting_dvdbluray_menus_on_mac/\">[comments]</a></span>",
        "id": 2654072,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kkaehv/help_extracting_dvdbluray_menus_on_mac",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help Extracting DVD/Blu-ray Menus on Mac",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SomeDudeWithFailures",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T20:12:28.786043+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T19:26:38+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk93jw/is_it_weird_to_have_this_much_storage_in_my_phone/\"> <img src=\"https://preview.redd.it/4u0si3dye70f1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8020557abcf684bc7ef3b57aa3c9ef2877504f87\" alt=\"Is it weird to have this much storage in my phone?\" title=\"Is it weird to have this much storage in my phone?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>In total of almost 2tb </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SomeDudeWithFailures\"> /u/SomeDudeWithFailures </a> <br/> <span><a href=\"https://i.redd.it/4u0si3dye70f1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk93jw/is_it_weird_to_have_this_much_storage_in_my_phone/\">[comments]</a></span> </td></tr></table>",
        "id": 2653768,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kk93jw/is_it_weird_to_have_this_much_storage_in_my_phone",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/4u0si3dye70f1.jpeg?width=640&crop=smart&auto=webp&s=8020557abcf684bc7ef3b57aa3c9ef2877504f87",
        "title": "Is it weird to have this much storage in my phone?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/slvrvlt",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T19:02:18.869542+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T18:23:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Where do you go to find used cheap computer cases that can hold multiple drives? Not looking to spend too much on one. Tried Craigslist and offer up on my area. Mad at myself for getting rid of my old gaming pc case that had multiple hdd drive mounts. Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/slvrvlt\"> /u/slvrvlt </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk7mow/cheap_case/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk7mow/cheap_case/\">[comments]</a></span>",
        "id": 2653399,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kk7mow/cheap_case",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cheap case",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Alarmed_Rabbit_494",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T19:02:19.089811+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T18:08:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, So one of my favorite websites lets you backup chats as an html file. Problem is in the html file you have to click on each individually meaning command+f doesn&#39;t work to find what i need. Does anyone know of any good applications/ways to full text search an html file? There is at least a years worth of very long chats so looking individually is super time consuming.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Alarmed_Rabbit_494\"> /u/Alarmed_Rabbit_494 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk7b09/anyone_know_a_way_to_full_text_search_an_html_file/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk7b09/anyone_know_a_way_to_full_text_search_an_html_file/\">[comments]</a></span>",
        "id": 2653400,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kk7b09/anyone_know_a_way_to_full_text_search_an_html_file",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone know a way to full text search an html file?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SportPotential6860",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T21:19:56.601067+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T17:06:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi to everyone.</p> <p>I&#39;m a long time lurker with a throwaway account and a wall of text off my chest.</p> <p>Sorry for that and thank you if you read it.</p> <p>I&#39;m having this feelings since long time ago, but I&#39;m kinda stuck in a loop.</p> <p>I love hoarding. I grew up with the born of the internet (newsgroups, IRC, Napster, Kazaa, eDonkey...) I&#39;m one of those kids. The ability of having anything you wanted, for free, was amazing.</p> <p>I&#39;ve been downloading since then, and almost 20 years later I still have that domapine rush whenever I found something to download (examples overexaggerated, but you&#39;ll get the point)</p> <ul> <li>That obscure game from the mid 90s you used to sneak with your friends in those hot floppy disks? Check.</li> <li>The latest BDREMUX-8K-AI-UPSCALED-DOLBY-ATMOS-DOLBY-VISION edition of that movie you&#39;ve seen hundreds of times since it was released in VHS? Check</li> <li>The latest GOTY-REPACK-A",
        "id": 2654071,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kk5ucv/datahoarding_is_making_my_life_miserable",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Datahoarding is making my life miserable",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/JordanFilmmaker",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T21:19:57.009338+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T16:56:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking to see if there is a dual slot NVME enclosure that I can put two 8 TB nvme drives into for a total of 16 TB that would be good for editing (1250 mb/s)</p> <p>Anyone have recommendations?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JordanFilmmaker\"> /u/JordanFilmmaker </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk5m7x/dual_slot_nvme_drive_ssd_enclosure/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk5m7x/dual_slot_nvme_drive_ssd_enclosure/\">[comments]</a></span>",
        "id": 2654073,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kk5m7x/dual_slot_nvme_drive_ssd_enclosure",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dual slot NVME drive ssd enclosure",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Gestalternative",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T15:47:32.430230+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T15:41:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Deal is pretty good but I would hope i get it due to box damage and not returns</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Gestalternative\"> /u/Gestalternative </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk3x9i/is_buying_used_like_new_terabyte_hard_drives_not/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk3x9i/is_buying_used_like_new_terabyte_hard_drives_not/\">[comments]</a></span>",
        "id": 2652339,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kk3x9i/is_buying_used_like_new_terabyte_hard_drives_not",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is buying used - Like New terabyte hard drives not ideal from Amazon Resale?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/nachoha",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T15:47:32.623779+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T14:57:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a collection of VR videos that have duplicate video on the right and the left, and the use the sort of fish eye lens (Not sure the exact term for the lens they use). I can convert the ones that only have the duplicate right and left, but I can&#39;t find any program that can correct for the lens effect.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nachoha\"> /u/nachoha </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk2xlj/im_looking_for_a_video_editor_that_will_convert/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk2xlj/im_looking_for_a_video_editor_that_will_convert/\">[comments]</a></span>",
        "id": 2652340,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kk2xlj/im_looking_for_a_video_editor_that_will_convert",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I'm looking for a video editor that will convert VR video to a standard video. Any ideas?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Purple-Notice5773",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T14:42:18.034008+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T14:29:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello!<br/> I am looking for a robust backup for imporotant files (1-2 TB). And when looking for an external HD I stumbeled across a 2 TB SanDisk Extreme PRO microSDXC. My gut feeling is that sauch an SD card must be extremly robust. More robust than, say, the SanDisk Creator Pro Portable SSD 2 TB I was contemplating. </p> <p>Granted, I guess the SD card is very slow. But in an ideal world I will only have it to use once a year to add new file and perferabyl never to resotre any files. </p> <p>Is there any downside I don&#39;t see?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Purple-Notice5773\"> /u/Purple-Notice5773 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk2bl7/backing_up_important_files_what_about_sandisk/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kk2bl7/backing_up_important_files_what_about_sandisk/\">[comments]</a></span>",
        "id": 2652021,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kk2bl7/backing_up_important_files_what_about_sandisk",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "backing up important files: what about SanDisk Extreme PRO microSDXC",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AlfredDaGreat25",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T12:31:03.016311+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T12:16:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Finally got <a href=\"https://www.seagate.com/products/external-hard-drives/expansion-desktop-hard-drive/?sku=STKP6000400\">two 18TB Seagate Expansion</a> external drives just to backup/hoard stuff. Bought them straight from Seagate with a 10% sign-up discount. I think it was a decent price.</p> <p>I was planning to buy re-certified drives on eBay and put them in enclosures but couldn&#39;t find a deal I liked.</p> <p>Anyways my question is what to do with all those 2.5 portable hard drives I&#39;ve been using for backup? Any creative suggestions? </p> <p>2TB x 4<br/> 4TB x 4<br/> 5TB x 2</p> <p>Yup, I was caught up with the fascination of how these small drives can hold so much data and bought whenever they were are on sale. Using a 2TB SSD to do current work on so won&#39;t be needing these. I guess I&#39;ll try to sell or give them away to family and friends. :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Al",
        "id": 2651287,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjzobs/two_many_portable_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Two many portable drives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/FailedCriticalSystem",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T12:31:03.204373+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T12:10:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m going on a flight tomorrow and I have a subscription to pilot institute. I can download the videos via video download helper but it&#39;s one at a time. There are like 200 videos each topic being just a few minutes long. Is there any way to make a bulk download? The website looks like it&#39;s a teachable website (not sure if that helps) Anything i can do without clicking download 200 times. Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/FailedCriticalSystem\"> /u/FailedCriticalSystem </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjzkje/downloading_website_with_videos/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjzkje/downloading_website_with_videos/\">[comments]</a></span>",
        "id": 2651288,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjzkje/downloading_website_with_videos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Downloading website with videos?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/OrneryWhelpfruit",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T12:31:02.711757+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T11:50:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>see above. thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/OrneryWhelpfruit\"> /u/OrneryWhelpfruit </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjz7xm/whats_the_best_way_to_make_sure_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjz7xm/whats_the_best_way_to_make_sure_a/\">[comments]</a></span>",
        "id": 2651286,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjz7xm/whats_the_best_way_to_make_sure_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "what's the best way to make sure a recertified/renewed white label drive isn't SMR?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/blackmalt",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T10:10:15.416363+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T09:47:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m planning to purchase a 20TB drive to back up my PCs, laptops, and other data. I already have a fanless mini PC (ASRock N100DC-ITX) that can host the drive. I also have an HTPC that can hold up to six SATA drives. I have a collection of old drives totaling about 10TB, which I plan to use as a secondary backup for my most important files. I&#39;m considering using Windows Storage Spaces to unify them under a single path to simplify the backup setup.</p> <p>Does this sound like a reasonable plan?</p> <p>I&#39;m also debating between the Seagate Exos X20 20TB and the BarraCuda 24TB. They\u2019re similarly priced, and I don\u2019t plan to use the drive for anything other than backups. Which would be the better choice for my needs?</p> <p>Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/blackmalt\"> /u/blackmalt </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjxcfg/primary_backu",
        "id": 2650718,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjxcfg/primary_backup_with_a_new_20tb_drive_secondary",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Primary Backup with a new 20TB drive + Secondary Backup using old drives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Federal-Dot-8411",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T10:10:15.605692+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T09:21:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have two Seagate 3.5&quot; HDDs, which I will connect using their SATA-to-USB adapter, which already has a slot to connect the hard drives to their own power supply. </p> <p>The thing is, I want to connect the SATA-to-USB adapter to a Powered USB HUB, meaning to a 5V active USB HUB, while the power supply for each hard drive is 12V. </p> <p>Will this cause any issues, could the circuits be damaged, or could there be an electrical failure?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Federal-Dot-8411\"> /u/Federal-Dot-8411 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjwyvs/will_a_powered_usb_hub_damage_35_powered_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjwyvs/will_a_powered_usb_hub_damage_35_powered_drives/\">[comments]</a></span>",
        "id": 2650719,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjwyvs/will_a_powered_usb_hub_damage_35_powered_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Will a Powered USB Hub damage 3.5 powered drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LastOfTheClanMcDuck",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T16:52:19.314625+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T06:21:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m in a pretty anxiety inducing situation for a job and hoped you people might have some tips tricks, or at least pray for me i guess.</p> <p>I&#39;ll be working on a film and i&#39;ll have to do 2 backups on 2 separate Areca RAID 0 arrays with 4 HDD drives each. To be clear this was not my choice, i actually <em>heavily</em> argued about this, and explained fully the insane risk this is for each RAID, but for dumb reasons(=money) there&#39;s no other choice right now.<br/> And yes i explained that it&#39;s far cheaper to buy new gear than to reshoot a film lol. They didn&#39;t even get a third backup solution (yet?)</p> <p>Is there ANYTHING i can do to at least minimize the risk, even by a fraction of a percent?<br/> Should i keep the drives spinning all day at every shoot (roughly 10h/day) or shut the raid off after every transfer?<br/> If one of the RAIDs fail should i just rebuilt it ASAP and then backup from the other RAID 0 and hope for the",
        "id": 2652694,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjue7m/raid_0_survivability_backup_tips_or_prayers_for_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "RAID 0 survivability backup tips (or prayers) for a job",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/snovvman",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T06:55:14.939584+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T06:17:53+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/snovvman\"> /u/snovvman </a> <br/> <span><a href=\"/r/selfhosted/comments/1kjub81/photosync_is_it_capable_of_bidirectional_sync/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjuc1a/photosync_is_it_capable_of_bidirectional_sync/\">[comments]</a></span>",
        "id": 2650059,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjuc1a/photosync_is_it_capable_of_bidirectional_sync",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Photosync: is it capable of bidirectional sync?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MicrosoftExcel2016",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T04:45:12.194991+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T04:19:19+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjsif5/noaa_ending_its_billiondollar_disasters_database/\"> <img src=\"https://external-preview.redd.it/QUUIhpoVbr0tHsH60MNs4-8rUcDjKzIlDbhNxKtkKP8.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e29cdb32e214904b8d817c89b3ba0b0546effa4a\" alt=\"NOAA ending its &quot;billion-dollar disasters&quot; database\" title=\"NOAA ending its &quot;billion-dollar disasters&quot; database\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>It&#39;s a shame to see hard work building a database go to waste. I thought some here might appreciate or even be interested in saving what can be saved. I believe the events tab has some downloadable (CSV, JSON, PDF) data. [Link to NOAA tool](<a href=\"https://www.ncei.noaa.gov/access/billions/\">https://www.ncei.noaa.gov/access/billions/</a>)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MicrosoftExcel2016\"> /u/MicrosoftExcel2016 </a> <br/> <span><a hr",
        "id": 2649706,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjsif5/noaa_ending_its_billiondollar_disasters_database",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/QUUIhpoVbr0tHsH60MNs4-8rUcDjKzIlDbhNxKtkKP8.jpeg?width=640&crop=smart&auto=webp&s=e29cdb32e214904b8d817c89b3ba0b0546effa4a",
        "title": "NOAA ending its \"billion-dollar disasters\" database",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/faizikari555",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T04:45:12.587497+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T04:05:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all. It&#39;s been years that I haven&#39;t involves myself into encoding and ripping scene. </p> <p>I&#39;m just wondering, consider DVD Decrypter is dead for long time now, is there better software to extract DVD-ISO to VOB according to its chapter? </p> <p>I&#39;m used to use DVD Decrypter back in the days, and I use it to extract DVD-ISO of a music video collection and save it as VOB video of the individual music video for easier playback.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/faizikari555\"> /u/faizikari555 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjsa79/extract_dvdiso_to_vob_according_to_chapter_\u00e1_la/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjsa79/extract_dvdiso_to_vob_according_to_chapter_\u00e1_la/\">[comments]</a></span>",
        "id": 2649707,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjsa79/extract_dvdiso_to_vob_according_to_chapter_\u00e1_la",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Extract DVD-ISO to VOB according to chapter \u00e1 la DVD Decrypter",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BigFlubba",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T04:45:12.791854+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T03:49:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a library of VR videos with varying file properties (resolution, codecs, bitrates, camera types, &amp; more), and I have been running into playback issues with some 8K files, and I need to transcode them to a more manageable file type and resolution. How can I do this? Is there a way I can do this in a batch automatically?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BigFlubba\"> /u/BigFlubba </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjs01m/transcoding_vr_video/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjs01m/transcoding_vr_video/\">[comments]</a></span>",
        "id": 2649708,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjs01m/transcoding_vr_video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Transcoding VR Video",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheUnknownOne315",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T04:45:13.196977+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T03:45:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys,<br/> M discs are supposed to keep data for centuries, but in a scenario where we no longer have access to purchasing technological products (computers, etc), how do we read that data? The issue is that if your PC&#39;s SSD or HDD fails and you can&#39;t replace it, keeping a spare SSD or HDD for potential failure doesn\u2019t seem viable, as they wear out even if they\u2019re not used. The data is still there on the M discs, but you won\u2019t be able to access it. Have you thought of any solutions for this kind of situation?</p> <p>So far, I\u2019ve archived hoping to always have access to my data even after a global collapse. I do think data preservation is indeed possible, but I\u2019m now realizing that access probably isn\u2019t. I kind of feel stuck.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheUnknownOne315\"> /u/TheUnknownOne315 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjrxem/we_can_save_d",
        "id": 2649709,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjrxem/we_can_save_data_for_centuries_with_m_discs_but",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "We can save data for centuries with M discs, but...",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jabcreations",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T03:40:13.852171+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T02:57:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I download everything because there evil people who like retracting things that help others. Case in point: a guy posted a video...in a Facebook comment ...on his own video. I checked his video list and it&#39;s not in there, lame.</p> <p>On this page:</p> <p><a href=\"https://www.facebook.com/watch/?v=1462397605169872\">https://www.facebook.com/watch/?v=1462397605169872</a></p> <p>In a comment by &quot;John G Bego&quot; with the text &quot;Another great example \u2026&quot; is a video source I want to download.</p> <p>The video details:</p> <p><code>blob:https://www.facebook.com/7c50854b-0533-4f78-adde-58f634e25c32</code></p> <p><a href=\"https://video-lax3-2.xx.fbcdn.net/o1/v/t2/f2/m366/AQMU0Ao7LC293XZsDBvu9s5ngryEpEFDpV5nnilYJv61Pb573R1hbdNWEoYgmOewdbY7A0GUPB6x6TgFuUUV8s17lRrVqwbm3WNS_to.mp4\">https://video-lax3-2.xx.fbcdn.net/o1/v/t2/f2/m366/AQMU0Ao7LC293XZsDBvu9s5ngryEpEFDpV5nnilYJv61Pb573R1hbdNWEoYgmOewdbY7A0GUPB6x6TgFuUUV8s17lRrVqwbm3WNS_to.mp4</a></p> ",
        "id": 2649547,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjr49p/how_to_download_a_facebook_comment_video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to download a Facebook comment video?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Desertprep",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T03:40:14.085076+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T02:37:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am studying to be a nurse and have a lot of info that I must consume. Worst part is that I will continue to see it after I take the test on it. I was thinking that a scanning pen with ocr software would be really helpful. I would be able to quickly scan words, sentences and short paragraphs (printed material from text or ebooks) into a program like Anki Cards and then use that app to study. Can anyone recommend a good pen for about $60 that will do this? I don&#39;t need foreign language translation. Using phones to take pics and then crop down is too time consuming.</p> <p>PS It is good to see that there are other data hoarders out there!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Desertprep\"> /u/Desertprep </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjqrob/need_to_scan_words_sentences_for_studies/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/co",
        "id": 2649548,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjqrob/need_to_scan_words_sentences_for_studies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need to scan words & sentences for studies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/-Sofa-King-",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T02:36:47.747437+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T02:13:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m consolidating data from multiple 1TB\u20135TB drives into one large archive drive (which I\u2019ll mirror to another for safety). After years of phone dumps, reformats, and \u201cjust in case\u201d folders, I know there are tons of duplicate files scattered everywhere\u2014some buried so deep I don\u2019t even know what\u2019s down there anymore; prob cobwebs and daddy long legged spiders. Once the master copy finishes, I want to safely find and clean up duplicates without risking anything important. I\u2019m looking at WinMerge, Duplicate Cleaner, and AllDup. Anyone used these? Do they just locate duplicates and let you decide what to delete, or do they assist with the cleanup process? How manual vs. automatic is it? Looking for something thorough but not reckless. Appreciate any input. Or I\u2019ll just lean into it and keep hoarding for another 20 years, lol. My IT friend used to call me a digital packrat.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/u",
        "id": 2649377,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjqcna/cleaning_digital_clutter_best_tool_for_finding",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cleaning Digital Clutter: Best Tool for Finding Duplicates Post-Consolidation",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/No-Intern-6017",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T03:40:13.624589+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T01:01:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve got a Dell 3050 micro running an Ubuntu desktop based server, I want to get a raid enclosure, ideally one that allows smart data to be sent to the host on Linux.</p> <p>Any suggestions?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No-Intern-6017\"> /u/No-Intern-6017 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjp1ym/external_hard_drive_that_supports_smart_pass/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjp1ym/external_hard_drive_that_supports_smart_pass/\">[comments]</a></span>",
        "id": 2649546,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjp1ym/external_hard_drive_that_supports_smart_pass",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "External hard drive that supports Smart pass through and works with Ubuntu?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/philcrumpler",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T01:30:14.632961+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T00:50:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>As the title suggests, what&#39;s the best &#39;lossy&#39; codec for music storage locally? I&#39;m finally starting to tidy and update my digital music collection which (shamefully) is pretty random levels of MP3. </p> <p>Most of the albums I can easily re-rip, but I definitely don&#39;t have the space for over 15,000 and counting tracks in .flac, my more recent rips have been highest possible VBR MP3, but I&#39;m now wondering if AAC would be a better option?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/philcrumpler\"> /u/philcrumpler </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjov59/best_lossy_codec_for_personal_music_library/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjov59/best_lossy_codec_for_personal_music_library/\">[comments]</a></span>",
        "id": 2649231,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjov59/best_lossy_codec_for_personal_music_library",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best 'lossy' codec for personal music library?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Lanky-Landscape-844",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T01:30:14.852168+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T00:28:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I am looking to purchase 2 HDD of around 10 terabytes for redundancy. Are there any recommendations on what to purchase?</p> <p>Thank you</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lanky-Landscape-844\"> /u/Lanky-Landscape-844 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjogqz/purchasing_hdds/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjogqz/purchasing_hdds/\">[comments]</a></span>",
        "id": 2649232,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjogqz/purchasing_hdds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Purchasing HDDs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CarelessAstronaut391",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-11T00:25:17.220505+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-11T00:24:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m having trouble finding my data on an SSD that I removed from an Acer 713 Chromebook whose motherboard has died. This is the first time I have tried something like this. As you can see in the attached screenshots, the enclosure recognizes the SSD but none of the folders show me where the data is. It&#39;s a 128GB SSD and if you look at the bottom of one of the photos you can see it says 44.3 GB free space and 11.7 free space on another photo. That matches up to how much data I think is left on the SSD. So it must be somewhere. Any suggestions?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CarelessAstronaut391\"> /u/CarelessAstronaut391 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1kjoebe\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kjoebe/ssd_enclosure_not_showing_data/\">[comments]</a></span>",
        "id": 2649069,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kjoebe/ssd_enclosure_not_showing_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SSD Enclosure Not Showing Data",
        "vote": 0
    }
]