[
    {
        "age": null,
        "album": "",
        "author": "/u/Background_Link_2537",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T19:39:41.310622+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T18:01:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all<br/> I am struggling with this website for scraping and wanted to see if anyone has had any success with this website. If so, what volume per day or per minute are you trying?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Background_Link_2537\"> /u/Background_Link_2537 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kwu45n/has_anyone_had_success_with_scraping_shopeetw_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kwu45n/has_anyone_had_success_with_scraping_shopeetw_for/\">[comments]</a></span>",
        "id": 2783265,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwu45n/has_anyone_had_success_with_scraping_shopeetw_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Has anyone had success with scraping Shopee.tw for high volumes",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jpjacobpadilla",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T17:28:48.951522+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T17:27:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>Just released <a href=\"https://github.com/jpjacobpadilla/SearchAI\">SearchAI</a>, a tool to search the web and turn the results into well formatted Markdown or JSON for LLMs. It can also be used for &quot;Google Dorking&quot; since I added about 20 built-in filters that can be used to narrow down searches!</p> <h1>Features</h1> <ul> <li>Search Google with 20+ powerful filters</li> <li>Get results in LLM-optimized Markdown and JSON formats</li> <li>Built-in support for asyncio, proxies, regional targeting, and more!</li> </ul> <h1>Target Audience</h1> <p>There are two types of people who could benefit from this package:</p> <ol> <li>Developers who want to easily search Google with lots of filters (Google Dorking)</li> <li>Developers who want to get search results, extract the content from the results, and turn it all into clean markdown/JSON for LLMs.</li> </ol> <h1>Comparison</h1> <p>There are a lot of other Google Search packages ",
        "id": 2779656,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwt8x7/searchai_scrape_google_with_20_filters_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SearchAI: Scrape Google with 20+ Filters and JSON/Markdown Outputs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Kris_Krispy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T17:28:49.100455+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T14:34:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><h1>NEVERMIND IM AN IDIOT</h1> <h1>MAKE SURE YOUR SCRAPY allowed_domains PARAMETER ALLOWS INTERNATIONAL SUBDOMAINS OF THE SITE. IF YOU&#39;RE SCRAPING <a href=\"http://site.com\">site.com</a> THEN allowed_domains SHOULD EQUAL [&#39;site.com&#39;] NOT [&#39;<a href=\"http://www.site.com&#x27;\">www.site.com&#39;</a>] WHICH RESTRICTS YOU FROM VISITING &#39;no.site.com&#39; OR OTHER COUNTRY PREFIXES</h1> <h1>THIS ERROR HAS CAUSED ME NEARLY 30+ HOURS OF PAIN AAAAAAAAAA</h1> <p>My <em>intended</em> workflow is this:</p> <ol> <li>Spider starts in start_requests, makes a scrapy.Request to the url. callback is parseSearch</li> <li>Middleware reads path, recognizes its a search url, and uses a web driver to load content inside process_request</li> <li>parseSearch reads the request and pulls links from the search results. for every link it does response.follow with the callback being parseJob</li> <li>Middleware reads path, recognizes its a job url, and waits for dyna",
        "id": 2779657,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwotus/confused_about_error_related_to_requests",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Confused about error related to requests & middleware",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/aky71231",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T17:28:48.651282+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T14:31:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Somewhat new to scraping. I know that different platforms can take different amount of time to scrape, but just wondering how you calculate how much you want to charge your clients?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/aky71231\"> /u/aky71231 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kwoqlt/how_much_do_you_charge_your_clients_for_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kwoqlt/how_much_do_you_charge_your_clients_for_scraping/\">[comments]</a></span>",
        "id": 2779654,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwoqlt/how_much_do_you_charge_your_clients_for_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How much do you charge your clients for scraping?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/aky71231",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T17:28:48.800507+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T14:24:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Curious if scraping is like a one time thing for you or do you mostly have to scrape the same platform regularly?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/aky71231\"> /u/aky71231 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kwoks7/how_often_do_you_have_to_scrape_the_same_platform/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kwoks7/how_often_do_you_have_to_scrape_the_same_platform/\">[comments]</a></span>",
        "id": 2779655,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwoks7/how_often_do_you_have_to_scrape_the_same_platform",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How often do you have to scrape the same platform?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/shhhhhhhh179",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T17:28:48.501073+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T13:17:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Been testing automation against a site protected by Akamai Bot Manager. Using residential proxies and undetected_chromedriver. Still getting blocked or hit with sensor checks after a few requests. I&#39;m guessing it&#39;s a combo of fingerprinting, TLS detection, and behavioral flags. Has anyone found a reliable approach that works in 2025? Tools, tweaks, or even just what not to waste time on would help.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/shhhhhhhh179\"> /u/shhhhhhhh179 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kwn0rx/anyone_managed_to_get_around_akamai_lately/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kwn0rx/anyone_managed_to_get_around_akamai_lately/\">[comments]</a></span>",
        "id": 2779653,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwn0rx/anyone_managed_to_get_around_akamai_lately",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone managed to get around Akamai lately",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T17:28:48.350471+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T13:01:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels\u2014whether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>If you&#39;re new to web scraping, make sure to check out the <a href=\"https://webscraping.fyi\">Beginners Guide</a> \ud83c\udf31</p> <p>Commercial products may be mentioned in replies. If you want to promote your own products and services, continue to use the <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">monthly thread</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 2779652,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwmoat/weekly_webscrapers_hiring_faqs_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weekly Webscrapers - Hiring, FAQs, etc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Lazy-Masterpiece8903",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T17:28:49.250245+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T12:25:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I&#39;ve been trying to bypass the security and scrape the sales estimator for Amazon on the Helium10 Site for a couple weeks. <a href=\"https://www.helium10.com/tools/free/amazon-sales-estimator/\">https://www.helium10.com/tools/free/amazon-sales-estimator/</a></p> <p>Selectors:</p> <p>BSR input</p> <p>Price input</p> <p>Marketplace selection</p> <p>Category selection</p> <p>Results extraction</p> <p>I&#39;ve tried Beautifulsoup, Playright &amp; Scrape.do API with no success.</p> <p>I&#39;m brand new to scraping, and I was doing this as a personal project. But I cannot get it to work. You&#39;d think it would be simple, and maybe it would be for more competent scraping experts, but I cannot figure it out.</p> <p>Does anyone have any suggestions maybe you can help?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lazy-Masterpiece8903\"> /u/Lazy-Masterpiece8903 </a> <br/> <span><a href=\"https://www.reddit.com/r/web",
        "id": 2779658,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwlxqy/scraping_amazon_sales_estimator_no_success",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Amazon Sales Estimator No Success",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Hour-Letterhead-8239",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T21:50:19.628585+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T09:36:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Try it here : <a href=\"https://constellix.vercel.app/\">https://constellix.vercel.app/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hour-Letterhead-8239\"> /u/Hour-Letterhead-8239 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kwj2d2/open_sourced_an_ai_scraper_and_mcp_server/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kwj2d2/open_sourced_an_ai_scraper_and_mcp_server/\">[comments]</a></span>",
        "id": 2784174,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwj2d2/open_sourced_an_ai_scraper_and_mcp_server",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Open sourced an AI scraper and mcp server",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/93bx",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T17:28:49.429139+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T08:47:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to scrape a streaming website for the m3u8 by intercepting the requests and fetching the m3u8 links, which is sent when the play button is clicked. The website has a turnstile Captcha which loads the iframe if passed. Otherwise it loads an empty iframe. I&#39;m using puppeteer and I tried all the modified versions and plugins, but still it doesn&#39;t work. Any tips on how to solve this challenge? Note: The captcha is invisible and works in the background, there&#39;s no click the button to verify you&#39;re human. The website url: <a href=\"https://vidsrc.xyz/embed/tv/tt7587890/4-22\">https://vidsrc.xyz/embed/tv/tt7587890/4-22</a> The data to extract: m3u8 links</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/93bx\"> /u/93bx </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1kwid2h/turnstile_captcha_bypass/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscra",
        "id": 2779659,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwid2h/turnstile_captcha_bypass",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Turnstile Captcha bypass",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/New_Needleworker7830",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T17:28:49.608635+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T03:56:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>I just released a new scraping module/library called <strong>ispider</strong>.</p> <p>You can install it with:</p> <pre><code>pip install ispider </code></pre> <p>It can handle thousands of domains and scrape complete websites efficiently.</p> <p>Currently, it tries the <code>httpx</code> engine first and falls back to <code>curl</code> if <code>httpx</code> fails - more engines will be added soon.</p> <p>Scraped data dumps are saved in the output folder, which defaults to <code>~/.ispider</code>.</p> <p>All configurable settings are documented for easy customization.</p> <p>At its best, it has processed up to 30,000 URLs per minute, including deep spidering.</p> <p>The library is still under testing and improvements will continue during my free time. I also have a detailed diagram in <a href=\"http://draw.io\">draw.io</a> explaining how it works, which I plan to publish soon.</p> <p>Logs are saved in a <code>logs</code> folder within the scr",
        "id": 2779660,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwdwnv/new_spider_modulelib",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New spider module/lib",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Mr-Johnny_B_Goode",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T03:01:11.383275+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T02:53:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I\u2019ve been trying to tackle a problem that\u2019s been stumping me. I\u2019m trying to monitor a specific release webpage for new products that randomly come available but in order to access it you must first navigate to the base website and do the age verification.</p> <p>I\u2019m going for speed as competition is high. I don\u2019t know enough about how cookies and headers work but recently had come luck by passing a cookie I used from my own real session that also had an age verification parameter? I know a good bit about python and have my own scraper running in production that leverages an internal api that I was able to find but this page has been a pain.</p> <p>For those curious the base website is <a href=\"http://www.finewinesandgoodspirits.com\">www.finewinesandgoodspirits.com</a> and the release page is <a href=\"http://www.finewineandgoodspirits.com/whiskey-release/whiskey-release\">www.finewineandgoodspirits.com/whiskey-release/whiskey-release</a></p> </di",
        "id": 2778465,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwcs17/scraping_liquor_store_with_age_verification",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping liquor store with age verification",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/tuduun",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-27T03:01:11.533182+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-27T02:29:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><pre><code> &quot;frame_index&quot;: 0, &quot;form_index&quot;: 0, &quot;metadata&quot;: { &quot;form_index&quot;: 0, &quot;is_visible&quot;: true, &quot;has_enabled_submit&quot;: true, &quot;submit_type&quot;: &quot;submit&quot;, &quot;frame_index&quot;: 1, &quot;form_index&quot;: 0, &quot;metadata&quot;: { &quot;form_index&quot;: 0, &quot;is_visible&quot;: true, &quot;has_enabled_submit&quot;: true, &quot;submit_type&quot;: &quot;submit&quot;, </code></pre> <p>Hi, I am creating a headless playwright script that fills out forms. It did pull the forms but some websites have multiple forms and I don&#39;t know which one is the one the user sees. I used form.is_visible() and button.is_visible(), but even it was not enough to identify the real form from the fake one. However, the only diffrerence was the iframe_index. So how can one successfully identify the field the user is seeing or is on the screen? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a ",
        "id": 2778466,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1kwcbj5/identify_hiddendecoy_forms",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Identify Hidden/Decoy Forms",
        "vote": 0
    }
]