[
    {
        "age": null,
        "album": "",
        "author": "/u/Regular_Aspect_2191",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-23T22:57:27.707960+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-23T22:48:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><ol> <li>And lets say I got a new laptop, I install docker and how do I run my docker then? since there is no file on my new laptop. </li> <li>And If I write Cron job where It will call a funtion let&#39;s say function &quot;NotifyMe&quot; every friday , can docker do that when my pc is off?</li> <li>I read about docker image/container, Can I just throw my container to Cloud? like AWS ? So I can create container for Staging and for production?</li> <li>When should I use K8S then? I heard its a cheat code for Docker</li> <li>Is it hard to do all this is 8 hours enough? I know how Bubble sort DSA works, I&#39;m still CS student ,if it matters</li> </ol> <p>I&#39;m still new learning docker</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Regular_Aspect_2191\"> /u/Regular_Aspect_2191 </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1ktwv37/can_u_use_docker_to_install_mssql_or_postgressql/\">[link]</a></s",
        "id": 2758398,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ktwv37/can_u_use_docker_to_install_mssql_or_postgressql",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can u use docker to install MSSQL or postgressql, and install my ToDoList . And once install , I can just type like localhost:300 and it show my website on my pc? without using VS code?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/More_Share5042",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-23T22:57:27.945471+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-23T22:02:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to install Docker on my D: drive, as my C: drive only has 128 GB of storage. If I install Docker (with VirtualBox) on my D: drive, can I still use the D: drive to store other personal and project files without conflicting with VirtualBox&#39;s operation?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/More_Share5042\"> /u/More_Share5042 </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1ktvvep/want_to_install_docker_in_d_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1ktvvep/want_to_install_docker_in_d_drive/\">[comments]</a></span>",
        "id": 2758399,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ktvvep/want_to_install_docker_in_d_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Want to install docker in D drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Human133",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-23T19:16:00.290462+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-23T18:41:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have set up a few apps behind caddy as reverse proxy for remote access (all in docker in synology NAS). The logs always show ip address of the caddy network gateway See below more information and things I tried. I&#39;ll use jellyfin as example.</p> <ul> <li>I use cloudflare domain and dns records set to dns only.</li> <li>I have all apps reversed proxied by caddy in the same caddy custom network (e.g. 172.20.0.0/24)</li> <li><p>In caddyfile I use container name and port instead of local ip address (tried both). For example</p> <pre><code>jellyfin.domain.com { reverse_proxy jellyfin:8096 } </code></pre></li> <li><p>I added caddy container name, ip address, gateway ip address, subnet, local host ip address in the trusted proxies field in jellyfin. </p></li> <li><p>I manually passed X-forwarded headers in caddyfile with {remote_host} (this gives caddy network gateway ip) and {remote_ip} (gives caddy container ip)</p></li> <li><p>I run whoami container",
        "id": 2756987,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ktr691/struggling_with_services_behind_caddy_not_showing",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Struggling with services behind caddy not showing real ip address",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BlindTreeFrog",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-23T19:16:00.440621+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-23T18:35:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Feel like every guidance I can find for setting the DNS nameserver in my containers is failing me.</p> <p>To start with, the host machine is at 192.168.1.11 and PiHole is a contianer on a bridge at 192.168.2.53<br/> The resolve.conf on the containers looks like this: </p> <pre><code>root@5ec101a004e4:/# cat /etc/resolv.conf # Generated by Docker Engine. # This file can be edited; Docker Engine will not make further changes once it # has been modified. nameserver 127.0.0.11 search lan options ndots:0 # Based on host file: &#39;/etc/resolv.conf&#39; (internal resolver) # ExtServers: [8.8.8.8 192.168.2.53 192.168.1.11] # Overrides: [nameservers] # Option ndots from: internal </code></pre> <p>The ExtServers comment comes from the docker compose file I assume. relevant section: </p> <pre><code> jellyfin: image: jellyfin/jellyfin container_name: jellyfin networks: - docker-br0 # bridge on 192.168.0.xxx dns: - &quot;8.8.8.8&quot; - &quot;192.168.2.53&quot; #",
        "id": 2756988,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ktr0xp/configuring_dns_for_a_bridge",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Configuring DNS for a bridge",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Augurbuzzard",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-23T18:09:37.015629+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-23T17:16:37+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Augurbuzzard\"> /u/Augurbuzzard </a> <br/> <span><a href=\"/r/OpenMediaVault/comments/1kt79nf/dockerfile_help_for_nextcloud_aio_with_tailscale/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1ktp32k/dockerfile_help_for_nextcloud_aio_with_tailscale/\">[comments]</a></span>",
        "id": 2756557,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ktp32k/dockerfile_help_for_nextcloud_aio_with_tailscale",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dockerfile Help for Nextcloud AIO with tailscale and caddy sidecar",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EmbeddedSoftEng",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-23T17:04:39.869387+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-23T16:12:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I know the canonical way to run a docker container image is to import it, but that copies it in my machine so now there are two massive files taking up disk space, and if this were a multi-user system, it would place my custom docker container image at the beck and call of the rabble.</p> <p>I was sure there was a way to just</p> <pre><code>docker run custom-container.tar.bz </code></pre> <p>and not have to import it first? Was that just a fever dream?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EmbeddedSoftEng\"> /u/EmbeddedSoftEng </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1ktnikc/running_a_container_without_importing_it_first/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1ktnikc/running_a_container_without_importing_it_first/\">[comments]</a></span>",
        "id": 2755940,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ktnikc/running_a_container_without_importing_it_first",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Running a container without importing it first?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Competitive_Finance5",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-23T17:04:39.661715+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-23T16:07:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi redditors</p> <p>I&#39;m using all the default settings for networking, but a newly created docker compose container can&#39;t reach external network in network bridge mode. (network host mode works fine) I don&#39;t see traffic on the eth0 interface, while I see the same traffic originating from the docker interfaces. It seems a NAT rule or general FW rule is missing, but for my understanding, the default docker configuration should make them when spinning up the container.</p> <p>FW and nat rules after the container is created:</p> <pre><code>[root@m-inf-nrl-a1-01 docker]# iptables -nvL Chain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 312 28856 DOCKER-USER all -- * * 0.0.0.0/0 0.0.0.0/0 312 28856 DOCKER-FORWARD all -- * * 0.0.0.0/0 0.0.0.0/0 Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts by",
        "id": 2755939,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ktndol/docker_container_on_rhel_cant_access_external",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Docker container on RHEL can't access external network",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cloudbells",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-23T15:59:40.477046+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-23T15:07:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have Home Assistant running in an internal bridge network. See below:</p> <pre><code>internal_network: driver: bridge name: internal_network internal: true ipam: - etc </code></pre> <p>Home Assistant has an integration for sending magic packets. I want to be able to turn on my PC from the Home Assistant host (they&#39;re both on the same network) and since I can&#39;t access my home network let alone broadcast from the isolated container here is my solution. I&#39;m wondering if it&#39;s maybe unnecessarily convoluted or maybe even stupid.</p> <p>I have a proxy service connected to two bridge networks: the internal_network and an external network:</p> <pre><code>external_network: driver: bridge name: external_network ipam: - etc </code></pre> <p>Now I can access the host network but I still am not allowed to broadcast, so I set up a second proxy using the host driver. I then do something like</p> <pre><code>nc -vulp9 | hexdump </code></pre> <p>and I",
        "id": 2755274,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ktlwi9/wake_on_lan_from_internal_bridge_network",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Wake on LAN from internal bridge network",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/usrdef",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-23T11:39:43.013384+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-23T10:57:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I use Linux aliases a lot. Recently, I&#39;ve wanted to use aliases inside of containers that I access shell from, but the tests I tried will cause the alias to stop at whatever step involves going inside the container. </p> <p>Which I guess makes sense since the alias is being read on the host and isn&#39;t available in the container&#39;s shell.</p> <p>Has anyone else needed such functionality and found a way to get around this? Would their be a way where I can define some aliases via the <code>docker-compose.yml</code> and then I can call them from inside the container.</p> <p>I guess if I absolutely had to have one, I could throw them in a script, upload somewhere, and then wget. But I perfer not having to start installing packages each time I need to access the container.</p> <p>By Linux aliases, I mean being able to assign multiple commands to a single Linux command which runs all of them once triggered.</p> <p>The only other thing I can think o",
        "id": 2753093,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ktgm8c/aliases_for_internal_container_management",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Aliases for internal container management",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/whirl_and_twist",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-05-23T07:17:28.062295+00:00",
        "date_dead_since": null,
        "date_published": "2025-05-23T06:38:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><blockquote> <p><code>nginx | Setting WordPress permissions... nginx | chown: changing ownership of &#39;/var/www/html/wp-content/themes&#39;: Operation not permitted nginx | chown: changing ownership of &#39;/var/www/html/wp-content/plugins&#39;: Operation not permitted nginx | chown: changing ownership of &#39;/var/www/html/wp-content/cache&#39;: Operation not permitted nginx | chown: changing ownership of &#39;/var/www/html/wp-content/uploads&#39;: Operation not permitted nginx | chown: changing ownership of &#39;/var/www/html/wp-content&#39;: Operation not permitted nginx | chown: changing ownership of &#39;/var/www/html&#39;: Operation not permitted</code></p> </blockquote> <p>No matter what I did, this god forsaken warning appeared on my docker running terminal whenever i ran docker docker-compose up --build. It is a wordpress-fpm website running on bitnami&#39;s version of nginx without root and other things, with mysql, phpmyadmin and basic php s",
        "id": 2751537,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1ktcvge/how_to_grant_the_correct_permissions_to_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to grant the correct permissions to a rootless nginx image? (bitnami image of nginx unprivileged)",
        "vote": 0
    }
]