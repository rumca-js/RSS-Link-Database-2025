[
    {
        "age": null,
        "album": "",
        "author": "/u/aliciafinnigan",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-14T18:17:02.335051+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-14T17:02:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I&#39;ve been working on scraping a website for a while now. The API I have access to returns a JSON file, however, this file is multiple thousands of lines long with a lot of different IDs and mysterious names. I have trouble finding relations and parsing the scraped data into a data frame. </p> <p>Has anyone encountered something similar? I tried to look into the JavaScript of the site, but as I don&#39;t have any experience with JS, it&#39;s tough to know what to look for exactly. How would you try to parse such a response?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/aliciafinnigan\"> /u/aliciafinnigan </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ngwmef/parsing_api_response/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ngwmef/parsing_api_response/\">[comments]</a></span>",
        "id": 3572298,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ngwmef/parsing_api_response",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Parsing API response",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Classic-Anybody-9857",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-14T18:17:02.492836+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-14T16:56:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I&#39;m a beginner and this simple code isn&#39;t working, can someone help me :</p> <p>import requests</p> <p>from bs4 import BeautifulSoup</p> <p>headers = {&#39;User-Agent&#39;: &#39;Mozilla/5.0&#39;}</p> <p>url = &quot;<a href=\"https://www.amazon.in/product-reviews/B0DZDDQ429/ref=cm%5C_cr%5C_dp%5C_d%5C_show%5C_all%5C_btm?ie=UTF8&amp;reviewerType=all%5C_reviews\">https://www.amazon.in/product-reviews/B0DZDDQ429/ref=cm\\_cr\\_dp\\_d\\_show\\_all\\_btm?ie=UTF8&amp;reviewerType=all\\_reviews</a>&quot;</p> <p>response = requests.get(url, headers=headers)</p> <p>amazon_soup = BeautifulSoup(response.text, &quot;html.parser&quot;)</p> <p>all_divs = amazon_soup.find_all(&#39;span&#39;, {&#39;data-hook&#39;: &#39;review-body&#39;})</p> <p>all_divs</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Classic-Anybody-9857\"> /u/Classic-Anybody-9857 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ngwgml/doe",
        "id": 3572299,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ngwgml/does_beautifulsoup_work_for_scraping_amazon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does beautifulsoup work for scraping amazon product reviews?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ill_Dare8819",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-14T19:31:10.985840+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-14T16:13:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, the title speaks for itself. The goal is as follows: to scrape the mobile version of a site (not the app, just the mobile web version) that has a JS check and, as I suspect, also uses TLS fingerprinting + WebRTC verification.</p> <p>Basically, I managed to bypass this using Camoufox (Python) + a custom fingerprint generated using BrowserForge (which comes with Camoufox). However, as soon as I tried running it through Docker (using headless=&quot;virtual&quot; + xvfb installed), the results fell apart. The Docker test is necessary for me since I plan to later deploy the scraper on a VPS with Ubuntu 24.04. Same when I try to run it in headless mode.</p> <p>Any ideas? Has anyone managed to get results?</p> <p>I face the same issue with basically everything I&#39;ve tried.</p> <p>All other libraries I\u2019ve looked into (including patchright, nodriver, botosaurus) don\u2019t provide <em>any</em> documentation for proper mobile browser emulation.</p> <p>In gene",
        "id": 3573019,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ngvc6w/camoufox_or_any_other_library_gets_detected_when",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Camoufox (or any other library) gets detected when running in Docker",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ill-Examination8668",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-14T16:19:20.041870+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-14T15:42:43+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1nguk57/walmart_press_and_hold_captchabot_bypass/\"> <img src=\"https://a.thumbs.redditmedia.com/meJpbMRs6T9RQz0iFWtW0Q9nW5RVQWgyb5nj-xxdcg8.jpg\" alt=\"Walmart press and hold captcha/bot bypass\" title=\"Walmart press and hold captcha/bot bypass\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>anyone know a solution to get past this ??</p> <p><a href=\"https://preview.redd.it/6j8i16pth5pf1.png?width=903&amp;format=png&amp;auto=webp&amp;s=dffc8ba5330ec4b1a73459028862de5c110ff0a3\">https://preview.redd.it/6j8i16pth5pf1.png?width=903&amp;format=png&amp;auto=webp&amp;s=dffc8ba5330ec4b1a73459028862de5c110ff0a3</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ill-Examination8668\"> /u/Ill-Examination8668 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nguk57/walmart_press_and_hold_captchabot_bypass/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.",
        "id": 3571833,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nguk57/walmart_press_and_hold_captchabot_bypass",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/meJpbMRs6T9RQz0iFWtW0Q9nW5RVQWgyb5nj-xxdcg8.jpg",
        "title": "Walmart press and hold captcha/bot bypass",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Impressive_Safety_26",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-14T16:19:20.158578+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-14T15:28:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Anyone come across any good solutions? Say I have a page I&#39;m scraping or automating. The entire HTML/DOM is likely to be thousands if not tens of thousands of lines. I might only care about input elements, or certain words/certain text in the page. Has anyone used any libraries/approaches/frameworks that minify HTML where it makes it affordable to go into an LLM ? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Impressive_Safety_26\"> /u/Impressive_Safety_26 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ngu783/minifying_htmldom_for_llms/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ngu783/minifying_htmldom_for_llms/\">[comments]</a></span>",
        "id": 3571834,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ngu783/minifying_htmldom_for_llms",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Minifying HTML/DOM for LLM's",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/younesbensafia7",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-14T19:31:12.074308+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-14T15:06:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>What are the main differences between BeautifulSoup, Scrapy, and Selenium, and when should each be used?</strong></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/younesbensafia7\"> /u/younesbensafia7 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ngtnht/beautifulsoup_vs_scrapy_vs_selenium/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ngtnht/beautifulsoup_vs_scrapy_vs_selenium/\">[comments]</a></span>",
        "id": 3573020,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ngtnht/beautifulsoup_vs_scrapy_vs_selenium",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "BeautifulSoup vs Scrapy vs Selenium",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/michal-kkk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-14T10:56:56.998188+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-14T09:58:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>Clever idea from <a href=\"https://www.reddit.com/user/zoe_is_my_name/\">zoe_is_my_name</a> from this thread is not longer working (google do not accept these old headers anymore) - <a href=\"https://www.reddit.com/r/webscraping/comments/1m9l8oi/is_scraping_google_search_still_possible/\">https://www.reddit.com/r/webscraping/comments/1m9l8oi/is_scraping_google_search_still_possible/</a></p> <p>Any other genious ideas guys? I already use paid api but woud like some &#39;traditional&#39; methods as well.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/michal-kkk\"> /u/michal-kkk </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ngnawx/google_webscraping_newest_methods/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ngnawx/google_webscraping_newest_methods/\">[comments]</a></span>",
        "id": 3569990,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ngnawx/google_webscraping_newest_methods",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Google webscraping newest methods",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ai_naymul",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-14T07:53:38.666150+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-14T07:31:35+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1ngkxh4/new_ui_release_of_browserpilot/\"> <img src=\"https://external-preview.redd.it/engwODV5ZTIyM3BmMYXNVlxe4XC1pxidibZnrCyVRdGAeLYohZuPfPsyYjPR.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4a585595ab1d3f38e3a7604375e8dd146d16762f\" alt=\"New UI Release of browserpilot\" title=\"New UI Release of browserpilot\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>New UI has been released for browserpilot.<br/> Check it out here: <a href=\"https://github.com/ai-naymul/BrowserPilot/\">https://github.com/ai-naymul/BrowserPilot/</a></p> <p>What browserpilot is: ai web browsing + advanced web scraping + deep research on a single browser tab </p> <p>Landing: <a href=\"https://browserpilot-alpha.vercel.app/\">https://browserpilot-alpha.vercel.app/</a> </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ai_naymul\"> /u/ai_naymul </a> <br/> <span><a href=\"https://v.redd.it/la14pye223pf1\">[link",
        "id": 3569285,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ngkxh4/new_ui_release_of_browserpilot",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/engwODV5ZTIyM3BmMYXNVlxe4XC1pxidibZnrCyVRdGAeLYohZuPfPsyYjPR.png?width=640&crop=smart&auto=webp&s=4a585595ab1d3f38e3a7604375e8dd146d16762f",
        "title": "New UI Release of browserpilot",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Low-Difficulty121",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-14T06:45:37.170030+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-14T06:38:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://scanpros.ai/web-fetch\">https://scanpros.ai/web-fetch</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Low-Difficulty121\"> /u/Low-Difficulty121 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ngk111/forget_your_old_school_scraping_try_this/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ngk111/forget_your_old_school_scraping_try_this/\">[comments]</a></span>",
        "id": 3569071,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ngk111/forget_your_old_school_scraping_try_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Forget your old school scraping. Try this!",
        "vote": 0
    }
]