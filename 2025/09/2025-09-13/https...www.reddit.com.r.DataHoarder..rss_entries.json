[
    {
        "age": null,
        "album": "",
        "author": "/u/akindofuser",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T22:47:51.356829+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T22:17:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been shopping but there are not many options. </p> <p>I had a small M.2 NGFF RAID enclosure by Orico using 2 WD Blue SA510 1TB drives. I built this small setup for travel photography trips after a trip went sour one year in which my thumbstick failed mid trip losing all photos.</p> <p>So this setup has actually saved me once in which one of the WD Blue drives failed. The other one still intact it was easy to just plug it into a new enclosure to access the data as if nothing had happened. WD Replaced the failed drive with a better WD Red SA500 1TB. But that meant I had 1 blue and 1 red in a RAID 1 now. That worked of about a year until the 2nd blue finally failed, just out of warantee. </p> <p>Now I&#39;m concerned. Did the blue&#39;s fail because of hte Orico enclosure? Or are they just cheap. </p> <p>I&#39;d like to rebuild the exact same setup with 2 WD Reds, but IDK if I should be trusting this enclosure?</p> <p>One thing that has me nervo",
        "id": 3567692,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ngaeey/dual_m2_enclosure_with_raid_1_for_travel",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dual m2 enclosure with Raid 1 for travel",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/uzico",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T22:47:51.058475+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T22:13:53+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ngabgy/sas_dock_yes_it_is_actually_pretty_decent/\"> <img src=\"https://external-preview.redd.it/LWjWGgtYIugPV5wLlxMR81nfE5eiTGAdh3xV2nDpU4Y.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=18fb5fe651a77a1b1fa34ec5409910cfd70501dc\" alt=\"SAS Dock - yes it is actually pretty decent\" title=\"SAS Dock - yes it is actually pretty decent\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Bought very cheap SAS drives for cold storage, so I got myself a SAS Dock and tested it a bit.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/uzico\"> /u/uzico </a> <br/> <span><a href=\"https://youtu.be/yl7wHDFvLe8\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ngabgy/sas_dock_yes_it_is_actually_pretty_decent/\">[comments]</a></span> </td></tr></table>",
        "id": 3567691,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ngabgy/sas_dock_yes_it_is_actually_pretty_decent",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/LWjWGgtYIugPV5wLlxMR81nfE5eiTGAdh3xV2nDpU4Y.jpeg?width=320&crop=smart&auto=webp&s=18fb5fe651a77a1b1fa34ec5409910cfd70501dc",
        "title": "SAS Dock - yes it is actually pretty decent",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Acidy_Sakura",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T22:47:51.488407+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T22:12:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was trying to find the full Fuji Rock Festival video from 2019 but it was private.</p> <p><a href=\"https://youtu.be/NKHx6l6tWxA\">https://youtu.be/NKHx6l6tWxA</a></p> <p>I tried using the way back machine and it said it was saved but I didn\u2019t see like the video or anything please help \ud83d\ude4f\ud83d\ude4f or if anyone has Mitskis full live preformance at Fuji rock festival pls send it to me</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Acidy_Sakura\"> /u/Acidy_Sakura </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ngaafl/how_to_use_wayback_machine/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ngaafl/how_to_use_wayback_machine/\">[comments]</a></span>",
        "id": 3567693,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ngaafl/how_to_use_wayback_machine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to use wayback machine?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EarSoggy1267",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T21:45:57.546906+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T21:33:37+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ng9e53/i_like_to_horde_my_data_raw/\"> <img src=\"https://preview.redd.it/1oh50uwj30pf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6a1a834be00f973a81b4cf1fb174b5469d5f9795\" alt=\"I like to horde my data raw\" title=\"I like to horde my data raw\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>There was a post about another member getting an optane p5800x. I would love to get one of those drives some day, until then I at least have one of the 300mm wafers. i was there when they announced they were discontinuing 3d Xpoint and was given this when production ended.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EarSoggy1267\"> /u/EarSoggy1267 </a> <br/> <span><a href=\"https://i.redd.it/1oh50uwj30pf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ng9e53/i_like_to_horde_my_data_raw/\">[comments]</a></span> </td></tr></table>",
        "id": 3567421,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ng9e53/i_like_to_horde_my_data_raw",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/1oh50uwj30pf1.jpeg?width=640&crop=smart&auto=webp&s=6a1a834be00f973a81b4cf1fb174b5469d5f9795",
        "title": "I like to horde my data raw",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/phlaries",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T21:45:57.768510+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T21:05:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My windows is finally deteriorating and I&#39;m forced to do a fresh install. Rather than doing a full backup of every drive, I&#39;m being particular with the files I&#39;m saving. </p> <p>Which files, folders and configs are typically overlooked when doing this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/phlaries\"> /u/phlaries </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ng8qu2/when_manually_backing_up_your_pc_what_files/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ng8qu2/when_manually_backing_up_your_pc_what_files/\">[comments]</a></span>",
        "id": 3567422,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ng8qu2/when_manually_backing_up_your_pc_what_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "When Manually Backing up Your PC, What Files / Folders are Typically Overlooked?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HairOnBroadway",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T20:45:05.341428+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T20:36:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have 4 WD external HDDs (mix of EasyStore and Elements) that are a couple of years old. I recently started noticing an odor like thermal paper or old style store receipts or carbon copy paper that I can smell about 3 feet away. So I sniffed the other 3 hard drives, and they all have that smell, except I have to put my nose right above them to smell it. Is this normal, and what part is giving off that smell?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HairOnBroadway\"> /u/HairOnBroadway </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ng82mk/smell_from_wd_external_hdds/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ng82mk/smell_from_wd_external_hdds/\">[comments]</a></span>",
        "id": 3567122,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ng82mk/smell_from_wd_external_hdds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Smell from WD external HDDs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SoManyHobbies1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T20:45:05.117219+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T19:20:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Built a new Synology NAS. </p> <p>Technically my 5D3 still works, but due to no future support, just built a NAS now to also share with my partner. </p> <p>Question is, should I just keep using this 5D3 as part of backup strategy or build a new DAS out of the old HDs inside the 5D3 then back up to that. </p> <p>Thank you! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SoManyHobbies1\"> /u/SoManyHobbies1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ng698c/what_to_do_with_old_drobo_5d3/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ng698c/what_to_do_with_old_drobo_5d3/\">[comments]</a></span>",
        "id": 3567121,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ng698c/what_to_do_with_old_drobo_5d3",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What to do with old Drobo 5D3",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/7990",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T17:53:42.268085+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T17:00:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I have a remote seedbox set up with the -arr suite to automatically download music, movies, and tv shows as they release/I request them</p> <p>but i&#39;ve always manually downloaded them to my local plex server</p> <p>I want to automate this so once something is downloaded to the seedbox it syncs to the local server and then organizes it into my local library automatically</p> <p>what tool would you use for this?</p> <p>in my quick research for this, davos seems like the leading contender, but i&#39;m wondering if anyone has tackled a similar problem and has a better solution? or maybe a config for the -arr suite to do it more elegantly</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/7990\"> /u/7990 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ng2okh/how_would_you_automate_downloads_from_a_seedbox/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments",
        "id": 3566385,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ng2okh/how_would_you_automate_downloads_from_a_seedbox",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How would you automate downloads from a seedbox to a local server?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/vanderzee",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T16:46:45.004356+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T16:04:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>freecommander is gone (website doesnt load anymore). and i need an alternative that to replace it. </p> <p>(sorry if its a bother, but i have a few disabilities and finding this on my own would be nigh impossible?!] </p> <p><strong>what i used freecommander for:</strong> </p> <p>- bulk/batch renaming all files inside a folder and also subfolder to its respective folders name</p> <p>example:</p> <p>folder P</p> <p>subfolder 1</p> <p>subfolder 2</p> <p>subfolder 3</p> <p>subfolder 4</p> <p>all files inside folder P are named &quot;folder P [sequencial number] &quot;</p> <p>all files inside subfolder 1 are named &quot;subfolder 1 [sequencial number] &quot;</p> <p>all files inside subfolder 2 are named &quot;subfolder 2 [sequencial number] &quot;</p> <p>etc.</p> <p>thanks!</p> <p><strong><em>ps: tried :</em></strong> </p> <p><strong><em>1. &quot;bulk rename utility&quot;</em></strong> <em>but got overwhelmed by the interface and options, couldnt get it wo",
        "id": 3565975,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ng19u3/freecommander_is_gone_need_alternative_need",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "freecommander is gone - need alternative - need suggestions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/omniscrubs",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T15:31:39.408413+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T15:17:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Id like to have backup folders on my pc for folders in my phone. Are there any softwares which would do this automatically over wlan? </p> <p>I tried syncthing, but what I want is a backup folder and not them to sync between the devices(ie even if I delete files on my phone, they should remain in the pc folder). The &#39;ignoredelete&#39; option in syncthing does the job, but its not something that is solid enough to be trusted with important data(one such issue i encountered was, in case of file name conflicts, the files were overwritten, leading to the loss of one of the files)</p> <p>So, is there any solid options? I saw a similar query posted here around 4 yrs back, but that didnt get any good recommendations. 4 years down the lane, is there a better solution, or is it still same?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/omniscrubs\"> /u/omniscrubs </a> <br/> <span><a href=\"https://www.reddit.com/r/Data",
        "id": 3565630,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ng03jz/any_software_or_apps_to_create_backup_of_folders",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any software or apps to create backup of folders in android to PC automatically and over wlan?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GamerboyJD",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T15:31:39.005043+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T14:36:29+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfz2wi/save_the_internet_archive/\"> <img src=\"https://external-preview.redd.it/RxesimV77k97rOxYccx6JkR8qj5cpRByMlVD9ucAVno.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5b0de93f273b3e67a245b5db72f5e46317b168c7\" alt=\"Save the Internet Archive!\" title=\"Save the Internet Archive!\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GamerboyJD\"> /u/GamerboyJD </a> <br/> <span><a href=\"https://c.org/MxtYJLgFwS\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfz2wi/save_the_internet_archive/\">[comments]</a></span> </td></tr></table>",
        "id": 3565629,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nfz2wi/save_the_internet_archive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/RxesimV77k97rOxYccx6JkR8qj5cpRByMlVD9ucAVno.jpeg?width=640&crop=smart&auto=webp&s=5b0de93f273b3e67a245b5db72f5e46317b168c7",
        "title": "Save the Internet Archive!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/WalrusInAnuss",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T14:19:55.641609+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T14:19:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I currently have LSI 9305-8i HBA in our home server and it&#39;s perfectly fine, but it&#39;s SAS/SATA only, and I&#39;m sure I&#39;ll get a NVMe upgrade itch sooner or later, and despite not needing NVMe speeds for static storage of backups and illicit content, that won&#39;t prevent me from dumping money into this nonsense.</p> <p>I&#39;ve been looking at the possibilities what to replace the current card with, and it seems like 9500-8i (which is a currently produced model it seems) is a sound choice (with 9400 also being NVMe, but its power consumption is much higher I believe, and if I upgrade, I want something newer just out of general principle), however when I go to Ebay and look it up, there are hardly any listings in Europe and those I can see are pretty expensive.<br/> There are plenty of cards located in China however, but with all the fakes, scams and whatnot I am sceptical about that.<br/> Can anyone tell me whether this is fine or my sus",
        "id": 3565235,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nfyog1/shall_i_avoid_buying_a_hba_from_china",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Shall I avoid buying a HBA from China?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Wufi",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T14:19:55.420362+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T13:29:14+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Wufi\"> /u/Wufi </a> <br/> <span><a href=\"/r/homelab/comments/1nfxinn/best_miniitx_motherboard_for_node_304_nas_zfs_ecc/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfxj8o/best_miniitx_motherboard_for_node_304_nas_zfs_ecc/\">[comments]</a></span>",
        "id": 3565234,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nfxj8o/best_miniitx_motherboard_for_node_304_nas_zfs_ecc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best mini-ITX motherboard for Node 304 NAS (ZFS, ECC, 6\u00d7SATA, 10GbE)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/_shellsort_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T13:05:31.255971+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T12:51:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Title</p> <p>Also jbod</p> <p><del>Also what do you store on it?</del></p> <p>Edit: Just saw there&#39;s a megathread for the last question. The first one still stands thou!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/_shellsort_\"> /u/_shellsort_ </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfwq1o/so_who_here_has_the_most_storage_space/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfwq1o/so_who_here_has_the_most_storage_space/\">[comments]</a></span>",
        "id": 3564855,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nfwq1o/so_who_here_has_the_most_storage_space",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "So who here has the most storage Space?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cutandjoin",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T13:05:30.875550+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T11:58:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I built a lightweight freeware app that works kind of like running SQL queries on MP3 frames.<br/> If you still keep a local MP3 library, it might give you a new way to experience your music.<br/> Cjam: <a href=\"https://cjmapp.net\">https://cjmapp.net</a><br/> Some script examples can be found here:<br/> <a href=\"https://forum.cjmapp.net/viewforum.php?f=9\">https://forum.cjmapp.net/viewforum.php?f=9</a> </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cutandjoin\"> /u/cutandjoin </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfvo14/a_tool_that_lets_you_query_your_mp3s_like_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfvo14/a_tool_that_lets_you_query_your_mp3s_like_a/\">[comments]</a></span>",
        "id": 3564854,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nfvo14/a_tool_that_lets_you_query_your_mp3s_like_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "A tool that lets you query your MP3s like a database",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Cece143",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T11:57:20.685449+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T11:44:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Yeah just the question above, something tells me it would be but I sure hope not??</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Cece143\"> /u/Cece143 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfve6i/if_i_attach_a_video_onto_a_pages_word_document_on/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfve6i/if_i_attach_a_video_onto_a_pages_word_document_on/\">[comments]</a></span>",
        "id": 3564545,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nfve6i/if_i_attach_a_video_onto_a_pages_word_document_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "If I attach a video onto a pages word document on my iPhone and then save the video I just uploaded, will its quality be different to the initial one in my camera roll?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/waiting_for_zban",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T11:57:19.998190+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T11:42:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, it seems that The Great Firewall of China (GFW) experienced the largest leak of internal documents in its history on Thursday September 11, 2025. Over 500 GB of source code, work logs, and internal communication records were leaked, revealing details of the GFW\u2019s research, development, and operations. </p> <p>Half fun. </p> <p><a href=\"https://gfw.report/blog/geedge_and_mesa_leak/en/\">https://gfw.report/blog/geedge_and_mesa_leak/en/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/waiting_for_zban\"> /u/waiting_for_zban </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfvcyw/so_the_great_firewall_of_china_had_a_massive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfvcyw/so_the_great_firewall_of_china_had_a_massive/\">[comments]</a></span>",
        "id": 3564544,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nfvcyw/so_the_great_firewall_of_china_had_a_massive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "So the great firewall of China had a massive 500GB data leak. I need more HDDs.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Emotional_Dust2807",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T08:29:16.779890+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T07:31:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was wondering if mediarange discs were just branded verbatim discs. Where I am, they are a bit cheaper than Verbatim discs? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Emotional_Dust2807\"> /u/Emotional_Dust2807 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfrch6/are_mediarange_bdr_dl_just_branded_verbatim_discs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfrch6/are_mediarange_bdr_dl_just_branded_verbatim_discs/\">[comments]</a></span>",
        "id": 3563631,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nfrch6/are_mediarange_bdr_dl_just_branded_verbatim_discs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are Mediarange BD-R Dl just branded verbatim discs?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Jancox77",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T04:51:15.088448+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T03:50:55+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nfnk6u/cant_download_an_online_coursebook_from/\"> <img src=\"https://preview.redd.it/1tx2xuwutuof1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a84ef47b430ac8453f536b12d3baf60a253f85ec\" alt=\"Can\u2019t download an online course/book from React/flipbook viewer \u2013 need help\" title=\"Can\u2019t download an online course/book from React/flipbook viewer \u2013 need help\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I\u2019m trying to download a digital book/course that is presented in a web-based viewer built with React (flipbook style, with horizontal scrolling). I want to save it in a PDF format with the same layout and images as I see on the website.</p> <p>Here\u2019s what I\u2019ve tried so far:</p> <ul> <li><strong>Saving the page as HTML</strong> \u2192 only captures the content currently loaded, misses pages, images, and formatting.</li> <li><strong>SingleFile Chrome extension</strong> \u2192 saves the HTML, but when open",
        "id": 3562905,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nfnk6u/cant_download_an_online_coursebook_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/1tx2xuwutuof1.png?width=640&crop=smart&auto=webp&s=a84ef47b430ac8453f536b12d3baf60a253f85ec",
        "title": "Can\u2019t download an online course/book from React/flipbook viewer \u2013 need help",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/edomamee",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T02:29:24.806230+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T02:01:55+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nflgqb/seagates_data_recovery_service_actually_worked/\"> <img src=\"https://b.thumbs.redditmedia.com/luE0_uIhByIMOmELWdGj7tZTk5-3uO4mQ-Mv2t1pb1s.jpg\" alt=\"Seagate\u2019s Data Recovery Service actually worked for me\" title=\"Seagate\u2019s Data Recovery Service actually worked for me\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>There are a lot of posts here dunking on Seagate&#39;s free data recovery service, so I figured I&#39;d share a different experience, because mine was surprisingly positive.</p> <p>Recently, one of my Seagate external hard drives (5TB) malfunctioned. Symptoms included constant vibrations, scraping noises, my PC recognized it, but as soon as I tried to open anything, File Explorer would freeze... and then my PC would promptly stop responding to anything I do until I unplugged the hard drive. I&#39;m not very tech-savvy, so after a few attempts, I just unplugged it and was preparing myself to tos",
        "id": 3562430,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nflgqb/seagates_data_recovery_service_actually_worked",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/luE0_uIhByIMOmELWdGj7tZTk5-3uO4mQ-Mv2t1pb1s.jpg",
        "title": "Seagate\u2019s Data Recovery Service actually worked for me",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ThecoolHD2",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T02:29:25.017157+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T01:56:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys. I have long had a plan to save all Windows editions/distros until they are available. I\u2019ll likely do something similar for Linux as well. Has anyone ever done this before? If so, just on a simple external HDD or something cooler? Opinions?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ThecoolHD2\"> /u/ThecoolHD2 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nflcbl/windows_hoarding/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nflcbl/windows_hoarding/\">[comments]</a></span>",
        "id": 3562431,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nflcbl/windows_hoarding",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Windows hoarding",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Lucaslamr",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T02:29:24.604719+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T01:36:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So basically I have some folders with same imagens but not necessarily same bytes. (PCs and phones backups kinda stacked) and I want to use a software to find these duplicates and I want to analyze them, because to me is inportant to keep the most original one (best resolution and most original metadata, especially the date). Going through a quick look here I found <a href=\"https://github.com/qarmin/czkawka\">czkawka</a>, <a href=\"https://github.com/arsenetar/dupeguru\">dupeGuru</a> and <a href=\"https://www.mindgems.com/products/Fast-Duplicate-File-Finder/Fast-Duplicate-File-Finder-About.htm\">Free Duplicate File Finder</a>. My first thought on the last one when visiting the website is that it looks like old sketchy websites lol. But anyways, I need a free software that can get me those results, which one should I try? is there any other that I missed on? (using windows 11 btw)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit",
        "id": 3562429,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nfkxyz/best_software_for_deduplicating_images",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "best software for deduplicating images",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/killipjp",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T02:29:25.427778+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T01:35:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Budding data hoarder here and I need some help: </p> <p>My mom found a pretty old computer (AMD phenom II and windows 7) in a house she was cleaning out and inside is this HDD. <a href=\"https://imgur.com/a/IwUT99c\">https://imgur.com/a/IwUT99c</a></p> <p>Now id like to be able to safely format it so i can test the drive health and possibly use it but im a little scared to plug this bad boy in lol. </p> <p>I have 2 main computers i use that i will absolutely not be connecting this to, BUT i have a 3rd computer that I could possibly try it on. It doesnt have anything important on it files wise but id rather not kill any part of the pc as im broke and dont wanna replace anything. I also have an external HDD enclosure [plugs in via usb] i could pop it in so its not internally in my pc</p> <p>Thoughts? People say to use a throwaway pc or raspberry pi setup but i dont have that. Also im not savvy enough to know how to make a completely isolated machine in ca",
        "id": 3562432,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nfkxhn/safe_way_to_format_this_random_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Safe way to format this random HDD?",
        "vote": 0
    }
]