[
    {
        "age": null,
        "album": "",
        "author": "/u/Thin-Durian9258",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T19:20:08.206881+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T18:24:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys! </p> <p>I&#39;m quite experienced in web scraping using python, I know different approaches, some antibots bypassing etc.</p> <p>Recently I came across a site that uses wasm to set cookies. To scrape it I need to visit it using playwright/any other browser imitation lib, get wasm cookies and then I can scrape the site using requests for some time, like 5-10 minutes.</p> <p>After ~10 minutes I have to reopen browser to get new wasm cookies. I don&#39;t like the speed, and open browser at all.</p> <p>So, the question is, maybe someone had meet same issues and know how to bypass it, maybe there are some libraries which can help with wasm cookies.</p> <p>Will be reeeeeeally grateful for help! Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Thin-Durian9258\"> /u/Thin-Durian9258 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ng4v2z/need_help_with_wasm_cookies/\">[link]</a></spa",
        "id": 3566823,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ng4v2z/need_help_with_wasm_cookies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help with wasm cookies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/KillAllDogsNow",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T18:11:00.515351+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T17:00:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Working on a project that requires webscrapping local news websites for informaiton between 2012-2020. DM for details, we can talk on discord.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/KillAllDogsNow\"> /u/KillAllDogsNow </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ng2o7c/hiring_freelancer_for_local_news_webscapper_dm/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ng2o7c/hiring_freelancer_for_local_news_webscapper_dm/\">[comments]</a></span>",
        "id": 3566475,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ng2o7c/hiring_freelancer_for_local_news_webscapper_dm",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hiring Freelancer for local news webscapper. DM for details.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/gutsytechster",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T17:08:44.603761+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T16:33:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey folks</p> <p>How do we know if a website uses some fingerprinting technique? I&#39;ve been following this article: <a href=\"https://www.zenrows.com/blog/browser-fingerprinting#browser-fingerprinting-example\">https://www.zenrows.com/blog/browser-fingerprinting#browser-fingerprinting-example</a> to know more about browser fingerprinting.</p> <p>The second example under it discovers a JS call to get the source that enable fingerprinting for this website <a href=\"https://www.lemonde.fr/\">https://www.lemonde.fr/</a>. I can&#39;t find the same call as it&#39;s being shown into the article.</p> <p>Further, how do I know which JS calls does that? Do I track all JS calls &amp; see how do they work?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/gutsytechster\"> /u/gutsytechster </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ng20gq/how_to_identify_browser_fingerprinting_in_a_site/\">[link]</a><",
        "id": 3566140,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ng20gq/how_to_identify_browser_fingerprinting_in_a_site",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to identify browser fingerprinting in a site",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Front_Lavishness8886",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-13T15:51:20.706452+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-13T14:53:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been scraping for years, and the hardest part is rarely the extraction \u2014 it\u2019s the <strong>post-processing.</strong></p> <p>Messy HTML \u2192 inconsistent fields \u2192 nested JSON \u2192 edge cases that break regex\u2026 you know the pain.</p> <p>Lately, I\u2019ve been experimenting with <strong>LLMs as a data cleaning layer</strong>:</p> <ul> <li>Feed raw scraped text (tables, product descriptions, job postings) into a model</li> <li>Ask it to normalize into structured JSON or CSV format</li> <li>Let it infer missing fields (e.g., turning \u201c$49.9\u201d into a clean <code>49.90</code>)</li> <li>Use it as a lightweight ETL step before storing in DB</li> </ul> <p>It\u2019s surprisingly good for small to medium datasets, especially when schema flexibility is needed. But I\u2019m hitting some issues:</p> <ul> <li><strong>Cost &amp; speed:</strong> inference isn\u2019t cheap at scale.</li> <li><strong>Hallucination risk:</strong> sometimes it fabricates values when input is incomplete.</li> <li><",
        "id": 3565733,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nfzhqy/anyone_using_llms_to_clean_or_structure_scraped",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone Using LLMs to Clean or Structure Scraped Data?",
        "vote": 0
    }
]