[
    {
        "age": null,
        "album": "",
        "author": "/u/One_Nose6249",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-08T20:54:52.427980+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-08T20:19:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>hey there!</p> <p>I\u2019m new to scraping and was trying to learn about it a bit. Pixelscan test is successful and my scraper works for every other websites</p> <p>However when it comes to hermes or also louis vouitton, I\u2019m always getting 403 somehow. I\u2019ve tried headful headless and actually headful was even worse\u2026. Anyone can help with it?</p> <p>Techstack is Crawlee + Camoufox</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/One_Nose6249\"> /u/One_Nose6249 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nbynn8/scraping_hermes/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nbynn8/scraping_hermes/\">[comments]</a></span>",
        "id": 3526167,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nbynn8/scraping_hermes",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Hermes",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/shadow--404",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-08T18:18:16.751698+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-08T17:59:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>90% off for 1 year. Ping if want to know.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/shadow--404\"> /u/shadow--404 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nbux5k/found_a_way_to_get_gemini_pro_at_90_discount/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nbux5k/found_a_way_to_get_gemini_pro_at_90_discount/\">[comments]</a></span>",
        "id": 3524951,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nbux5k/found_a_way_to_get_gemini_pro_at_90_discount",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Found a way to get gemini pro at 90% discount",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Piyush452412006",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-08T15:46:13.817923+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-08T15:27:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I&#39;m working on a price comparator website for PC components and as I can&#39;t directly access Amazon, Flipkart APIs and I also have to include some local vendors who don&#39;t provide APIs so the only option left with me is webscraping. As a student I can&#39;t afford any of the paid webscrapers, and thus looking for free webscrapers who can provide data in JSON format.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Piyush452412006\"> /u/Piyush452412006 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nbqryb/looking_for_a_free_webscraper_for_college_project/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nbqryb/looking_for_a_free_webscraper_for_college_project/\">[comments]</a></span>",
        "id": 3523650,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nbqryb/looking_for_a_free_webscraper_for_college_project",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a free webscraper for college project (price comparator)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/plintuz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-08T15:46:13.517143+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-08T15:03:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>We&#39;re a small team of 2 people, and right now we scrape a bit over 100 websites every day. Expansion is already in the plans - the workload keeps growing.</p> <p>We build everything in Python. It&#39;s simple, has tons of ready-to-use libraries, and lets us launch new scrapers quickly.</p> <p>Whenever possible, we avoid browsers - direct GET/POST requests are faster and cheaper. But the reality is that about half of the websites still need browser automation. Proxies (residential and mobile, often from different regions) are a must-have to keep things stable.</p> <p>In the beginning, we ran separate VPS servers for each project. That quickly became a pain to manage. Now we&#39;re moving toward a more centralized setup, which makes it easier to scale and maintain.</p> <p>The data itself is usually exported in Excel, JSON, CSV, or XML formats. Depending on the case, it can be delivered through files, file links, or APIs.</p> <p>Of course, scrapers b",
        "id": 3523649,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nbq5iq/our_journey_of_scraping_100_websites_daily",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Our journey of scraping 100+ websites daily",
        "vote": 0
    }
]