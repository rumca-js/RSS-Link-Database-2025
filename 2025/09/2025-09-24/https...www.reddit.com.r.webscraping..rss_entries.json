[
    {
        "age": null,
        "album": "",
        "author": "/u/vroemboem",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-24T19:49:44.633643+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-24T19:41:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to &quot;scrape&quot; websocket messages sent from a websocket server. </p> <p>My node.js script works perfectly locally, I&#39;ve tried to deploy on Render and Railway, but run into status 502 errors.</p> <p>What is an easy way to deploy a websocket client and host it in the cloud?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/vroemboem\"> /u/vroemboem </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nplvqz/hosting_a_websocket_client_for_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nplvqz/hosting_a_websocket_client_for_scraping/\">[comments]</a></span>",
        "id": 3656354,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nplvqz/hosting_a_websocket_client_for_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hosting a websocket client for scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Horror-Tower2571",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-24T19:49:44.839583+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-24T19:32:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys,</p> <p>Ive been wondering, pastebin has some pretty valuable data if you can find it, how hard would it be to scrape all recent posts and continuously scrape posts on their site without an api key, i heard of people getting nuked by their WAF and bot protections but then it couldnt be much harder than lkdin or Gettyimages, right? If I was to use a headless browser pulling recent posts with a rotating residential ip, throw those slugs into Kafka, a downstream cluster picks up on them and scrapes the raw endpoint and saves to s3, what are the chances of getting detected?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Horror-Tower2571\"> /u/Horror-Tower2571 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nplo13/is_scraping_pastebin_hard/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nplo13/is_scraping_pastebin_hard/\">[comments]</a></span>",
        "id": 3656355,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nplo13/is_scraping_pastebin_hard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is scraping pastebin hard?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/vision_deals",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-24T19:49:44.270923+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-24T19:03:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m building a small keyword tool that scrapes YouTube search results, but I\u2019m not sure how aggressive I can be with it. Basically, I want to automate pulling search queries to see what videos and channels are ranking, but my worry is whether YouTube has a hidden rate limit or if I could actually get IP-banned for doing too many requests.</p> <p>Has anyone here tried something similar? Is it safe if I keep the requests slower/paced out, or does YouTube usually block you pretty quickly if you go overboard? I don\u2019t want to mess up my server by doing this. I&#39;ve heard people use proxies for scraping, any recommendations which ones to go with/where?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/vision_deals\"> /u/vision_deals </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1npkwnv/is_there_a_rate_limit_for_youtube_search_what/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/",
        "id": 3656353,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1npkwnv/is_there_a_rate_limit_for_youtube_search_what",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a rate limit for YouTube search, what proxies to use?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Calm-Seat51",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-24T18:48:29.925173+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-24T18:35:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So... What I would like to know is next. Is there somehow or somewhere I can ask for scraping? I have a website. <a href=\"https://www.hok-cba.hr/imenik/\">Imenik odvjetnika \u2013 Hrvatska odvjetni\u010dka komora</a> and its a list of all laywer firms in Croatia. They have a PDF to download but no email in it while online emails are written. </p> <p>I am doing some art project that I need to get some data in way of a quiz answers from layers as its about laws concerning artists. So I would like to get as much as possible. So before I start opening link by link and copy pasteing it brute force. I am sure this can be done in more smart way.</p> <p>So I am asking here :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Calm-Seat51\"> /u/Calm-Seat51 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1npk5fh/scraping_email_dont_worry_its_just_lawers/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.c",
        "id": 3655996,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1npk5fh/scraping_email_dont_worry_its_just_lawers",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping email. dont worry its just lawers :)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Gojo_dev",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-24T18:48:30.248941+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-24T18:19:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m writing this to share the process I used to scrape an e-commerce site and one thing that was new to me.</p> <p>I started with the collection pages using Python, requests, and BeautifulSoup. My goal was to grab product names, thumbnails, and links. There were about 500 products spread across 12 pages, so handling pagination from the start was key. It took me around 1 hour to get this first part working reliably.</p> <p>Next, I went through each product page to extract descriptions, prices, images, and sometimes embedded YouTube links. Scraping all 500 pages took roughly 2-3 hours. </p> <p>The new thing I learned was how these hidden video links were embedded in unexpected places in the HTML, so careful inspection and testing selectors were essential.</p> <p>I cleaned and structured the data into JSON as I went. Deduplicating images and keeping everything organized saved a lot of time when analyzing the dataset later.</p> <p>At the end, I had a neat",
        "id": 3655997,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1npjpx6/scraping_hundreds_of_products_and_finding_weird",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Hundreds of Products and Finding Weird Surprises",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/do_less_work",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-24T17:46:23.119286+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-24T17:07:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Working on a new web scraper today, not getting any data!</strong> The site was a single page app, I tested my CSS selectors in console oddly they returned null. </p> <p>Looking at the HTML I spotted &quot;Slots&quot; and got to thinking components are being loaded, wrapping there contents in the shadow dom. </p> <p>To be honest with a little help from ChatGPT, came up with this script I can run in Google Console and it highlights any open Shadow Dom elements.</p> <p>How often do people run into this type of issue?</p> <p>Alex</p> <p>Below: highlight shadow dom elements in console.</p> <pre><code>(() =&gt; { const hosts = [...document.querySelectorAll(&#39;*&#39;)].filter(el =&gt; el.shadowRoot); // outline each shadow host hosts.forEach(h =&gt; h.style.outline = &#39;2px dashed magenta&#39;); // also outline the first element inside each shadow root so you can see content hosts.forEach(h =&gt; { const q = [h.shadowRoot]; while (q.length) { co",
        "id": 3655296,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nphux5/how_frequently_do_people_run_into_shadow_dom",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How frequently do people run into shadow dom?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Pretty-Lobster-2674",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-24T15:04:57.041034+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-24T14:32:09+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1npdq2w/totally_new_to_web_scraping_dont_know_shit/\"> <img src=\"https://a.thumbs.redditmedia.com/FdFKAw6AtSGWunBXA0g-ziMMxTBQkERum3YGiIneQE8.jpg\" alt=\"Totally NEW to 'Web Scraping' !! dont know SHIT\" title=\"Totally NEW to 'Web Scraping' !! dont know SHIT\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi guys...just picked up web scrapping and watched a SCRAPY tutorial from freecodecamp and implementing on it a useless college project. </p> <p>Help me if with everything u would want to advice an ABSOLUTE BEGINNER ..is this domain even worth in putting in effort..can I use this skill to earn some money tbh...ROADMAP...how to use LLMs like gpt , claude to build scappings projects...ANY KIND OF WORDS would HELP </p> <p>PS : hate this html selector LOL...but loved pipeline preprocessing and how to rotate through a list of proxies , user agents , req headers part every time u make a request to the website stuff </",
        "id": 3654229,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1npdq2w/totally_new_to_web_scraping_dont_know_shit",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/FdFKAw6AtSGWunBXA0g-ziMMxTBQkERum3YGiIneQE8.jpg",
        "title": "Totally NEW to 'Web Scraping' !! dont know SHIT",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ok-Homework9186",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-24T22:57:02.688609+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-24T10:22:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m building a Telegram-first bargain-hunting bot network. Pilot is already live with working scrapers (eBay, Gumtree, CeX, MusicMagpie, Box, HUKD). The pipeline handles: scrape \u2192 normalize \u2192 filter \u2192 anchor (CeX/eBay sold) \u2192 score \u2192 Telegram alerts.</p> <p>I\u2019m looking for a developer partner to help scale: \u2022 Infra (move off local \u2192 VPS/cloud, Docker, monitoring) \u2022 Add new scrapers &amp; features (automation, seized goods, expansion sites) \u2022 Improve resilience (anti-bot, retries, dedupe)</p> <p>\ud83d\udca1 Revenue model: crypto subscriptions + VIP Telegram channels. The vision: build the go-to network for finding underpriced tech, with speed = profit.</p> <p>Not looking for a 9\u20135 contract \u2014 looking for someone curious, who likes web scraping/data engineering, and wants to grow a side-project into something serious.</p> <p>If you\u2019re into scraping, Telegram bots, crypto payments, and startups \u2192 let\u2019s chat.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href",
        "id": 3657679,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1np8gj6/dev_partner_wanted_telegram_bot_network_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dev Partner Wanted \u2013 Telegram Bot Network (Scraping + Crypto)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Upstairs-Public-21",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-24T12:46:58.804176+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-24T09:03:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I\u2019ve been working on some scraping projects recently, and I\u2019ve hit some IP bans and captchas along the way, which got me thinking\u2014am I stepping into legal or ethical grey areas? Just wanted to ask, how do you guys make sure your scraping is all good?</p> <p><strong>Here are some questions I\u2019ve got:</strong></p> <ul> <li><strong>Legal risks:</strong> Has anyone gotten into legal trouble because of scraping? How did you handle it?</li> <li><strong>Ethical scraping:</strong> What steps do you take to make sure you\u2019re scraping ethically? Do you follow robots.txt, throttle requests, etc.?</li> <li><strong>Data use:</strong> A lot of the data we scrape belongs to others\u2014how do you handle that? Do you check a site\u2019s terms of service before scraping?</li> <li><strong>Avoiding blocks:</strong> What are some tips for avoiding being blocked or flagged while scraping?</li> </ul> <p>Would love to hear how you all handle these things! Just tryi",
        "id": 3653059,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1np791k/legal_issues_while_scraping_how_do_you_stay_safe",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Legal issues while scraping? How do you stay safe?",
        "vote": 0
    }
]