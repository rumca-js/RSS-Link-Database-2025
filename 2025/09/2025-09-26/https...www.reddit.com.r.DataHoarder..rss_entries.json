[
    {
        "age": null,
        "album": "",
        "author": "/u/koriwi",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T22:06:59.500629+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T21:50:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys!<br/> I started to feel a bit uneasy with my current server storage setup. I do not frequent this sub, but I remembered you!</p> <p>My current server setup:</p> <p>Ryzen 5 3600<br/> 32GB RAM<br/> gtx 1070<br/> /: 512gb nvme ssd<br/> /opt/stacks (all general docker compose files and volumes): RAID1 2x1TB SATA SSD<br/> /opt/data (used for more important and bigger data like NVR): RAID1 2x4TB Endurance HDD<br/> /opt/unsafe (where i backup the torrents of my favorite linux distro ISOs, not a real problem if the drive fails) 1x16TB HDD</p> <p>For my current use case it is still ok. But I feel like i am less flexible like i would be with zfs or a different solution for example in case i want to add more camera. Or if i want to extend my library of linux distro ISOs or make those more secure (for the convenience of not needing to redownload up to 16tb in case of failure)</p> <p>I would really appreciate if you shoot me some ideas! from less to more e",
        "id": 3674006,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nre1rc/help_me_migrate_to_a_better_storage_solution_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help me migrate to a better storage solution for my server",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Nu_Wav",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T21:06:07.532406+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T20:46:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Bought 2 WD RED 24TB drives in march when they were on sale, and just got around to installing them today. The first one works fine, but the second one wont initialize and says &quot;request cannot be performed because of i/o device error&quot;. I&#39;ve tried using different cables and different ports, even the same ones that worked fine with the first drive. When I tried my other computer it would not even boot with the drive plugged in even though it works fine with the other one. I figure the drive is defective. I am just wondering since I am still in the warranty time but after 30 days will they only replace it with a refurbished drive even though the one I am sending back has never been used or initialized?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Nu_Wav\"> /u/Nu_Wav </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nrcj5v/wd_warranty/\">[link]</a></span> &#32; <span><a href=\"htt",
        "id": 3673629,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nrcj5v/wd_warranty",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WD warranty",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Jaded-Assignment6893",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T21:06:07.777598+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T20:17:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, hoping you could provide some advice on what I should do with my storage, I currently have 250gb ssd for os and applications. The other hard drives I have for media, documents and computing files (game ROMs, software, os isos etc) are;</p> <p>20tb, 10tb, 8tb, 4tb, 4tb and a few 2tb and 1tbs. </p> <p>Ideally I&#39;d like to keep all files on one disk, the 20tb then have the remaining discs as backups. </p> <p>I&#39;m currently using omv7 but will likely move over to proxmox + zemaos.</p> <p>My use case is jellyfin for video hosting, currently around 5tb but rapidly growing, navidrome for music hosting, currently around 1.5tb but growing and around 2.5tb of documents and computing. </p> <p>Ideally looking for advice on operating systems, software to manage the discs, filesystem&#39;s (currently ext4), backup configuration and scheduling and any other advise you might think helpful. </p> <p>Thanks in advance</p> </div><!-- SC_ON --> &#32; submitt",
        "id": 3673630,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nrbsq3/storage_software_advice",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Storage + software advice",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PricePerGig",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T20:04:02.460995+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T20:03:32+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PricePerGig\"> /u/PricePerGig </a> <br/> <span><a href=\"https://pricepergig.com/ebay-it\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nrbg3t/i_updated_pricepergigcom_to_add_ebayit_italy_as/\">[comments]</a></span>",
        "id": 3673264,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nrbg3t/i_updated_pricepergigcom_to_add_ebayit_italy_as",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I Updated PricePerGig.com to add \ud83c\uddee\ud83c\uddf9 eBay.it Italy \ud83c\uddee\ud83c\uddf9as requested in this sub",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ice_Black",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T20:04:02.673688+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T19:50:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m looking for advice from folks who use Duplicacy (or similar tools) for backing up large photo/video libraries plus documents.</p> <p>Here\u2019s what I\u2019m considering:</p> <p>-- Bucket A (Archive):</p> <p>One-off or infrequent backup of my entire photo/video/document library.</p> <p>Immutable / Object Lock enabled (Backblaze B2).</p> <p>No pruning, so it basically acts as a \u201ccold archive\u201d that can\u2019t be touched even if files are deleted or corrupted locally.</p> <p>-- Bucket B (Active / Rolling backup):</p> <p>Regular scheduled backups with Duplicacy.</p> <p>Versioned snapshots (daily/weekly).</p> <p>Prune policy to keep 90 days of dailies, then monthly snapshots forever.</p> <p>Object Lock optional (maybe shorter retention).</p> <p>The idea is: Bucket A = \u201cforever archive\u201d Bucket B = \u201ctime machine with rolling history\u201d</p> <p>Do you think this dual-bucket design makes sense for large, mostly-static media and documents? Or would you recommend something s",
        "id": 3673265,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nrb3sw/anyone_running_a_dualbucket_duplicacy_setup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone running a dual-bucket Duplicacy setup (immutable archive + rolling backup)?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TrashKitZee",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T20:04:03.726754+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T19:23:59+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nrafxz/thoughts_on_this_hard_drive/\"> <img src=\"https://preview.redd.it/niqyryz98krf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0be36e5a683a449b75af8e5719af47580ac8dc85\" alt=\"Thoughts on this hard drive\" title=\"Thoughts on this hard drive\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TrashKitZee\"> /u/TrashKitZee </a> <br/> <span><a href=\"https://i.redd.it/niqyryz98krf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nrafxz/thoughts_on_this_hard_drive/\">[comments]</a></span> </td></tr></table>",
        "id": 3673268,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nrafxz/thoughts_on_this_hard_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/niqyryz98krf1.jpeg?width=640&crop=smart&auto=webp&s=0be36e5a683a449b75af8e5719af47580ac8dc85",
        "title": "Thoughts on this hard drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Cingen",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T20:04:02.970926+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T19:23:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all! </p> <p>I recently started my own media server, and thought my beelink S12 mini pc with a 6TB external HDD would be more than big enough. I now realize how naive this was. </p> <p>I am looking into getting a DAS for external storage (since I already own a mini pc a NAS feels unneeded), and I keep seeing the Terramaster D4 320 being mentioned. </p> <p>This one is currently at the top of my list, but the D6 320 seems interesting as well. </p> <p>Between these two, does the D6 make more noise than the D4? How is the power consumption difference between the two? Just trying to understand why I see so much mention of the D4 but hardly any of the D6.</p> <p>My main criteria for the DAS are a USB connection, and low noise since it will be in our living room about 3-4 meters behind the couch we watch tv in. </p> <p>Low power consumption is handy as well since my goal is to save money long term with this setup (although I realize this may be naive), a",
        "id": 3673266,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nrafg6/new_to_big_data_storage_terramaster_d4_320_d6_320",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New to big data storage, Terramaster D4 320, D6 320 or something else for low noise?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/macclearich",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T20:04:01.424332+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T19:16:17+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nra8vp/warning_aoostar_wtr_max_seized_for_counterfeit/\"> <img src=\"https://preview.redd.it/shbgmb0d6krf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2e8185ba38a27213ac7e279d0ee24380d6e53b86\" alt=\"Warning: AOOSTAR WTR MAX Seized for Counterfeit Postage\" title=\"Warning: AOOSTAR WTR MAX Seized for Counterfeit Postage\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Well, this is new.</p> <p>Package has been &quot;in transit&quot; for two weeks and today, when I went to check on its status, I got this message. I don&#39;t know what&#39;s going on, I&#39;ve sent email to the addresses I know for them, but this looks pretty bad.</p> <p>Really, really glad I paid for this with a credit card.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/macclearich\"> /u/macclearich </a> <br/> <span><a href=\"https://i.redd.it/shbgmb0d6krf1.png\">[link]</a></span> &#32; <span><a href=\"https",
        "id": 3673262,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nra8vp/warning_aoostar_wtr_max_seized_for_counterfeit",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/shbgmb0d6krf1.png?width=640&crop=smart&auto=webp&s=2e8185ba38a27213ac7e279d0ee24380d6e53b86",
        "title": "Warning: AOOSTAR WTR MAX Seized for Counterfeit Postage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/comicgopher",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T20:04:03.176368+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T19:12:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hoping someone has some experience used Pinchflat on a Ugreen NAS and are able to help. I&#39;ve downloaded 300gb of video with Pinchflat and can see it through the built in interface however I cannot locate it anywhere on my NAS. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/comicgopher\"> /u/comicgopher </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nra5o3/needing_help_with_pinchflat_and_ugreen_nas_cant/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nra5o3/needing_help_with_pinchflat_and_ugreen_nas_cant/\">[comments]</a></span>",
        "id": 3673267,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nra5o3/needing_help_with_pinchflat_and_ugreen_nas_cant",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Needing help with Pinchflat and Ugreen NAS - can't find files",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BlackBerryCollector",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T20:04:01.848082+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T19:05:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://burglaralarmbritain.wordpress.com/index\">https://burglaralarmbritain.wordpress.com/index</a></p> <p>HTTrack is too slow and seems to duplicate images. I&#39;m on Win7 but can also use Win11.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BlackBerryCollector\"> /u/BlackBerryCollector </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr9z6w/how_do_i_download_all_pages_and_images_on_this/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr9z6w/how_do_i_download_all_pages_and_images_on_this/\">[comments]</a></span>",
        "id": 3673263,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr9z6w/how_do_i_download_all_pages_and_images_on_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do I download all pages and images on this site as fast as possible?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/RaKouKuRz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T21:06:08.122963+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T18:50:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>Previously, I had a WD Red Plus 12TB with 256MB of cache. When I saw that there was a version with 512MB of cache, I bought the 512 version, thinking that the drive would be better and that it would make the same noise. Imagine my surprise when I realized that during a full load, it literally sounds like someone is knocking on my door or hammering away 5 meters from my NAS. In short, where I live, the WD Red Plus 12TB 256MB drives are almost unavailable, or very expensive (~80-100\u20ac more than two weeks ago). In your opinion, what is the quietest HDD currently available?</p> <p>Thank you in advance for your answers =)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/RaKouKuRz\"> /u/RaKouKuRz </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr9kvs/current_quietest_hdd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr9kvs/current_quietest_hdd/\"",
        "id": 3673631,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr9kvs/current_quietest_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Current quietest HDD?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/username-_redacted",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T19:02:01.356771+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T18:47:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m new to RHash and playing around with various settings in preparation for cataloging some large file sets. I picked a folder with about 10000 files in it totaling 1 GB to see how long various options took. The first time through that created an SFV file (albeit using MD5) in about 200 seconds. The strange thing is that the second time through it took 20 seconds with the same settings. In between I closed the command prompt and renamed the hash file. I&#39;m assuming this means that the results of the hashing is still in memory somewhere and so it&#39;s not recalculating. Changing the directory name does not change the outcome -- still only takes 20 seconds.</p> <p>I know it&#39;s weird to be complaining about it being <em>too fast</em> but other than rebooting the machine is there another way to get rhash to behave like it hasn&#39;t already hashed the files?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user",
        "id": 3672883,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr9i16/how_to_make_rhash_forget_what_it_knows_and_start",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to make RHash forget what it knows and start from scratch",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Few-Gas-8147",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T19:02:01.063000+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T18:30:05+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr91yq/i_indexed_1m_reddit_posts_and_built_a_visual/\"> <img src=\"https://preview.redd.it/iqsjydilxjrf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0a349f7456642d9e2609c3a186cf9ed700868713\" alt=\"I indexed 1M+ Reddit posts and built a visual search engine\" title=\"I indexed 1M+ Reddit posts and built a visual search engine\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey! Thought some of you might be interested in this project I&#39;ve been working on.</p> <p>I&#39;ve indexed ~1 million Reddit posts containing images, GIFs and videos from 587 subreddits, so far.</p> <p>Because every image, GIF, and video is embedded, I&#39;m able to provide a search feature that &quot;understands&quot; the content instead of relying only on titles or tags. So you can search Reddit posts with queries like &quot;man eating in the dark&quot; or &quot;drawing of city skyline&quot;, and filter by subreddit, time, NSFW/SFW, a",
        "id": 3672882,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr91yq/i_indexed_1m_reddit_posts_and_built_a_visual",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/iqsjydilxjrf1.png?width=640&crop=smart&auto=webp&s=0a349f7456642d9e2609c3a186cf9ed700868713",
        "title": "I indexed 1M+ Reddit posts and built a visual search engine",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TinderSubThrowAway",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T19:02:01.474769+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T18:18:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, how do you handle it?</p> <p>I have things setup with each artist having a folder, then in that folder I have their albums and then any songs I have not on an album I just have listed in the folder directly, and then also a secondary Live folder for live stuff, which is usually broken down into events under that.</p> <p>I also have a OMPS and Compilation folder, so like Armageddon OMPS is in the OMPS folder or Grammy Nominees 1998 or Now! That&#39;s What I call Music 87398 is in the Complication folder.</p> <p>What if you have a song from one the OMPS or Complations on the original album of the artist? So if your dedupe software picks them up, do you keep both? or just the original album?</p> <p>Additionally, if you don&#39;t have the song in the original artist folder at all, would you make a second copy there?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TinderSubThrowAway\"> /u/TinderSubThrowAway </a> <b",
        "id": 3672884,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr8rcp/how_do_you_handle_multiples_of_same_song",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you handle multiples of same song, different albums?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/therealwalterwhiter",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T21:06:08.338728+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T17:53:10+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr84eb/ytdlp_no_longer_working/\"> <img src=\"https://external-preview.redd.it/7hrTWaOEHw7ZKapzaCYbe9q7lihvu2Q0PCRue6jaFRk.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0de2b936e79f779fc7bb33ff9abde3988823de09\" alt=\"YT-DLP no longer working?\" title=\"YT-DLP no longer working?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/ps8rxnyrqjrf1.png?width=1906&amp;format=png&amp;auto=webp&amp;s=e28cdbb9e9468d6ac5cef6f2c5e34d6229ebbb19\">https://preview.redd.it/ps8rxnyrqjrf1.png?width=1906&amp;format=png&amp;auto=webp&amp;s=e28cdbb9e9468d6ac5cef6f2c5e34d6229ebbb19</a></p> <p>yt-dlp was working fine for me the other day, then I installed Dino to combat the eventual blocking as per <a href=\"https://www.reddit.com/r/DataHoarder/comments/1npxkek/google_will_soon_break_all_thirdparty_yt_clients/\">https://www.reddit.com/r/DataHoarder/comments/1npxkek/google_will_soon_break_all_thirdparty_yt_c",
        "id": 3673632,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr84eb/ytdlp_no_longer_working",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/7hrTWaOEHw7ZKapzaCYbe9q7lihvu2Q0PCRue6jaFRk.png?width=640&crop=smart&auto=webp&s=0de2b936e79f779fc7bb33ff9abde3988823de09",
        "title": "YT-DLP no longer working?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ailothaen",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T17:00:11.153904+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T16:31:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>I have around 2 TB of data on a NAS. I use the second disk of the NAS as the backup medium for the first one: every week, a snapshot of the changes is taken, so that I can rollback to it (or restore specific files) if needed. I am also used to borg and use it for backup of Linux systems.</p> <p>Now, I am trying to fill the &quot;1&quot; of the 3-2-1 strategy, and I need to think of a cold storage method. I have several old 2.5&quot; drives laying around, and I was thinking of using two of them (1 TB each) to put a copy of the first disk like once or twice a year, and then store the box of disks at a relative or friend&#39;s house, to ensure I still have something in case of a robbery or a fire for example.</p> <p>However, I wonder how to do that properly. Especially, I would have two questions: - What is a simple and robust way of aggregating several disks together as a single medium for backup purposes? - I am intending of encr",
        "id": 3672048,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr60r1/advice_needed_for_cold_archival_on_several_old",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Advice needed for cold archival on several old hard drives with encryption",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Zaidk9",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T17:00:11.861381+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T16:05:24+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr5bw4/seagate_4tb_health_fell_to_0_need_to_recover_also/\"> <img src=\"https://preview.redd.it/b8o2usst8jrf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cbe057ff8c671695ccdcf4704e97c2a08fa2c590\" alt=\"Seagate 4tb health fell to 0%. Need to recover. Also i cant open as t6 is smaller than this screw. Which screwdriver to use for this?\" title=\"Seagate 4tb health fell to 0%. Need to recover. Also i cant open as t6 is smaller than this screw. Which screwdriver to use for this?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Out of the ble the drive health went to 0%. No phycal damage. It was an external drive. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Zaidk9\"> /u/Zaidk9 </a> <br/> <span><a href=\"https://i.redd.it/b8o2usst8jrf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr5bw4/seagate_4tb_health_fell_to_0_need_to_rec",
        "id": 3672049,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr5bw4/seagate_4tb_health_fell_to_0_need_to_recover_also",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/b8o2usst8jrf1.jpeg?width=640&crop=smart&auto=webp&s=cbe057ff8c671695ccdcf4704e97c2a08fa2c590",
        "title": "Seagate 4tb health fell to 0%. Need to recover. Also i cant open as t6 is smaller than this screw. Which screwdriver to use for this?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SirWillem1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T17:00:10.900630+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T16:03:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>does anyone have a backup of it? i have the PerfectDisk program but it&#39;s kinda hard to use when all resources for it are gone.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SirWillem1\"> /u/SirWillem1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr5a6i/perfectdisk_websiteforum_backuprequest/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr5a6i/perfectdisk_websiteforum_backuprequest/\">[comments]</a></span>",
        "id": 3672047,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr5a6i/perfectdisk_websiteforum_backuprequest",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "PerfectDisk website/forum backup(request)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Either_External_7937",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T21:06:08.770671+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T14:54:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How can you download photo and video from fantrie? There are downloaders for sites like onlyfans and patreon, but I can&#39;t find a fantrie downloader no matter how hard I search. How on earth do you get the photos and videos from fantrie?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Either_External_7937\"> /u/Either_External_7937 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr3hl9/how_to_download_from_fantrie/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr3hl9/how_to_download_from_fantrie/\">[comments]</a></span>",
        "id": 3673633,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr3hl9/how_to_download_from_fantrie",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to download from fantrie",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/xnbxb",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T15:56:25.653109+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T14:54:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><ul> <li>On the right side of <a href=\"https://www.hellomolly.com/collections/swim/products/floral-tides-swim-bottom-white-floral\">this page</a>, there is a part where it says &quot;As Seen On&quot; and there is a video underneath.</li> <li>How do I download videos like this?</li> </ul> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/xnbxb\"> /u/xnbxb </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr3h68/tolstoy_video_from_hellomollycom/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr3h68/tolstoy_video_from_hellomollycom/\">[comments]</a></span>",
        "id": 3671513,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr3h68/tolstoy_video_from_hellomollycom",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tolstoy video from hellomolly.com",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ReeRead",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T13:47:45.433683+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T13:29:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Split into parts on Windows</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ReeRead\"> /u/ReeRead </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr1e17/what_app_can_split_large_disk_image_dmg_files/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr1e17/what_app_can_split_large_disk_image_dmg_files/\">[comments]</a></span>",
        "id": 3670489,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr1e17/what_app_can_split_large_disk_image_dmg_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What app can split large disk image .dmg files?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LINUXisobsolete",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T13:47:44.877204+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T13:02:34+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr0s3k/ive_just_uploaded_900_images_of_the_production_of/\"> <img src=\"https://external-preview.redd.it/gfK_VbdxO0hy-zoxJc_4XQ-R9NciSnAoyK-eBHgxEwo.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=59b72374b9bc50b4c6a5bb80aafd12564cc49981\" alt=\"I've just uploaded 900+ images of the production of &quot;Clash of the Titans&quot; (2010) to the Internet Archive.\" title=\"I've just uploaded 900+ images of the production of &quot;Clash of the Titans&quot; (2010) to the Internet Archive.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LINUXisobsolete\"> /u/LINUXisobsolete </a> <br/> <span><a href=\"https://archive.org/details/dsc-0067-3\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr0s3k/ive_just_uploaded_900_images_of_the_production_of/\">[comments]</a></span> </td></tr></table>",
        "id": 3670487,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr0s3k/ive_just_uploaded_900_images_of_the_production_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/gfK_VbdxO0hy-zoxJc_4XQ-R9NciSnAoyK-eBHgxEwo.jpeg?width=108&crop=smart&auto=webp&s=59b72374b9bc50b4c6a5bb80aafd12564cc49981",
        "title": "I've just uploaded 900+ images of the production of \"Clash of the Titans\" (2010) to the Internet Archive.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/REDDIT-XDND",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T13:47:45.003282+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T12:47:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Planning to get JottaCloud </p> <p>What can happen if I upload pirated movies BUT DON&#39;T share them with others?<br/> I have edited all tracks, including the SRT file, so that it does not contain where the file was downloaded from.</p> <p>Do they just close the account and the money is lost?</p> <p>Or will I be reported to the authorities and I have to look forward to a fine?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/REDDIT-XDND\"> /u/REDDIT-XDND </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr0fg0/movies_and_nsfw_movies_on_cloud_services/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nr0fg0/movies_and_nsfw_movies_on_cloud_services/\">[comments]</a></span>",
        "id": 3670488,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nr0fg0/movies_and_nsfw_movies_on_cloud_services",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Movies and NSFW movies on Cloud services ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/rymsjr",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T08:25:57.677401+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T08:19:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Seriously, I\u2019ve got so many GoPro and action cam videos that I don\u2019t even know where half of them are. External drives are starting to pile up everywhere \ud83d\ude05 Has anyone found a good system for storing everything without breaking the bank?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/rymsjr\"> /u/rymsjr </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nqvr6y/quick_question_how_do_you_guys_manage_terabytes/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nqvr6y/quick_question_how_do_you_guys_manage_terabytes/\">[comments]</a></span>",
        "id": 3668740,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nqvr6y/quick_question_how_do_you_guys_manage_terabytes",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Quick question: how do you guys manage terabytes of GoPro/action cam videos? My external drives are a mess\u2026",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Macestudios32",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T07:11:06.109509+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T07:00:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>In view of the prices of hard drives and their increase in price, I am starting to consider using LTO tapes. </p> <p>I have to say that I am totally ignorant in this system. </p> <p>In terms of price/cost ratio, does it compensate? Which generations of LTO are more compensating in current times? </p> <p>Taking into account current file sizes and price. </p> <p>I know that there are two capacities, the normal and the compressed. If for example I wanted to save videos or LLM would I follow the typical compression rule? That is, 1 TB 500 GB compressed...... </p> <p>Have your say, recommend, talk!</p> <p>Thanks a lot</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Macestudios32\"> /u/Macestudios32 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nquk7a/thinking_about_lto/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nquk7a/thinkin",
        "id": 3668273,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nquk7a/thinking_about_lto",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Thinking about LTO",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Milo_007",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T07:11:06.229079+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T06:53:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Greetings to all, </p> <p>I am looking to expand my storage with a SATA SSD. 2 of 6 SATA ports on my motherboard are not in use currently. My PC case has only two hard drive mounts &amp; I have two Crucial MX500s already plugged in. Since high end consumer grade SATA SSDs (TLC with DRAM cache) are going out of market rapidly, I plan to pick one soon for some additional storage populating one of my unused SATA ports. In my country, the notable options which are still available at the 2TB range are: </p> <ol> <li>Samsung 870 EVO</li> <li>WD Red SA500</li> <li>Kingston KC600</li> </ol> <p>I am avoiding Samsung 870 EVO due to widespread reported issues of data corruption and high failure rates. So it has come down to choosing between WD Red SA500 vs Kingston KC600. I wish the Crucial MX500 (2TB) was still around for sale but unfortunately it&#39;s out of stock everywhere. </p> <p>Anybody having experience with either of them, please suggest the better pic",
        "id": 3668274,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nquftm/best_pick_kingston_kc600_vs_wd_red_sa500",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best Pick - Kingston KC600 vs WD Red SA500",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/736384826",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T07:11:06.416452+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T06:25:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I\u2019m moving to another country permanently and I have a lot of old HDDs laying around and I want to backup everything in there to one secure place, ideally offline, and keep for years and occasionally add stuff to it. I was thinking of an external HDD like WD My Book 8TB, I\u2019m not sure if it\u2019s the right choice or have something else to recommend or give any advice. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/736384826\"> /u/736384826 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nqu03l/best_way_to_backup_music_documents_photos_videos/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nqu03l/best_way_to_backup_music_documents_photos_videos/\">[comments]</a></span>",
        "id": 3668275,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nqu03l/best_way_to_backup_music_documents_photos_videos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best way to backup music, documents, photos, videos etc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Letterhead-Dear",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T06:08:54.225889+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T05:57:19+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Letterhead-Dear\"> /u/Letterhead-Dear </a> <br/> <span><a href=\"/r/lostmedia/comments/1nqm2kq/archival_im_looking_for_a_youtube_video_any_help/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nqtj7g/archival_im_looking_for_a_youtube_video_any_help/\">[comments]</a></span>",
        "id": 3667960,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nqtj7g/archival_im_looking_for_a_youtube_video_any_help",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[archival] I\u2019m looking for a YouTube video, any help is appreciated",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/bristolfarms",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T06:08:53.062630+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T05:10:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i have a WD passport that my mac can&#39;t read. it&#39;s in exfat format and my PC can read it. i reached out to support and they said this: &quot;it has &quot;File System check exit code-1&quot; which means a Mac is not a standard error message and may refer to various issues, but it most likely indicates a problem with disk permissions, a corrupt file system, or an issue with the APFS (Apple File System) itself. In order to resolve the issue, I would suggest you to connect the drive to your other computer and then backup the data on the drive, and then Reformat the drive into Apfs file system&quot;</p> <p>i did buy a new WD passport 4TB, which is the same model as my corrupted original one. i read that exfat format is easily corrupted - is there a way to mitigate this? i eject it every time and i used it a few months ago, so i&#39;m confused as to what happened. i can only transfer everything on my PC but otherwise, i primarily use a macbook. shoul",
        "id": 3667958,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nqsrlv/mac_cant_read_external_hard_drive_but_pc_can_what",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "mac can't read external hard drive, but PC can. what is a good solution for backing everything up?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PsychologicalTap1541",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T06:08:53.356339+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T05:08:44+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nqsqb4/github_websitecrawler_extract_data_from_websites/\"> <img src=\"https://external-preview.redd.it/RP_5WJQ2R9zAGFMU7y3eS1YADzqcFS69iAGZC5WPypI.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7dcea4e8e5b79c8714b189e242ad238f5cbf878b\" alt=\"GitHub - Website-Crawler: Extract data from websites in LLM ready JSON or CSV format. Crawl or Scrape entire website with Website Crawler\" title=\"GitHub - Website-Crawler: Extract data from websites in LLM ready JSON or CSV format. Crawl or Scrape entire website with Website Crawler\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PsychologicalTap1541\"> /u/PsychologicalTap1541 </a> <br/> <span><a href=\"https://github.com/pc8544/Website-Crawler\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nqsqb4/github_websitecrawler_extract_data_from_websites/\">[comments]</a></span> </td></tr></table>",
        "id": 3667959,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nqsqb4/github_websitecrawler_extract_data_from_websites",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/RP_5WJQ2R9zAGFMU7y3eS1YADzqcFS69iAGZC5WPypI.png?width=640&crop=smart&auto=webp&s=7dcea4e8e5b79c8714b189e242ad238f5cbf878b",
        "title": "GitHub - Website-Crawler: Extract data from websites in LLM ready JSON or CSV format. Crawl or Scrape entire website with Website Crawler",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Viewlesslight",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T03:02:56.996895+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T02:47:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hopefully this is an appropriate question for this sub. Im expanding my unraid server with my first large hdd. I mainly use it as a nas and plex server. For roughly the same price I can get either an exos 12tb or a Barracuda 20tb. They both seem to be CMR. as far as I can tell SMR seems to be the biggest downside of cheaper drives. Is there any reason I shouldn&#39;t go for the 20tb option?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Viewlesslight\"> /u/Viewlesslight </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nqq49e/seagate_exos_12tb_or_barracuda_20tb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nqq49e/seagate_exos_12tb_or_barracuda_20tb/\">[comments]</a></span>",
        "id": 3667060,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nqq49e/seagate_exos_12tb_or_barracuda_20tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seagate exos 12tb or Barracuda 20tb",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PetrusNlt",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T04:04:09.114573+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T01:33:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Sep 2025 \u2013 Fully Working Solution</strong></p> <p>Guys, this is the sum of many hours trying to recover some old AVI videos from an old Vivitar camera with (very) cryptic and old codecs.<br/> In the end, i succeed and the following is the result of the saga.</p> <p>hope to index this in the search engines and help other desperate guys like i was trying to solve this.</p> <p>----------------------------------------------------------</p> <h1>\u2705 THE PROBLEM:</h1> <p>Old AVI files recorded with the <strong>Vivitar Vivicam 10</strong> (early 2000s) use a proprietary codec called:</p> <p><strong>GTCC \u2013 Grand Tech Camera Codec</strong></p> <p>These files don\u2019t play in modern players (VLC, WMP, etc.), and give errors even in VirtualDub like:</p> <p><em>&quot;Couldn&#39;t locate decompressor for format &#39;GTCC&#39; (unknown)&quot;</em></p> <p>The codec is not supported by ffmpeg, ffdshow, or any current DirectShow/VFW filters. Even installing the orig",
        "id": 3667427,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nqon5g/how_to_recover_and_convert_vivitar_vivicam_10_avi",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to Recover and Convert Vivitar Vivicam 10 AVI Files Using the GTCC Codec (Grand Tech Camera Codec)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/nilz_bilz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-26T02:01:27.071516+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-26T01:20:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been running a mini PC with Proxmox as a home server for learning and testing. ( Thinkcenter i5 6500T 32gb RAM). This currently has only 1 boot SSD.</p> <p>I want to build a NAS, and want to get some drives to start collecting media that I care about (Music, Movies, Books, Website archives, etc). </p> <p>I&#39;m a student in Australia, so I thought I&#39;d get started with second hand/used drives for now to stay within a tighter budget. </p> <p>My current machine doesn&#39;t have additional drive bays, so I was wondering whether I should hook up a USB DAS, or just buy USB HDDs instead? I presume there&#39;s a difference in reliability but would like to get some opinions on how I should go about this. </p> <p>Additionally, I&#39;d like to get some guidance on: - Where to get good second hard drives (in Aus) - What to look for when buying used drives? - What would be the best way to setup the NAS? I was thinking of running TrueNAS or Open media",
        "id": 3666823,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nqodde/guidance_on_building_a_nas_on_a_budget_australia",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Guidance on building a NAS (on a budget - Australia)",
        "vote": 0
    }
]