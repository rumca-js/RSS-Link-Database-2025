[
    {
        "age": null,
        "album": "",
        "author": "/u/pineguy64",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T23:46:48.374819+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T23:11:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Posts directly related to data removal by a government agency are inherently relevant to datahorders, despite the involvement of politics. Removal of political posts unrelated to datahoarding make sense, but mods are removing directly relevant stories due to involvement of politics.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/pineguy64\"> /u/pineguy64 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1niwwcj/data_removal_by_government_agencies_is_inherently/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1niwwcj/data_removal_by_government_agencies_is_inherently/\">[comments]</a></span>",
        "id": 3592472,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1niwwcj/data_removal_by_government_agencies_is_inherently",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Data removal by government agencies is inherently a datahording issue despite politics involvement",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Lord_Muddbutter",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T22:46:09.880252+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T22:22:38+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nivqgk/michigan_gop_bill_aims_to_ban_pornography_online/\"> <img src=\"https://external-preview.redd.it/goRaQKzvN7_efee74u3Hh_DYIU2GQvjcKrCYD9EAYC0.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f8e74f2d92d3668fe3f7d2c5f2017b79a859531\" alt=\"Michigan GOP bill aims to ban pornography online, including content on &quot;disconnection between biology and gender&quot;\" title=\"Michigan GOP bill aims to ban pornography online, including content on &quot;disconnection between biology and gender&quot;\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Stash exists for a reason people!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lord_Muddbutter\"> /u/Lord_Muddbutter </a> <br/> <span><a href=\"https://www.cbsnews.com/detroit/news/michigan-republican-bill-aims-to-ban-pornography-online/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nivqgk/mi",
        "id": 3592150,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nivqgk/michigan_gop_bill_aims_to_ban_pornography_online",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/goRaQKzvN7_efee74u3Hh_DYIU2GQvjcKrCYD9EAYC0.jpeg?width=640&crop=smart&auto=webp&s=5f8e74f2d92d3668fe3f7d2c5f2017b79a859531",
        "title": "Michigan GOP bill aims to ban pornography online, including content on \"disconnection between biology and gender\"",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mahsyn",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T20:38:17.523879+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T20:02:06+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nis3u9/sortanything_oraganize_your_hoarded_stuff/\"> <img src=\"https://external-preview.redd.it/Aq4plHp76aqgA2gxsXK61U847lK-xrKXK7vijO3Poaw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=efa69c660022033f0b3ee540a8062f271ac62341\" alt=\"SortAnything: Oraganize your Hoarded Stuff\" title=\"SortAnything: Oraganize your Hoarded Stuff\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><h1>Why You Need SortAnything</h1> <ul> <li><strong>Cluttered folders slowing you down?</strong> If you\u2019ve ever stared at a messy folder full of downloads, documents, or images, paralyzed by the thought of sorting it all, SortAnything simplifies the process. <strong>Just select your files, set up your categories, and start sorting</strong>\u2014file by file, as fast as you can decide.</li> <li><strong>Ever wanted to assign files to folders just by pressing a key?</strong> With SortAnything, you can. Instead of dragging and dropping, <strong>assig",
        "id": 3591264,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nis3u9/sortanything_oraganize_your_hoarded_stuff",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/Aq4plHp76aqgA2gxsXK61U847lK-xrKXK7vijO3Poaw.png?width=640&crop=smart&auto=webp&s=efa69c660022033f0b3ee540a8062f271ac62341",
        "title": "SortAnything: Oraganize your Hoarded Stuff",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Glass_Interaction_40",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T20:38:17.650888+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T19:55:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I\u2019ve been reading about people corrupting their drives when an unexpected reboot of pc or external drive disconnect occurred, so I wanted to ask here if I should be worried. I have Seagate Expansion 5 TB encrypted with veracrypt. I was using it in my Linux VM and downloading a file and saving straight to it when my laptop shut down (stupid me had forgotten to turn off a shutdown timer I\u2019d set earlier in the day, so when I came back, the laptop was off lol). I booted it back up and mounted the drive. The file that was downloading didn\u2019t finish because of the shutdown, but that\u2019s not a big deal I can redownload it. What I\u2019m worried about is whether any data got corrupted. At first glance everything seems fine, every file I try to open opens normally and seems fine. But I\u2019m concerned that there could be some small, hidden corruption somewhere. Since I\u2019ll be mirroring this drive to another as a backup, I don\u2019t want to copy over any corrupted files but",
        "id": 3591265,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nirxej/should_i_be_worried_about_data_corruption",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Should I be worried about data corruption?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/palepatriot76",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T18:32:14.817642+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T18:31:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I have a couple big TV DVD sets. I want to create ISO files so I can make disks if need be, or even make MKV files from the ISO for myself</p> <p>I made a couple ISO files from a few disks to test. Used an older DVD FAB, like version 9, did 100% conversions (DVD9) and so far the few I have done look just like the original DVD&#39;s</p> <p>So curious if other most programs are the same, some better, worse than what I am using to save time before I five into doing this with 100+ DVD&#39;s</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/palepatriot76\"> /u/palepatriot76 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nipn9w/are_all_programs_about_the_same_for_quality_when/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nipn9w/are_all_programs_about_the_same_for_quality_when/\">[comments]</a></span>",
        "id": 3590297,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nipn9w/are_all_programs_about_the_same_for_quality_when",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are all programs about the same for quality when creating ISO file backups?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/flaccidcomment",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T18:32:15.095786+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T18:13:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to archive pages from <a href=\"https://examples.libsdl.org/SDL3/\">https://examples.libsdl.org/SDL3/</a> for offline viewing but I can&#39;t. I&#39;ve tried httrack and wget.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/flaccidcomment\"> /u/flaccidcomment </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nip5gk/how_do_you_save_pages_which_use_web_assembly/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nip5gk/how_do_you_save_pages_which_use_web_assembly/\">[comments]</a></span>",
        "id": 3590298,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nip5gk/how_do_you_save_pages_which_use_web_assembly",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you save pages which use web assembly?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Deathenglegamers1144",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T18:32:16.318181+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T18:12:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.reddit.com/r/Piracy/s/rn9Rt6ksL1\">https://www.reddit.com/r/Piracy/s/rn9Rt6ksL1</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Deathenglegamers1144\"> /u/Deathenglegamers1144 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nip4lc/is_anyone_gonna_data_hoarding_this_website/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nip4lc/is_anyone_gonna_data_hoarding_this_website/\">[comments]</a></span>",
        "id": 3590301,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nip4lc/is_anyone_gonna_data_hoarding_this_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is anyone gonna data hoarding this website?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/YouthProfessional739",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T18:32:15.374162+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T17:57:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I don&#39;t know about you, but as of today, I can no longer download TikToks in HD. All the sites I knew are now limited to 540p.<br/> TikWM and Tikdownloader are no longer in HD. Has anyone managed to find a site where it&#39;s still possible?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/YouthProfessional739\"> /u/YouthProfessional739 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1niop4b/unable_to_download_tiktoks_in_hd_starting_today/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1niop4b/unable_to_download_tiktoks_in_hd_starting_today/\">[comments]</a></span>",
        "id": 3590299,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1niop4b/unable_to_download_tiktoks_in_hd_starting_today",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Unable to download TikToks in HD starting today",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/FauxReal",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T18:32:14.196979+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T17:55:47+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nions3/doj_deletes_domestic_terrorist_study/\"> <img src=\"https://external-preview.redd.it/GFEHBp-wiLSMt4Y2Kv8fJUomMt61pYG-myaE7kZNCuc.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b73a85206541661bdd74d4d5318e832da7de9ff8\" alt=\"DOJ Deletes Domestic Terrorist Study\" title=\"DOJ Deletes Domestic Terrorist Study\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/FauxReal\"> /u/FauxReal </a> <br/> <span><a href=\"https://www.404media.co/doj-deletes-study-showing-domestic-terrorists-are-most-often-right-wing\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nions3/doj_deletes_domestic_terrorist_study/\">[comments]</a></span> </td></tr></table>",
        "id": 3590296,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nions3/doj_deletes_domestic_terrorist_study",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/GFEHBp-wiLSMt4Y2Kv8fJUomMt61pYG-myaE7kZNCuc.jpeg?width=640&crop=smart&auto=webp&s=b73a85206541661bdd74d4d5318e832da7de9ff8",
        "title": "DOJ Deletes Domestic Terrorist Study",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Amareiuzin",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T18:32:15.693865+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T17:29:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>When pasting files to a directory, and said files are found at the directory, we have the option to overwrite/skip them.<br/> Overwriting takes more time and is not needed for me.<br/> Skipping is what I want for such cases, although the skipped files aren&#39;t only skipped on the copy process, but also skipped on the delete process, which happens right after.<br/> I assume this is a know behaviour, so is there any known way to enforce all cut files to be deleted after the paste is succesful, including those which were skipped due to them already being present at the destination?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Amareiuzin\"> /u/Amareiuzin </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ninx4w/teracopy_cut_and_paste_behaviour/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ninx4w/teracopy_cut_and_paste_behaviour/\">[comments]</a></span",
        "id": 3590300,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ninx4w/teracopy_cut_and_paste_behaviour",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "teracopy cut and paste behaviour",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MantaManfred",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T17:27:45.858848+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T17:09:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone, </p> <p>Recently, I have had a large amount of data that I want to transfer and store. Now my hard drive is nearing the end of its life and I need an alternative to protect and back up my data in the long term. </p> <p>I myself have little to no idea what the best way would be. </p> <p>This is because I need to manage documents, images and YouTube videos. Some data is, of course, only temporary. </p> <p>There are now two of us who need to access the storage and require filing and organisation systems. </p> <p>I would like something energy-efficient that doesn&#39;t break the bank and can be expanded in the long term. </p> <p>The solution seems to be a NAS, and I have selected the following. I would appreciate your input.</p> <ol> <li>Ugreen NASync DH4300 Plus 4 Bay </li> <li>Ugreen NASync DXP4800 4 Bay </li> <li>Synology Beestation </li> </ol> <p>Everything helps! Thanks in Advance! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a",
        "id": 3589716,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nind9d/new_to_data_hoarding_and_dont_know_where_to_start",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New to Data hoarding and don\u2019t know where to start",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/panpoppular",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T15:21:36.041014+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T15:03:11+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nijz0p/learned_hard_way_that_do_not_clean_label_with_95/\"> <img src=\"https://preview.redd.it/orsnjfp5jjpf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=43855728292bc908c5d9a40946aa03211ea90177\" alt=\"Learned hard way that DO NOT Clean label with 95% Ethanol\" title=\"Learned hard way that DO NOT Clean label with 95% Ethanol\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Attempted to clean stains on label that wont come off with water, this is the result after using 95% ethanol with few heavy wipes.</p> <p>The drive is still working fine.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/panpoppular\"> /u/panpoppular </a> <br/> <span><a href=\"https://i.redd.it/orsnjfp5jjpf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nijz0p/learned_hard_way_that_do_not_clean_label_with_95/\">[comments]</a></span> </td></tr></table>",
        "id": 3588489,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nijz0p/learned_hard_way_that_do_not_clean_label_with_95",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/orsnjfp5jjpf1.jpeg?width=640&crop=smart&auto=webp&s=43855728292bc908c5d9a40946aa03211ea90177",
        "title": "Learned hard way that DO NOT Clean label with 95% Ethanol",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/milestfbaxxter",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T15:21:36.510316+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T14:51:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Pretty sure I&#39;ll be settling on a DPX2800 NAS from Ugreen to store my dara hoarding/creating. So now is the question which hard drive to get. (Only starting with one, money be tight.) So here&#39;s another &quot;which HD to get&quot; post! Here are the ones I&#39;ve been considering from what&#39;s available in my country (Norway) and within my price range.</p> <p><a href=\"https://www.proshop.no/Harddisk/Toshiba-N300-18TB-Harddisk-HDWG51JUZSVA-SATA-600-35/3024325\">Toshiba N300 18TB (HDWG51JUZSVA)</a> ~ $390<br/> <a href=\"https://www.computersalg.no/i/20303572/exos-x24-16tb-hdd-512e-4kn-sata-12gb\">Seagate Exos X24 16TB (ST16000NM002H)</a> ~ $410<br/> <a href=\"https://www.computersalg.no/i/8701882/seagate-ironwolf-pro-st16000nt001-harddisk-16-tb-intern-3-5-sata-6gb-s-7200-rpm-buffer-256-mb-med-3-%C3%A5rs-seagate-rescue-data\">Seagate IronWolf Pro 16TB (ST16000NT001)</a> ~ $410<br/> <a href=\"https://www.dustinhome.no/product/5011230705/red-pro-16tb\">W",
        "id": 3588490,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nijnsb/considering_hdd_for_a_ugreen_dpx2800_nas_thoughts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Considering HDD for a Ugreen DPX2800 NAS, thoughts appreciated!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PaganofFilthy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T19:36:43.040421+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T14:30:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Since I can&#39;t find a way to bulk download the databse in sci-hub, what is the smartest way to go about this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PaganofFilthy\"> /u/PaganofFilthy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nij43b/im_looking_to_download_the_top_1000_at_least/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nij43b/im_looking_to_download_the_top_1000_at_least/\">[comments]</a></span>",
        "id": 3590779,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nij43b/im_looking_to_download_the_top_1000_at_least",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I'm looking to download the top 1000 (at least) famous scientific journals / articles per subject (Psychologoy / Economics)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ZestycloseRabbit7039",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T15:21:36.832468+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T14:26:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I currently have a server running unraid with 150 TB of used storage. I\u2019ve become unhappy with the speed and I\u2019ve heard truenas has better transfer speeds. I\u2019m wanting to migrate my OS over and I don\u2019t want to lose all my data. I know the transfer up and down will take awhile and will incur costs. Does anyone have any experience with temporary online storage for a move such as this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ZestycloseRabbit7039\"> /u/ZestycloseRabbit7039 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1niizey/temporary_online_storage_for_os_change_on_server/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1niizey/temporary_online_storage_for_os_change_on_server/\">[comments]</a></span>",
        "id": 3588491,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1niizey/temporary_online_storage_for_os_change_on_server",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Temporary online storage for OS change on server",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Negative-Engineer614",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T13:15:42.721905+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T12:38:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Having a nas with 2 10tb HDD in raid 1 at home + an offsite backup in a single 10tb HDD installed in my work pc offsite would be an acceptable level of risk for me, is it possible to set this up with the OS installed in the ugreen nas and windows installed in the pc? Unfortunately i cannot setup a port forwarding at work.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Negative-Engineer614\"> /u/Negative-Engineer614 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nigavv/is_it_possible_to_send_backups_to_a_hdd_inside_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nigavv/is_it_possible_to_send_backups_to_a_hdd_inside_a/\">[comments]</a></span>",
        "id": 3587150,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nigavv/is_it_possible_to_send_backups_to_a_hdd_inside_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is it possible to send backups to a hdd inside a pc at my workplace from my nas (ugreen dxp2800)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheKevinBoone",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T19:36:43.769534+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T12:17:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>My current setup is a media server running proxmox on an old mini pc, I also have a QNAP NAS TS453D with a TR-004 DAS connected for extra storage running as individual disks (4x18TB). Lately the TR-004 is acting up and seems to shutdown for no apparent reason (green status light blinking but drive LED&#39;s are off) which causes me to power cycle the device and reconnect. There is no notification in QTS whatsoever that the device or drives have failed and SMART values show that the drives are healthy. The content seems to be accessible in QTS which is even more strange. The content is not critical since these are all movies and tv-shows. However, to be sure I&#39;m thinkin of replacing this HDD box with another third party enclosure, does someone have experience with this? Would this work with the QNAP software on the NAS? Is it better to connect this directly to the Proxmox Mini PC? Any recommended enclosures or suggestions are al",
        "id": 3590780,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nifu7o/does_qnap_support_third_party_hdd_enclosures_via",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does QNAP support third party HDD enclosures via USB?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/JdubDiedAgain",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T11:08:33.857740+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T10:42:20+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nidyui/hdd_deal_too_good_to_be_true/\"> <img src=\"https://preview.redd.it/67hee2e3aipf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a106a24954e3fb4fc2c1cdbb4a80d13bf529ec5b\" alt=\"HDD Deal too good to be true?\" title=\"HDD Deal too good to be true?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I am currently in the market for a new HDD for my datahoarding adventures, and I found this deal on eBay, <a href=\"https://ebay.us/m/niV7Fi\">https://ebay.us/m/niV7Fi</a> . What are the concerns with this HDD? The price is insanely good and it\u2019s very close to 10$ per TB. But I am worried it may be too good to be true. Let me know your thoughts!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JdubDiedAgain\"> /u/JdubDiedAgain </a> <br/> <span><a href=\"https://i.redd.it/67hee2e3aipf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nidyu",
        "id": 3586072,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nidyui/hdd_deal_too_good_to_be_true",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/67hee2e3aipf1.jpeg?width=640&crop=smart&auto=webp&s=a106a24954e3fb4fc2c1cdbb4a80d13bf529ec5b",
        "title": "HDD Deal too good to be true?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NUYvbT6vTPs",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T09:03:52.147071+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T08:18:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am trying to download the high res version of this map, but I am unable to. I tried zooming in, each tile of the map is a small square png, so it will be really tedious to download every single tile, and I don&#39;t know even know how many there is.</p> <p><a href=\"https://magicalnepal.com/annapurna-circuit-trek-map/\">Map link</a></p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NUYvbT6vTPs\"> /u/NUYvbT6vTPs </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nibny5/anyway_to_download_this_zoomable_map_doesnt_work/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nibny5/anyway_to_download_this_zoomable_map_doesnt_work/\">[comments]</a></span>",
        "id": 3585293,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nibny5/anyway_to_download_this_zoomable_map_doesnt_work",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyway to download this zoomable map? Doesn't work with dezoomify",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MaelduinTamhlacht",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T09:03:52.411625+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T08:08:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a DVD I&#39;d like to make into an mp4 so I can watch it on my phone and not haul a computer along on a journey. One of the audio choices is French - but how do I choose this audio on the file? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MaelduinTamhlacht\"> /u/MaelduinTamhlacht </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nibix2/changing_language_when_converting_to_dvd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nibix2/changing_language_when_converting_to_dvd/\">[comments]</a></span>",
        "id": 3585294,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nibix2/changing_language_when_converting_to_dvd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Changing language when converting to DVD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Historical-Zucchini1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T04:54:28.580655+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T04:52:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, I\u2019m trying to track down an old YouTube video that\u2019s now private. I have the link/ID but no access, and I\u2019m hoping someone here might either have a copy, know how to reach the uploader, or saved it before it went private.</p> <p>YouTube ID / Link: <a href=\"https://m.youtube.com/watch?v=PtxZSb-ma5A\">https://m.youtube.com/watch?v=PtxZSb-ma5A</a></p> <p>I\u2019ve already checked the Wayback Machine, but unfortunately it doesn\u2019t have a working copy of this video.</p> <p>If anyone has leads, backups, or contact info for the uploader, I\u2019d greatly appreciate it. Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Historical-Zucchini1\"> /u/Historical-Zucchini1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni8crn/looking_for_help_to_access_private_youtube_video/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni8crn/looking_for_help_t",
        "id": 3584197,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni8crn/looking_for_help_to_access_private_youtube_video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for help to access private YouTube video (ID: PtxZSb-ma5A)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AggravatingFan2942",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T04:54:28.707366+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T04:51:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone, I&#39;m looking for a torrent or some kind of server that i can get all of adult swims tv shows, including specials and obscure/early/less known adult swim stuff. i basically want everything they have on the website including the ones hidden behind trick names. I have searched all over including this sub, pirate bay, and <a href=\"http://archive.org\">archive.org</a> but i haven\u2019t been able to find a full archive download yet. i was wondering if someone could help me out. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AggravatingFan2942\"> /u/AggravatingFan2942 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni8byg/adult_swim_archive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni8byg/adult_swim_archive/\">[comments]</a></span>",
        "id": 3584198,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni8byg/adult_swim_archive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Adult Swim Archive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/glacierstarwars",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T04:54:28.835021+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T04:10:35+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni7lbz/archiving_the_lawrence_of_arabia_bluray/\"> <img src=\"https://b.thumbs.redditmedia.com/V_YdTU0AMXGhvorh5Esdt34XtXeSEIyJjEbqdLrY0Ow.jpg\" alt=\"Archiving the Lawrence of Arabia Blu-ray \u201cPicture-in-Graphic\u201d Track\" title=\"Archiving the Lawrence of Arabia Blu-ray \u201cPicture-in-Graphic\u201d Track\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey all, first time posting in this sub,</p> <p>I\u2019m trying to preserve one of the more unusual Blu-ray bonus features: the <em>\u201cSecrets of Arabia: Picture-in-Graphic Track\u201d</em> on the <em>Lawrence of Arabia</em> disc. Unlike PiP/BonusView, this isn\u2019t a secondary video stream. It\u2019s a BD-J driven feature that overlays PNG graphics + commentary text on the movie in real time.</p> <p><a href=\"https://preview.redd.it/skf54kb6cgpf1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=243159f99fdaf1772ee4064c5c4a7fcf8ec2b122\">https://preview.redd.it/skf54kb6cgpf1.png?width=1920&amp;fo",
        "id": 3584199,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni7lbz/archiving_the_lawrence_of_arabia_bluray",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/V_YdTU0AMXGhvorh5Esdt34XtXeSEIyJjEbqdLrY0Ow.jpg",
        "title": "Archiving the Lawrence of Arabia Blu-ray \u201cPicture-in-Graphic\u201d Track",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/tarekalshawwa",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T04:54:28.325156+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T03:53:30+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tarekalshawwa\"> /u/tarekalshawwa </a> <br/> <span><a href=\"/r/Kiwix/comments/1ni7929/how_to_get_older_versions_of_wikipedia_like_2020/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni79i0/how_to_get_older_versions_of_wikipedia_like_2020/\">[comments]</a></span>",
        "id": 3584196,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni79i0/how_to_get_older_versions_of_wikipedia_like_2020",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to get older versions of Wikipedia? (like 2020, pre generative ai era)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/shallnoel",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T03:53:38.363481+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T03:02:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a bunch of cosplay folders, each full of their own images, and I want a basic way to filter the folders\ud83d\udcc1.</p> <p>Is anyone familiar with a linux solution that would allow me to go through my collection like the tagging system that the site &#39;ehentai&#39; uses? I also want the thumbnail feature they have.</p> <p>I have tried DigiKam but it doesn&#39;t let me tag folders. I also tried TagSpaces, but it is very slow when loading images and it paywalls folder preview images while also not automatically making them like in the Dolphin file manager for those familiar with it. I don&#39;t really care about tagging individual images since the folders will hold that information. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/shallnoel\"> /u/shallnoel </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni694u/hoarding_cosplays/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r",
        "id": 3583998,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni694u/hoarding_cosplays",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hoarding cosplays",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Odd-Tone9183",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T08:02:15.567342+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T01:00:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have about 5 TB of tv shows and movies. How do I keep this backed up and safe. I dont see how this 3-2-1 system works, if one file gets corrupted it must eventually affect the others. Please help!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Odd-Tone9183\"> /u/Odd-Tone9183 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni3ol4/concerned_about_video_collection/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni3ol4/concerned_about_video_collection/\">[comments]</a></span>",
        "id": 3584988,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni3ol4/concerned_about_video_collection",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Concerned About Video Collection",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Brilliant_Hold_1239",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T00:49:36.292234+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T00:44:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Well, my country is so f***** up that there are neither retailers nor distributors (even the official ones, from toshiba, wd, seagate) selling mobile or external hdds (2.5&quot;) with a valid warranty, and if I try to buy one with a valid one I&#39;m gonna spend too much, I&#39;m about to give up and get the most reliable one that I can find and take the risk of something without warranty, good luck for me, YIKES!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Brilliant_Hold_1239\"> /u/Brilliant_Hold_1239 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni3c6u/i_can_only_find_new_hdds_that_are_out_of_warranty/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni3c6u/i_can_only_find_new_hdds_that_are_out_of_warranty/\">[comments]</a></span>",
        "id": 3583339,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni3c6u/i_can_only_find_new_hdds_that_are_out_of_warranty",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I can only find new HDDs that are out of warranty!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/x23_wolverine",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T08:02:15.288005+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T00:44:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>IBM announced the world\u2019s first HDD, the 3.75MB RAMAC 350 disk storage unit, 69 years ago today \u2014 unit weighed more than a ton, 50 platters ran at 1,200 RPM</p> <p><a href=\"https://www.tomshardware.com/pc-components/hdds/ibm-announced-the-worlds-first-hdd-the-3-75mb-ramac-350-disk-storage-unit-69-years-ago-today-unit-weighed-more-than-a-ton-50-platters-ran-at-1-200-rpm\">https://www.tomshardware.com/pc-components/hdds/ibm-announced-the-worlds-first-hdd-the-3-75mb-ramac-350-disk-storage-unit-69-years-ago-today-unit-weighed-more-than-a-ton-50-platters-ran-at-1-200-rpm</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/x23_wolverine\"> /u/x23_wolverine </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni3bie/this_article_popped_up_for_me_today_the_hard/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni3bie/this_article_popped_up_for_me_today_the_hard/\">[c",
        "id": 3584987,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni3bie/this_article_popped_up_for_me_today_the_hard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "This article popped up for me today, the hard drive is 69 years ild",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ReagentX",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T00:49:36.003290+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T00:36:12+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni355h/imessage_exporter_310_foothill_clover_is_now/\"> <img src=\"https://external-preview.redd.it/J6hLyUKjkyCQR0nJZWm2vbg0vmmuyEFJIEjbwtX2wwY.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=191774f5aa35aa856f4b2d71f73fa33c9f80a438\" alt=\"iMessage Exporter 3.1.0 Foothill Clover is now available, bringing support for all new iOS 26 and macOS Tahoe features\" title=\"iMessage Exporter 3.1.0 Foothill Clover is now available, bringing support for all new iOS 26 and macOS Tahoe features\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ReagentX\"> /u/ReagentX </a> <br/> <span><a href=\"https://github.com/ReagentX/imessage-exporter\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni355h/imessage_exporter_310_foothill_clover_is_now/\">[comments]</a></span> </td></tr></table>",
        "id": 3583338,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni355h/imessage_exporter_310_foothill_clover_is_now",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/J6hLyUKjkyCQR0nJZWm2vbg0vmmuyEFJIEjbwtX2wwY.png?width=640&crop=smart&auto=webp&s=191774f5aa35aa856f4b2d71f73fa33c9f80a438",
        "title": "iMessage Exporter 3.1.0 Foothill Clover is now available, bringing support for all new iOS 26 and macOS Tahoe features",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Such-Bench-3199",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T00:49:35.777361+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T00:16:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This is the only thing in life I am really good at; I can download and archive anything, and I archive what happens throughout the world almost every single day and have done since 2011. Only since 2016 I feel like I am documenting the downfall of humanity. I just wish the content was better. </p> <p>It sucks having to hunt down the unblurred footage of the woman on the train, or anything kirk related. My hobby hurts me daily, but I push through it, in the one that one day I can somehow pass it all on. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Such-Bench-3199\"> /u/Such-Bench-3199 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni2p2n/my_10000_hours_sucks/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ni2p2n/my_10000_hours_sucks/\">[comments]</a></span>",
        "id": 3583336,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni2p2n/my_10000_hours_sucks",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "My 10,000 hours sucks",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/iVXsz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T00:49:35.898786+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T00:13:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I observed this very interesting and insanely big difference in quality for grabs I&#39;ve made in the past compared to the same videos later on, even for the same codec &amp; res. Look at this comparison between an Early stream and an &quot;Processed&quot; stream that was grabbed 11 hours later, and try to guess which is which without looking at their names at the top: <a href=\"https://slow.pics/c/wo9hg1UK\">https://slow.pics/c/wo9hg1UK</a>.</p> <p>Turns out, YouTube&#39;s initial VP9 stream when a video is first uploaded is one of the highest quality streams you will get from a video, and it will disappear quickly within hours if you aren&#39;t quick enough (basically, if you don&#39;t have automatic archiving scripts).</p> <p>You know what&#39;s the craziest part is? The higher quality early stream is LOWER in size than the processed stream, check it out in this bitrate plot: <a href=\"https://slow.pics/c/67s1YTkt\">https://slow.pics/c/67s1YTkt</a> I ",
        "id": 3583337,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni2n8h/youtubes_secret_quality_that_you_probably_dont",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "YouTube's secret quality that you probably don't know about",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LuckyLuciano13",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-16T00:49:36.456523+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-16T00:05:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was hoping to get some advice and recommendations for the scenario I&#39;m in.</p> <p>I currently own several portable USB hard drives, mostly Western Digital, with a total capacity of approximately <strong>12 TB</strong>. My primary concern is the <strong>lack of redundancy</strong> across these drives, which I&#39;ve been unable to address due to budget constraints.</p> <p>My current workflow involves using these drives as cold storage. I only connect them occasionally to add or access files. The major inconveniences are the <strong>inability to consolidate files</strong> into a single location and the <strong>risk of data loss</strong> due to no redundancy.</p> <p>I&#39;ve been looking into <strong>Direct-Attached Storage (DAS)</strong> enclosures as a solution and found the <strong>QNAP TR-004</strong> to be a potential fit.</p> <p>My plan is to use a DAS with a RAID configuration, likely <strong>RAID 5</strong> or <strong>RAID 1</strong>, and a",
        "id": 3583340,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ni2gz7/das_recommendationsadvice",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "DAS Recommendations/Advice?",
        "vote": 0
    }
]