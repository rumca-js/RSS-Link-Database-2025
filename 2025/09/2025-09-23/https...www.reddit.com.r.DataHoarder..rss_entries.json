[
    {
        "age": null,
        "album": "",
        "author": "/u/Curiosityscroller0",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T23:16:52.302860+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T22:35:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi! I\u2019m studying to be an archivist (going for a masters in library/archive studies but have to get a bachelor\u2019s in museum studies first) and am two years into university for it but have done nothing even related to digital archives or online data storage yet, we don\u2019t start that until the masters program \ud83d\ude14 I have basic computer skills and I fear i\u2019m not at the level to understand half the stuff in this subreddit but I really want to learn and get experience!! Anyone have any good resources or recommendations for learning how to get the most out of cloud/data storage, any software used for online archives/libraries, or where to start with all this? \ud83d\ude2d Thanks and much appreciated for any help :))</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Curiosityscroller0\"> /u/Curiosityscroller0 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1novm23/newbie/\">[link]</a></span> &#32; <span><a href=\"htt",
        "id": 3649426,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1novm23/newbie",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Newbie",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GenericUser104",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T22:09:41.660772+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T21:34:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Like a text document that </p> <p>Would write down </p> <p>Test folder Example.mp4 Example.mp4</p> <p>Etc etc </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GenericUser104\"> /u/GenericUser104 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nou4sh/maybe_a_dumb_question_is_there_a_way_to_create_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nou4sh/maybe_a_dumb_question_is_there_a_way_to_create_a/\">[comments]</a></span>",
        "id": 3648987,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nou4sh/maybe_a_dumb_question_is_there_a_way_to_create_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Maybe a dumb question, is there a way to create a text document that lists every file in a given folder for data recovery?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/UniqueAttourney",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T22:09:42.125291+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T21:12:34+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1notl4p/how_good_are_these_ocpc_qlc_ssds_in_the_long_term/\"> <img src=\"https://b.thumbs.redditmedia.com/YY4sW01pKt-BAMu8NB4qK7of7mvYAAQqO_6eM8f8RSk.jpg\" alt=\"How good are these OCPC QLC SSDs in the long term\" title=\"How good are these OCPC QLC SSDs in the long term\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I recently found these 1tb QLC OCPC SSDs (OCPC XTL-200 1To SATA 2.5) for about $62 in local currency which is a great price. i intend to use them for data storage, small amount of reads but i need enough speed and snappiness that i can&#39;t have an HDD instead.</p> <p>i checked online and saw different markings related to the MBFT (mean before failure time) :</p> <p>- 430Tb written<br/> - 2.5 Million hours</p> <p>that is probably the biggest indicator of whether these SSDs can be trusted or not, but i don&#39;t really understand them completely nor did i have to do this in a serious manner before.</p",
        "id": 3648988,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1notl4p/how_good_are_these_ocpc_qlc_ssds_in_the_long_term",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/YY4sW01pKt-BAMu8NB4qK7of7mvYAAQqO_6eM8f8RSk.jpg",
        "title": "How good are these OCPC QLC SSDs in the long term",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/V3NOM0US_VALKYIR3",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T21:02:00.436819+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T19:56:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>There was an artist on there, that I was very inspired by in 2015. Their account is still up but all the posts are deleted, but the folders still say that the gallery has 1K posts. I tried to use the way back machine, to no avail. Any help is appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/V3NOM0US_VALKYIR3\"> /u/V3NOM0US_VALKYIR3 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1norm3p/how_can_i_viewdownload_deleted_deviantart_posts/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1norm3p/how_can_i_viewdownload_deleted_deviantart_posts/\">[comments]</a></span>",
        "id": 3648523,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1norm3p/how_can_i_viewdownload_deleted_deviantart_posts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can I view/download deleted DeviantART posts?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/alternative_owl97",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T19:54:12.362417+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T19:29:27+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1noqwc8/is_this_hdd_good/\"> <img src=\"https://preview.redd.it/1yw2ihjiuyqf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c45772d916df5e912d47fc93b3fa999366224d45\" alt=\"Is this hdd good?\" title=\"Is this hdd good?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I just bought this hdd and I&#39;m not professional at readings ( Victoria ) Can anyone help me to know it that good or not ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/alternative_owl97\"> /u/alternative_owl97 </a> <br/> <span><a href=\"https://i.redd.it/1yw2ihjiuyqf1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1noqwc8/is_this_hdd_good/\">[comments]</a></span> </td></tr></table>",
        "id": 3648118,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1noqwc8/is_this_hdd_good",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/1yw2ihjiuyqf1.png?width=640&crop=smart&auto=webp&s=c45772d916df5e912d47fc93b3fa999366224d45",
        "title": "Is this hdd good?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BookShelfRandom",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T18:44:33.958113+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T18:36:29+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nophv3/internet_archive_is_asking_for_money_again/\"> <img src=\"https://preview.redd.it/iq5bfkkokyqf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=365eb2727bb30ddd4093a64974a1820f932882ea\" alt=\"Internet archive is asking for money again!\" title=\"Internet archive is asking for money again!\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>they do ask a lot... the archive is powered on donations. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BookShelfRandom\"> /u/BookShelfRandom </a> <br/> <span><a href=\"https://i.redd.it/iq5bfkkokyqf1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nophv3/internet_archive_is_asking_for_money_again/\">[comments]</a></span> </td></tr></table>",
        "id": 3647518,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nophv3/internet_archive_is_asking_for_money_again",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/iq5bfkkokyqf1.png?width=320&crop=smart&auto=webp&s=365eb2727bb30ddd4093a64974a1820f932882ea",
        "title": "Internet archive is asking for money again!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/iKamikadze",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T17:25:22.902221+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T16:16:40+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/iKamikadze\"> /u/iKamikadze </a> <br/> <span><a href=\"/r/buildapc/comments/1nohk2z/choosing_a_soundproof_pc_case/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nolrb6/choosing_a_soundproof_pc_case/\">[comments]</a></span>",
        "id": 3646742,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nolrb6/choosing_a_soundproof_pc_case",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Choosing a soundproof PC case",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Pizzapug64",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T16:13:31.456292+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T15:30:01+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nokis9/would_this_be_okay/\"> <img src=\"https://preview.redd.it/qprii5pqnxqf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5c8654c3648c448fb19394d1f61b9098023d4e33\" alt=\"Would this be okay?\" title=\"Would this be okay?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I wanted to put a third drive in my pc but but my drive bay is full. </p> <p>I would probably drill new holes into the case.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Pizzapug64\"> /u/Pizzapug64 </a> <br/> <span><a href=\"https://i.redd.it/qprii5pqnxqf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nokis9/would_this_be_okay/\">[comments]</a></span> </td></tr></table>",
        "id": 3646036,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nokis9/would_this_be_okay",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/qprii5pqnxqf1.jpeg?width=640&crop=smart&auto=webp&s=5c8654c3648c448fb19394d1f61b9098023d4e33",
        "title": "Would this be okay?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/g0ldenfox_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T15:00:22.151500+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T14:52:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What is the best I can get (in terms of price-performance) as a 2tb external ssd for video cutting and editing. I have some knowlage of custom hardware builds etc. so I am open for pre builts (like Samsung T7 etc.) and home build ssd cases with ssd inside.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/g0ldenfox_\"> /u/g0ldenfox_ </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nojibc/external_ssd_for_video_editing/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nojibc/external_ssd_for_video_editing/\">[comments]</a></span>",
        "id": 3645344,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nojibc/external_ssd_for_video_editing",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "External SSD for video editing",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/g0ldenfox_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T15:00:22.269839+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T14:51:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What is the best I can get (in terms of price-performance) as a 2tb external ssd for video cutting and editing. I have some knowlage of custom hardware builds etc. so I am open for pre builts (like Samsung T7 etc.) and home build ssd cases with ssd inside.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/g0ldenfox_\"> /u/g0ldenfox_ </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nojhk1/external_ssd_2tb_video_editing/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nojhk1/external_ssd_2tb_video_editing/\">[comments]</a></span>",
        "id": 3645345,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nojhk1/external_ssd_2tb_video_editing",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "External SSD 2TB Video Editing",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Takpundek",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T15:00:22.388029+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T14:22:10+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Takpundek\"> /u/Takpundek </a> <br/> <span><a href=\"/r/techsupport/comments/1noipxt/how_do_i_address_issues_with_my_video_and_photo/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1noiqp6/how_do_i_address_issues_with_my_video_and_photo/\">[comments]</a></span>",
        "id": 3645346,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1noiqp6/how_do_i_address_issues_with_my_video_and_photo",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do i address issues with my video and photo transfer??",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/True-Entrepreneur851",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T13:48:59.821938+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T12:40:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What\u2019s the difference between Clear and combine in the YM RAID switches ? I read the manual and it\u2019s surprisingly nit well explained.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/True-Entrepreneur851\"> /u/True-Entrepreneur851 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nogaff/yottamaster_clear_or_combine/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nogaff/yottamaster_clear_or_combine/\">[comments]</a></span>",
        "id": 3644682,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nogaff/yottamaster_clear_or_combine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Yottamaster - clear or combine.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Still-Sorbet-3198",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T17:25:23.328496+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T12:34:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have all my Discord server exports (HTML) downloaded, including images, videos, and text. I need a tool that can:</p> <ul> <li>Sort <strong>all media files by user</strong> into separate folders.</li> <li>Keep files <strong>chronologically ordered</strong> per user across all channels.</li> <li>Ignore text and emojis.</li> <li>Work <strong>locally on Mac</strong> </li> </ul> <p>Python scripts haven\u2019t worked reliably, so I\u2019m looking for a tool or software that can do this efficiently.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Still-Sorbet-3198\"> /u/Still-Sorbet-3198 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nog5ss/best_tool_to_organise_discord_export_media_by_user/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nog5ss/best_tool_to_organise_discord_export_media_by_user/\">[comments]</a></span>",
        "id": 3646743,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nog5ss/best_tool_to_organise_discord_export_media_by_user",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best tool to organise Discord export media by user",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/meariim",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T12:37:08.559516+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T12:00:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello! I want to archive hide itoh&#39;s icons and the only place i could find them archived was on <a href=\"https://www.iconarchive.com/artist/pixture.html\">https://www.iconarchive.com/artist/pixture.html</a> (there was some on other sites, but not as many as here)</p> <p>i want to download them all, but the site only lets me download them one by one, and have to click like 3 times to get the .ico file, each icon individually.</p> <p>I tried JD2, and two tools i found on github specifically made to download from iconarchive, but they didnt work. I also tried WinHTTrack, but I couldnt get the ico files for some reason</p> <p>Any idea how I can download them all?</p> <p>EDIT: Realized I can dig them up from a newer (2008) version of their website, but I will leave this open for other icon packs from the same website</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/meariim\"> /u/meariim </a> <br/> <span><a href=\"http",
        "id": 3644106,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1noffm2/trying_to_download_in_bulk_from_iconarchive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to download in bulk from iconarchive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GoodFroge",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T12:37:08.961124+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T11:53:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I found out a little while ago that the MX500 isn\u2019t low on stock but is actually discontinued, so I went with a BX500. A massive mistake. It\u2019s easily the slowest and worst drive I\u2019ve experienced, you can\u2019t even watch a video off it without some stuttering. </p> <p>What is the current best alternative to the MX500? It was a fantastic drive for its price point and I feel lost without it. I don\u2019t know much about DRAM but I recall the Bx500 lacks it, which maybe explains why it was so terrible. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GoodFroge\"> /u/GoodFroge </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nofa9s/alternative_to_mx500/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nofa9s/alternative_to_mx500/\">[comments]</a></span>",
        "id": 3644107,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nofa9s/alternative_to_mx500",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Alternative to MX500?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PeterGunn8000",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T11:28:29.884966+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T11:18:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Im looking for previous content from fansly. Does any kind of archive exist? Im looking for specific a username from 2020 to 2024 (or just whatever exists)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PeterGunn8000\"> /u/PeterGunn8000 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1noelst/fansly_archive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1noelst/fansly_archive/\">[comments]</a></span>",
        "id": 3643632,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1noelst/fansly_archive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Fansly archive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/heart_healar",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T11:28:30.081363+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T11:14:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m new to this whole thing, to be completely honest, so apologies in advance.</p> <p>I want to get rid of the bulk of my DVDs and most Blu-Rays as I don&#39;t have the physical space to store them all, but I am willing to rip &amp; archive them all into MKVs &amp; ISOs (which I already know how to do). After about a day of cataloguing everything I currently own, I&#39;m looking at about 27336.8gb.</p> <p>My question is this, how should go about constructing such a large amount of storage for this purpose? Should I build a PC and just have (eventually maybe) 8 hard drives (or 4 16tb) in there, along with the blu-ray drive, or should I go about making a server or raid array and have all the ripping be done on a seperate computer? Or is there another option that could be better.</p> <p>I&#39;d like to start off with about 32tb, with room to expand to around 64tb, used either as a backup or as additional storage, which I guess would bring it up to 12",
        "id": 3643633,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1noej4n/how_to_go_about_making_a_32tb_storage_array_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to go about making a 32tb storage array for archiving DVDs & Blu-Rays?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ryszv",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T17:25:23.563791+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T11:10:20+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1noegr1/tree_backups_as_browsable_tarballs/\"> <img src=\"https://external-preview.redd.it/eMLMiL3o5rOMJ1-RPFhXwIrdz-ot_nN1Z8y8gMqhOfc.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5991530ca32f32981dbf89171986595ebe8a0234\" alt=\"Tree backups as browsable tarballs\" title=\"Tree backups as browsable tarballs\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;d like to share a personal project I&#39;ve been working on for my own hoarding needs, hoping it&#39;ll be useful to others also. I always had the problem that I had more data than I could ever backup, but also needed to keep track of what would need reaquiring in case of catastrophic data loss.</p> <p>I used to do this with tree-style textual lists, but sifting through walls of text always annoyed me, and so I came up with the idea to just replicate directory trees into browsable tarballs. The novelty is that all files are replaced with zero byte placeh",
        "id": 3646744,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1noegr1/tree_backups_as_browsable_tarballs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/eMLMiL3o5rOMJ1-RPFhXwIrdz-ot_nN1Z8y8gMqhOfc.jpeg?width=640&crop=smart&auto=webp&s=5991530ca32f32981dbf89171986595ebe8a0234",
        "title": "Tree backups as browsable tarballs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DomMistressMommy_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T11:28:30.589823+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T11:05:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i want to know that, How do i download All of the Rule34video.<br/> i searched on this sub, people have tried Yt DL, gallery DL<br/> But all of these goes above my head, i have never used github, let alone installing anything from github to my system, i once tried and failed, didnt understood a thing, even after using gpt as a help.</p> <p>Basically i wanna download all the video like in a automated way, and upload it to [ megcloud. tv ] megacloudtv also provide API to auto upload and download, just like any API, well i have no knowledge how to use it though.</p> <p>So it fetch the video from rule34video, download it only megacloud or download and then upload to mega cloud</p> <p>- would be better if it could even name the video matching the original title</p> <p>anyone know how can i achieve this is simple terms</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DomMistressMommy_\"> /u/DomMistressMommy_ </a> <br/> <",
        "id": 3643634,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1noedqf/how_do_i_download_all_of_the_rule34video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do i download All of the Rule34video",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Foxagon101",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T10:17:56.409176+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T10:13:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>for context, my motherboard only supports pcie gen 3 storage, so recommend me gen 3, gen 4 anything which is affordable, I&#39;m considering the Western Digital SN5000 (which is the goat imo).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Foxagon101\"> /u/Foxagon101 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nodhhw/best_ssd_with_500_or_500_gb_storage_which_is/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nodhhw/best_ssd_with_500_or_500_gb_storage_which_is/\">[comments]</a></span>",
        "id": 3643146,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nodhhw/best_ssd_with_500_or_500_gb_storage_which_is",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best SSD with 500 or 500+ gb storage which is affordable?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lectric_7166",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T10:17:56.620259+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T09:51:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>Any recs for something like this?</p> <ul> <li><p>Under 100 USD</p></li> <li><p>reliable / not prone to failures (this is the most important consideration)</p></li> <li><p>5 TB or so, could be more if it stays in the price range</p></li> <li><p>magnetic disk or solid-state (solid-state is ideal but a 5 TB under 100 USD is probably unreasonable, so either one is okay)</p></li> <li><p>somewhat fast or at least not horrible performance</p></li> </ul> <p>This will be used to store backup images of other smaller drives. Thanks for any suggestions.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lectric_7166\"> /u/lectric_7166 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nod43q/looking_for_a_recommendation_on_a_budget_portable/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nod43q/looking_for_a_recommendation_on_a_budget_portable/\">[",
        "id": 3643147,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nod43q/looking_for_a_recommendation_on_a_budget_portable",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "looking for a recommendation on a budget portable drive that's reliable",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/hardchorus",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T10:17:56.136119+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T09:26:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have 4tb of music that I would like to backup to another external hd, how do I go about this process? Is there risk involved? I\u2019m curious if I need to transfer a bit at a time or can I just drag and drop everything over? Thanks in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hardchorus\"> /u/hardchorus </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nocqn9/whats_the_best_and_safest_way_to_transfer_4tb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nocqn9/whats_the_best_and_safest_way_to_transfer_4tb/\">[comments]</a></span>",
        "id": 3643145,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nocqn9/whats_the_best_and_safest_way_to_transfer_4tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What\u2019s the best and safest way to transfer 4tb from one external hd to another?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/praudmur1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T06:50:36.986158+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T06:44:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi!</p> <p>I&#39;ve got a mini-PC as homelab server and I&#39;d like to connect some 7200 HDDs to it. I know there&#39;s a heat problem for those drives so HDD dock needs cooling. The problem is - I haven&#39;t found any solutions. For instance, there&#39;s Orico DS500U3-BK which has a good speed and a fan but according to reviews it doesn&#39;t cool HDDs enough.</p> <p>So I need recommendation on HDD dock with good cooling capabilities. Or maybe I should use a NAS? Can I use NAS just as a storage and manage disk space via mini-PC(I use proxmox on my homelab server). Any particular cheap NAS servers that would server my purpose? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/praudmur1\"> /u/praudmur1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1noabl6/whats_the_best_way_to_connect_hdds_to_a_minipchdd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comment",
        "id": 3642160,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1noabl6/whats_the_best_way_to_connect_hdds_to_a_minipchdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's the best way to connect HDDs to a mini-PC?(HDD dock or NAS)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/i_married_an_amazon",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T18:44:34.776785+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T06:23:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>For the foreseeable future, I will have spotty internet. I&#39;d like to be able to load a couple of terabytes of Linux ISOs onto an 8TB hard drive and have it mailed to me, then send it back to a friend for some fresh Linux ISOs, rinse and repeat. Is this advisable or should I just buy a Crucial X10 8TB SSD for $440</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/i_married_an_amazon\"> /u/i_married_an_amazon </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1no9zmo/whats_the_best_way_to_ship_a_35_hard_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1no9zmo/whats_the_best_way_to_ship_a_35_hard_drive/\">[comments]</a></span>",
        "id": 3647519,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1no9zmo/whats_the_best_way_to_ship_a_35_hard_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's the best way to ship a 3.5\" hard drive repeatedly?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Key-Seaworthiness517",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T06:50:36.196289+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T06:05:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>&quot;We do not allow sexual content involving non-consensual activity including synthetic, simulated, illustrated, or animated versions.&quot; </p> <p>Vague borders, so could end up hitting everything without an explicit &quot;I consent!&quot; from any involved character; the people I follow mostly just do microfics and this largely targets illustrations so most of what I follow will probably be fine, but better safe than sorry.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Key-Seaworthiness517\"> /u/Key-Seaworthiness517 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1no9oo6/is_there_a_way_to_mass_archive_posts_from_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1no9oo6/is_there_a_way_to_mass_archive_posts_from_a/\">[comments]</a></span>",
        "id": 3642159,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1no9oo6/is_there_a_way_to_mass_archive_posts_from_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a way to mass archive posts from a specific bsky user? New TOS coming into effect October 15th that might cause mass deletions.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ShortstopGFX",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T04:36:28.927012+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T04:09:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey there,</p> <p>So I have a weird thing where I have had an old tower that I use for Linux occassionally for emulators, hoarding music and movies, and stuff like that. It has an i7 CPU, 16 gigs of RAM, and a video card that basically does VGA out to a spare CRT monitor pretty nicely for emulators occassionally. I plan on replacing this PC with a PC I plan on building sometime next year that will dominate it in terms of just overall emulation capabilities aka the ultimate end game computer (Ryzen 9600X, 32 gigs RAM, VGA video card for same CRT setup with 86Box and other weird stuff etc).</p> <p>Thing is though, I got a mini PC about a year ago that I use to kind of mess around with Docker via Portainer and that is a pretty fun machine that just hooks up to the router very nicely by default, and runs Kubuntu just fine. Stuff like Navidrome, Jellyfin, and local Kiwix instances are running awesome.</p> <p>I would like to somehow move over my actual two ",
        "id": 3641590,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1no7pci/good_usb_based_jbod_setups_for_a_mini_pc_in_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Good USB Based JBOD Setups For A Mini PC In 2025?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NXGZ",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T04:36:28.492921+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T04:01:17+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NXGZ\"> /u/NXGZ </a> <br/> <span><a href=\"/r/kof/comments/1no6w8j/youtube_is_removing_most_of_the_arranged_kof/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1no7jos/youtube_is_removing_most_of_the_arranged_kof/\">[comments]</a></span>",
        "id": 3641589,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1no7jos/youtube_is_removing_most_of_the_arranged_kof",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "YouTube is removing most of the arranged KOF tracks",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Weary_Instruction706",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T16:13:32.361974+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T03:06:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m backing up our family Blu-ray collection so the kids can watch stuff on Apple TV at home and on their iPads when we travel. External BD drive here. I&#39;ve put together a rough routine and wanna see if I&#39;m missing anything obvious before I stick it on a note.</p> <p>Here&#39;s what I want the workflow to cover:</p> <ul> <li>auto-grab the actual movie, not 20 trailers</li> <li>keep surround + stereo audio by default, plus subs only when needed</li> <li>quick preview so I know I didn&#39;t pick the wrong thing before wasting hours</li> </ul> <p>Target containers: MP4/H.265 for iPads, MKV or MP4 for the Apple TV. Library lives in Plex/Infuse, naming like {Movie (Year)}.</p> <p>Am I missing any gotchas that will bite later (e.g., audio track order, subtitle surprises, naming edge cases)?</p> <p>Any smart defaults you use for file size/bitrate so iPads don&#39;t fill up but TV still looks great?</p> </div><!-- SC_ON --> &#32; submitted by &#32",
        "id": 3646038,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1no6i07/trying_to_lock_down_a_simple_bluray_ripping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to lock down a simple Blu-ray ripping routine",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/heljara",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T02:19:17.127646+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T01:46:07+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1no4v6f/wake_up_babe_new_datahoarder_filesystem_just/\"> <img src=\"https://external-preview.redd.it/D6v3Q0hZAIemcM2eg1TVRuaNmO_OJIvsII0l-TYHh_4.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d2ad2c3357797eda0928f58669bf74dcc91a4408\" alt=\"Wake up babe, new datahoarder filesystem just dropped\" title=\"Wake up babe, new datahoarder filesystem just dropped\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/heljara\"> /u/heljara </a> <br/> <span><a href=\"https://github.com/XTXMarkets/ternfs\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1no4v6f/wake_up_babe_new_datahoarder_filesystem_just/\">[comments]</a></span> </td></tr></table>",
        "id": 3641110,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1no4v6f/wake_up_babe_new_datahoarder_filesystem_just",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/D6v3Q0hZAIemcM2eg1TVRuaNmO_OJIvsII0l-TYHh_4.png?width=640&crop=smart&auto=webp&s=d2ad2c3357797eda0928f58669bf74dcc91a4408",
        "title": "Wake up babe, new datahoarder filesystem just dropped",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/fizzy_me",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T02:19:17.351013+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T01:23:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>subreddit i love is being deleted, i was wondering if there is a tool to scrape and compile all post titles into a big text document before its gone</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/fizzy_me\"> /u/fizzy_me </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1no4ejg/way_to_scrape_subreddit_post_titles/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1no4ejg/way_to_scrape_subreddit_post_titles/\">[comments]</a></span>",
        "id": 3641111,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1no4ejg/way_to_scrape_subreddit_post_titles",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "way to scrape subreddit post titles?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/smudgedbarcode",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-23T02:19:17.683959+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-23T01:23:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Like the title says. The account owner is in jail, soon to be in prison, for crimes involving his children. I\u2019m hoping I can find a way to get his account deleted because it\u2019s easily accessible.</p> <p>In the hopes that his account gets deleted, I want to save the photos in case his kids want to see them down the road. I know I can save them individually, but there\u2019s a lot and I\u2019m emotionally at my max.</p> <p>Side note, if anyone can point me in the right direction to get his account deleted, I\u2019m happy to chat. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/smudgedbarcode\"> /u/smudgedbarcode </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1no4e2k/easy_way_to_save_100s_of_photos_from_someone/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1no4e2k/easy_way_to_save_100s_of_photos_from_someone/\">[comments]</a></span>",
        "id": 3641112,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1no4e2k/easy_way_to_save_100s_of_photos_from_someone",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Easy way to save 100s of photos from someone else\u2019s FB?",
        "vote": 0
    }
]