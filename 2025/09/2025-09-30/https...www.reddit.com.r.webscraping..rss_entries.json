[
    {
        "age": null,
        "album": "",
        "author": "/u/Slight_Bank3091",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-30T18:15:58.862575+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-30T18:09:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Will it still be possible to scrape SofaScore in 2025 without using proxies and without being blocked? I need it for 24/7 live scraping.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Slight_Bank3091\"> /u/Slight_Bank3091 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nukkhm/sofascore_scrapping_2025/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nukkhm/sofascore_scrapping_2025/\">[comments]</a></span>",
        "id": 3701415,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nukkhm/sofascore_scrapping_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Sofascore Scrapping 2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Atronem",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-30T18:15:59.030498+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-30T17:34:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>We seek an operator to download metadata (titles) and cover images for ~1,000,000 books from an online library).<br/> For each recorded title, retrieve the corresponding PDF when available from the Wayback Machine.<br/> Estimated raw storage requirement: ~20 TB; required disk capacity will be supplied.</p> <p>The project is dedicated solely to the preservation of knowledge and carries no commercial intent.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Atronem\"> /u/Atronem </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nujmau/download_1_million_pdfs_from_way_back_machine/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nujmau/download_1_million_pdfs_from_way_back_machine/\">[comments]</a></span>",
        "id": 3701416,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nujmau/download_1_million_pdfs_from_way_back_machine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Download 1 million PDFs from Way Back Machine",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mehmetflix_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-30T14:39:50.995814+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-30T14:20:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>the title says it all.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mehmetflix_\"> /u/mehmetflix_ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nuehm6/does_cloudflare_detect_and_block_clients_in/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nuehm6/does_cloudflare_detect_and_block_clients_in/\">[comments]</a></span>",
        "id": 3699154,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nuehm6/does_cloudflare_detect_and_block_clients_in",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "does cloudflare detect and block clients in docker containers",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Blaze0297",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-30T14:39:50.673628+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-30T14:07:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Does someone have experience scraping RSC? I am trying to scrape sites with data like this but its rly hard for it to be stable. Sometimes I can&#39;t use just DOM to extract my data.</p> <p>Here is example site where I found this data:<br/> <a href=\"https://nextjs.org/docs/pages/building-your-application/routing/api-routes\">https://nextjs.org/docs/pages/building-your-application/routing/api-routes</a></p> <p>Example how it looks like:</p> <pre><code>16:[&quot;$&quot;,&quot;h2&quot;,null,{&quot;id&quot;:&quot;nested-routes&quot;,&quot;data-docs-heading&quot;:&quot;&quot;,&quot;children&quot;:[&quot;$&quot;,&quot;$L6&quot;,null,{&quot;href&quot;:&quot;#nested-routes&quot;,&quot;children&quot;:[&quot;Nested routes&quot;,[&quot;$&quot;,&quot;span&quot;,null,{&quot;children&quot;:[&quot;$&quot;,&quot;svg&quot;,null,{&quot;viewBox&quot;:&quot;0 0 16 16&quot;,&quot;height&quot;:&quot;0.7em&quot;,&quot;width&quot;:&quot;0.7em&quot;,&quot;children&quot;:[&quo",
        "id": 3699153,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nue687/scraping_site_with_rsc_react_server_componenets",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping site with RSC (react server componenets)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-30T13:03:26.706321+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-30T13:01:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels\u2014whether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>If you&#39;re new to web scraping, make sure to check out the <a href=\"https://webscraping.fyi\">Beginners Guide</a> \ud83c\udf31</p> <p>Commercial products may be mentioned in replies. If you want to promote your own products and services, continue to use the <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">monthly thread</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 3697739,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nucktm/weekly_webscrapers_hiring_faqs_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weekly Webscrapers - Hiring, FAQs, etc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/that_one_doggie",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-30T14:39:50.446675+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-30T12:37:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How frustration with Spanish bureaucracy led to turning an Android phone into a scraping war machine</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/that_one_doggie\"> /u/that_one_doggie </a> <br/> <span><a href=\"https://kpliuta.github.io/blog/posts/scraping-websites-on-android-with-termux/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nuc14r/scraping_websites_on_android_with_termux/\">[comments]</a></span>",
        "id": 3699152,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nuc14r/scraping_websites_on_android_with_termux",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Websites on Android with Termux",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/B4nan",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-30T11:01:55.493919+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-30T10:16:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, our team just launched <a href=\"https://github.com/apify/crawlee-python/\"><strong>Crawlee for Python \ud83d\udc0d</strong></a> <strong>v1.0</strong>, an open source web scraping and automation library. We launched the beta version in Aug 2024 <a href=\"https://www.reddit.com/r/Python/comments/1dyyaky/crawlee_for_python_is_live/\">here</a>, and got a lot of feedback. With new features like Adaptive crawler, unified storage client system, Impit HTTP client, and a lot of new things, the library is ready for its public launch.</p> <p><strong>What My Project Does</strong></p> <p>It&#39;s an open-source web scraping and automation library, which provides a unified interface for HTTP and browser-based scraping, using popular libraries like <a href=\"https://pypi.org/project/beautifulsoup4/\">beautifulsoup4</a> and <a href=\"https://playwright.dev/python/\">Playwright</a> under the hood.</p> <p><strong>Target Audience</strong></p> <p>The target audience is develo",
        "id": 3697034,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nu9d0r/crawlee_for_python_v10_is_live",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Crawlee for Python v1.0 is LIVE!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/pioneertelesonic",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-30T09:37:10.615945+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-30T09:13:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m building an app that will have some web scraping. Maybe ~30 scrapes a month per user. I am trying to understand why server-side is better here. I know it&#39;s supposed to be the better way to do it but if it happens on client, I don&#39;t have to worry about the server IP getting blocked and overall complexity would be much less. I did hundreds of tests locally and it works fine locally. I&#39;m using RN fetch()</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/pioneertelesonic\"> /u/pioneertelesonic </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nu8dvn/scraping_client_side_in_react_native_app/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nu8dvn/scraping_client_side_in_react_native_app/\">[comments]</a></span>",
        "id": 3696473,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nu8dvn/scraping_client_side_in_react_native_app",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping client side in React Native app?",
        "vote": 0
    }
]