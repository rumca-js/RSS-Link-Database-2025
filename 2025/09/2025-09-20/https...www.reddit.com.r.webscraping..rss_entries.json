[
    {
        "age": null,
        "album": "",
        "author": "/u/Horror-Tower2571",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T21:30:53.152344+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T20:36:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Written in GoLang, its a fast and efficient system to scrape proxy aggregators for Socks/Http(s) proxies and store them in DynamoDB for instant access, I use this for web scraping because constantly scraping a provider for a new proxy is slow (like 1-5 seconds to get a new proxy) this lets you get it from a DynamoDB table in single digit milliseconds. </p> <p><a href=\"https://github.com/odinglyn0/Proxy-Managment-DynamoDB\">https://github.com/odinglyn0/Proxy-Managment-DynamoDB</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Horror-Tower2571\"> /u/Horror-Tower2571 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nm8vtt/an_open_source_project_i_made_for_aggregating_and/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nm8vtt/an_open_source_project_i_made_for_aggregating_and/\">[comments]</a></span>",
        "id": 3625313,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nm8vtt/an_open_source_project_i_made_for_aggregating_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "An open source project i made for aggregating and storing proxies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/xcode_lover",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T17:12:25.868754+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T16:19:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>im newbie in using crawl4ai, so my current setup works slightly but in many webpages not works as expected, for example this <a href=\"https://www.surreyandberkshireconstructionandroofing.co.uk\">website </a>if we browse it we can notice there is an email, but the responce of crawl not included it, i tried to read the docs but i still confused.<br/> here is my current body request :</p> <p><code>{</code><br/> <code>&quot;urls&quot;: [</code><br/> <code>&quot;https://www.surrey****&quot;</code><br/> <code>],</code><br/> <code>&quot;crawler_config&quot;: {</code><br/> <code>&quot;type&quot;: &quot;CrawlerRunConfig&quot;,</code><br/> <code>&quot;params&quot;: {</code><br/> <code>&quot;stream&quot;: false,</code><br/> <code>&quot;cache_mode&quot;: {</code><br/> <code>&quot;type&quot;: &quot;CacheMode&quot;,</code><br/> <code>&quot;params&quot;: &quot;bypass&quot;</code><br/> <code>},</code><br/> <code>&quot;js_code&quot;: &quot;window.scrollTo(0, document.b",
        "id": 3624114,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nm2fxm/help_me_improve_my_crawl4ai_config",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "help me improve my crawl4ai config",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Seth_Rayner",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T13:58:59.792058+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T13:05:26+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1nlxogt/heres_an_open_source_project_i_made_this_week/\"> <img src=\"https://external-preview.redd.it/gEqxBnd3397hR-KO-YPojIHl2Q39cLOpx08Y4mR3Ccc.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4bc5b1813d5a5aedaa5cb3b1fe50806a76d0bf64\" alt=\"Here's an open source project I made this week\" title=\"Here's an open source project I made this week\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://github.com/zan-keith/cherry-pick\"><strong>CherryPick - Browser Extension for Quick Scraping Websites</strong></a></p> <p>Select the elements like title or description you want to scrape (two or three of em) and click Scrape Elements and the extension finds the rest of the elements. I made it to help myself w online job search, I guess you guys could find some other purpose for it.</p> <p><a href=\"https://github.com/zan-keith/cherry-pick\">Cherry Pick - Link to github</a></p> <p><em>Idk if something like this al",
        "id": 3623038,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nlxogt/heres_an_open_source_project_i_made_this_week",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/gEqxBnd3397hR-KO-YPojIHl2Q39cLOpx08Y4mR3Ccc.png?width=640&crop=smart&auto=webp&s=4bc5b1813d5a5aedaa5cb3b1fe50806a76d0bf64",
        "title": "Here's an open source project I made this week",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Wonderful-Levels",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T12:47:57.644587+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T12:36:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>hello. i am designing a build to scrape properties from property auctions, estate agents and property websites. i am needing full listings from images to descriptions to minor details. the idea, at first would be a manual scrape of all site, then a daily scan and scrape of just new adverts. this would, sometime in the future, develop into a permanant listener. i envision coming up against anti bot measures. just wondering if there is anyone who has done something simolar who might be able to tell me what to expect in as far as bot detection from these types of sites so i can do some research and give my programmer so he has all avenues to explore as and when he comes up against a hurdle. it will also serve as knowledge for future projects.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Wonderful-Levels\"> /u/Wonderful-Levels </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nlx2d1/scraping_",
        "id": 3622658,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nlx2d1/scraping_property_websites",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Property Websites",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EnvironmentalGap3500",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T08:21:58.863709+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T07:38:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello , im trying to learn webscraping so i have tried to scrap <a href=\"https://shopee.tw\">https://shopee.tw</a> by using playwright connectOverCDP with antibotdetect browser then I intercepted the api response of get_pc and get the product data (title, images ,reviews,\u2026). ,the problem is when i open 100+ links with one account i get loading issue page And that ban goes after sometime, So basically i just need to know how open 1k links without getting loading issue page Means i need to open 100 and wait sometime until i open another 100 i just need to know how much that time is , so please if anyone did this method let us know in the replies PS: im new to this so excuse me for any mistakes</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EnvironmentalGap3500\"> /u/EnvironmentalGap3500 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nlrz9t/shopee_scraping/\">[link]</a></span> &#32; <span><a ",
        "id": 3621507,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nlrz9t/shopee_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Shopee scraping",
        "vote": 0
    }
]