[
    {
        "age": null,
        "album": "",
        "author": "/u/wat3va",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T23:07:59.920164+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T22:31:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.abc.net.au/news/2025-09-21/what-makes-china-confident-to-ban-nvdia-microchips/105795486\">https://www.abc.net.au/news/2025-09-21/what-makes-china-confident-to-ban-nvdia-microchips/105795486</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/wat3va\"> /u/wat3va </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nmbk3b/what_makes_china_confident_enough_to_ban/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nmbk3b/what_makes_china_confident_enough_to_ban/\">[comments]</a></span>",
        "id": 3625770,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nmbk3b/what_makes_china_confident_enough_to_ban",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What makes China confident enough to ban microchips made by US firm Nvidia?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dan_howell",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T22:04:16.565678+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T21:40:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Brave AI (Leo):</strong></p> <p><em>when is 8,965 days after september 19, 2002</em></p> <p>8,965 days after September 19, 2002, is <strong>Friday, June 13, 2025</strong>.</p> <p>This calculation is based on standard date arithmetic using the Gregorian calendar, which is the calendar system used for such computations. The result is derived by adding the specified number of days to the start date, accounting for leap years and the varying number of days in each month.</p> <p><strong>Google AI overview:</strong></p> <p><em>when is 8,965 days after september 19, 2002</em></p> <p>8,965 days after September 19, 2002, is October 26, 2027. You can use an online day counter tool to accurately calculate this date, as it automatically accounts for leap years and varying month lengths. </p> <p>Here&#39;s how you can find the answer: </p> <ol> <li><p>Use an online date calculator or a spreadsheet program that can handle date calculations.</p></li> <li><p>",
        "id": 3625502,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nmadya/why_you_cant_trust_ai_with_math_problems",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Why you can't trust AI with math problems",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/calliope_kekule",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T22:04:16.445160+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T21:02:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Scientists have now used AI to generate complete viral genomes, creating bacteriophages that could infect and kill antibiotic-resistant <em>E. coli</em>. It\u2019s a major step toward AI-designed life, and it raises some pretty big biosafety and ethics questions.</p> <p>In the words of Dr. Ian Malcolm: <em>\u201cYour scientists were so preoccupied with whether or not they could, they didn\u2019t stop to think if they should.\u201d</em></p> <p>Source: <a href=\"https://doi.org/10.1038/d41586-025-03055-y\">https://doi.org/10.1038/d41586-025-03055-y</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/calliope_kekule\"> /u/calliope_kekule </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nm9iat/ai_just_designed_working_viruses_for_the_first/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nm9iat/ai_just_designed_working_viruses_for_the_first/\">[comments]</a><",
        "id": 3625501,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nm9iat/ai_just_designed_working_viruses_for_the_first",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI just designed working viruses for the first time",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DenysDemchenko",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T22:04:16.824061+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T20:55:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><em>Disclaimer: I don\u2019t have a background in AI, so I might be missing key details. This could be fueling some of my anxiety about this.</em></p> <p>So I&#39;ve watching/reading a lot about AI recently and it&#39;s fascinating. I have one concern however, and it mostly stems from what Yampolskiy and Bostrom seem to be saying. Basically: AI &gt; smarter AI &gt; smarter than human AI &gt; makes its own AI &gt; unstoppable pursuit of goals &gt; humans in the way (or human = resource) &gt; humans eliminated (or relegated to meaningless). It&#39;s a bit more elaborate than that but whatever, that&#39;s the core logic.</p> <p>Basically, and please correct me if I&#39;m wrong, I think it&#39;s clear that we (humans) will have no control over ASI if/once it emerges. I mean we&#39;re technically limited by a 3-digit IQ, so by definition, a 100-digit IQ entity wouldn\u2019t stay under our control.</p> <p>Now I know we\u2019re not even close to ASI, and even AGI is debata",
        "id": 3625503,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nm9cby/can_we_predict_the_breaking_point_when_aiagi",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can we predict the breaking point when AI/AGI slips out of control?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/No-Author-2358",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T20:55:10.694808+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T20:36:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://futurism.com/microsoft-ceo-concerned-ai-destroy-company\">Link to article</a> 9/20/25 <em>by</em> <a href=\"https://futurism.com/authors/victor\">Victor Tangermann</a> </p> <h1>It&#39;s a high stakes game.</h1> <p>Morale among employees at <a href=\"https://www.microsoft.com/en-us/store/b/home\">Microsoft</a> is circling the drain, as the company has been roiled by constant rounds of layoffs <a href=\"https://futurism.com/microsoft-boss-ai-advice\">affecting thousands of workers</a>.</p> <p>Some say they&#39;ve <a href=\"https://www.businessinsider.com/microsoft-layoffs-culture-change-employee-resigned-found-new-job-2025-8\">noticed a major culture shift</a> this year, with many suffering from a constant fear of being sacked \u2014 or <a href=\"https://www.engadget.com/gaming/xbox/even-before-the-xbox-layoffs-there-was-tension-at-halo-studios-002031995.html?guccounter=1\">replaced by AI</a> as the company <a href=\"https://futurism.com/microsoft-copil",
        "id": 3624798,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nm8vvy/microsoft_ceo_concerned_ai_will_destroy_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Microsoft CEO Concerned AI Will Destroy the Entire Company",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/QuietInnovator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T20:55:11.596578+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T20:14:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><h1>This week witnessed transformative developments across the AI industry, with major funding announcements exceeding billions in investment and groundbreaking research collaborations between industry leaders. Tech giants are accelerating their AI strategies while regulatory bodies worldwide establish comprehensive frameworks to govern AI deployment. The convergence of massive capital investment, safety research, and regulatory clarity signals a maturing industry preparing for widespread adoption.</h1> <p><strong>This Week&#39;s Snapshot</strong></p> <p><strong>AI Models:</strong> Meta releases new open-source language model with improved efficiency</p> <p><strong>Startups:</strong> AI healthcare startup raises $150M for diagnostic tools development</p> <p><strong>Enterprise:</strong> Fortune 500 companies report 40% increase in AI adoption this quarter</p> <p><strong>Open Source:</strong> New collaborative AI research platform launches with 10,000+ con",
        "id": 3624799,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nm8cjr/ai_weekly_5_billion_ai_investment_initiative",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI Weekly - $5 Billion AI Investment Initiative, OpenAI-Anthropic Safety Collaboration, and EU Passes Comprehensive AI Framework",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Creative-Type9411",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T20:55:11.972005+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T18:25:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to start off by saying if you already have a WSL installation for Ubuntu 24.04 this script isn&#39;t for you. I did not take into account existing installations when making this there is too much to consider... if you do not currently have a WSL build installed, this will get you going</p> <p>This is a script designed to get a local model downloaded to your machine (via huggingface repos), it&#39;s basically a one click solution for installation/setup and a one click solution for launching the model.. It contains CMD/Powershell/C#/Bash. it can be running client only mode where it will behave as an open AI compatible client to communicate with the model, or it can be run in client server hybrid, where you can interact with the model right on the local machine..</p> <p>MyAI: <a href=\"https://github.com/illsk1lls/MyAI\">https://github.com/illsk1lls/MyAI</a></p> <p>I currently have 12gb of VRAM and wanted to experiment and see what kind of model I c",
        "id": 3624800,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nm5mta/myai_a_wrapper_for_vllm_on_windows_wwsl",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "MyAI - A wrapper for vLLM on Windows w/WSL",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ai-but-better",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T17:46:24.054488+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T16:55:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Are we moving toward a future where only AI can defend against AI? </p> <p>Would love to hear thoughts from fellow cybersecurity professionals and AI researchers!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ai-but-better\"> /u/ai-but-better </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nm3d2n/whats_your_take_on_aipowered_cybersecurity/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nm3d2n/whats_your_take_on_aipowered_cybersecurity/\">[comments]</a></span>",
        "id": 3624278,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nm3d2n/whats_your_take_on_aipowered_cybersecurity",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's your take on AI-powered cybersecurity?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheTeamBillionaire",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T16:41:27.094676+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T15:53:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Autonomous AI agents</strong> have the potential to transform how we work, from systems that can code themselves to AIs capable of managing entire businesses. But are we really at that point, or is this just another example of technological hype outpacing what we can actually achieve?</p> <ul> <li>Have you had any success in building or using a truly autonomous agent?</li> <li>What do you see as the biggest obstacle: reliability, costs, hallucinations, or the limitations of current tools?</li> <li>Do you think these agentic systems will ultimately take over workflows, or will they merely serve as advanced copilots?</li> </ul> <p>I\u2019m eager to hear from those who are actively building and testing these agents in real-world scenarios, not just speculating.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheTeamBillionaire\"> /u/TheTeamBillionaire </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialIn",
        "id": 3623948,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nm1rq8/is_agentic_ai_already_overhyped",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is Agentic AI Already Overhyped?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Jayu777",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T15:34:47.966528+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T15:14:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>TL;DR: Jobs that rely on human senses like taste, smell, touch, emotion are harder for AI to fully replace. AI can assist with recipes, scents, or music, but it can\u2019t experience flavor, aroma, or feeling like we do\u2026 yet.</p> <p>When we talk about AI replacing jobs, a lot of focus is on coding, customer service, or logistics. But what about jobs that rely heavily on our biological senses?</p> <p>Cooks who taste and adjust as they go.</p> <p>Wine tasters or perfumers who rely on insanely subtle scent differences.</p> <p>Musicians who bring an emotional \u201cfeel\u201d to sound.</p> <p>AI is already creeping into these areas:</p> <p>Cooking: IBM\u2019s Chef Watson can generate recipes and suggest flavor pairings.</p> <p>Perfume: Firmenich uses AI to design new scent molecules.</p> <p>Music: AIVA and Amper Music generate tracks on demand.</p> <p>But here\u2019s the catch: AI doesn\u2019t experience taste, smell, or emotion. it processes data. A sensor detects molecules; a model ",
        "id": 3623575,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nm0stf/are_sensorybased_jobs_safe_from_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are sensory-based jobs safe from AI?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Low_Spread9760",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T15:34:48.204365+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T14:46:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>AI is coming to charities as well as businesses\u2014but we need to make sure it helps, not harms or hinders. I\u2019m writing a governance report for a UK health charity focussed on advocacy, awareness raising, support services like befriending and a helpline, and providing reliable, trustworthy, accessible information. I would highly appreciate feedback from this community.</p> <p><strong>What I\u2019ve Covered So Far:</strong><br/> \u2022 The opportunities and risks of AI in a charity context (e.g. efficiencies, new services, bias, over-reliance, reputational harm).<br/> \u2022 Current and potential uses: communications, analysis, risk management, language translation.<br/> \u2022 Options for implementation: readymade tools vs. custom models.<br/> \u2022 Key risks: misinformation, bias/discrimination, security/privacy, accessibility, governance by algorithm, environmental impact, prompt injection, staff morale, etc.<br/> \u2022 Relevant law and standards: GDPR, Equality Act, UK/EU AI bil",
        "id": 3623576,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nm033m/ai_governance_in_the_uk_charity_sector_looking",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI Governance in the UK Charity Sector - Looking for Feedback",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CalligrapherFine6407",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T12:13:52.960813+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T11:43:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m a AI/software engineer and I\u2019m trying to redesign my workflow so that <strong>AI is the core of how I build</strong>, not just a tool I occasionally reach for. My goal is to reach a point where &gt;80% of my engineering workflow (architecture, coding, debugging, testing, documentation) is done using AI/agents.</p> <p>For folks who have made this shift or researched it:</p> <ul> <li>What does an <em>AI-centric</em> workflow look like in practice?</li> <li>Are there frameworks or patterns for structuring projects so that LLMs/agents are integral from design to deployment, rather than an add on?</li> <li>How do you balance AI-driven coding/automation with the need for human oversight and robust architecture?</li> <li>What are the failure points you\u2019ve seen when teams try to make AI central, and how do you mitigate them?</li> </ul> <p><em>For context: my stack is</em> <strong><em>Python, Django, FastAPI, Supabase, AWS, DigitalOcean, Docker, GitHub</em",
        "id": 3622465,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nlw0m6/d_what_does_an_aifirst_workflow_look_like_in_real",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[D] What does an \u201cAI-first workflow\u201d look like in real software engineering?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/g_rogers5",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T12:13:53.112721+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T11:07:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been thinking a lot recently about what counts as excessive use of AI.</p> <p>I run a small business and have been using the same spreadsheet to track sales for the last year. Recently, I started using ChatGPT to completely overhaul it\u2014adding formulas, automations, and features in Excel that I never even knew existed. It feels amazing to have things so streamlined, and I don\u2019t see a problem with using AI for this.</p> <p>But it did make me realise something: I would never have been able to build these tools myself without years of studying and practice. AI basically let me skip all that. And honestly, why shouldn\u2019t I, if it saves time and effort?</p> <p>The question is: where\u2019s the line between using AI in a useful way vs. in a lazy way?</p> <p>Some thoughts I\u2019ve had:</p> <p>Cooking: Should I use AI to help plan meals or even guide me through cooking? It feels similar to the spreadsheet example. On the one hand, AI can always \u201cjust do it\u201d for me,",
        "id": 3622466,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nlvcwt/using_ai_as_a_tool_but_not_voiding_the_process_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Using AI as a tool, but not voiding the \u2018process of learning\u2019",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Suspicious-Buyer8135",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T08:51:31.160511+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T08:17:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ll admit I have zero technical ability and barely use AI tools. Everything I know comes from reading articles in the media and on Reddit.</p> <p>It seems to me that the lack of data to feed AI is going to be a major issue for ongoing improvement to models. I assume the major AI companies have sucked the well dry. Further, model collapse has to be a problem as more of the internet is populated by content produced by AI.</p> <p>So my question is; do you think anyone is looking at direct neural interfaces to human brains as a data source?</p> <p>I know Elon is has Neuralink. Do you think they are considering the data implications for AI?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Suspicious-Buyer8135\"> /u/Suspicious-Buyer8135 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nlskws/human_mind_as_data_source/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Arti",
        "id": 3621615,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nlskws/human_mind_as_data_source",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Human mind as data source",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Life_Situation_9466",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T07:47:07.448616+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T06:58:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Current large language models (LLMs) are monolithic, leading to a trade-off between capability, safety, and efficiency. We propose the Governed Multi-Expert (GME) architecture, a novel inference framework that transforms a single base LLM into a dynamic, collaborative team of specialists. Using efficient Low-Rank Adaptation (LoRA) modules for expertise and a streamlined governance system, GME routes user queries to specialized &quot;expert&quot; instances, validates outputs in real-time, and manages computational resources like a distributed network. This design promises significant gains in response quality, safety, and scalability over standard inference approaches.</p> <ol> <li>The Core Idea: From One Model to a Team of Experts</li> </ol> <p>Imagine a company. Instead of one employee trying to do every job, you have a team of specialists: a lawyer, a writer, a engineer. They all share the same company knowledge base (the base model) but have their ",
        "id": 3621375,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nlrc3z/governed_multiexpert_aka_gme",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Governed multi-expert AKA (GME)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/gkv856",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T06:44:04.281164+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T05:57:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I haev been thinking about the current state of building agentic AI systems, and it feels like we&#39;re still in the &quot;build-it-yourself&quot; phase, which is too complex for most of people.</p> <p>And recently NVIDIA published SLMs over LLMs for agentic workflow. It got me wondering if the future looks more like a plug-and-play ecosystem.</p> <p>The idea is simple:</p> <ol> <li><strong>An &quot;Agent Play Store&quot;:</strong> A marketplace (like Hugging Face, but more consumer-focused) where you can browse and download specialized, small language models. Not giant foundation models, but niche experts: a super-accurate PDF-parsing SLM, a data-graphing SLM, a compliance-checking SLM for finance, etc.</li> <li><strong>An Orchestration Layer:</strong> You&#39;d use a tool like LangChain (or something even simpler) to visually connect these &quot;agent-lets.&quot; Basically, a Zapier for AI. &quot;When new email arrives -&gt; send to PDF-parser SLM ",
        "id": 3621152,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nlqc1g/is_the_next_step_for_ai_agents_a_simple_play",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is the next step for AI Agents a simple \"Play Store\" for models?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EpDisDenDat",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T02:16:43.230724+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T01:46:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I suck when it comes to syntax, I blame my ADHD brain. I&#39;ve done pretty well so far engineering solutions by just analogically mapping whatever I don&#39;t know and learning to things I do know very well. And it&#39;s funny some of things I&#39;ve learned how to do with AI - without being scored on syntax. Everything is just pattern recognition... We recognize existing patterns, and if we acknowledge that they&#39;re everywhere, we can learn anything. Reinventing the wheel is never a waste - because to invent anything is to enable yourself the ability to understand anything. And when you seek understanding everywhere and in everything, and everyone - then you are an entity of momentum, drawn to the inertia of absolute knowledge. </p> <p>I spent the afternoon coming up with a different way of doing semantic search by assigning quaternion operations to a type of coordinate system... it was fun. I&#39;m into scifi and math and an omakase of many othe",
        "id": 3620340,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nllohi/maintaining_grounded_perspective_between_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Maintaining Grounded Perspective between AI Delusion and Nuanced Reality via Metaphor and Analogical Mapping.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AkatsukiShi",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-20T01:03:34.343101+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-20T00:19:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This post is here only cause I\u2019m tired of young people getting mindfd by people that just want to drag a narrative to make money.</p> <p>Almost all jobs will be here on the long run. Ai just makes things easier.</p> <p>It\u2019s nice marketing for ai companies to sell a dream to investors but sadly a machine that will replace a human on an important task such as marketing and engineering on any serious level is very far away from what our current tech can achieve.</p> <p>Don\u2019t get wasted by Sam Altmans bullshido and pick what you like.</p> <p>Just don\u2019t do anything that is repeatable All that will be taken by ai thank any god you pray to.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AkatsukiShi\"> /u/AkatsukiShi </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nljxfu/ai_wont_take_your_job/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comment",
        "id": 3620045,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nljxfu/ai_wont_take_your_job",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ai won\u2019t take your job!!!",
        "vote": 0
    }
]