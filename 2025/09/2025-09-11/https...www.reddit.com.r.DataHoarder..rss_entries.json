[
    {
        "age": null,
        "album": "",
        "author": "/u/TheUlfhedin",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T23:25:17.879299+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T23:21:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I came across a box of these I would love to store on my server for watching. Anyone here have recommendations. Was hoping I could track down a converter so I could at least rip to DVD then DVD to server but no one sells that stuff anymore. So much memoires lost. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheUlfhedin\"> /u/TheUlfhedin </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nenqyv/ripping_vhsc_and_minidv/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nenqyv/ripping_vhsc_and_minidv/\">[comments]</a></span>",
        "id": 3553014,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nenqyv/ripping_vhsc_and_minidv",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ripping VHS-C and MiniDV",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/FalsettoChild",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T23:25:18.100134+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T22:45:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve searched Diffractor documentation and tried experimenting a bit and am at a loss. Can anyone tell me how Diffractor handles referencing multiple catalogs for removable hard drives that either share the same drive letter assignment or the drive letter assignment changes? Typical issues when you are moving drives around. My copy doesn&#39;t seem to recognize if I have Hard Drive #01 as Drive D: and I catalog it, and then I attach another drive Drive #02 to the computer and it also assigns drive letter D;, and I catalog that... how do I view these thumbnail catalogs for a specific drive that is not attached?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/FalsettoChild\"> /u/FalsettoChild </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nemywo/diffractor_image_cataloguer_cataloging_multiple/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nemywo/",
        "id": 3553015,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nemywo/diffractor_image_cataloguer_cataloging_multiple",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Diffractor Image Cataloguer - Cataloging Multiple Removable Drives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/South-Branch-7890",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T23:25:17.578634+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T22:27:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have ZenDrive U9M (SDRW-08U9M-U) and I had bought these Verbatim BD-R 25 GB discs. Unfortunately this drive can burn only DVD (4.7GB) discs and not Blu-Ray. </p> <p>I have seen past posts here on that, but I cannot find anyone in Europe selling the original DVD M-DISCs (that suppose/are &quot;tested&quot; to last for 1000 years). Does anyone know anything more on that?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/South-Branch-7890\"> /u/South-Branch-7890 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nemjrd/dvd_mdiscs_in_europe/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nemjrd/dvd_mdiscs_in_europe/\">[comments]</a></span>",
        "id": 3553013,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nemjrd/dvd_mdiscs_in_europe",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "DVD M-DISCs in Europe",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fulcro97",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T21:06:34.114561+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T20:40:25+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nejyt1/is_this_noise_normal_during_transfer/\"> <img src=\"https://external-preview.redd.it/ZWlzMGh2YThrbG9mMe5Zby8mkS8Fzhb3sSfPZVdKepIF1RP6hl4ohKd5dyNi.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4b94a6c28b540bb76a62695e265d7f1e9d4dab3a\" alt=\"Is this noise normal during transfer?\" title=\"Is this noise normal during transfer?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi guys, just bought my first big drive (20tb seagate) and it\u2019s making these noises during a big transfer, is it normal? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Fulcro97\"> /u/Fulcro97 </a> <br/> <span><a href=\"https://v.redd.it/6uc54ch8klof1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nejyt1/is_this_noise_normal_during_transfer/\">[comments]</a></span> </td></tr></table>",
        "id": 3552107,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nejyt1/is_this_noise_normal_during_transfer",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/ZWlzMGh2YThrbG9mMe5Zby8mkS8Fzhb3sSfPZVdKepIF1RP6hl4ohKd5dyNi.png?width=640&crop=smart&auto=webp&s=4b94a6c28b540bb76a62695e265d7f1e9d4dab3a",
        "title": "Is this noise normal during transfer?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/bilegeek",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T21:06:32.326069+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T20:31:41+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/bilegeek\"> /u/bilegeek </a> <br/> <span><a href=\"https://www.phoronix.com/news/Linux-6.18-write-cache-pages\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nejqpw/linux_618_will_further_complicate_nongpl/\">[comments]</a></span>",
        "id": 3552105,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nejqpw/linux_618_will_further_complicate_nongpl",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Linux 6.18 Will Further Complicate Non-GPL Out-Of-Tree File-Systems",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Bestgirl95",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T21:06:32.809402+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T20:06:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Any idea on how to download books from Perlego into a PDF? </p> <p>Would appreciate the help! and with the help if there are any books you need just let me know </p> <p>Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Bestgirl95\"> /u/Bestgirl95 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nej3g7/perlego_download_update/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nej3g7/perlego_download_update/\">[comments]</a></span>",
        "id": 3552106,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nej3g7/perlego_download_update",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Perlego Download update",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/physicistbowler",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T21:06:31.962508+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T19:50:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><h2>Intro</h2> <p>I&#39;ve been getting acclimated to the disc ripping world using <strong>Automatic Ripping Machine</strong>, which I know primarily relies on MakeMKV &amp; HandBrake. I started with DVDs &amp; CDs, and in the last few weeks I purchased a couple Blu-Ray drives, but I&#39;ve had trouble getting those ripped. First, some specifics:</p> <h2>Hardware &amp; software</h2> <ul> <li>2x LG BP50NB40 SVC NB52 drive, double-flashed as directed on the <a href=\"https://forum.makemkv.com/forum/viewtopic.php?f=16&amp;t=22896\">MakeMKV forum</a> <ul> <li>LibreDrive Information</li> <li>Status: Enabled</li> <li>Drive platform: MT1959</li> <li>Firmware type: Patched (microcode access re-enabled)</li> <li>Firmware version: one w/ BP60NB10 &amp; the other w/ BU40N</li> <li>DVD all regions: Yes</li> <li>BD raw data read: Yes</li> <li>BD raw metadata read: Yes</li> <li>Unrestricted read speed: Yes</li> </ul></li> <li>Computers &amp; software <ul> <li>Laptop 1 &",
        "id": 3552104,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1neiohd/bluray_drives_rip_dvds_but_not_bluray_fhd_or_uhd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Blu-Ray drives rip DVDs but not Blu-Ray (FHD or UHD)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EderMats32",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T18:15:01.060660+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T18:09:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Might be in the wrong sub, please suggest another one if you know of a more fitting one. </p> <p>In the process of digitizing VHS tapes i compared S-Video to RCA.<br/> The S-Video output is full of artifacts.<br/> Can anyone identify what causes this?<br/> Is it most likely:</p> <ul> <li>The S-Video cable</li> <li>The SCART to RCA/S-Video converter? (I have tried two, both of them are pretty cheap though so i don&#39;t rule them out)</li> <li>The Analog to Digital convert, this one: <a href=\"https://www.amazon.it/dp/B078H54QDR\">https://www.amazon.it/dp/B078H54QDR</a></li> <li>The tape (I will try with another one tomorrow)</li> <li>The VHS player JVC HR-J672</li> </ul> <p>Comparison images:</p> <p>S-Video: <a href=\"https://postimg.cc/bDBXjJVC\">https://postimg.cc/bDBXjJVC</a><br/> RCA: <a href=\"https://postimg.cc/642k6XD9\">https://postimg.cc/642k6XD9</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EderMats32\">",
        "id": 3550783,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1neg1lq/vhs_digitize_bad_svideo_signal_cause",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "VHS digitize - Bad S-Video signal - Cause?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/smrcmr",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T19:48:34.973344+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T17:58:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m working on setting up a NAS with hard drives I have around, but am having a hard time determining if my drives use SMR or CMR. I&#39;ve read that SMR drives are incompatible with ZFS, so I wanted to verify the format of my drives before putting everything together.</p> <p>The hard drives in question have model numbers <code>WD120EMAZ</code> and <code>WD120EMFZ</code>, both 12TB drives pulled from WD EasyStore external drives purchased years ago. From what I can find online, WD has never explicitly stated if these drives use SMR or CMR.</p> <p>Are there any tests I could perform to figure this out? I&#39;m worried that if I inadvertently put SMR drives into my NAS, I could risk data loss from SMR-related errors in the future.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/smrcmr\"> /u/smrcmr </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nefrjc/definitive_way_to_tell_if_a_drive_us",
        "id": 3551435,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nefrjc/definitive_way_to_tell_if_a_drive_uses_smr_or_cmr",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Definitive way to tell if a drive uses SMR or CMR?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MomentSmart",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T19:48:35.372967+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T17:56:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What systems are you using to locate specific files across dozens of external drives? I\u2019ve got backups going back years and I always think, \u201cI know I have that file\u2026 somewhere.\u201d But unless I plug in half my archive, it is lost to the ages. Do you keep detailed spreadsheets? Use drive cataloging software? Just really good at remembering folder names? </p> <p>Would love to hear how others are managing this.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MomentSmart\"> /u/MomentSmart </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nefp24/how_do_you_guys_actually_find_files_buried_on_old/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nefp24/how_do_you_guys_actually_find_files_buried_on_old/\">[comments]</a></span>",
        "id": 3551436,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nefp24/how_do_you_guys_actually_find_files_buried_on_old",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you guys actually find files buried on old drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/65544",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T18:15:01.474856+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T17:37:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m looking for a way (tool, website, or method) to find all the services, subscriptions, or accounts that are connected to my email address. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/65544\"> /u/65544 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nef7jd/is_there_a_way_to_see_all_the_services/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nef7jd/is_there_a_way_to_see_all_the_services/\">[comments]</a></span>",
        "id": 3550784,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nef7jd/is_there_a_way_to_see_all_the_services",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a way to see all the services, subscriptions, or accounts linked to my email address?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/stingrayjerk11211",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T18:15:01.736758+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T17:10:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>There are dozens of these sites online. I don&#39;t mind having to go 1 post at a time. However when I download a post it must &quot;carry over&quot; the original information I had in the posts description. Once a post is downloaded I must be able to right click on the .jpg and go to properties and then details and be able to read what I had. </p> <p>I&#39;m all done with 4kstogram after many years. Which I really enjoyed as it would carry over the info for me for each post. I finally started getting warnings the other day about using a 3rd party app so I&#39;m done. WFdownloader looks pretty good but it appears you have to download the information separately as a .json </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/stingrayjerk11211\"> /u/stingrayjerk11211 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1neehmk/looking_for_a_simple_online_tool_to_download_my/\">[link]</a></span> &#32; <sp",
        "id": 3550785,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1neehmk/looking_for_a_simple_online_tool_to_download_my",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a simple online tool to download my instagram pics but it MUST carry over the original information I had.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Endeavour1988",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T18:15:01.963613+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T17:09:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I wanted to manually backup some data to an external harddrive, there is quite a few TBs worth of data and some folders might have new refreshed data in. Using a robocopy command what switches at the end do I need to use to ensure new stuff is copied even if it has the same file name but the file is newer. </p> <p>I normally just use/E on the end.. but I just wanted to keep it updated and current </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Endeavour1988\"> /u/Endeavour1988 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1neegkz/manual_backups_with_robocopy/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1neegkz/manual_backups_with_robocopy/\">[comments]</a></span>",
        "id": 3550786,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1neegkz/manual_backups_with_robocopy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Manual backups with robocopy",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Kaiser_Richard_1776",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T17:01:22.437001+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T16:50:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need to upgrade a consoles storage to 2tb and all the sd cards I&#39;ve seen are either 200 dollars or 80 bucks. I tried the cheaper option and I&#39;ve been scammed twice. Is there any good 2 tb sd cards that aren&#39;t scams that won&#39;t break the bank? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kaiser_Richard_1776\"> /u/Kaiser_Richard_1776 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nedyls/what_would_you_recommend_for_a_2_tb_sd_card/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nedyls/what_would_you_recommend_for_a_2_tb_sd_card/\">[comments]</a></span>",
        "id": 3549933,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nedyls/what_would_you_recommend_for_a_2_tb_sd_card",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What would you recommend for a 2 tb sd card?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/towerrh",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T17:01:22.193717+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T16:11:20+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1necxe4/new_silverstone_cs_823_120tb_setup/\"> <img src=\"https://b.thumbs.redditmedia.com/f7rxEw-mbxjKC4t_U_MxUYFNeJucNxmAeDvc6t-XlDE.jpg\" alt=\"New Silverstone CS 823 - 120tb setup.\" title=\"New Silverstone CS 823 - 120tb setup.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Just bought this overly expensive case with 8 eBays. Added the 4bay in the 5.25 slot. Cleans up pretty nice.</p> <p>Currently running an unraid 11 disk array mixed with two parity. 3x1tb nvmes. 2x1tb sata ssds.</p> <p>Only issue I have is the fans. Will be swapping those out with a 92mm to 120mm fan adapter. With these fan maxed they keep the drives at 40c.</p> <p>Overall an amazing case with tons of options and was super easier to install</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/towerrh\"> /u/towerrh </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1necxe4\">[link]</a></span> &#32; <span",
        "id": 3549932,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1necxe4/new_silverstone_cs_823_120tb_setup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/f7rxEw-mbxjKC4t_U_MxUYFNeJucNxmAeDvc6t-XlDE.jpg",
        "title": "New Silverstone CS 823 - 120tb setup.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Emotional_Dust2807",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:04.806494+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T15:47:28+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Emotional_Dust2807\"> /u/Emotional_Dust2807 </a> <br/> <span><a href=\"/r/Archivists/comments/1ne97kr/what_is_the_best_of_way_of_archiving_a_youtube/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1necb7p/what_is_the_best_of_way_of_archiving_a_youtube/\">[comments]</a></span>",
        "id": 3547802,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1necb7p/what_is_the_best_of_way_of_archiving_a_youtube",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What is the best of way of archiving a youtube channel?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ILoveComputer4553",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:04.656135+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T15:33:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I currently use Usenet on my home server and haven\u2019t needed a VPN so far. Now I\u2019d like to add another client as a secondary option, which does require VPN protection. I know it\u2019s possible to bind the VPN to qBittorrent, but another application I use (slsk) doesn\u2019t support vpn binding.</p> <p>If I run the VPN system-wide, it interferes with services I host on my network (media server, SMB shares). That makes it tricky to stay protected without breaking local access.</p> <p>Is there a way to solve this so I can keep certain apps behind a VPN while keeping my local network services functional? I need to be careful since I\u2019m based in Germany.</p> <p>This is not about downloading or sharing copyrighted content.</p> <p>Thanks! \ud83d\ude42</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ILoveComputer4553\"> /u/ILoveComputer4553 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1nebygq/vpn_question_for_downloa",
        "id": 3547801,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nebygq/vpn_question_for_downloading",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "VPN Question for downloading",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HeroponRikiBestest",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:05.071527+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T15:11:55+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1nebevl/western_digital_hdd_connector_pcb_screw_sizetype/\"> <img src=\"https://b.thumbs.redditmedia.com/kCG1auTjK7clbs5gKhDNbwgq_-rjUPnM0zUrqWzNkNo.jpg\" alt=\"Western Digital HDD connector PCB screw size/type?\" title=\"Western Digital HDD connector PCB screw size/type?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Apologies if there&#39;s an easy place to find this information, but I couldn&#39;t find it anywhere online. I misplaced the screws for my HDD&#39;s sata connector PCB, and I need to buy more. I want to make sure I have the right kind of screw, since the board is mainly just held in place via pressure from the screws. I think it&#39;s some kind of torx 6 flathead screw, but I&#39;m not 100% sure, nor do I know the exact length. I&#39;ve attached a picture of the PCB below. This came out of a WD180EDGZ-11B9PA0, if it matters.</p> <p><a href=\"https://preview.redd.it/k8mcqm6mxjof1.jpg?width=5000&amp;for",
        "id": 3547804,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1nebevl/western_digital_hdd_connector_pcb_screw_sizetype",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/kCG1auTjK7clbs5gKhDNbwgq_-rjUPnM0zUrqWzNkNo.jpg",
        "title": "Western Digital HDD connector PCB screw size/type?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Global_Selection_923",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:05.197822+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T15:06:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a couple of medical MRI DVDs. I&#39;m looking to make a copy of each so that I can give one copy of each to a doctor and can keep one myself. How to go about copying each on Windows 11. Would prefer to use Win 11 native tools if possible, but I can load another utility if I need to. I&#39;ve attached images of the properties and contents of each. I would expect this to be pretty simple. Just don&#39;t know the method. Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Global_Selection_923\"> /u/Global_Selection_923 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1neba2o/how_to_copy_an_mri_dvd_to_another_dvd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1neba2o/how_to_copy_an_mri_dvd_to_another_dvd/\">[comments]</a></span>",
        "id": 3547805,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1neba2o/how_to_copy_an_mri_dvd_to_another_dvd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to copy an MRI DVD to another DVD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Zloty_Diament",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:04.161425+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T13:19:56+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne8mrj/how_would_someone_archive_these_books_if_he/\"> <img src=\"https://external-preview.redd.it/q6oHEGbi1VtSYsBTXz5A4w5ojEXpHlfFXOI2k4l4c4k.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8309d960a19645bccd69733d3e871bc5a2d967a8\" alt=\"How would someone archive these books if he wanted to pick them up from shelves and open them? (Trigger Warning)\" title=\"How would someone archive these books if he wanted to pick them up from shelves and open them? (Trigger Warning)\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Zloty_Diament\"> /u/Zloty_Diament </a> <br/> <span><a href=\"https://v.redd.it/w97eui90w5of1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne8mrj/how_would_someone_archive_these_books_if_he/\">[comments]</a></span> </td></tr></table>",
        "id": 3547799,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ne8mrj/how_would_someone_archive_these_books_if_he",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/q6oHEGbi1VtSYsBTXz5A4w5ojEXpHlfFXOI2k4l4c4k.png?width=640&crop=smart&auto=webp&s=8309d960a19645bccd69733d3e871bc5a2d967a8",
        "title": "How would someone archive these books if he wanted to pick them up from shelves and open them? (Trigger Warning)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ardakilic",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:05.447034+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T13:05:30+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ardakilic\"> /u/Ardakilic </a> <br/> <span><a href=\"/r/opensource/comments/1ne84vt/lilt_a_lightweight_tool_to_convert_hires_flac/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne8axm/lilt_a_lightweight_tool_to_convert_hires_flac/\">[comments]</a></span>",
        "id": 3547806,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ne8axm/lilt_a_lightweight_tool_to_convert_hires_flac",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Lilt - A Lightweight Tool to Convert Hi-Res FLAC Files",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cube8021",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:04.470873+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T12:30:19+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne7iyx/dont_you_love_when_a_drive_fails_in_another_vdev/\"> <img src=\"https://preview.redd.it/ncvdegpm3jof1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=92b91788eb729f12b9383540487ccf3202e6b73d\" alt=\"Don't you love when a drive fails in another vdev during a resilver?\" title=\"Don't you love when a drive fails in another vdev during a resilver?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>DiskPool0 is currently a party zone! I&#39;m actually in the middle of a rolling replacement of all the drives in my &quot;Linux ISO&quot; server. We&#39;ve got one resilver chugging along in raidz2-0 (only 2 days left on that one!), and then poof, another drive in raidz2-4 decides to bail and of course, it&#39;s one of the <em>new</em> ones, only a few weeks old! So now we&#39;re doing two resilvers at once. At least there are no data errors... yet. Send snacks and good vibes.</p> </div><!-- SC_ON --> &#32; submitted ",
        "id": 3547800,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ne7iyx/dont_you_love_when_a_drive_fails_in_another_vdev",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ncvdegpm3jof1.png?width=640&crop=smart&auto=webp&s=92b91788eb729f12b9383540487ccf3202e6b73d",
        "title": "Don't you love when a drive fails in another vdev during a resilver?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NXGZ",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:04.007180+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T12:25:18+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne7f3v/vimeo_to_be_acquired_by_bending_spoons_for_138/\"> <img src=\"https://external-preview.redd.it/nowCyuaNWDnIbU8787AvT1QehxSrOmtv1rifdZtEqf4.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3b8d9b3de7dcee3e991e0ac3a21cf297411d8662\" alt=\"Vimeo to be acquired by Bending Spoons for $1.38 billion\" title=\"Vimeo to be acquired by Bending Spoons for $1.38 billion\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>The European software company will take Vimeo private after the deal closes</p> <p><a href=\"https://investors.vimeo.com/news-releases/news-release-details/vimeo-enters-definitive-agreement-be-acquired-bending-spoons-138/\">https://investors.vimeo.com/news-releases/news-release-details/vimeo-enters-definitive-agreement-be-acquired-bending-spoons-138/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NXGZ\"> /u/NXGZ </a> <br/> <span><a href=\"https://www.theverge.com/ne",
        "id": 3547798,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ne7f3v/vimeo_to_be_acquired_by_bending_spoons_for_138",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/nowCyuaNWDnIbU8787AvT1QehxSrOmtv1rifdZtEqf4.jpeg?width=640&crop=smart&auto=webp&s=3b8d9b3de7dcee3e991e0ac3a21cf297411d8662",
        "title": "Vimeo to be acquired by Bending Spoons for $1.38 billion",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/T-nash",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:04.922297+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T12:00:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Basically that, i know discs tend to get errors, and i used to use cd recovery box back in the day (which never worked). If there&#39;s anything new or better, would love recommendations. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/T-nash\"> /u/T-nash </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne6wdo/i_have_a_few_family_photovideo_discs_from_the/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne6wdo/i_have_a_few_family_photovideo_discs_from_the/\">[comments]</a></span>",
        "id": 3547803,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ne6wdo/i_have_a_few_family_photovideo_discs_from_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I have a few family photo/video discs from the 2000s i want to digitize, any DVD recovery software in case i run into errors?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Wilson1218",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:05.738618+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T10:30:56+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Wilson1218\"> /u/Wilson1218 </a> <br/> <span><a href=\"/r/servers/comments/1ne3ief/identifying_rackmountable_drive_chassis/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne593p/identifying_rackmountable_drive_chassis/\">[comments]</a></span>",
        "id": 3547807,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ne593p/identifying_rackmountable_drive_chassis",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Identifying rack-mountable drive chassis",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/United_Ad5067",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:05.910445+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T10:24:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Drive on idle. This periodic high pitch at the beginning and around 11s makes me worry.</p> <p><a href=\"https://reddit.com/link/1ne55fi/video/3sc4qlhciiof1/player\">https://reddit.com/link/1ne55fi/video/3sc4qlhciiof1/player</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/United_Ad5067\"> /u/United_Ad5067 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne55fi/does_this_sound_normal_for_a_brand_new_seagate/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne55fi/does_this_sound_normal_for_a_brand_new_seagate/\">[comments]</a></span>",
        "id": 3547808,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ne55fi/does_this_sound_normal_for_a_brand_new_seagate",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does this sound normal for a brand new Seagate expansion 20t?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Prudent_Impact7692",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:06.103453+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T09:56:20+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne4oal/whats_the_size_of_annas_archive_deduplicated/\"> <img src=\"https://b.thumbs.redditmedia.com/vtIOuX0BECXXAdc7ypesIP2NKqE7yacM5Q_Z_cS4JFg.jpg\" alt=\"What's the size of anna's archive deduplicated?\" title=\"What's the size of anna's archive deduplicated?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/c6wt7zk7ziof1.png?width=434&amp;format=png&amp;auto=webp&amp;s=890b640e3e8687bd2da98c79ae768d943390db4b\">https://preview.redd.it/c6wt7zk7ziof1.png?width=434&amp;format=png&amp;auto=webp&amp;s=890b640e3e8687bd2da98c79ae768d943390db4b</a></p> <p>Anna&#39;s archive does not only host its own collection but also mirrors of other libraries such as Z-Lib and Library Genesis.</p> <p>If someone would to download the entire archive, how large would the total collection be once all duplicates are removed? Does anyone have numbers, estimates, or personal experience with this?</p> <p>Thank",
        "id": 3547809,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ne4oal/whats_the_size_of_annas_archive_deduplicated",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/vtIOuX0BECXXAdc7ypesIP2NKqE7yacM5Q_Z_cS4JFg.jpg",
        "title": "What's the size of anna's archive deduplicated?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BeeKey537",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:06.250913+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T09:47:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have around 2 TB of data (movies, tv shows, family photos) on my PC that i need to store. But I&#39;m confused between getting an SSD or HDD. Yes there is a price gap but i don&#39;t care about it. My priority is reliability.<br/> My use case will be writing once, and then reading multiple times. Once it gets filled, no more data will be replaced, rather, ill get a new one.<br/> Suppose i want to watch a show, it will be copied to my PC, then a pendrive, which will then be plugged into TV. So that SSD will only be plugged into my pc say about 15-20 times a year.<br/> I&#39;m skeptical of HDDs because i have 2 of them. One bought in 2010, 1 TB, which still works fine to this day, although its speed is a measly 10 Mbps and another, bought in 2018, 2 TB, which died an instant death (both are WD).<br/> They say that SSDs can retain data for upto a year without charge, but i don&#39;t think that&#39;s going to be a problem because of my use case.<br/> Pl",
        "id": 3547810,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ne4jfi/ssd_vs_hdd_for_storage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SSD vs HDD for storage?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Anxious-Outside-1373",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:06.427285+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T08:22:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey folks, I\u2019ve been tinkering with a Python project that combines Playwright for login + cookie handling, yt-dlp for video fetching, and aria2 for parallel downloading for <a href=\"http://faphouse.com\">faphouse.com</a> (premium). You will need a <a href=\"http://faphouse.com\">faphouse.com</a> premium account.</p> <p>Features:</p> <ul> <li>Logs in once, saves/reuses cookies automatically</li> <li>Scrapes all videos from a target model/page</li> <li>Downloads in parallel (yt-dlp + aria2) for speed</li> <li>Cleans up temp files afterwards</li> <li>Uses a simple <code>requirements.txt</code> setup</li> </ul> <p>It\u2019s basically <strong>a \u201cset it and forget it\u201d way to grab</strong> <strong><em>everything</em></strong> <strong>from a model/page</strong> \u2014 kind of perfect if you\u2019re in the data-hoarder mindset and want full archives.</p> <p>I recorded a <strong>video walkthrough</strong> of the setup and usage \u2014 if you\u2019re curious, I\u2019d appreciate feedback on it.",
        "id": 3547811,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ne39jj/built_a_python_web_scraperdownloader_for_faphouse",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Built a Python web scraper/downloader for faphouse (premium) with Playwright + yt-dlp + aria2 (cookie-based login, parallel downloads, auto cleanup)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/daveyjrobinson",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:53:06.636414+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T08:00:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone--I&#39;m doing a TV series that will be around 100TB in size. What is the best hard drive configuration for storing the files while being fast enough for browsing / light editing from the drives? The majority of editing will be done with light proxies, but I still want to access the drives often without the footage bogging down from a slow setup.</p> <p>I have about $12K for budget. It seems like getting two 8-bay enclosures with 8 Exos 20TB drives would give me enough space to do RAID 6 on both systems (in different locations).</p> <p>Does this configuration make sense? Does this sound safe enough for the only location of footage? And what 8-bay enclosures do you recommend for this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/daveyjrobinson\"> /u/daveyjrobinson </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ne2xif/data_managing_for_a_tv_series/\">[link]</a></span> &#32; <s",
        "id": 3547812,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ne2xif/data_managing_for_a_tv_series",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Data Managing For a TV Series",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/playdoob",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T07:51:34.588330+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T03:20:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi! </p> <p>I\u2019ve already done quite a bit of research, but I still have a few questions I bet you guys know the answer to. </p> <ol> <li><p>QNAP &gt; Synology now because of Synology\u2019s new anti-consumer drive specificity policy, correct? Or is a DIY NAS the best route, even if a steeper learning curve (this is the main thing I haven\u2019t researched much yet)?</p></li> <li><p>TS-AI642 for $597 after tax a good deal for a 6 drive bay chassis? </p></li> <li><p>Prioritize getting Ironwolf or WD Red instead of saving money on non-NAS drives? </p></li> <li><p>Serverpartdeals / Goharddrive still the best and most financially sound way to purchase drives for the NAS? </p></li> <li><p>Aim for $10/TB, or is that unrealistic for NAS drives (assuming I should prioritize those)? </p></li> </ol> <p>Any insight would be greatly appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/playdoob\"> /u/playdoob </a> <br/> <span><a ",
        "id": 3544801,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ndyaab/beginner_diving_into_nas_questions_and_advice",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Beginner diving into NAS. Questions and advice wanted!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/encore2097",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T07:51:34.144336+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T02:48:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.seagate.com/products/external-hard-drives/expansion-desktop-hard-drive/\">https://www.seagate.com/products/external-hard-drives/expansion-desktop-hard-drive/</a></p> <p>24 hours sale, not as good as the 26TB for $249.99 but if you need it..</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/encore2097\"> /u/encore2097 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ndxnyn/hdd_seagate_24tb_external_24999_or_22499_w_10_off/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ndxnyn/hdd_seagate_24tb_external_24999_or_22499_w_10_off/\">[comments]</a></span>",
        "id": 3544799,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ndxnyn/hdd_seagate_24tb_external_24999_or_22499_w_10_off",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[HDD] Seagate 24TB External - $249.99 (or 224.99 w/ 10% off) exp. 9/11 8AM EST",
        "vote": 0
    }
]