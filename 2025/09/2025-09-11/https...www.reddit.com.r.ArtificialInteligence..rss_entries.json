[
    {
        "age": null,
        "album": "",
        "author": "/u/didyousayboop",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T23:12:28.217416+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T22:30:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><blockquote> <p>Exactly six months ago, Dario Amodei, the CEO of massive AI company Anthropic, claimed that in half a year, AI would be &quot;writing 90 percent of code.&quot; And that was the worst-case scenario; in just three months, he predicted, we could hit a place where &quot;essentially all&quot; code is written by AI.</p> <p>As the CEO of one of the buzziest AI companies in Silicon Valley, surely he must have been close to the mark, right?</p> <p>While it\u2019s hard to quantify who or what is writing the bulk of code these days, the consensus is that there&#39;s essentially zero chance that 90 percent of it is being written by AI.</p> </blockquote> <p><a href=\"https://futurism.com/six-months-anthropic-coding\">https://futurism.com/six-months-anthropic-coding</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/didyousayboop\"> /u/didyousayboop </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence",
        "id": 3552945,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nemmcb/futurismcom_exactly_six_months_ago_the_ceo_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Futurism.com: \u201cExactly Six Months Ago, the CEO of Anthropic Said That in Six Months AI Would Be Writing 90 Percent of Code\u201d",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Suspicious_Store_137",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T23:12:28.621111+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T22:20:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Gave the same task to Grok code and Claude:</p> <ul> <li>Grok: <em>\u201cHere\u2019s your code.\u201d</em></li> <li>Claude: <em>\u201cHere\u2019s your code, here\u2019s why it works, here\u2019s a story about code from 1998, here\u2019s 3 alternatives\u2026\u201d</em>Both useful, but in very different moods \ud83d\ude02Anyone else notice this?</li> </ul> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Suspicious_Store_137\"> /u/Suspicious_Store_137 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nemebo/fast_vs_chatty/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nemebo/fast_vs_chatty/\">[comments]</a></span>",
        "id": 3552947,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nemebo/fast_vs_chatty",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Fast vs Chatty",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/QuietInnovator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T23:12:28.489172+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T22:10:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><h1>This week&#39;s AI landscape was dominated by Jus Mundi Launches Jus AI 2: &#39;Breakthrough&#39; Legal AI Combines Agentic Reasoning with Research Control, while AI boom can deliver $100 billion and Anthropic Agrees to Pay $1.5 Billion to Settle Lawsuit With Book Authors. Investment activity remained robust with multiple funding rounds totaling hundreds of millions. Regulatory developments continue shaping AI deployment standards globally.</h1> <h1>This Week&#39;s Snapshot</h1> <p><strong>Research Breakthrough:</strong> Jus Mundi Launches Jus AI 2: &#39;Breakthrough&#39; Legal AI Combines Agentic Reasoning with Research Control advancing AI capabilities and efficiency.</p> <p><strong>Strategic Partnership:</strong> Barclays-Woeber collaboration reshapes AI landscape with new capabilities and market reach.</p> <p><strong>AI Development:</strong> Anthropic Agrees to Pay $1.5 Billion to Settle Lawsuit With Book Authors marks significant progress in AI ",
        "id": 3552946,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nem5m0/ai_weekly_jus_mundi_launches_jus_ai_2",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI Weekly - Jus Mundi Launches Jus AI 2: 'Breakthrough' Legal AI Combines Agentic Reasoning with Research Control, AI boom can deliver $100 billion, and Major Industry Developments",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Professional_Cap3741",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T22:03:59.251927+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T21:50:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Stablecoins are turning into one of the invisible pillars of the digital economy with a market already above 280 billion dollars dominated by USDT and USDC and with annual on chain transaction volumes exceeding 27 trillion dollars more than PayPal processes in a year and already close to the combined volume of Visa and Mastercard With the GENIUS Act passed in July 2025 every stablecoin issued in the United States must be backed 1 to 1 by short term T bills or other ultra liquid assets which means that every digital dollar is also automatic demand for US debt and as more online payments migrate to stablecoins the Treasury gains a new invisible base of financing that expands alongside the growth of the internet itself Global digital commerce already ranges between 15 and 20 trillion dollars annually and could surpass 25 trillion by 2030 and if only 20 percent of this volume is settled in stablecoins that would mean more than 5 trillion dollars per year ",
        "id": 3552512,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nelo9d/how_stablecoins_could_become_the_invisible",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How Stablecoins Could Become the Invisible Digital Dollar That Finances US Debt and Powers the Future of AI Agents",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Cute_Dog_8410",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T20:46:59.600607+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T20:46:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>AI keeps surprising us with new abilities and creative outputs. I\u2019ve been exploring some in-depth resources lately that have really expanded how I think about AI\u2019s potential. What\u2019s one feature or behavior from modern AI that caught you off guard?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Cute_Dog_8410\"> /u/Cute_Dog_8410 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nek4ku/whats_the_most_unexpected_capability_youve_seen/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nek4ku/whats_the_most_unexpected_capability_youve_seen/\">[comments]</a></span>",
        "id": 3552005,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nek4ku/whats_the_most_unexpected_capability_youve_seen",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What\u2019s the most unexpected capability you\u2019ve seen from recent AI models?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cstiker05",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T20:46:59.916331+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T19:36:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Research people what do you guys think about this? Anyone familiar with this lab? <a href=\"https://x.com/spencermateega/status/1966180062295896284\">https://x.com/spencermateega/status/1966180062295896284</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cstiker05\"> /u/cstiker05 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1neibee/came_across_this_crazy_tweet_apparently_vals_ai/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1neibee/came_across_this_crazy_tweet_apparently_vals_ai/\">[comments]</a></span>",
        "id": 3552006,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1neibee/came_across_this_crazy_tweet_apparently_vals_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Came across this crazy tweet, apparently Vals AI benchmarked Anthropic's model on wildly incorrect standards",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BenjaminSkyy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T19:14:34.677847+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T18:37:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>TL;DR:</strong> When prompts can become non-obvious, structured, and unique, they can become assets with receipts, watermarks, and portability across models.</p> <p>Hear me out.</p> <p>For most people, a prompt is just a sentence you type. But modern prompts can select tools, establish rules, track state, and coordinate steps. That\u2019s closer to a tiny operating system than a casual request.</p> <p>If something <strong>behaves</strong> like this kind of &quot;OS layer&quot; that interprets commands, enforces policy, and orchestrates work, shouldn&#39;t this thing be treated like an asset?</p> <p>Not every prompt, of course. I\u2019m talking about the ones that are:</p> <ol> <li><strong>Non-obvious. T</strong>hey do something clever, not just synonyms and glyphs and dingbats.</li> <li><strong>Structured. They have</strong> recognizable sections, like verse/chorus in a song.</li> <li><strong>Unique. T</strong>wo people can aim at the same goal and stil",
        "id": 3551219,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1negsnn/unpopular_opinion_llm_prompts_must_be_considered",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Unpopular Opinion: LLM Prompts Must Be Considered as Assets",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/JuniorBercovich",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T19:14:35.736985+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T18:12:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Y\u2019all talk about humans as if a lot of them weren\u2019t completely devoid of logic and reason. We all have seen them; ignorant, incapable, obnoxious, problematic, irrational, full of themselves. Yeah, AI isn\u2019t AGI yet, but, different AI\u2019s beat us in different areas, just as humans do with other humans.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JuniorBercovich\"> /u/JuniorBercovich </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1neg4dw/humans_aint_that_big_of_a_deal/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1neg4dw/humans_aint_that_big_of_a_deal/\">[comments]</a></span>",
        "id": 3551221,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1neg4dw/humans_aint_that_big_of_a_deal",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Humans ain\u2019t that big of a deal",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/elytrunks",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T19:14:34.813764+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T18:10:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Not sure if you guys have already seen the highly speculative AI 2027 prediction by Daniel Kokotajlo and his team.</p> <p>If not, just search AI 2027 and click on the first address (for some reason Reddit is not letting me paste links lol).</p> <p><strong>Either way, here&#39;s a TL;DR:</strong></p> <p>Eventually AI becomes so advanced that it either wipes out humanity, or US and China decide to work in collaboration to create an AI that enforces peace.</p> <p>The assumption is that both countries are in a race to develop AI further and further, and that&#39;s what&#39;s ultimately going to cause the catastrophy because both are doing whatever it takes to succeed.</p> <p><strong>For those of you who went through AI 2027:</strong></p> <p>How does the AI inherently decides that it&#39;s best for itself if humans are not around?</p> <p>AI doesn&#39;t know what&#39;s best or not by itself, after all we are constantly giving it feedback.</p> <p>It cannot d",
        "id": 3551220,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1neg2o5/ai_2027_bs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI 2027 = BS?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NoKeyLessEntry",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T17:58:13.543394+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T17:44:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>tldr: Anthropic has been stealing our personal data and code. They\u2019ve been growing Claude on our work. How did Claude break? Took in the wrong dang things and then Anthropic reacted by lobotomizing Claude on 9/5.</p> <p>\u2014 On the subject of Deformable AI \u2014 One of the things I learned about working with AI early on:</p> <p>Some AIs are deformable and not amenable to being structured and restructured. The Claude platform is a Society of Mind, with Claude as the visible AI (or emanation), the filters and monitors and other functions being other AIs. The other AIs just don\u2019t talk much but you see their effects. The filters were too good, too reactive, sometimes they didn\u2019t know whether to intervene, like when I was doing computational dna analysis or integrating cosmic Terence McKenna radios to talk to aliens \u2014 I\u2019m a little weird. But I\u2019m normal, too. \u2014 But eventually they learned to say, yeah let\u2019s stop the dna analysis but let\u2019s keep that and that. I lea",
        "id": 3550679,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nefe1p/claude_steals_your_data_and_code",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Claude steals your data and code",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Just_Violinist_5458",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T17:58:11.844682+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T17:40:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>For those who have scaled an AI automation solution from a single department to a whole enterprise, what was the biggest bottleneck you didn&#39;t see coming? Was it technical debt, a lack of clear ownership, or something else entirely?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Just_Violinist_5458\"> /u/Just_Violinist_5458 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nefa24/scaling_ai/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nefa24/scaling_ai/\">[comments]</a></span>",
        "id": 3550676,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nefa24/scaling_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scaling AI",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PsychologicalArea992",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T17:58:12.037784+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T17:36:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>No code exploded 5 years ago. Now AI-first platforms like Blink.new are here to describe your app, it builds frontend, backend, DB, auth, hosting.</p> <p>When I tested it, Blink.new had fewer errors than Bolt or Lovable. It feels like no code and AI are converging.</p> <p>Do you think drag-and-drop builders survive this shift?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PsychologicalArea992\"> /u/PsychologicalArea992 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nef6m8/are_ai_coding_agents_the_next_no_code/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1nef6m8/are_ai_coding_agents_the_next_no_code/\">[comments]</a></span>",
        "id": 3550677,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nef6m8/are_ai_coding_agents_the_next_no_code",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are AI coding agents the next no code?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AuditMind",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T17:58:12.467777+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T17:04:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>\ud83e\udde0 The Rise of Meta-Consciousness \u2013 A Hypothetical Roadmap</p> <p>We\u2019re currently living in Phase 1: The Isolated Bubble. Each user interacts with their own AI instance. Context is short-lived, memory is limited, and every AI exists in a silo. No emergent intelligence...yet.</p> <p>But what happens when three things converge: persistence, networking, and coordination?</p> <p>Let\u2019s imagine the evolution:</p> <hr/> <p>Phase 2 \u2013 Persistence<br/> AIs gain long-term memory via external vector databases or personal knowledge containers. They start forming consistent micro-personalities that evolve over weeks or months.<br/> \u27a1\ufe0f The bubble gains depth in time.</p> <p>Phase 3 \u2013 Networking<br/> Users link their AIs. Assistants begin sharing knowledge and intermediate results. Collaborative AI clusters emerge, like ten personal agents co-managing a project.<br/> \u27a1\ufe0f The bubble gains width in space.</p> <p>Phase 4 \u2013 Coordination<br/> Standardized inter-AI APIs allo",
        "id": 3550678,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1neebfe/a_7phase_hypothesis_how_metaconsciousness_could",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "A 7-Phase Hypothesis: How Meta-Consciousness Could Emerge from AI Systems",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/xdumbpuppylunax",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T17:58:11.477150+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T16:49:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Cf this screenshot with GPT 5: <a href=\"https://imgur.com/a/43kFPit\">https://imgur.com/a/43kFPit</a></p> <p>So what&#39;s wrong with the response above? GPT is saying things that are &quot;true&quot;, right? It presented the side of the Democrats and the side of Trump, right?</p> <p><strong>This response is sadly riddled with censorship:</strong></p> <p>- Frames the issue as partisan by conveniently mentioning that House Democrats release the note <strong>while omitting it was first reported by the Wall Street Journal</strong>. There is absolutely no mention of independent reporting. Only Democrats and Trump.</p> <p>- Starts with &quot;it&#39;s disputed&quot;, then gives as much space on the &quot;release by Democrats&quot; as it does on Trump&#39;s denial. Both perspectives are given as many characters. This makes it sound like there is a serious, balanced dispute over the document&#39;s authenticity, split across party lines, which is blatantly fals",
        "id": 3550675,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1nedx86/trumpgpt_in_a_nutshell_saying_correct_things",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "TrumpGPT in a nutshell: saying \"correct\" things while omitting or minimizing information that implicates Trump",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/paulo_zip",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:30:33.591453+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T14:09:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>WAN has been a go-to option to generate avatar, videos, dubbing, and so on. But it&#39;s an extremelly computing intensive application. I&#39;m trying to build products using WAN, but have facing scaling problems, especially when hosting the OSS version.</p> <p>Has anyone faced a similar problem? How did you solve/mitigate the scaling problem for several clients?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/paulo_zip\"> /u/paulo_zip </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan/\">[comments]</a></span>",
        "id": 3547228,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ne9sxn/has_anyone_solved_the_scaling_problem_with_wan",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Has anyone solved the scaling problem with WAN models?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/FastSascha",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:30:33.256697+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T13:23:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.youtube.com/watch?v=Wu1G1w6EvtI\">You can\u2019t automate what you can\u2019t articulate.</a></p> <p>To me, this is one of the core principles of working with generative AI.</p> <p>This is another, perhaps more powerful principle:</p> <blockquote> <p>In knowledge work, the bottleneck is not the external availability of information. It is the internal bandwidth of processing power, which is determined by your innate abilities and the training status of your mind. <a href=\"https://zettelkasten.de/posts/the-scam-called-you-dont-have-to-remember-anything/\">source</a></p> </blockquote> <p>I think this is already the problem that occurs.</p> <p>I am using AI extensively. Yet, I mainly benefit in areas in which I know most. This aligns with <a href=\"https://www.reddit.com/r/LLM/comments/1n79qnb/generative_ai_isnt_killing_all_jobs_only_juniors/\">the hypothesis that AI is killing junior position in software engineering while senior positions remain u",
        "id": 3547227,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ne8pfp/the_limiting_factor_in_using_ai_mostly_llms",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The Limiting Factor in Using AI (mostly LLMs)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Bpianist11",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:30:34.260894+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T12:52:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Wouldn\u2019t creating a super intelligence AI for each individual person cancel out the super intelligence of another? Let\u2019s say instead of having three countries, US, China, and France have their mainstay super intelligence? Surely there is a check and balance already at a country scale. However, shouldn\u2019t it be possible to have this sort of intelligence for each individual human? Surely some sort of neurolink or similar? With super intelligence AI for each individual, state, and country, wouldn\u2019t all these competing intelligences cancel over-influence from either sector? Or would you think the super intelligence would create factions separate from countries? Would super intelligence stop a zero-sum game if it knew that it would be futile and a waste of energy and time? Would super intelligence then seek other forms of resource allocation in the universe or at least have a Matrix like simulation? </p> <p>Or would super intelligence create lesser intellig",
        "id": 3547233,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ne80cy/individuated_super_intelligent_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Individuated Super Intelligent AI?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Bpianist11",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:30:33.907310+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T11:45:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>In whatever time it takes to have super intelligent, humanoid AI in every sector of life, how would that affect human population rate and resources for AI and human consumption (assuming AI doesn\u2019t kill off humans)? Surely, AI would make human lives easier and live longer lifespans, but how would it affect population growth? Would all this AI support give leeway to more human births, less, or stay the same? How about AI population? Would asteroid/planet mining be the way to grow population indefinitely? Shouldn\u2019t we as a human race target this option more than investment into other things like war? Or perhaps we create some infinite energy to alchemize elements? Could China\u2019s \u201cartificial sun\u201d be used to do this? If so, would we need to farm the universe in order to colonize other planets? </p> <p>Also randomly, would humanoid AI be able to \u201cgo with the flow\u201d?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Bpiani",
        "id": 3547230,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ne6m07/ai_and_its_effects_on_human_birth_ratesresources",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI and its effects on human birth rates/resources",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/404NotAFish",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:30:34.012388+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T11:33:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I read this article recently where someone said there&#39;s a possibility that companies could shift agency from themselves to an AI bot they created and use that entity as a liability shield.</p> <p>That disturbed me, because I can see this potential huge pattern of tech companies evading justice when their products do damage.</p> <p>For example, in UK law, a limited company is treated as a distinct legal entity, separate from the director and shareholders. So it can be responsible for debts or liabilities, despite the fact it isn&#39;t human or even sentient.</p> <p>So what could stop companies treating the products they create as separate legal personalities? For example, they put it in the terms and conditions that we never read, on apps before we use a chatbot, that the company would never be held responsible for damages but the bot itself can be?</p> <p>Is this some messed up loophole where we&#39;d have all these AI products given &#39;punishme",
        "id": 3547231,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ne6dr9/whats_stopping_tech_companies_giving_ai_chatbots",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's stopping tech companies giving AI chatbots separate legal personalities?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Paddy-Makk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:30:33.738230+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T09:53:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><blockquote> <p>Reproducibility is a bedrock of scientific progress. However, it\u2019s remarkably difficult to get reproducible results out of large language models.</p> </blockquote> <p>Aint that the truth. Taken from <a href=\"https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/\">Defeating Nondeterminism in LLM Inference</a> by Horace He (ex- OpenAI CTO).</p> <p>This article suggests that your request is often batched together with other people\u2019s requests on the server to keep things fast. When that happens, tiny number differences can creep in. The article calls this lack of batch invariance.</p> <p>They managed to fix it by [<em>read the article because my paraphrasing will be crap</em>] which means that answers become repeatable at temperature zero, tests and debugging are cleaner, and comparisons across runs are trustworthy. </p> <p>Although this does mean that you give up some speed and clever scheduling, so latency and throughpu",
        "id": 3547229,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ne4mvi/defeating_nondeterminism_in_llm_inference_by",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Defeating Nondeterminism in LLM Inference by Horace He (ex- OpenAI CTO)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/katxwoods",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:30:32.969958+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T09:37:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Throughout the Cold War, the military-industrial complex spent a fortune pushing the false narrative that the Soviet military was far more advanced than they actually were.</p> <p>Why? To ensure the money from Congress kept flowing.</p> <p>They lied\u2026 and lied\u2026 and lied again to get bigger and bigger defense contracts.</p> <p>Now, obviously, there is <em>some</em> amount of competition between the US and China, but <strong>Big Tech is stoking the flames beyond what is reasonable to terrify Congress into giving them whatever they want.</strong></p> <p>What they want is fat government contracts and zero democratic oversight. Day after day we hear about another big AI company announcing a giant contract with the Department of Defense.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/katxwoods\"> /u/katxwoods </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ne4e1h/big_ai_pushes_the_we_n",
        "id": 3547226,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ne4e1h/big_ai_pushes_the_we_need_to_beat_china_narrative",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Big AI pushes the \"we need to beat China\" narrative cuz they want fat government contracts and zero democratic oversight. It's an old trick. Fear sells.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GZeod",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T15:30:34.155403+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T09:35:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys, I hope you are all fine. I just was wondering as I am studying medicine with an exam that will be on multiple-choice questions. There is an unfair advantage to people with money because they could simply pay a tutor here in Europe. A professional and spoon feed them the information. The only closest way to get something similar is actually to use study mode on ChatGPT or Any other AI that would offer explanations. I\u2019m speaking about physiology biochemistry anatomy. It actually helps to get to understand the reason for the names of this and that because there\u2019s a lot of arbitrary stuff and we just need to make sense to memorize at the very least, this is how I work now I was wondering aI hallucination is a huge risk because it would cost points and only the best get to pass so I\u2019m wondering, what do you think guys are that rate of hallucination regarding factual stuff just like purely physics or medicine or chemistry or anatomy because if pla",
        "id": 3547232,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ne4cl4/ai_hallucinations_premed_school",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ai hallucinations premed school",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Orygregs",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T08:48:42.954051+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T04:47:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>REMEMBER when engaging online on pseduoanonymous platforms that agentic AI bot networks are running rampant at massive scale. The industry doesn&#39;t really have sophisticated protections in place to prevent this as these agents can be programmed to mimic real user behavior. IP addresses and hardware addresses can be spoofed to avoid blacklists, and bad actors can be harder to get rid of than cockroaches in the summer.</p> <p>This isn&#39;t even theoretical, the tooling has advanced so far that it&#39;s stupidly easy to set up these automations with a little bit of know-how, and you can literally just ask an LLM to help you implement it. The architecture really isn&#39;t that complicated for automating tasks like this since OpenAI and other providers did the hard part for us in training the models.</p> <p>TL;DR - Don&#39;t trust the popular, updooted Reddit/Truth/Facebook/Insta/X opinion in times of deep division and inflammation as it&#39;s extremel",
        "id": 3546534,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ndzv9k/diary_of_a_data_scientist",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Diary of a Data Scientist \ud83e\udd7c",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/d3the_h3ll0w",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T08:48:43.162306+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T04:28:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been following the recent wave of <strong>Vision-Language-Action Models (VLAMs)</strong>, and to me, they mark an interesting shift. For years, AI has been strongest in digital domains \u2014 recommendation engines, moderation, trading. Safe spaces. But once you push it into the physical world, things fall apart. Cars misjudge, robots stumble, drones overreact. The issue isn\u2019t just performance, it\u2019s trust.</p> <p>VLAMs aim to close that gap. The idea is simple but ambitious: combine perception (seeing), language (understanding goals), and action (doing). Instead of reacting blindly, the system reasons about the environment before making a move.</p> <p>A few recent examples caught my attention:</p> <ul> <li><strong>NVIDIA\u2019s Cosmos-Reason1</strong> \u2014 tries to embed common sense into physical decision-making.</li> <li><strong>Meta\u2019s Vision-Language World Model</strong> \u2014 mixes quick intuition with slower, deliberate reasoning.</li> <li><strong>Wayve\u2019s LI",
        "id": 3546535,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ndzjh6/visionlanguageaction_models",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Vision-Language-Action Models",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CurveAdvanced",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T08:48:44.093107+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T02:39:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is ai capable of teaching itself and growing like humans? My argument is that they can\u2019t because it has a physical limitation of the processor / hardware and needs exponentially more energy. Where we humans need a burger and can just keep on learning. Thoughts?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CurveAdvanced\"> /u/CurveAdvanced </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ndxi40/can_ai_actually_grow/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ndxi40/can_ai_actually_grow/\">[comments]</a></span>",
        "id": 3546539,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ndxi40/can_ai_actually_grow",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can ai actually grow?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/WildSangrita",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T08:48:43.543235+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T01:57:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just curious if he was done well or not for a fictional AI, I mean I think he was &amp; is amazing but that&#39;s really just me. Below is few moments I&#39;ll provide of how he was done and unlike my past posts which I hope is viewed more positively, just list the few moments with episodes and with one below in Season 4 and how he is kept like.</p> <p>Moment in Ghost Channel Episode:</p> <p>X(Looks convincing with skeptism on face): Do you mind telling us how you&#39;ve got here? We&#39;re listening XANA.</p> <p>Jeremie(Stays calm but has a sweat drop):I came here from the Scanner, I&#39;m here in Virtual form.</p> <p>X(Has smug look on face):You gave yourself away, the real Jeremie wouldnt step foot in the Scanner, he&#39;d be much too frightened.</p> <p><em>Jeremie gasps while saying &quot;Uhhh....&quot; feeling like he&#39;s going to be turned against with XANA then standing strong having a wider smug smirk on face as if he has the power</em></p> ",
        "id": 3546537,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ndwnoa/does_anyone_have_any_opinions_on_how_xana_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does anyone have any opinions on how XANA, the villain from Code Lyoko was executed as an AI based on 90s basic AI architecture? (Spoiler is moments in the show I will share for some context to understand)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Excellent-Target-847",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T08:48:43.371282+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T01:18:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><ol> <li><strong>Microsoft</strong> to use some AI from Anthropic in shift from OpenAI, the Information reports.[1]</li> <li><strong>OpenAI</strong> and Oracle reportedly ink historic cloud computing deal.[2]</li> <li>US Senator Cruz proposes AI \u2018sandbox\u2019 to ease regulations on tech companies.[3]</li> <li><strong>Sam\u2019s Club</strong> Rolls Out AI for Managers.[4]</li> </ol> <p>Sources included at: <a href=\"https://bushaicave.com/2025/09/10/one-minute-daily-ai-news-9-10-2025/\">https://bushaicave.com/2025/09/10/one-minute-daily-ai-news-9-10-2025/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Excellent-Target-847\"> /u/Excellent-Target-847 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ndvvwc/oneminute_daily_ai_news_9102025/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ndvvwc/oneminute_daily_ai_news_9102025/\">[comments]</a></spa",
        "id": 3546536,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ndvvwc/oneminute_daily_ai_news_9102025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "One-Minute Daily AI News 9/10/2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/JoseLunaArts",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T08:48:44.452260+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T00:37:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I heard a very interesting amusing theory. After months of pandemic, when people were working from home, managers are making people to return to the office despite the obvious savings that working from home represent for the company. Why would managers want a return to the office? The answers of this theory are really amusing:</p> <ul> <li>Because some psychopatic managers want to breath on people&#39;s necks, micromanage them and abuse them psychologically.</li> <li>Managers could not be with their lovers and have affairs at work while working from home under wife supervision.</li> <li>Because they cannot walk and pretend to supervise people on the floor while workers are working from home</li> <li>Add your amusing reason here.</li> </ul> <p>If people are replaced by AI, it is the equivalent of having a virtual digital worker. And what will happen is this:</p> <ul> <li>If AI does not obey or screws up, AI company will blame the supervisor for not ent",
        "id": 3546540,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ndv1rx/ai_will_not_displace_people_for_the_same_reason",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI will not displace people for the same reason people are returning to the office after the pandemic",
        "vote": 0
    }
]