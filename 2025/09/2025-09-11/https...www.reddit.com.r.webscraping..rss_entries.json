[
    {
        "age": null,
        "album": "",
        "author": "/u/Jammurger",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T21:26:09.891413+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T20:32:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Yesterday google made an update and my every request now captcha with playwright and other browsers anyone able to get search inside now? Need help.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Jammurger\"> /u/Jammurger </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nejr8j/help_is_anyone_can_scrape_google_now_impossible/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1nejr8j/help_is_anyone_can_scrape_google_now_impossible/\">[comments]</a></span>",
        "id": 3552296,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nejr8j/help_is_anyone_can_scrape_google_now_impossible",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "HELP Is anyone can scrape Google now? IMPOSSIBLE with playwright?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dread_war",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T18:38:22.760438+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T17:58:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello! I\u2019m working on creating a dataset of all cars released from the year 2000 to the present. I want the dataset to include details such as models, variants, fuel type, transmission, and more. Right now, I\u2019m collecting data from car resale websites. These sites usually have a \u201csell\u201d option where you select the car\u2019s make, model, year, variant, etc. Currently, I copy this data year by year and paste it into Gemini AI, which organizes it into a table format. From there, I export it to Excel. This method is faster than doing everything manually but still much slower compared to web scraping. I\u2019d like to know if there\u2019s a way to scrape this type of data directly. I don\u2019t have much experience in coding, but I\u2019m willing to learn because I also want to create similar datasets for bikes and trucks. Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dread_war\"> /u/dread_war </a> <br/> <span><a href=\"https://www",
        "id": 3550955,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nefr59/how_to_scrape_vehicle_information_from_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape vehicle information from website",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/VGBounceHouse",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T18:38:23.285339+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T17:50:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Howdy!</p> <p>I\u2019m helping a friend migrate her blog from TypePad to WordPress. I should say \u201cblogs\u201d as she has 16 which I have set up using WordPress MultiSite. The problem is TypePad does not offer her images as a download and I\u2019m talking over 70,000 all stored in a /.a/ folder off the root of her blog protected by CloudFlare challenges, no file extensions and half redirects.</p> <p>Using Cyotek WebCopy I\u2019ve gotten about 1/5 of the images, it gets past the challenges and saves the images usually with the right file extension, and the ones it doesn\u2019t I can fix with Irfanview. The problem with the app is it has no resume feature and it is prone to choking, has no way to retry failed files (and TypePad has been very intermittent this past week) and can sometimes spit out weird errors about the local file system which causes it to abort.</p> <p>I thought I\u2019d be clever and write a mode.js app to go through the TypePad export files and extract all the link",
        "id": 3550956,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1nefjq5/advice_on_dealing_with_a_large_typepad_site",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Advice on dealing with a large TypePad site",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Distinct-Ad-7149",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T18:38:22.165991+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T16:01:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>For those who are experienced in the web scraping tool market, what&#39;s your take on the current profitability and market saturation? What are the biggest challenges and opportunities for new entrants offering scraping solutions? I&#39;m especially interested in understanding what differentiates a successful tool from one that struggles to gain traction.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Distinct-Ad-7149\"> /u/Distinct-Ad-7149 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1neco59/is_the_web_scraping_market_saturated/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1neco59/is_the_web_scraping_market_saturated/\">[comments]</a></span>",
        "id": 3550954,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1neco59/is_the_web_scraping_market_saturated",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is the Web Scraping Market Saturated?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/wildjezza",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T16:11:34.561879+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T12:59:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am looking for help from someone that has already done this - please send me a message if that is you</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/wildjezza\"> /u/wildjezza </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ne85jj/trying_to_scrape_ucc_data_anyone_can_help_willing/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ne85jj/trying_to_scrape_ucc_data_anyone_can_help_willing/\">[comments]</a></span>",
        "id": 3548651,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ne85jj/trying_to_scrape_ucc_data_anyone_can_help_willing",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to scrape UCC data - anyone can help? Willing to pay",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/vroemboem",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T16:11:34.864266+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T10:57:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been using Zendriver (<a href=\"https://github.com/cdpdriver/zendriver\">https://github.com/cdpdriver/zendriver</a>) as my browser automation solution. It is based on Nodriver (<a href=\"https://github.com/ultrafunkamsterdam/nodriver\">https://github.com/ultrafunkamsterdam/nodriver</a>) which is the successor of Undetected Chromedriver.</p> <p>I have everything working successfully locally. </p> <p>Now I want to deploy my code to the cloud. Normally I use Render for this, but have been unsuccessful so far.</p> <p>I would like to run it in headless mode without GPU.</p> <p>Any pointers on how to deploy this? I assume you need Docker. But how to correctly set this up?</p> <p>Can you share your experience with deploying a browser automation tool with chrome? What are some best practices?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/vroemboem\"> /u/vroemboem </a> <br/> <span><a href=\"https://www.reddit.com/r/w",
        "id": 3548652,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ne5p23/how_to_deploy_nodriver_zendriver_with_chrome",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to deploy Nodriver / Zendriver with Chrome using Docker?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheCompMann",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T08:15:27.340408+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T06:18:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So basically, I am trying to reverse engineer Ebay&#39;s API, through capturing mobile network packets from my phone. However, the problem I am facing is that every single request going out to every single endpoint is sent with an authorization Bearer JWE token. I need to find a way to generate it from scratch. After analyzing the endpoints, there is a post url that generates this bearer token, but the request details to send this post request to get the bearer token is sent with an hmac key, which I have absolutely zero clue how that was generated. Im fairly new to this kind of advanced web scraping and would love for any help and advice.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheCompMann\"> /u/TheCompMann </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ne1d9p/how_to_reverseengineer_mobile_api_hidden_by/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 3545568,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ne1d9p/how_to_reverseengineer_mobile_api_hidden_by",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to Reverse-Engineer mobile api hidden by Bearer JWE tokens.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/pleasehelpmeout12353",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T08:15:27.085175+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T03:10:12+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1ndy3ln/hi_everyone_i_was_working_on_a_side_project_to/\"> <img src=\"https://a.thumbs.redditmedia.com/Bhw9sbg_YI3NRlde17O-fqKIy1NVjA3lpRECse1MJM4.jpg\" alt=\"Hi everyone I was working on a side project to learn about web scrapping and got stuck. If someone can help me out it would be really nice.\" title=\"Hi everyone I was working on a side project to learn about web scrapping and got stuck. If someone can help me out it would be really nice.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi everyone I was working on a side project to learn about web scrapping and got stuck. In the first photo you can see where I am trying to access but I couldnt manage it. Second photo has my code. I can try my best to give more information if its needed. I am really new to web scrapping. If someone can also explain my mistake it would be really nice. Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://ww",
        "id": 3545567,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ndy3ln/hi_everyone_i_was_working_on_a_side_project_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/Bhw9sbg_YI3NRlde17O-fqKIy1NVjA3lpRECse1MJM4.jpg",
        "title": "Hi everyone I was working on a side project to learn about web scrapping and got stuck. If someone can help me out it would be really nice.",
        "vote": 0
    }
]