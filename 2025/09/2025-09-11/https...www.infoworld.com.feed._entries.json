[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T23:24:24.057449+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T22:36:34+00:00",
        "description": "<div id=\"remove_no_follow\">\n\t\t<div class=\"grid grid--cols-10@md grid--cols-8@lg article-column\">\n\t\t\t\t\t  <div class=\"col-12 col-10@md col-6@lg col-start-3@lg\">\n\t\t\t\t\t\t<div class=\"article-column__content\">\n<section class=\"wp-block-bigbite-multi-title\"><div class=\"container\"></div></section>\n\n\n\n<p>Visual Studio Code 1.104, the latest release of Microsoft\u2019s popular code editor, features flexibility for models in chat and a security capability to confirm edits.</p>\n\n\n\n<p>Released <a href=\"https://code.visualstudio.com/updates/v1_104\">September 11</a>, the August 2025 release of <a href=\"https://www.infoworld.com/article/2254808/get-started-with-visual-studio-code.html\">VS Code</a> can be downloaded at <a href=\"https://code.visualstudio.com/Download\">code.visualstudio.com</a> for Windows, Linux, and Mac operating systems. This version previews an automatic model selection capability in chat. When developers choose \u201cAuto\u201d in the model picker, VS Code automatically selects a model for optimal ",
        "id": 3553008,
        "language": "en-US",
        "link": "https://www.infoworld.com/article/4056026/vs-code-1-104-emphasizes-ai-model-selection-agent-security.html",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 468,
        "source_url": "https://www.infoworld.com/feed/",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "VS Code 1.104 emphasizes AI model selection, agent security",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T09:04:03.227722+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T09:00:00+00:00",
        "description": "<div id=\"remove_no_follow\">\n\t\t<div class=\"grid grid--cols-10@md grid--cols-8@lg article-column\">\n\t\t\t\t\t  <div class=\"col-12 col-10@md col-6@lg col-start-3@lg\">\n\t\t\t\t\t\t<div class=\"article-column__content\">\n<section class=\"wp-block-bigbite-multi-title\"><div class=\"container\"></div></section>\n\n\n\n<p>Basic chatbots get much of the publicity associated with modern AI platforms, but they have limited use cases, providing a simple <a href=\"https://www.infoworld.com/article/2260903/what-is-natural-language-processing-ai-for-speech-and-text.html\">natural language</a> interface to search tools. It\u2019s certainly useful, provided you implement fine-tuning and <a href=\"https://www.infoworld.com/article/2335814/what-is-retrieval-augmented-generation-more-accurate-and-reliable-llms.html\">grounding in your own data</a>, but it is still best thought of as an extension of existing search tools.</p>\n\n\n\n<p>AI has other uses: embedding the technology inside enterprise IT stacks, providing advanced filtering an",
        "id": 3546782,
        "language": "en-US",
        "link": "https://www.infoworld.com/article/4054974/how-linkedin-built-an-agentic-ai-platform.html",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 468,
        "source_url": "https://www.infoworld.com/feed/",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How LinkedIn built an agentic AI platform",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T09:04:03.069348+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T09:00:00+00:00",
        "description": "<div id=\"remove_no_follow\">\n<body><div class=\"grid grid--cols-10@md grid--cols-8@lg article-column\">\n\t\t\t\t\t  <div class=\"col-12 col-10@md col-6@lg col-start-3@lg\">\n\t\t\t\t\t\t<div class=\"article-column__content\">\n<section class=\"wp-block-bigbite-multi-title\"><div class=\"container\"></div></section>\n\n\n\n<p>When working with ASP.NET Core applications, there are several ways in which you can enhance your application\u2019s performance. Caching is one of the most widely used and proven strategies that can significantly boost your application\u2019s scalability and performance.</p>\n\n\n\n<p>In this post, we\u2019ll examine how we can work with caching in minimal APIs in ASP.NET Core. ASP.NET Core offers the flexibility to cache server responses on the client (response caching) or on the server (output caching). In addition, you can choose to cache the data in the memory of the application server (in-memory caching), or in an external data store such as Redis or SQL Server (distributed caching), or a combination of ",
        "id": 3546781,
        "language": "en-US",
        "link": "https://www.infoworld.com/article/4053115/how-to-implement-caching-in-asp-net-core-minimal-apis.html",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 468,
        "source_url": "https://www.infoworld.com/feed/",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to implement caching in ASP.NET Core minimal APIs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-11T09:04:03.402807+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-11T09:00:00+00:00",
        "description": "<div id=\"remove_no_follow\">\n\t\t<div class=\"grid grid--cols-10@md grid--cols-8@lg article-column\">\n\t\t\t\t\t  <div class=\"col-12 col-10@md col-6@lg col-start-3@lg\">\n\t\t\t\t\t\t<div class=\"article-column__content\">\n<section class=\"wp-block-bigbite-multi-title\"><div class=\"container\"></div></section>\n\n\n\n<p>Large language models (LLMs) like GPT and PaLM are transforming how we work and interact, powering everything from programming assistants to universal chatbots. But here\u2019s the catch: running these incredibly powerful models, especially as hosted services, is very expensive, often costing 10x times more than a traditional keyword search. A huge part of this cost comes down to inefficient memory management when serving LLMs.</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"the-hidden-memory-hog-the-kv-cache\">The hidden memory hog: The KV cache</h2>\n\n\n\n<p>So, at the heart of LLMs is the Transformer model, which generates text one token (word) at a time. To do this efficiently, the model needs to remember th",
        "id": 3546783,
        "language": "en-US",
        "link": "https://www.infoworld.com/article/4055048/unlocking-llm-superpowers-how-pagedattention-helps-the-memory-maze.html",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 468,
        "source_url": "https://www.infoworld.com/feed/",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Unlocking LLM superpowers: How PagedAttention helps the memory maze",
        "vote": 0
    }
]