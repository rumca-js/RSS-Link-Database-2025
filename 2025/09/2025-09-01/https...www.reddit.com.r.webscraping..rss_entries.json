[
    {
        "age": null,
        "album": "",
        "author": "/u/TownRough790",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-01T18:48:56.702908+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-01T17:44:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m a complete beginner and want to extract movie theater seating data for a personal hobby. The seat layout data is displayed in a scrollable HTML5 canvas element (I&#39;m not sure how to describe it precisely, but you can check the sample page for clarity). How can I extract the complete PNG image containing the seat data? Please suggest a solution. Sample page link provided below.</p> <p><a href=\"https://in.bookmyshow.com/movies/chen/seat-layout/ET00459706/KSTK/42912/20250904\">https://in.bookmyshow.com/movies/chen/seat-layout/ET00459706/KSTK/42912/20250904</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TownRough790\"> /u/TownRough790 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n5vfx6/capturing_data_from_scrolling_canvas_image/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n5vfx6/capturing_data_from_scrolling_canvas_image/\">[comments]",
        "id": 3470813,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n5vfx6/capturing_data_from_scrolling_canvas_image",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Capturing data from Scrolling Canvas image",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/0xReaper",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-01T16:39:14.356072+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-01T16:18:48+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1n5t3p2/scrapling_v03_solve_cloudflare_automatically_and/\"> <img src=\"https://preview.redd.it/3oogownzvkmf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=390aa36f689059f857fa545f59dd11780ad5619d\" alt=\"Scrapling v0.3 - Solve Cloudflare automatically and a lot more!\" title=\"Scrapling v0.3 - Solve Cloudflare automatically and a lot more!\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>\ud83d\ude80 Excited to announce Scrapling v0.3 - The most significant update yet!</p> <p>After months of development, we&#39;ve completely rebuilt Scrapling from the ground up with revolutionary features that change how we approach web scraping:</p> <p>\ud83e\udd16 AI-Powered Web Scraping: Built-in MCP Server integrates directly with Claude, ChatGPT, and other AI chatbots. Now you can scrape websites conversationally with smart CSS selector targeting and automatic content extraction.</p> <p>\ud83d\udee1\ufe0f Advanced Anti-Bot Capabilities: \u2022 Automatic Cloudflare T",
        "id": 3470008,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n5t3p2/scrapling_v03_solve_cloudflare_automatically_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/3oogownzvkmf1.png?width=640&crop=smart&auto=webp&s=390aa36f689059f857fa545f59dd11780ad5619d",
        "title": "Scrapling v0.3 - Solve Cloudflare automatically and a lot more!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/human__no_9291",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-01T14:23:15.485730+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-01T14:15:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This is something that I have been working on, but I cant build a fast or reliable system. </p> <p>I want to generate a complete list of active shopify stores, by the thousands, and add them to a spreadsheet with its link, but every solution I can find is either extremely expensive or limited in some way.</p> <p>If anyone knows how to do this or even just wants a programming challenge, any pointer in the right direction would be amazing.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/human__no_9291\"> /u/human__no_9291 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n5puhb/scraping_thousands_of_shopify_stores/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n5puhb/scraping_thousands_of_shopify_stores/\">[comments]</a></span>",
        "id": 3468932,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n5puhb/scraping_thousands_of_shopify_stores",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping thousands of shopify stores",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-01T03:29:24.192672+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-01T03:00:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello and howdy, digital miners of r/webscraping!</p> <p>The moment you&#39;ve all been waiting for has arrived - it&#39;s our once-a-month, no-holds-barred, show-and-tell thread!</p> <ul> <li>Are you bursting with pride over that supercharged, brand-new scraper SaaS or shiny proxy service you&#39;ve just unleashed on the world?</li> <li>Maybe you&#39;ve got a ground-breaking product in need of some intrepid testers?</li> <li>Got a secret discount code burning a hole in your pocket that you&#39;re just itching to share with our talented tribe of data extractors?</li> <li>Looking to make sure your post doesn&#39;t fall foul of the community rules and get ousted by the spam filter?</li> </ul> <p>Well, this is your time to shine and shout from the digital rooftops - Welcome to your haven!</p> <p>Just a friendly reminder, we like to keep all our self-promotion in one handy place, so any promotional posts will be kindly redirected here. Now, let&#39;s get ",
        "id": 3465783,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n5dl4x/monthly_selfpromotion_september_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Monthly Self-Promotion - September 2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Classic-Dependent517",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-09-01T02:23:55.378984+00:00",
        "date_dead_since": null,
        "date_published": "2025-09-01T01:27:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi fellow scrapers,</p> <p>As a full-stack developer and web scraper, I often notice the same questions being asked here. I\u2019d like to share some fundamental but important concepts that can help when approaching different types of websites.</p> <h1>Types of Websites from a Web Scraper\u2019s Perspective</h1> <p>While some websites use a hybrid approach, these three categories generally cover most cases:</p> <ol> <li><strong>Traditional Websites</strong> <ul> <li>These can be identified by their straightforward HTML structure.</li> <li>The HTML elements are usually clean, consistent, and easy to parse with selectors or XPath.</li> </ul></li> <li><strong>Modern SSR (Server-Side Rendering)</strong> <ul> <li>SSR pages are dynamic, meaning the content may change each time you load the site.</li> <li>Data is usually fetched during the server request and embedded directly into the HTML or JavaScript files.</li> <li>This means you won\u2019t always see a separate HTTP r",
        "id": 3465617,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n5br45/3_types_of_web",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "3 types of web",
        "vote": 0
    }
]