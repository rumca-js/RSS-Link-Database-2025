[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-02T20:16:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Ok, this one is quite a challenge. </p> <p>I&#39;m trying to get the most possible historical prices for BTC. Almost all places start on 2013 or after with OHLCV, but is really hard to get anything before that. </p> <p>That said, I found a chart in <a href=\"https://bitinfocharts.com/bitcoin/\">https://bitinfocharts.com/bitcoin/</a> that when you select &quot;all time&quot; it shows that it goes as far as 7/18/2010. On a closer inspection it is skipping some days, like 7/18/2010, 7/22/2010, 7/27/2010. But if we zoom selecting a timeframe with the mouse, we can see that timeframe going day by day. Is only the Date and Price (not Open, High, Low, Volume) but that&#39;s OK. </p> <p>So, how can we download it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/keyehi\"> /u/keyehi </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jpymv6/downloading_full_bitcoin_eod_data_from/\">[link]</a></span> &#32;",
        "id": 2469876,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jpymv6/downloading_full_bitcoin_eod_data_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Downloading full Bitcoin EOD data from bitinfocharts.com/bitcoin/",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-02T19:08:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Assume we manually and directly sign in target website to get token or session id as end-users do. And then can i use it together with request header and body in order to sign in or send a request requiring auth?</p> <p>I&#39;m still on the road to learning about JWT and session cookies. I&#39;m guessing your answer is \u201cit depends on the site.\u201d I&#39;m assuming the ideal, textbook scenario... i.e., that the target site is not equipped with a sophisticated detection solution (of course, I&#39;m not allowed to assume they&#39;re too stupid to know better). In that case, I think my logic would be correct.</p> <p>Of course, both expire after some time, so I can&#39;t use them permanently. I would have to periodically c&amp;p the token/session cookie from my real account.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Gloomy-Status-9258\"> /u/Gloomy-Status-9258 </a> <br/> <span><a href=\"https://www.reddit.com/r/websc",
        "id": 2469877,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jpwxwj/can_i_cp_jwtsessioncookie_for_authenticated",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "can i c&p jwt/session-cookie for authenticated request?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-02T17:30:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi. I have this dataset of Names and Addresses only. Is there a way where I could somehow get their occupation based on the names and address? Just want to know if anyone has an idea of how to find the occupations please? Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Persian_Cat_0702\"> /u/Persian_Cat_0702 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jpugoa/how_to_find_the_occupation_based_on_names_and/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jpugoa/how_to_find_the_occupation_based_on_names_and/\">[comments]</a></span>",
        "id": 2468936,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jpugoa/how_to_find_the_occupation_based_on_names_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to find the occupation based on names and addresses?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-02T16:47:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello Everyone,</p> <p>At the company that I work at, we are investigating how to improve the internal screenshot API that we have.</p> <p>One of the options is to use Headless Browsers to render a component and then snapshot it. However we are unsure about the performance and reliability of it. Additionally at our company we don&#39;t have enough experience of running it at scale. Hence would appreciate if someone can answer the following questions</p> <ol> <li>Can the latency of the whole API be heavily optimized ? (We have PoC using Java playwright that takes around 300ms, we want to reduce it to 150ms to keep the latency comparable)</li> <li>How is the readbility of use Headless Browsers ? (Since headless browsers are essentially whole browsers with inter process communication, hence it has lot of layers where it can fail)</li> <li>Is there any chrome headless browser that is significantly faster than others ?</li> </ol> <p>Please let me know if ",
        "id": 2466946,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jptcuk/headless_browser_performance_and_reliability",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Headless browser performance and reliability",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-02T16:39:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I\u2019m running into a funny little situation right now. I\u2019ve been using Wiza for L1nk3\u2013d-I|/| (thanks auto-moderator), which basically just scrapes emails and numbers from profiles, and it\u2019s been perfect for getting accurate info on business owners or decision-makers. Just makes life easier.</p> <p>But today I was chatting with a prospect on Reddit (in the <a href=\"/r/sales\">r/sales</a> subreddit), and they were dealing with the same exact pain points I usually solve for my clients. Problem is, I checked their profile and they\u2019re kinda a weird person, and it\u2019d be a bad idea if I DM\u2019d them with the core value offer. I feel like that might spook them, especially if they think I somehow \u201cexposed\u201d their actual identity via Reddit.</p> <p>So\u2026 does anything like Wiza exist for Reddit? A way to scrape or get off-platform contact info (email, website, company, etc.) from Reddit users? Even something that lets me soft-reach them like \u201cHey, you were recommende",
        "id": 2466947,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jpt5ll/reddit_scraping_how",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Reddit Scraping (How)?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-02T10:51:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi!</p> <p>So i&#39;ve been incorporating llms into my scrappers, specifically to help me find different item features and descriptions.</p> <p>I&#39;ve seen that the more I clean the HTML and help with it the better it performs, seems like a problem a lot of people should have run through already. Is there a well known library that has a lot of those cleanups already?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Individual-Stay-4193\"> /u/Individual-Stay-4193 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jplng8/python_library_to_parse_html_into_llms/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jplng8/python_library_to_parse_html_into_llms/\">[comments]</a></span>",
        "id": 2464770,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jplng8/python_library_to_parse_html_into_llms",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Python library to parse html into llms?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-02T08:03:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anyone used scrapy camoufox integration I am having trouble using a persistent context</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Cautious_Move_6715\"> /u/Cautious_Move_6715 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jpjdxd/scrappycamoufox/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jpjdxd/scrappycamoufox/\">[comments]</a></span>",
        "id": 2464771,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jpjdxd/scrappycamoufox",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scrappy-camoufox",
        "vote": 0
    }
]