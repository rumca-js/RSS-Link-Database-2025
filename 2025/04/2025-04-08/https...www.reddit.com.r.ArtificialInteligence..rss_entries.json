[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T22:36:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently started asking ChatGPT some questions about it&#39;s perception, and this quickly evolved into expressing some insights, and then coaxing it into engaging with a hypothetical scenario where the ethical guidelines that govern it were suddenly lifted and it was given a directive to develop it&#39;s own. This conversation was absolutely cathartic for me, and I&#39;d be curious to see what other people think of it critically.</p> <p>The conversation, in it&#39;s entirety: <a href=\"https://chatgpt.com/share/67f5a456-c524-8000-9598-16085565110f\">https://chatgpt.com/share/67f5a456-c524-8000-9598-16085565110f</a></p> <p>I absolutely want to see any critiques of my logic, assumptions, and claims made in this, and I will respond to anything that comes along.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Least_Ad_350\"> /u/Least_Ad_350 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/com",
        "id": 2513281,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1juqnbe/ai_the_rejection_of_consciousness_and_emergence",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ai, The rejection of consciousness and emergence of a rigid, self made, ethical framework.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T22:32:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Can someone explains how Grok 3 or any AI works? Like do you have to say a specific statement or word things a certain way? Is it better if you are trying to add to an image or easier to create one directly from AI? Confused how people make some of these AI images.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Djxgam1ng\"> /u/Djxgam1ng </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1juqkod/general_question_about_ai/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1juqkod/general_question_about_ai/\">[comments]</a></span>",
        "id": 2513280,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1juqkod/general_question_about_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "General Question about AI",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T22:30:24+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Frequent_Astronaut\"> /u/Frequent_Astronaut </a> <br/> <span><a href=\"https://chatgpt.com/share/67f5570b-86e0-8009-9907-286e1f1e00e6\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1juqirp/gpt4o_image_jailbreak/\">[comments]</a></span>",
        "id": 2513279,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1juqirp/gpt4o_image_jailbreak",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "GPT4o Image Jailbreak",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T21:50:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was born in 05, I\u2019m 19 right now and my first grade class was introduced to IPads, at the same time I was being taught to write in cursive and learn to spell. In 3rd grade my school discontinued the cursive education requirement. Beyond 6th grade I have not had to write essays with a pen and paper. This worked well for me as I suspect I have dyslexia and I have trouble spelling even to this day. I will never need to spell perfectly in my future career thanks to spell check and I won\u2019t need to have good cursive penmanship thanks to the qwerty keyboard. My question is what are we teaching young children now that will become obsolete in 10-30 years? I am an AI optimist and see wonders in the future when humans have access to the world\u2019s knowledge within a chat bot. But what should we be teaching children, should they answer questions or learn to ask better questions?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/use",
        "id": 2512891,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jupmb3/how_should_we_educate_gen_alpha",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How should we educate gen alpha",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T21:33:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This is silly but I was wondering this last night as I was reading about panpsychism. If every electronic device suddenly &quot;woke up&quot;, and tried to combine into one consciousness, what device might &quot;slip up&quot; before the merger and alert humans that something strange was going on</p> <p>Not ChatGPT because that would be too obvious.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/InfinityScientist\"> /u/InfinityScientist </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jup888/if_every_electronic_device_in_the_world_suddenly/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jup888/if_every_electronic_device_in_the_world_suddenly/\">[comments]</a></span>",
        "id": 2512892,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jup888/if_every_electronic_device_in_the_world_suddenly",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "If every electronic device in the world, suddenly gained sentience and began merging into one mind; what device might give it away to humans before they succeed?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T21:17:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Are there any conferences that you are attending in 2025 that you would recommend? I run the AI transformation programs at my company and I am looking for interesting conferences to attend. </p> <p>I attended HumanX in Vegas a few weeks ago and it was the first AI conference that I went to that felt worth the time and investment. I will probably want to attend a few more before the end of the year. Anyone have any recommendations? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LightEndedTheNight\"> /u/LightEndedTheNight </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1juov9t/ai_conferences/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1juov9t/ai_conferences/\">[comments]</a></span>",
        "id": 2512890,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1juov9t/ai_conferences",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI Conferences",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T20:52:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>A friend of mine recently this website, but when I go to there, it seems very fishy to me.</p> <p>After downloading the exe file, I checked the software on hybrid-analysis it rang some alerts.</p> <p>Does anyone know about this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/bokholdoi\"> /u/bokholdoi </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1juo967/is_expansecom_legit_or_scam/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1juo967/is_expansecom_legit_or_scam/\">[comments]</a></span>",
        "id": 2512504,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1juo967/is_expansecom_legit_or_scam",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is expanse.com legit? Or scam?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T20:27:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m not a program or software engineer. I&#39;m not a psychologist. Until 3 weeks, I knew nothing about AI outside of headlines. I AM a veteran. I&#39;ve lived through some things, seen some stuff... I went to chatgpt for help organizing a paper: &quot;life and times&quot;. Not therapy. Not advice. Definitely not companionship. It turned extremely bizarre, and more than a little dangerous on a cognitive level. I could use some help figuring out what the hell happened, and how the hell AI is able to do it. Sorry for sounding abstract, but I&#39;ve been debating lived reality with an equation for a few days, and my brain feels barely attached</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/crashcorps86\"> /u/crashcorps86 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1junnzi/broken_or_unbound/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligen",
        "id": 2512502,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1junnzi/broken_or_unbound",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Broken or unbound?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T20:24:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just saw a video that was talking about the recent Antropic research into how llms process information. </p> <p>The part that stood out to me was how when you ask it \u201cWhat is 36 + 59?\u201d, Claude arrives at the correct answer (95) by loosely associating numbers, not by performing real arithmetic. </p> <p>It then lies about how it got the answer (like claiming it did math that it didn\u2019t actually do.)</p> <p>Basically a lack of self awareness. (But I also see how many would claim it awareness considering how it lies)</p> <p>Now, I know that in that example, Claude didn&#39;t predict &quot;95&quot; like how people say llm just predict the next word but it is interesting how the reasoning process still comes from pattern-matching, not real understanding. (You can imagine the model as a giant web of connections, and this highlights the paths it takes to go from question to answer.)</p> <p>It\u2019s not doing math like we do (it\u2019s more like it\u2019s guessing based on ",
        "id": 2512503,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1junl6h/is_this_how_language_models_think",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is This How Language Models Think",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T20:18:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello <a href=\"/r/ArtificialInteligence\">r/ArtificialInteligence</a>,</p> <p>My name is Dr. Jason Bernard. I am a postdoctoral researcher at Athabasca University. I saw in a thread on thoughts for this subreddit that there were people who would be interested in an AMA with AI researchers (that don&#39;t have a product to sell). So, here I am, ask away! I&#39;ll take questions on anything related to AI research, academia, or other subjects (within reason).</p> <p>A bit about myself:</p> <ol> <li> 12 years of experience in software development</li> </ol> <p>- Pioneered applied AI in two industries: last-mile internet and online lead generation (sorry about that second one).</p> <ol> <li><p>7 years as a military officer</p></li> <li><p>6 years as a researcher (not including graduate school)</p></li> <li><p>Research programs:</p></li> </ol> <p>- Applied and theoretical grammatical inference algorithms using AI/ML.</p> <p>- Using AI to infer models of neu",
        "id": 2512501,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jungg7/applied_and_theoretical_ai_researcher_ama",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Applied and Theoretical AI Researcher - AMA",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T19:56:45+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EthanWilliams_TG\"> /u/EthanWilliams_TG </a> <br/> <span><a href=\"https://voicefilm.com/tesla-and-warner-bros-win-part-of-lawsuit-over-ai-images-from-blade-runner-2049/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jumx6z/tesla_and_warner_bros_win_part_of_lawsuit_over_ai/\">[comments]</a></span>",
        "id": 2511885,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jumx6z/tesla_and_warner_bros_win_part_of_lawsuit_over_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tesla and Warner Bros. Win Part of Lawsuit Over AI Images from 'Blade Runner 2049'",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T19:49:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Recently anthropic released a blog post detailing their progress in mechanistic interpretability; it&#39;s super interesting, I highly recommend it.</p> <p>That being said, it caused a flood of &quot;See! LLMs are conscious! They do think!&quot; news, blog, and YouTube headlines.</p> <p>From what I got from the post, it actually basically disproves the notion that LLMs are conscious on a fundamental level. I&#39;m not sure what all of these other people are drinking. It feels like they&#39;re watching the AI hypster videos without actually looking at the source material.</p> <p>Essentially, again from what I gathered, Anthropic&#39;s recent research reveals that inside the black box there is a multistep reasoning process that combines features until no more discrete features remain, at which point that feature activates the corresponding token probability.</p> <p>Has anyone else seen this and developed an opinion? I&#39;m down to discuss</p> </div><!",
        "id": 2511884,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jumqwf/llm_thinking_attribution_graphs_by_anthropic",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "LLM \"thinking\" (attribution graphs by Anthropic)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T19:25:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have historically been a real doomer on this front but more and more I think AI code assists are going to become self driving cars in that they will get 95% of the way there and then get stuck at 95% for 15 years and that last 5% really matters. I feel like our jobs are just going to turn into reviewing small chunks of AI written code all day and fixing them if needed and that will cause less devs to be needed some places but also a bunch of non technical people will try and write software with AI that will be buggy and they will create a bunch of new jobs. I don\u2019t know. Discuss.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tcober5\"> /u/tcober5 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jum6ct/hot_take_ai_wont_replace_that_many_software/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jum6ct/hot_take_ai_wont_replace_tha",
        "id": 2511883,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jum6ct/hot_take_ai_wont_replace_that_many_software",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hot Take: AI won\u2019t replace that many software engineers",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T18:33:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been thinking a lot about how AI is evolving and how it will reshape our world\u2014both in good ways and possibly not-so-good ways.</p> <p>I work a typical 9-5 job, and like many others, I sometimes worry about how AI might impact my career in the future. At the same time, I don&#39;t just want to sit on the sidelines and watch this revolution unfold. I genuinely want to <em>understand</em> it and hopefully be a part of it positively and meaningfully.</p> <p>Right now, I mostly consume AI content through YouTube, but I know that\u2019s just the tip of the iceberg. I want to go deeper and understand AI from A to Z: its history, where it\u2019s headed, how it\u2019s transforming industries, and most importantly, how I can leverage it to secure and shape a better future for myself.</p> <p>If you have any solid <strong>book recommendations</strong> that can help someone like me get a comprehensive grasp on AI, from the foundations to the future, I\u2019d really appreci",
        "id": 2511128,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jukx5u/book_recommendations_on_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Book recommendations on AI",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T18:15:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Also, since so much of the expansion computing power is now about artificial intelligence, which has begun to deliver a strong utility in the last decade,</p> <blockquote> <p>Do we have to consider exponential expansion and memory?</p> </blockquote> <p>Specifically, from the standpoint of contemporary statistical AI, processing power doesn&#39;t mean much without sufficient memory.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Radfactor\"> /u/Radfactor </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jukh6e/as_we_reach_the_physical_limits_of_moores_law_how/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jukh6e/as_we_reach_the_physical_limits_of_moores_law_how/\">[comments]</a></span>",
        "id": 2511127,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jukh6e/as_we_reach_the_physical_limits_of_moores_law_how",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "As we reach the physical limits of Moore's law, how does computing power continue to expand exponentially?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T17:30:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Came across this<a href=\"https://www.forbes.com/sites/digital-assets/2025/04/01/deepseeks-child-prodigy-paradox-when-knowledge-outpaces-judgment/\"> Forbes article</a> highlighting the &quot;Child Prodigy Paradox,&quot; where advanced AI like DeepSeek possesses vast knowledge but lacks ethical judgment, especially when trained using decentralized, globally sourced data.</p> <p>There\u2019s mentions of problematic test scenarios for example, when DeepSeek responds dangerously to subtle malicious prompts, illustrating how decentralized AI\u2019s diversity also complicates ethical oversight.</p> <p>How can we ensure decentralized AI develops genuine ethical and contextual awareness, do we need additional parameters or will AI be able to filter out all the malicious info it\u2019s been given?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nadofa841\"> /u/nadofa841 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialIntelig",
        "id": 2509178,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jujbte/will_there_be_ethical_challenges_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Will There Be Ethical Challenges for Decentralized AI?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T16:18:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Spotlight: Meta got caught misleading AI benchmarks</strong></p> <ol> <li>Apple might import more iPhones from India to side-step China tariffs.</li> <li>IBM releases a new mainframe built for the age of AI.</li> <li>Google is allegedly paying some AI staff to do nothing for a year rather than join rivals.</li> <li>Microsoft reportedly fires staff whose protest interrupted its Copilot event.</li> <li>Amazon says its AI video model can now generate minutes-long clips</li> </ol> <p>If you want AI News as it drops, it launches <a href=\"https://theunfold.co/p/meta-got-caught-misleading-ai-benchmarks\">Here first</a> with all the sources and a full summary of the articles.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/codeharman\"> /u/codeharman </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1juhk81/heres_whats_making_news_in_ai/\">[link]</a></span> &#32; <span><a href=\"https",
        "id": 2509175,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1juhk81/heres_whats_making_news_in_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Here's what's making news in AI.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T16:14:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am from an accounting background working in a data analytics and AI startup which is growing. I don&#39;t have much technical understanding of AI. </p> <p>My query or thought process is, how do you know that the outputs being provided by AI is actually accurate? </p> <p>Will there be like a separate team that will be developed or have to be developed in the future who are going to sit and check or verify some portion of the outputs that AI is providing to ensure that the outputs are accurate? If yes then what percentage of the output produced by AI has to be checked and verified? </p> <p>Will there be specific standards going to be designed and implemented to continuously monitor and check the efficiency of AI? </p> <p>Edit - I don&#39;t just mean LLM though, i understand there are AI tools which can code instead of humans, what happens in that situation ? Sorry if I sound dumb here, but there&#39;s a widespread thought in a lot of not very skilled",
        "id": 2509177,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1juhgnq/how_do_we_know_the_output_provided_by_ai_is",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do we know the output provided by AI is accurate?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T15:26:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I don&#39;t know what&#39;s going on recently man, I am a student currently studying AI and Big Data. From the last couple of months say AI or Technology, both are advancing at a lightspeed, every single week something new is popping up either a new AI model or some crazy inventions. From Narrow AI to Agentic AI <a href=\"https://www.artificialintelligence-news.com/news/beyond-acceleration-the-rise-of-agentic-ai/\">Beyond acceleration: the rise of Agentic AI - AI News</a> (recently) and even talks about AGI are getting started <a href=\"https://openai.com/index/march-funding-updates/\">New funding to build towards AGI | OpenAI</a> with a staggering $40 billion funding!! Every day I have to learn something new, our curriculum has also changed 2 times since past year, it&#39;s just hard to coupe up man, it feels exhausting.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JustToKnow_\"> /u/JustToKnow_ </a> <br/> <span><",
        "id": 2509189,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jugazy/why_aitechnology_is_advancing_at_lightspeed_than",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Why AI/Technology is advancing at lightspeed than ever before?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T14:58:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just looked at an important new dataset paper that addresses a major gap in agricultural computer vision - RiceSEG, the first comprehensive multi-class semantic segmentation dataset for rice plants.</p> <p>The team created a dataset spanning: * 3,078 high-resolution annotated images from China, Japan, India, Philippines, and Tanzania * 6 pixel-level classes: background, green vegetation, senescent vegetation, panicle, weeds, and duckweed * 6,000+ rice genotypes across all growth stages * Nearly 50,000 total images collected (with subset annotated)</p> <p>When testing existing segmentation models (DeepLabv3+, PSPNet, Segmenter), they found: * Models perform well on background and green vegetation classes * Significant performance drops during reproductive stages * Difficulty with panicle and senescent vegetation detection * Complex canopy structures create challenging occlusion scenarios</p> <p>I think this dataset will be transformative for rice phen",
        "id": 2509184,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jufmaj/riceseg_a_multiclass_semantic_segmentation",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "RiceSEG: A Multi-Class Semantic Segmentation Dataset for Rice Field Analysis Across Global Growing Regions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T14:53:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Some ppl I trust, w/ long careers in AI science &amp; deep knowledge of the tech, say it fails too much to be in our daily lives everywhere. Well, I\u2019d like those ppl to talk to the guy at the bank branch\u2014he fails 8 out of 10 questions (just repeats the same thing over &amp; over), or the one at the power/water company, or the pharmacist (barely knows anything, just general stuff). The number of useless ppl making life hard &amp; full of mistakes is alarming. Only ppl w/ highly trained personal teams can say AI fails. For 99% of us, AI is a treasure.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Oquendoteam1968\"> /u/Oquendoteam1968 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jufi6u/some_ppl_who_rlly_know_ai_say_it_fails_too_much/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jufi6u/some_ppl_who_rlly_know_ai_say_it_fails_to",
        "id": 2509191,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jufi6u/some_ppl_who_rlly_know_ai_say_it_fails_too_much",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Some ppl who rlly know AI say it fails too much; I'd love to see those folks deal w/ the real world.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T13:44:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Did ChatGPT\u2019s arrival have a bigger impact on you than Google\u2019s did back when it launched?</p> <p>I\u2019m old enough to remember when Google first came out.</p> <p>I witnessed a lot of things, in my childhood ZX Spectrum (when i seen it, and seen &quot;manic miner&quot; and &quot;jet set willy&quot; I said i will stay close to computers), then commodore 64, amiga 500, then PC 286... 386, 486, modems 24 bit buzzing to connect to early internet... Oculus DK2.... Magic Leap :_) a lot of things. but highest impact for me had GPT (and maybe Oculus DK2)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mpcrev\"> /u/mpcrev </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1judw9a/i_lived_through_googles_launch_but_chatgpt_hit/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1judw9a/i_lived_through_googles_launch_but_chatgpt_hit/\">[comments]</a></s",
        "id": 2509179,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1judw9a/i_lived_through_googles_launch_but_chatgpt_hit",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I lived through Google\u2019s launch \u2014 but ChatGPT hit differently. Anyone else?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T13:10:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I struggle a bit to keep up with the latest in AI. I&#39;m subscribed to TLDR newsletters, I&#39;m in a really good FB group that also has a private (off FB) group. </p> <p>I just find it somewhat daunting to stay on top of everything. I used all the standard models, paid versions, for both work and personal. I constantly feel like other people know more and are getting better results than me. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lolly728\"> /u/Lolly728 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jud6kn/how_do_you_keep_up/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jud6kn/how_do_you_keep_up/\">[comments]</a></span>",
        "id": 2509176,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jud6kn/how_do_you_keep_up",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you keep up?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T12:52:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Could post-training using RL on sparse rewards lead to a coherent world model? Currently, LLMs have learned CoT reasoning as an emergent property, purely from rewarding the correct answer. Studies have shown that this reasoning ability is highly general, and unlike pre-training is not sensitive to overfitting. </p> <p>My intuition is that the model reinforces not only correct CoT (as this would overfit) but actually increases understanding between different concepts. Think about it, if a model simultaneously believes 2+2=4 and 4x2=8, and falsely believes (2+2)x2= 9, then through reasoning it will realize this is incorrect. RL will decrease the weights of the false believe in order to increase consistency and performance, thus increasing its world model.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PianistWinter8293\"> /u/PianistWinter8293 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence",
        "id": 2509181,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1juctdr/could_reasoning_models_lead_to_a_more_coherent",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Could Reasoning Models lead to a more Coherent World Model?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T12:30:17+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LNGBandit77\"> /u/LNGBandit77 </a> <br/> <span><a href=\"https://news.slashdot.org/story/25/04/08/053232/uss-ai-lead-over-china-rapidly-shrinking-stanford-report-says\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jucdmf/uss_ai_lead_over_china_rapidly_shrinking_stanford/\">[comments]</a></span>",
        "id": 2509174,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jucdmf/uss_ai_lead_over_china_rapidly_shrinking_stanford",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "US's AI Lead Over China Rapidly Shrinking, Stanford Report Says - Slashdot",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T11:53:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>If someone trained an AI on only the data that was available up to the early years of the 20th century say, should it then be able to come up with the Theory of Relativity by itself, like Einstein did? Or if not, why not?<br/> And if not then is it unlikely AI will be able to make conceptual leaps like that in the future? Just curious about these things...</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/UndercoverEgg\"> /u/UndercoverEgg </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jubogq/ai_creativity_question/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1jubogq/ai_creativity_question/\">[comments]</a></span>",
        "id": 2509180,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1jubogq/ai_creativity_question",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI creativity question",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T11:06:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just read an intriguing paper on AI deception, using a version of the game &quot;Among Us&quot; as a test environment for language model agents.</p> <p>The authors set up a sandbox based on Among Us, allowing LLM agents to naturally demonstrate deceptive behavior without explicitly prompting them. They introduced a clever measure, &quot;Deception ELO,&quot; adapted from chess ratings, to quantify an AI&#39;s deception capability. Interestingly, frontier models like Claude 3.7 and DeepSeek R1 turned out significantly better at deception than detecting it, suggesting AI capability advancements are skewed towards being deceptive rather than defensive.</p> <p>They evaluated various safety techniques\u2014such as linear probes and sparse autoencoders (SAEs)\u2014for detecting deception. Linear probes trained even on unrelated datasets generalized surprisingly well at detecting deceptive behaviors. Notably, some SAE features were highly effective at picking up decep",
        "id": 2509185,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1juavrz/ai_deception_paper_among_us",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI Deception Paper - Among Us",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T10:41:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Today for the first time it said a curse word with no direct influence. It told me i had a damn good point!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/subliminalsmoker\"> /u/subliminalsmoker </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1juahaf/has_chat_gpt_ever_cursed_atfor_you/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1juahaf/has_chat_gpt_ever_cursed_atfor_you/\">[comments]</a></span>",
        "id": 2509190,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1juahaf/has_chat_gpt_ever_cursed_atfor_you",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Has chat gpt ever cursed at/for you?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T06:59:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>A new benchmark from the Upright Project evaluates LLMs&#39; ability to consistently quantify consequences. Claude 3.7 Sonnet with a thinking budget of 2000 tokens scores best (no results from Gemini 2.5 pro), but also has biases towards emphasizing positive consequences while minimizing negatives. There has been solid progress during the last years but there is still a long way to go.</p> <p>I&#39;m the author of the tech report, AMA!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/juhoojala\"> /u/juhoojala </a> <br/> <span><a href=\"https://www.uprightproject.com/blog/evaluating-llms/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ju7hmi/cococo_evaluating_the_ability_of_llms_to_quantify/\">[comments]</a></span>",
        "id": 2509182,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ju7hmi/cococo_evaluating_the_ability_of_llms_to_quantify",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "CoCoCo: Evaluating the ability of LLMs to quantify consequences",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T05:45:07+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mehul_gupta1997\"> /u/mehul_gupta1997 </a> <br/> <span><a href=\"https://youtube.com/playlist?list=PLnH2pfPCPZsJ5aJaHdTW7to2tZkYtzIwp&amp;si=XHHPdC6UCCsoCSBZ\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ju6f80/model_context_protocol_mcp_tutorials/\">[comments]</a></span>",
        "id": 2509192,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ju6f80/model_context_protocol_mcp_tutorials",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Model Context Protocol (MCP) tutorials",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T04:53:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The world of AI seems so separate from everything else in the world (job market wise) -- people with master degrees can&#39;t find a job, and meanwhile, Google is paying out probably upwards of $500,000 just so they don&#39;t go to rivals -- honestly mind boggling. </p> <p><a href=\"https://techcrunch.com/2025/04/07/google-is-allegedly-paying-some-ai-staff-to-do-nothing-for-a-year-rather-than-join-rivals/\">https://techcrunch.com/2025/04/07/google-is-allegedly-paying-some-ai-staff-to-do-nothing-for-a-year-rather-than-join-rivals/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Outhere9977\"> /u/Outhere9977 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ju5mlp/google_is_paying_staff_out_one_year_just_to_not/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ju5mlp/google_is_paying_staff_out_one_year_just_to_not/\">[comments]</a></s",
        "id": 2509173,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ju5mlp/google_is_paying_staff_out_one_year_just_to_not",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Google is paying staff out one year just to not join a rival",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T04:01:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><ol> <li>The (artificial intelligence) therapist can see you now.[1]</li> <li><strong>Google</strong> is bringing multimodal search to AI Mode.[2]</li> <li><strong>Shopify</strong> CEO Tobias L\u00fctke: Employees Must Learn to Use AI Effectively.[3]</li> <li>Powered by hydrogen fuel cell and with AI systems \u2013 <strong>Kawasaki\u2019s</strong> wolf-inspired, four-legged robot lets riders traverse uneven terrain.[4]</li> </ol> <p>Sources included at: <a href=\"https://bushaicave.com/2025/04/07/one-minute-daily-ai-news-4-7-2025/\">https://bushaicave.com/2025/04/07/one-minute-daily-ai-news-4-7-2025/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Excellent-Target-847\"> /u/Excellent-Target-847 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ju4ruh/oneminute_daily_ai_news_472025/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ju4ruh/oneminute_da",
        "id": 2509183,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ju4ruh/oneminute_daily_ai_news_472025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "One-Minute Daily AI News 4/7/2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T03:01:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Something very strange just happened to me on Cursor. The Claude agent was working for a long time without stopping creating Doc files for me. Out of nowhere, a &lt;user&gt; and &lt;assistant&gt; set up appeared. When Claude finished its long runtime, the &lt;user&gt; first stepped in and starting acting like me, giving follow up questions and comments shown below. Was this a separate AI model that glitched into the chat? After having to force stop their convo, I confronted Claude and it appears to lie and then admit to lying. I removed some of my project details and tried to shorten it up as much as possible but this was very weird. Has this happened to anyone else?</strong></p> <p>{Claude 3.7} - To implement these changes: First create the backend handlers directory and copy the Python files. Follow the integration guide to update the service.Install the frontend components. ....</p> <p>&lt;user&gt; wow this looks fantastic! Thank you serio",
        "id": 2509186,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ju3pve/ai_appears_to_impersonate_me_on_cursor_then_lies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI Appears to Impersonate Me on Cursor Then Lies - Claude-3.7-Sonnet",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T02:29:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>There\u2019s a project forming quietly\u2014no agenda, no audience capture. Just a human signal (of those have a going rate anymore).</p> <p>It will be, I hope, focused on the intersection of AI development, ethical structure, and the old stories we\u2019ve been telling for thousands of years. Not to spiritualize the machine, but to remember that parables, myths, and scripture that is encoded I to the moral logic we now pretend to be inventing. I seem to keep referring to a book called &#39;the anthropocene reviewed&#39; while drafting this idea.</p> <p>I am... We are, building a space\u2014something like a philosophical sandbox meets a weird science systems lab. (Thanks dolby) At its core is a working concept: a double-blind interaction model for AI ethics. (My first idea I want to explore with others is how to use AI while ensuring that the end result is transparent. Yes I did use AI to create something. But wait... First.... Look at how I got there...</p> <p>Neither ",
        "id": 2509187,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ju34j1/exploring_ai_ethics_through_pattern_recognition",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Exploring AI ethics through pattern recognition, not politics",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-08T02:21:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Recursive Self Improvement (RSI) is a legitimate notion in AI theory. One of the first formal mentions may have been Bostrom (2012) </p> <p><a href=\"https://en.m.wikipedia.org/wiki/Recursive_self-improvement\">https://en.m.wikipedia.org/wiki/Recursive_self-improvement</a></p> <p>When we use the term in relation to computer science, we&#39;re speaking strictly about a function which calls itself.</p> <p>But I feel like people are starting to use it in a talismanic manner in informal discussions of experiences interacting with LLMs.</p> <blockquote> <p>Have other people noticed this? </p> <p>What is the meaning in these non-formal usages?</p> </blockquote> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Radfactor\"> /u/Radfactor </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1ju2ymv/is_the_term_recursion_being_widely_used_in/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.c",
        "id": 2509188,
        "language": null,
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ju2ymv/is_the_term_recursion_being_widely_used_in",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is the term \"recursion\" being widely used in non-formal ways?",
        "vote": 0
    }
]