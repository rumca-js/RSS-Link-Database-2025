[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T20:15:25.582888+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T20:07:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have been scraping Vinted successfully for months using <a href=\"https://vinted.fr/api/v2/items/ITEM_ID\">https://vinted.fr/api/v2/items/ITEM_ID</a> (you have to use a numeric ID to get a 403 else you get a 404 and &quot;page not found&quot;). The only authentication needed was a cookie you got from the homepage. They changed something yesterday and now I get a 403 when trying to get data using this route. I get the error straight from the web browser, I think they just don&#39;t want people to use this route anymore and maybe kept it only for internal use. The workaround I found for now is scraping the listings pages to extract the Next.js props but a lot of properties I had yesterday are missing. Do anyone here is scraping Vinted and having the same issue as me?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Due-Exercise6990\"> /u/Due-Exercise6990 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/",
        "id": 2536063,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1k8lx6x/please_help_scraping_vinted",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Please help! Scraping Vinted",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T13:27:22.359200+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T12:16:05+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1k8blav/scraping_coordinates_tried_everything_chatgpt/\"> <img src=\"https://b.thumbs.redditmedia.com/2_sAFJQvDli9ePqWd617LjrNkF68drSqNIv0dlzHc5Y.jpg\" alt=\"Scraping coordinates, tried everything. ChatGPT even failed\" title=\"Scraping coordinates, tried everything. ChatGPT even failed\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p><strong>Context:</strong></p> <p>I am creating a data engineering project. The aim is to create a tool where rock climbing crags (essentially a set of climbable rocks) are paired with weather data so someone could theoretically use this to plan which crags to climb in the next five days depending on the weather.</p> <p>There are no publicly available APIs and most websites such as UKC and theCrag have some sort of protection like Cloudflare. Because of this I am scraping a website called Crag27.</p> <p>Because this is my first scraping project I am scraping page by page,",
        "id": 2533880,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1k8blav/scraping_coordinates_tried_everything_chatgpt",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/2_sAFJQvDli9ePqWd617LjrNkF68drSqNIv0dlzHc5Y.jpg",
        "title": "Scraping coordinates, tried everything. ChatGPT even failed",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T08:53:38.896460+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T07:55:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi folks.</p> <p>Happy to not be temporarily banned anymore for yelling at a guy, and coming with what I think might be a good conceptual question for the community.</p> <p>Some sites are demonstrably more difficult to scrape than others. For a little side quest I am doing, I recently deployed a nice endpoint for myself where I do news scraping with fallback sequencing from requests to undetected chrome with headless and headful playwright in between.</p> <p>It world like a charm for most news sites around the world (I&#39;m hitting over 60k domains and crawling out) but nonetheless I don&#39;t have a 100% success rate (although that is still more successes than I can currently handle easily in my translation/clustering pipeline; the terror of too much data!).</p> <p>And so I have been thinking about the multi-armed bandit problem I am confronted with and pose you with a question:</p> <p>Does <em>ease</em> of scraping (GET is easy, persistent undetect",
        "id": 2532639,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1k87rim/what_does_scraping_difficulty_imply_about_quality",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What does scraping difficulty imply about quality of content?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T07:48:49.803620+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T06:46:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>it will know if the picture was from the internet or you took the picture </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ApprehensiveFilm8938\"> /u/ApprehensiveFilm8938 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1k86r9b/whats_the_website_where_description/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1k86r9b/whats_the_website_where_description/\">[comments]</a></span>",
        "id": 2532363,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1k86r9b/whats_the_website_where_description",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "what\u2019s the website where (description)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T06:45:37.418835+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T03:05:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone! \ud83d\udc4b</p> <p>I recently built a small Python library called <a href=\"https://github.com/nuung/macWinUA/\"><strong>MacWinUA</strong></a>, and I&#39;d love to share it with you.</p> <p><strong>What it does:</strong><br/> MacWinUA generates <strong>realistic</strong> User-Agent headers for <strong>macOS</strong> and <strong>Windows</strong> platforms, always reflecting the <strong>latest Chrome versions</strong>.<br/> If you&#39;ve ever needed fresh and believable headers for projects like scraping, testing, or automation, you know how painful outdated UA strings can be.<br/> That&#39;s exactly the itch I scratched here.</p> <p><strong>Why I built it:</strong><br/> While using existing libraries, I kept facing these problems:</p> <ul> <li>They often return <strong>outdated</strong> or <strong>mixed old versions</strong> of User-Agents.</li> <li>Some include <strong>weird, unofficial, or unrealistic UA strings</strong> that you&#39;d almost never",
        "id": 2532048,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1k83628/i_built_macwinua_a_python_library_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I built MacWinUA: A Python library for always-up-to-date",
        "vote": 0
    }
]