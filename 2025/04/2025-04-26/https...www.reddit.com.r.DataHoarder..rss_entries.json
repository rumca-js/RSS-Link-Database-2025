[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T23:35:56.576560+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T23:28:52+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8q6r2/mounting_screws_dont_line_up_on_owc_thunderbay_4/\"> <img src=\"https://b.thumbs.redditmedia.com/QrT5Q3ydUJ2LnHpoJrUGPLxGHQ_57KeDWt8wAXCv74g.jpg\" alt=\"Mounting screws don't line up on OWC Thunderbay 4\" title=\"Mounting screws don't line up on OWC Thunderbay 4\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I was mounting the drives into the trays of my new Thunderbay 4 and the bottom end of the B tray has no accessible holes. I think they installed the wrong bracket but not sure? Do I need to use all 6 holes or can I use just the top 3 for now until OWC can send me a new tray (Hopefully).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Macgeek1\"> /u/Macgeek1 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1k8q6r2\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8q6r2/mounting_screws_dont_line_up_on_owc_thunderbay_4/\">[",
        "id": 2536631,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8q6r2/mounting_screws_dont_line_up_on_owc_thunderbay_4",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/QrT5Q3ydUJ2LnHpoJrUGPLxGHQ_57KeDWt8wAXCv74g.jpg",
        "title": "Mounting screws don't line up on OWC Thunderbay 4",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T23:35:56.340728+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T23:16:10+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8pxg6/drive_noise_cause_for_concern/\"> <img src=\"https://external-preview.redd.it/NmJkdDczdDdpOXhlMVYqV_chXb_90EgEB7N7DK0-rXJ9DHWLAbKC_hlwa-Qq.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c5f0438f1f807cfd423a5a04d4c21eba68e54bba\" alt=\"Drive noise cause for concern?\" title=\"Drive noise cause for concern?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I just received an Amazon refurbished 22TB Seagate drive, and reports show it&#39;s healthy and I was able to migrate ~12TB of data to it, but my god are they loud.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/oOBubbliciousOo\"> /u/oOBubbliciousOo </a> <br/> <span><a href=\"https://v.redd.it/w85yrkn7i9xe1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8pxg6/drive_noise_cause_for_concern/\">[comments]</a></span> </td></tr></table>",
        "id": 2536630,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8pxg6/drive_noise_cause_for_concern",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/NmJkdDczdDdpOXhlMVYqV_chXb_90EgEB7N7DK0-rXJ9DHWLAbKC_hlwa-Qq.png?width=640&crop=smart&auto=webp&s=c5f0438f1f807cfd423a5a04d4c21eba68e54bba",
        "title": "Drive noise cause for concern?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T23:35:56.867062+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T22:16:08+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Keeftraum\"> /u/Keeftraum </a> <br/> <span><a href=\"/r/PixelDrain/comments/1k8jgjl/bought_pixeldrain_pay_as_you_go_where_else_can_i/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8oprc/bought_pixeldrain_pay_as_you_go_where_else_can_i/\">[comments]</a></span>",
        "id": 2536633,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8oprc/bought_pixeldrain_pay_as_you_go_where_else_can_i",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Bought PixelDrain Pay As You Go \u2013 Where Else Can I Use My 10TB Quota?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T23:35:56.721986+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T21:38:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So when moving my content around from HD, SSD, to external HD, things are snappy, not perfect but transfer rate is ok for me</p> <p>Whenever I am transferring to my SanDisk Ultra 3.0 256 and 512 GB stick is unreal how slow it is, averaging 3.50 MB/s</p> <p>It was Fat32 because my old TV only used it but just formatted to NTFS and putting some content back on it and could swear it is even slower now!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/palepatriot76\"> /u/palepatriot76 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8nx8w/what_would_be_making_transfers_to_a_sandisk_ultra/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8nx8w/what_would_be_making_transfers_to_a_sandisk_ultra/\">[comments]</a></span>",
        "id": 2536632,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8nx8w/what_would_be_making_transfers_to_a_sandisk_ultra",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What would be making transfers to a SanDisk Ultra 3.0 SO slow?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T20:47:19.567020+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T20:19:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have one 12tb hard drive in my Synology nas DS423+. I just got three 20tb hard drives and I want to upgrade them. I know I&#39;m committing a sin here but I dont have a full back up. I can back up my most important things only. Is there any way to upgrade my drives without having to reset all my dsm and setting and apps.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Difficulty-Used\"> /u/Difficulty-Used </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8m6yb/hard_drive_upgrade/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8m6yb/hard_drive_upgrade/\">[comments]</a></span>",
        "id": 2536218,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8m6yb/hard_drive_upgrade",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hard drive upgrade",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T19:40:47.578180+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T19:33:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I&#39;m trying to buy a Samsung 870 EVO SSD from a seemingly reputable physical store. Is there anyway to check the packaging to know if it&#39;s fake? (Without opening the box)</p> <p>I searched online and it leads to Samsung Magician, which can only be run after I open the box, of course. </p> <p>Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/muffinBadger\"> /u/muffinBadger </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8l6j7/how_do_i_know_if_a_samsung_internal_ssd_is/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8l6j7/how_do_i_know_if_a_samsung_internal_ssd_is/\">[comments]</a></span>",
        "id": 2535904,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8l6j7/how_do_i_know_if_a_samsung_internal_ssd_is",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do I know if a Samsung Internal SSD is genuine before opening the box?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T19:40:47.705130+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T19:07:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need to acquire two used windows drives or devices that have not been wiped for my capstone project. Does anyone have any suggestions on what to search?? Most of the listings I\u2019ve seen on eBay/mercari have been wiped. My degree is in digital forensics so I\u2019ll just be analyzing the contents. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Unfair_Ad_9046\"> /u/Unfair_Ad_9046 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8klem/used_drives_or_devices/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8klem/used_drives_or_devices/\">[comments]</a></span>",
        "id": 2535905,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8klem/used_drives_or_devices",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Used drives or devices?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T19:40:47.827948+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T19:06:56+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8kkzv/home_media_server_is_showing_this/\"> <img src=\"https://preview.redd.it/3hisdcor98xe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b38adc2de1259aa498e6e1e7146882fb7d5de38c\" alt=\"Home media server is showing this.\" title=\"Home media server is showing this.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Should I be concerned?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/blakealanm\"> /u/blakealanm </a> <br/> <span><a href=\"https://i.redd.it/3hisdcor98xe1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8kkzv/home_media_server_is_showing_this/\">[comments]</a></span> </td></tr></table>",
        "id": 2535906,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8kkzv/home_media_server_is_showing_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/3hisdcor98xe1.jpeg?width=640&crop=smart&auto=webp&s=b38adc2de1259aa498e6e1e7146882fb7d5de38c",
        "title": "Home media server is showing this.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T18:37:21.259480+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T18:32:59+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8jt5s/magafriendly_website_publicsquare_backfires/\"> <img src=\"https://external-preview.redd.it/4-JKLIvTfLHpAm5R0JGNLYqgmAZSbvAAMIfhYelxnOk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=54de0dce102866fc9486a4981bdc5307b3f0de84\" alt=\"MAGA-Friendly Website PublicSquare Backfires\" title=\"MAGA-Friendly Website PublicSquare Backfires\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Is it possible to dupe the data on this site before it inevitably gets taken down? Asking for a friend \ud83d\ude08</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ill-Candidate8760\"> /u/Ill-Candidate8760 </a> <br/> <span><a href=\"https://www.huffpost.com/entry/publicsquare-trump-critics-boycott-businesses_n_680900d2e4b00850c6839b0b\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8jt5s/magafriendly_website_publicsquare_backfires/\">[comments]</a></span> </td></tr></t",
        "id": 2535594,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8jt5s/magafriendly_website_publicsquare_backfires",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/4-JKLIvTfLHpAm5R0JGNLYqgmAZSbvAAMIfhYelxnOk.jpg?width=640&crop=smart&auto=webp&s=54de0dce102866fc9486a4981bdc5307b3f0de84",
        "title": "MAGA-Friendly Website PublicSquare Backfires",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T18:37:21.409873+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T17:58:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>TL;DR: I want to get into backing up certain repos. So far, I tried to use a cronjob, but it&#39;s not really working too well - especially with multiple branches...</p> <p>What do you use or do you know a tool that does that?</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/IngwiePhoenix\"> /u/IngwiePhoenix </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8j0cp/system_to_continiously_archive_entire_git/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8j0cp/system_to_continiously_archive_entire_git/\">[comments]</a></span>",
        "id": 2535595,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8j0cp/system_to_continiously_archive_entire_git",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "System to continiously archive entire Git repos/Github orgs?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T18:37:21.081620+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T17:43:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello there! My first post here :)</p> <p>My family has thousands of images generated on their phones each month (mostly due to the use of Whatsapp, a must in certain countries without free SMS). Problem is, together with real photos they want to keep, there is a LOT of memes, old folk&#39;s &quot;good morning&quot; images, quotes images, slop political ones, and the eventual nude/porn...</p> <p>Most of the family doesn&#39;t have the means (or the will) to manually sort through all their files and select those they actually want to backup in our home server, which means (i) they just don&#39;t backup anything and keep a huge amount of things on their phones until it&#39;s full or lost; or (ii) they backup EVERYTHING they have, which is not only inefficient and expensive (more storage needs for the server), but makes our photo watching family sessions quite interesting, full of unnintended memes and eventual nudes popping up on the screen, not to ment",
        "id": 2535593,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8io87/easy_tool_for_sorting_real_photos_from_memes_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Easy Tool for Sorting Real Photos from Memes and Other Junk Images",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T18:37:21.532148+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T17:35:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a friend who\u2019s giving me a t330 and want to set that up as a NAS. I currently run a mini pc and two external drives. I would like to still use my mini pc to maintain the t330. Is that possible?(not sure what I am asking is making sense)</p> <p>I only use my current server as a jellyfin so nothing crazy. My current mini pc runs Ubuntu 24.04 so I would like to keep using that or some kind of Linux. Sorry if this sounds confusing I am still very new to all this. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Soybeanns\"> /u/Soybeanns </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8ihf2/t330_question/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8ihf2/t330_question/\">[comments]</a></span>",
        "id": 2535596,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8ihf2/t330_question",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "T330 question.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T17:31:00.246079+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T17:15:36+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8i0ym/straight_up_gone/\"> <img src=\"https://preview.redd.it/vbjdg02g47xe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9ebd1713ff8a5e069bbba459ddb56aa46253285e\" alt=\"straight up gone\" title=\"straight up gone\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Chicken_Witch\"> /u/Chicken_Witch </a> <br/> <span><a href=\"https://i.redd.it/vbjdg02g47xe1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8i0ym/straight_up_gone/\">[comments]</a></span> </td></tr></table>",
        "id": 2535198,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8i0ym/straight_up_gone",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/vbjdg02g47xe1.jpeg?width=640&crop=smart&auto=webp&s=9ebd1713ff8a5e069bbba459ddb56aa46253285e",
        "title": "straight up gone",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T16:26:08.492346+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T16:18:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, for my final project in a machine learning course I am to build a predictive model focusing on the US and China tariffs.</p> <p>My idea is to train the model based on historical tariff data, cost of goods, wealth inequality, maybe homelessness, economy/job market, but i havent found anything. I don\u2019t know how to scrape data either. </p> <p>If any of you heroes had anything you thought could help and wanted to share it, I would be very appreciative.</p> <p>Sorry if this is against the rules but I am 100% just looking for data and thought who has more data than <a href=\"/r/datahoarder\">r/datahoarder</a>. Thank you</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/kingkamikaze69\"> /u/kingkamikaze69 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8gp8k/tarriff_data_cost_of_goods_etc/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8gp8k/tarriff_da",
        "id": 2534901,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8gp8k/tarriff_data_cost_of_goods_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tarriff data, cost of goods etc.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T16:26:08.615641+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T16:18:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Purchased this to backup 2x 2TB Samsung shields (both about 1.4TB on each). Amazon purchase. Started playing up after day 2. I am a cautious cat, so I stopped using it &amp; finished backing up those 2x 2tb on another WD4tb (instead of the Samsung shield) out of an abundance of caution\u2026. </p> <p>Lo &amp; behold, went back to the Samsung T7 4TB Shield today to complete my original backup plan and it\u2019s failed.<br/> Disk repair won\u2019t work, Exit Code 8. Now a warning from my mac \u201cBack up the disk and reformat it as soon as you can\u201d.</p> <p>Should I bother reformatting it, or just send it back &amp; get another one? Is the T7 Shield 4TB known for having issues? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Artistic_Pear1834\"> /u/Artistic_Pear1834 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8gozt/samsung_t7_4tb_shield_failed_after_4_days/\">[link]</a></span> &#32; <span><a href=\"https://",
        "id": 2534902,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8gozt/samsung_t7_4tb_shield_failed_after_4_days",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Samsung T7 4tb Shield. Failed after 4 days. Reformat or send it back?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T16:26:08.737837+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T16:14:32+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hausdorffparty\"> /u/hausdorffparty </a> <br/> <span><a href=\"https://www.reddit.com/r/Teachers/comments/1k81mjd/eric_is_being_shut_down_this_is_how_people_around/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8glwf/eric_education_database_being_shut_down_does/\">[comments]</a></span>",
        "id": 2534903,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8glwf/eric_education_database_being_shut_down_does",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "ERIC education database being shut down, does anyone have an image?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T16:26:08.315192+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T15:57:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a lot of shows and movies saved on my hard drives. I&#39;m worried about bit rot and hard drive failure, so I&#39;m planning to create a duplicate of each drive. Is this enough to keep my data safe? I&#39;d love to hear how you guys manage your large collections and any tips or tricks you might have. Also, I&#39;m on a budget, so affordable suggestions would be appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MisakaMisakaS100\"> /u/MisakaMisakaS100 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8g77z/how_do_you_protect_your_large_media_collections/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8g77z/how_do_you_protect_your_large_media_collections/\">[comments]</a></span>",
        "id": 2534900,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8g77z/how_do_you_protect_your_large_media_collections",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How Do You Protect Your Large Media Collections? On a Budget",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T16:26:08.143896+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T15:31:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>My first data loss incident: back in 2014.</strong></p> <p><strong>My last data loss incident: January 2025. Got to know about it in April 2025.</strong></p> <p>I normally keep a backup my mobile contents (Photos, videos, call recordings etc.) in my PC. I admit, I do not do it regularly, but maybe about once in every two months or so. My mobile backup dates back to 2014. Every time I do a backup, I copy it over to the existing backup, so it gets added to the files that are already there. I do not keep everything on my phone because of storage space issue (Phone only has 512GB).</p> <p>Back in last January, I was backing up everything because I want to upgrade the RAID5 array to a RAID6, with more drives. I thought I might as well do a new backup of my mobile. I was doing a lot of things together, moving data out of the RAID5 to different drives (I am always running short of drives lol), and I made a mistake. Instead of adding the new backup, I",
        "id": 2534899,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8flyi/this_is_why_backup_versioning_is_so_important",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "This is why Backup versioning is so important!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T14:17:14.398508+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T14:12:26+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8dvje/in_youre_in_the_la_areahollywood_films_thrown_out/\"> <img src=\"https://preview.redd.it/ywu0m7s964xe1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6dcfa54c8b70514de879a92de795832df59dd777\" alt=\"In you're in the LA area...Hollywood films thrown out\" title=\"In you're in the LA area...Hollywood films thrown out\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lynivvinyl\"> /u/lynivvinyl </a> <br/> <span><a href=\"https://i.redd.it/ywu0m7s964xe1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8dvje/in_youre_in_the_la_areahollywood_films_thrown_out/\">[comments]</a></span> </td></tr></table>",
        "id": 2534070,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8dvje/in_youre_in_the_la_areahollywood_films_thrown_out",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ywu0m7s964xe1.png?width=640&crop=smart&auto=webp&s=6dcfa54c8b70514de879a92de795832df59dd777",
        "title": "In you're in the LA area...Hollywood films thrown out",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T14:17:14.543461+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T13:50:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, I am trying to figure out if I can get a mini itx board that can directly attach to a SAS 12G backplane without having to add a pcie HBA. </p> <p>I see that there are quite a few board (say, ASUS P12R-I) which say you can get 4 SATA with a mini SAS HD connector. But those won&#39;t work with a backplane right? Same for an oculink to 4 sata adapter, right?</p> <p>My understanding is that these connectors are universal and you can run many protocols over those. When you do oculink to 4sata then you need a specialized cable, but the motherboard knows how to use each lane independently as a sata one, but an HBA uses it differently. </p> <p>I think something like an H12ssl-NT would work but it is not itx :) </p> <p>Is there a solution? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nail_nail\"> /u/nail_nail </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8df3p/mini_itx_board_to_sff_8643_",
        "id": 2534071,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8df3p/mini_itx_board_to_sff_8643_backplane",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Mini Itx board to SFF 8643 backplane",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T16:26:09.003578+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T12:41:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Run the code to automatically download all the images from a list of URL-links in a &quot;.txt&quot; file. Works for google books previews. It is a Windows 10 batch script, so save as &quot;.bat&quot;.</p> <pre><code>@echo off setlocal enabledelayedexpansion rem Specify the path to the Notepad file containing URLs set inputFile= rem Specify the output directory for the downloaded image files set outputDir= rem Create the output directory if it doesn&#39;t exist if not exist &quot;%outputDir%&quot; mkdir &quot;%outputDir%&quot; rem Initialize cookies and counter curl -c cookies.txt -H &quot;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3&quot; &quot;https://books.google.ca&quot; &gt;nul 2&gt;&amp;1 set count=1 rem Read URLs from the input file line by line for /f &quot;usebackq delims=&quot; %%A in (&quot;%inputFile%&quot;) do ( set url=%%A echo Downloading !url! curl -b coo",
        "id": 2534904,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8c1os/download_images_in_bulk_from_urllist_with_windows",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Download images in bulk from URL-list with Windows Batch",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T12:00:02.234502+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T11:57:25+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8b9ff/how_to_stress_test_a_hdd_on_windows/\"> <img src=\"https://b.thumbs.redditmedia.com/A70Z9YIWnsPznIpXumcqlvG65x4uWNn1ea_BgaVppjA.jpg\" alt=\"How to stress test a HDD on windows?\" title=\"How to stress test a HDD on windows?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/mf0dyguh46xe1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=a7d305ed0501f819d4b00a6d6556d6a278b82021\">https://preview.redd.it/mf0dyguh46xe1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=a7d305ed0501f819d4b00a6d6556d6a278b82021</a></p> <p>Hi all! I want to see if my WD Elements HDDs are good before shucking them into a NAS. How else can I test that? I&#39;m looking for easy to use GUI that might have tutorials since I don&#39;t want to break anything.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SnooBunnies9252\"> /u/SnooBunnies9252 </a> <br/> <span><a href=\"ht",
        "id": 2533392,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8b9ff/how_to_stress_test_a_hdd_on_windows",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/A70Z9YIWnsPznIpXumcqlvG65x4uWNn1ea_BgaVppjA.jpg",
        "title": "How to stress test a HDD on windows?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T16:26:09.133990+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T10:46:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I think I need to redo my Debian NAS. I have a <a href=\"https://www.chenbro.com/en-global/products/RackmountChassis/4U_Chassis/RM42300\">Chenbro RM42300</a> chassis with two <a href=\"https://www.amazon.com/dp/B07TJHCGXL?ref_=ppx_hzsearch_conn_dt_b_fed_asin_title_6\">5-bay enclosures</a>. I also got a two of the <a href=\"https://www.amazon.com/dp/B07F22926M?ref_=ppx_hzsearch_conn_dt_b_fed_asin_title_5\">2-bay 2.5&quot; drive</a>. In the middle front of the chassis has 4-bay for HDD. My power supply is a Corsair HX850.</p> <p>Currently, I am powering each 5-bays with two SATA power and the 4x HDD in the middle with this <a href=\"https://www.amazon.com/dp/B00ENKYJB4?ref_=ppx_hzsearch_conn_dt_b_fed_asin_title_10&amp;th=1\">4-in-1 cable</a>. There were random times in the past that one of the HDD would disconnect from the system. When I ran the command <code>lsblk -f</code>, the disk is not there. I am not sure if it is a power issue or SATA cable issue. This ",
        "id": 2534905,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8a4wq/some_hdd_got_disconnected_from_the_system",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Some HDD got disconnected from the system",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T10:55:47.874263+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T10:29:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://en.wikipedia.org/wiki/Ultra_Density_Optical\">UDO and UDO2 drives. </a> I really wanted so bad. This was supposed to be 9.1gb magneto optical&#39;s replacement. Looks like giant minidiscs. 30-60gb discs. I waited for a SATA version to come out. Even at the time SCSI was on the way out, and this drive got released; SCSI only. A slow USB2.0 version was released but it&#39;s extremely rare and was reported to be too slow. And this is where UDO kinda froze in time. The drives never got an update; never a SATA or firewire version. They announced the 80gb discs but were never released. But the 30/60gb discs were made well past UDO&#39;s decline. </p> <p>Man, I would love to back up my TV show DVD collection onto those chonky UDO discs.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/churnopol\"> /u/churnopol </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k89vt0/obsolete_data_sto",
        "id": 2533080,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k89vt0/obsolete_data_storage_tech_that_you_wish_became",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Obsolete data storage tech that you wish became popular.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T09:51:38.930357+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T09:42:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I did a recovery, and while almost 99% of the file works, their names have changed. Now I need to compare it with a recent backup and delete the duplicates so I can get the old backup files back.</p> <p>Is there any duplicate finder that will find files with same sizes? I sort both the backup folder and recovered folder in windows by size, and I can see same files with same file sizes on both, except the names have changed. 52,086 files is a lot to go through one by one manually, so I need a duplicate finder.</p> <p>Thank you very much in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/manzurfahim\"> /u/manzurfahim </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8982v/any_duplicate_file_finder_that_finds_duplicate_by/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k8982v/any_duplicate_file_finder_that_finds_duplicate_by/\">[comments]</a></sp",
        "id": 2532803,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k8982v/any_duplicate_file_finder_that_finds_duplicate_by",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any duplicate file finder that finds duplicate by size?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T09:51:39.075454+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T09:27:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i want to download this stream <a href=\"https://parti.com/video/74545\">https://parti.com/video/74545</a></p> <p>im on my ipad rn but can use windows laptop if its required to download stream</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Beautiful_Acadia_381\"> /u/Beautiful_Acadia_381 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k890rs/anyone_knows_how_to_download_these_live_stream/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k890rs/anyone_knows_how_to_download_these_live_stream/\">[comments]</a></span>",
        "id": 2532804,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k890rs/anyone_knows_how_to_download_these_live_stream",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone knows how to download these live stream from parti.com?? im new into this and only know how to download twitch , yt live streams",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T09:51:38.748605+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T09:22:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey, i have a problem. I have a br burner from verbatim and use ashampoo. I can burn the 25 gb mdisc (old version), but the new version, which supports faster writing speeds, no longer does. Firmware etc. is up to date. On the new discs it even says on the packaging that it works with any BR burner that supports 4x. Wtf. Do you have any ideas?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/red__flag_\"> /u/red__flag_ </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k88yjo/mdisc_new_version_25_gb_cannot_be_burned_with/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k88yjo/mdisc_new_version_25_gb_cannot_be_burned_with/\">[comments]</a></span>",
        "id": 2532802,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k88yjo/mdisc_new_version_25_gb_cannot_be_burned_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "mdisc (new version, 25 gb) cannot be burned with Verbatim burner?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T09:51:39.214699+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T09:11:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, Hoarders! I wanted to get some feedback on the change I&#39;m planning for my storage system and see if anyone has a better idea or any useful suggestions.</p> <p>I&#39;m still using my DS415play with 4x 8TB drives, but I&#39;ve never been completely happy with the setup since the multimedia section isn&#39;t secured, and my data is only mirrored. Basically, two of the drives hold multimedia files without any backup, while the other two are mirrored for redundancy. The multimedia section hasn&#39;t worried me much since I could rebuild almost everything, but now that storage space is starting to run out, I want to improve security overall and reorganize my system.</p> <p>The idea I have in mind, without it being excessively expensive, is the following:</p> <ul> <li>Keep the DS415play with the drives but convert it into RAID 5 or SHR, so I gain an extra 8TB drive for multimedia with added redundancy.</li> <li>For backups and general data storage",
        "id": 2532805,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k88t6x/suggestions_to_optimize_my_storage_system",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Suggestions to optimize my storage system",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T08:45:29.985775+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T08:30:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been using 990s for my DAS, but I just bought myself a TerraMaster NAS and was just wondering if I should keep using 990s or if I can buy slower and cheaper m.2s?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/zgrad2\"> /u/zgrad2 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k888vg/does_speed_matter_for_a_nas/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k888vg/does_speed_matter_for_a_nas/\">[comments]</a></span>",
        "id": 2532551,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k888vg/does_speed_matter_for_a_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does speed matter for a nas?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T08:45:30.355818+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T08:11:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking for an external hard drive to move videos, pictures and other files into and I found a Toshiba Canvio gaming 2TB at a good price and I thought that&#39;s nice with that I can get more bang for my buck, but someone told me that external hard drives can&#39;t really store both gaming and media, is that true??</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sakugalv77\"> /u/Sakugalv77 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k87zdp/do_gaming_external_hard_drives_support_other/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k87zdp/do_gaming_external_hard_drives_support_other/\">[comments]</a></span>",
        "id": 2532552,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k87zdp/do_gaming_external_hard_drives_support_other",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Do gaming external hard drives support other files that aren't gaming related?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T07:40:22.587906+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T07:03:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Have a client that I need to setup with a 400tb nas. Was going to synology DS3622xs+ and expansion bay for a total of 400tb of storage across 2 pools on raid 6 . I was planning on using western digital red pro 20tb drives\u2026.but now hearing about their drive lock announcement throws a complete wrench into my situation. </p> <p>What are other good alternative that are space and noise conscience ? User has limited space and these drives will be sitting in an office so can\u2019t be super loud. So anything 45 drives is out of the question. </p> <p>Anyone got any recommendations? Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/linsane24\"> /u/linsane24 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k870cc/best_solution_for_space_and_noise_conscience_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k870cc/best_solution_for_space_and_noise_conscience",
        "id": 2532265,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k870cc/best_solution_for_space_and_noise_conscience_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best solution for space and noise conscience data hoarding?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T07:40:22.710919+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T06:58:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My knitting partner used to follow a blog called untangling knots where a prolific knitter hosted patterns they developed for sale. The owner closed up shop and they&#39;re no longer available.</p> <p>Has anybody saved some these by any chance? If not that blog, are there any good archives for knitting patterns?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/minorminer\"> /u/minorminer </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k86xmh/where_to_find_repositories_of_knitting_patterns/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k86xmh/where_to_find_repositories_of_knitting_patterns/\">[comments]</a></span>",
        "id": 2532266,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k86xmh/where_to_find_repositories_of_knitting_patterns",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Where to find repositories of knitting patterns",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T06:35:09.173006+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T06:17:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anyone ever had a WD elements drive shucked and not show up anymore? Wont initialize but i could here it spinning up. Used kapton tape on the 3 pins it didnt work but didnt have problems with the others. Then it didnt even work back in the enclosure </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Responsible_Help_277\"> /u/Responsible_Help_277 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k86az3/shucking_wd_elements_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k86az3/shucking_wd_elements_drives/\">[comments]</a></span>",
        "id": 2531620,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k86az3/shucking_wd_elements_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Shucking WD elements drives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T06:35:09.295225+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T04:37:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Would anyone recommend either of these 3 QNAP NAS for home use? beginners? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Limp_Fig6236\"> /u/Limp_Fig6236 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k84rcx/would_you_recommend_qnap_tbs464_tsh765eu_or/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k84rcx/would_you_recommend_qnap_tbs464_tsh765eu_or/\">[comments]</a></span>",
        "id": 2531621,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k84rcx/would_you_recommend_qnap_tbs464_tsh765eu_or",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Would you recommend? QNAP TBS-464? TS-h765eU? or TBS-453DX?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T06:35:09.463502+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T04:13:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I did some research and I was going to buy the DS423+. Now that Synology is planning to lock down hard drive options for 2025 Plus models, I&#39;m wondering if it is still wise to buy a Synology NAS. Even though the DS423+ is not affected by the hard drive limitation, it is missing the upgrades from the 2025 version and Synology might potentially pull off some retroactive cripple hammer.</p> <p>My use case would be mainly for backing up my photos and videos and editing photos. I might stream media via Plex, and perhaps run some servers through Docker, though these are not as critical. The main thing I would be missing is editing videos off of the NAS - the 1 Gbps ethernet and the lack of USB-C/Thunderbolt access means that I would have to copy the files off the hard drive before I could edit them.</p> <p>I did some research on hard drive enclosures and the consensus seems to be that they are unreliable and may potentially corrupt my files. Also, they ",
        "id": 2531622,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k84d1b/should_i_just_buy_the_synology_ds423_now_that",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Should I just buy the Synology DS423+ now that they are limiting hard drives options?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T06:35:08.666792+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T04:12:58+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1k84czw/attn_los_angeles_film_fansarchivistshobbyists/\"> <img src=\"https://external-preview.redd.it/RPiYTej5khZWUWvxIxUuFnuP4-DTcLODAFGnzv3W3yM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b59a479938b334c97c4daa3274260ab4aed43e48\" alt=\"ATTN Los Angeles film fans/archivists/hobbyists!\" title=\"ATTN Los Angeles film fans/archivists/hobbyists!\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Dumpster full of film reels apparently available to any who want them at 936 Seward St in Hollywood, from recently bankrupted Technicolor offices. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hyacinth_house_\"> /u/hyacinth_house_ </a> <br/> <span><a href=\"https://bsky.app/profile/srothbell.com/post/3lnolrwuon22b\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k84czw/attn_los_angeles_film_fansarchivistshobbyists/\">[comments]</a></span> </td></t",
        "id": 2531617,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k84czw/attn_los_angeles_film_fansarchivistshobbyists",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/RPiYTej5khZWUWvxIxUuFnuP4-DTcLODAFGnzv3W3yM.jpg?width=640&crop=smart&auto=webp&s=b59a479938b334c97c4daa3274260ab4aed43e48",
        "title": "ATTN Los Angeles film fans/archivists/hobbyists!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T06:35:09.585608+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T03:17:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am working on a project that will allow people to connect to different wifi networks and view web content using the captive portal feature (like you use in a hotel or airport). The goal is to have an opportunity for people to view/save data from these portals. This is limited to basic html + jpegs + movie files as its not possible to host pdfs or more complex content. I&#39;m looking for suggestions for intriguing data sets to host in this capacity - things you could sit and read, watch, or save images to your phone. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cmeerdog\"> /u/cmeerdog </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k83dn1/data_sharing_network_need_suggestions/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k83dn1/data_sharing_network_need_suggestions/\">[comments]</a></span>",
        "id": 2531623,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k83dn1/data_sharing_network_need_suggestions",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Data Sharing Network - Need Suggestions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T06:35:08.812780+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T03:14:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Very simple and probably 10 minutes of searching would have found the answer but it is nice to get a more recent thread started every now and again.</p> <p>For my scenario is it movies and that&#39;s it. I have about 25TB spread over 4 HDD&#39;s (all WD Gold) but I have zero plan for HDD failure. What should I be doing because as we all know, some of those old movies are hard to fine seeds?!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BigMcLargeHuge-\"> /u/BigMcLargeHuge- </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k83bxo/what_should_the_plan_be_for_hdd_failure/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k83bxo/what_should_the_plan_be_for_hdd_failure/\">[comments]</a></span>",
        "id": 2531618,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k83bxo/what_should_the_plan_be_for_hdd_failure",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What should the plan be for HDD failure?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T06:35:08.544257+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T02:13:47+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1k827il/just_set_up_my_first_home_server_4_days_ago_i/\"> <img src=\"https://preview.redd.it/oksrtba093xe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6854ef60dad15734934d0c35af0c2a5f364bf708\" alt=\"Just set up my first home server 4 days ago. I never imagined it would be so addicting..\" title=\"Just set up my first home server 4 days ago. I never imagined it would be so addicting..\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Noversi\"> /u/Noversi </a> <br/> <span><a href=\"https://i.redd.it/oksrtba093xe1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k827il/just_set_up_my_first_home_server_4_days_ago_i/\">[comments]</a></span> </td></tr></table>",
        "id": 2531616,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k827il/just_set_up_my_first_home_server_4_days_ago_i",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/oksrtba093xe1.jpeg?width=640&crop=smart&auto=webp&s=6854ef60dad15734934d0c35af0c2a5f364bf708",
        "title": "Just set up my first home server 4 days ago. I never imagined it would be so addicting..",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T06:35:08.981505+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T01:56:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a container that can store 20 3.5&quot; hard drives safely and securely and i personally don&#39;t plan to get a NAS or some sort of device to have them constantly on or on most of the time as a lot of people do.</p> <p>So instead I plan to just put them into a dock to read and write when needed and place them back into the container and half of the hard drives will be copies of the other half just in case something happens to the main 10.Also I plan to expand the amount I have over time but currently I have the capacity to store 20 hard drives.</p> <p>I would like to know if this is something reasonable to do and isn&#39;t generally a bad thing to do for long term and large amount of data storage.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ContestIndividual975\"> /u/ContestIndividual975 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k81w4f/looking_for_personal_opinions_about_",
        "id": 2531619,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k81w4f/looking_for_personal_opinions_about_my_hard_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "looking for personal opinions about my hard drive situation.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-26T06:35:08.374786+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-26T00:31:25+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1k80abi/exclusive_trumps_dc_prosecutor_threatens/\"> <img src=\"https://external-preview.redd.it/3mCSC-I4eYzSWQivyG8I0M3_IEmWaYJgFoaK-MmHQjE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=62c9129dd5aea37d3186be73ffabc3ca56af25d0\" alt=\"Exclusive: Trump\u2019s D.C. Prosecutor Threatens Wikipedia\u2019s Tax-Exempt Status\" title=\"Exclusive: Trump\u2019s D.C. Prosecutor Threatens Wikipedia\u2019s Tax-Exempt Status\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Jacksharkben\"> /u/Jacksharkben </a> <br/> <span><a href=\"https://www.thefp.com/p/trump-prosecutor-threatens-wikipedia?hide_intro_popup=true\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1k80abi/exclusive_trumps_dc_prosecutor_threatens/\">[comments]</a></span> </td></tr></table>",
        "id": 2531615,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1k80abi/exclusive_trumps_dc_prosecutor_threatens",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/3mCSC-I4eYzSWQivyG8I0M3_IEmWaYJgFoaK-MmHQjE.jpg?width=640&crop=smart&auto=webp&s=62c9129dd5aea37d3186be73ffabc3ca56af25d0",
        "title": "Exclusive: Trump\u2019s D.C. Prosecutor Threatens Wikipedia\u2019s Tax-Exempt Status",
        "vote": 0
    }
]