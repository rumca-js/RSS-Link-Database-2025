[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-04T20:37:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My company only has allowed 1 website on the entire network and I&#39;m trying to use selenium to scrape data on that site using selenium and edge driver</p> <p>I&#39;ve installed python/selenium fine but Microsoft edge driver doesn&#39;t seem to work because it seems to have a dependency to an online resource that is being blocked?</p> <p>Anyone have experience with working with selenium and edge driver in this situation?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ExpensiveEuro\"> /u/ExpensiveEuro </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jrm1cg/web_scraping_where_everything_is_closed_off/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jrm1cg/web_scraping_where_everything_is_closed_off/\">[comments]</a></span>",
        "id": 2487745,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jrm1cg/web_scraping_where_everything_is_closed_off",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Web scraping where everything is closed off?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-04T11:23:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, do you have any tools or extensions to recommend? I use the Instant Data Scraping extension; however, it doesn&#39;t include a contact number.</p> <p>please helpp</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Huge-Review-6226\"> /u/Huge-Review-6226 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jr9i9m/free_tool_for_scraping_leads_in_google_maps/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jr9i9m/free_tool_for_scraping_leads_in_google_maps/\">[comments]</a></span>",
        "id": 2482822,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jr9i9m/free_tool_for_scraping_leads_in_google_maps",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Free Tool for Scraping Leads in Google Maps",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-04T09:22:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is that the right way or should one use Git to push the code on another system? When should one be using docker if not in this case?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dadiamma\"> /u/dadiamma </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jr7ps0/is_it_okay_to_use_docker_for_web_scraping_scripts/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jr7ps0/is_it_okay_to_use_docker_for_web_scraping_scripts/\">[comments]</a></span>",
        "id": 2481978,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jr7ps0/is_it_okay_to_use_docker_for_web_scraping_scripts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is it okay to use Docker for web scraping scripts?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-04T09:04:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently open-sourced a little repo I\u2019ve been using that makes it easier to run <strong>Puppeteer on AWS Lambda</strong>. Thought it might help others building serverless scrapers or screenshot tools.</p> <p>\ud83d\udce6 GitHub: <a href=\"https://github.com/geiger01/puppeteer-lambda\">https://github.com/geiger01/puppeteer-lambda</a></p> <p>It\u2019s a minimal setup with:</p> <ul> <li>Puppeteer bundled and ready to run inside Lambda</li> <li>Simple example handler for extracting HTML</li> </ul> <p>I use a similar setup in my side projects, and it\u2019s worked well so far for handling headless Chromium tasks without managing servers.</p> <p>Let me know if you find it useful, or if you spot anything that could be improved. PRs welcome too :)<br/> (and stars \u2728 as well)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Jonathan_Geiger\"> /u/Jonathan_Geiger </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jr7h2v/open",
        "id": 2481977,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jr7h2v/open_source_aws_lambda_puppeteer_starter_repo",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Open Source: AWS Lambda + Puppeteer Starter Repo",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-04T08:29:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently open-sourced a little repo I\u2019ve been using that makes it easier to run <strong>Puppeteer on AWS Lambda</strong>. Thought it might help others building serverless scrapers or screenshot tools.</p> <p>\ud83d\udce6 GitHub: <a href=\"https://github.com/geiger01/puppeteer-lambda\">https://github.com/geiger01/puppeteer-lambda</a></p> <p>It\u2019s a minimal setup with:</p> <ul> <li>Puppeteer bundled and ready to run inside Lambda</li> <li>Simple example handler for extracting HTML</li> </ul> <p>I use a similar setup in <a href=\"https://capturekit.dev/\">CaptureKit</a>, and it\u2019s worked well so far for handling headless Chromium tasks without managing servers.</p> <p>Let me know if you find it useful, or if you spot anything that could be improved. PRs welcome too :)<br/> (and stars \u2728 as well)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Jonathan_Geiger\"> /u/Jonathan_Geiger </a> <br/> <span><a href=\"https://www.reddit.com/r/w",
        "id": 2481657,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jr70h2/open_source_aws_lambda_puppeteer_starter_repo",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Open Source: AWS Lambda + Puppeteer Starter Repo",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-04T04:26:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Can I still scrape X posts from specific dates for free, without logging in or using a paid API?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/FeelingShower4338\"> /u/FeelingShower4338 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jr3eec/help_with_webscraping_x/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jr3eec/help_with_webscraping_x/\">[comments]</a></span>",
        "id": 2480904,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jr3eec/help_with_webscraping_x",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help With Webscraping X",
        "vote": 0
    }
]