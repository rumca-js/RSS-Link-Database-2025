[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-09T19:21:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been wanting to extract soccer player data from <a href=\"http://premierleague.com/players\">premierleague.com/players</a> for a silly personal project but I&#39;m a web scraping novice. Thought I&#39;d get some help from <a href=\"http://Claude.ai\">Claude.ai</a> but every script it gives me doesn&#39;t work or returns no data. </p> <p>I really just want a one time extraction of some specific data points (name, DOB, appearances, height, image) for every player to have played in the Premier League. I was hoping I could scrape every player&#39;s bio page (e.g. <a href=\"http://premierleague.com/players/1\">premierleague.com/players/1</a> <a href=\"http://premierleague.com/players/2\">premierleague.com/players/2</a> etc. and so on) but everything I&#39;ve tried has turned up nothing. </p> <p>Can someone help me do this or suggest a bettter way?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sikhsthroughtime\"> /u",
        "id": 2521075,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jveaqt/trying_to_learn_web_scraping_from_claude_and_feel",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to learn web scraping from Claude and feel like an idiot",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-09T18:33:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><h3>Long story short:</h3> <p>Landed job at a local startup, first real job outta school. Only developer on team? At least according to team. I am the only one with computer science degree/background at least. Majority of the stuff had been setup by past devs, some of it haphazardly.</p> <p>Job sometimes consists of needing to scrape sites like Bobcat/JohnDeere for agriculture/ construction dealerships.</p> <h1>Problem and issues</h1> <p>Occasionally scrapers break. I need to fix it. I begin fixing and testing. Scraping takes anywhere from 25-40 mins depending on the site.</p> <p>Not a problem for production as the site only really needs to be scraped once a month to update. Problem for testing when I can only test a hand full of times before work day ends. </p> <h2>Questions and advice needed</h2> <p>I need any kind of pointers or general advice into scaling this up. New to most of if not all this webdev stuff. Felling decent at my progress so far for ",
        "id": 2520537,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jvd4f7/in_need_of_direction_for_a_newbie",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "In need of direction for a newbie",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-09T15:56:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently brought a new windows server to run scraping projects off rather than always running them off my local machine. </p> <p>I have a script using playwright that will scrape certain corportae accounts on a social media site after I&#39;ve logged in. </p> <p>This script works fine on my local machine. However after a day&#39;s use I&#39;m being blocked from even being able to login on the server. Any attempt to login just takes me back to the login screen on a loop. </p> <p>I assume this is because of something on the server settings making it look sketchy. Any idea what this could be? Is there anything about a fresh windows server that would be likely to get flagged compared to a regular desktop computer?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ArchipelagoMind\"> /u/ArchipelagoMind </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jv98k6/unable_to_login_to_social_media_site_o",
        "id": 2519325,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jv98k6/unable_to_login_to_social_media_site_on_brand_new",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Unable to login to social media site on brand new windows server",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-09T15:09:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve a about 200 million rows of data. I have names of users and I&#39;ve to find the gender of those users. I was using genderize.io api. Even with proxy and random user agents, it gives me error code 429. Is there any way to predict the gender of user using its first name. I really dont wanna train a model rn</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/expiredUserAddress\"> /u/expiredUserAddress </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jv841y/error_code_429_with_proxy/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1jv841y/error_code_429_with_proxy/\">[comments]</a></span>",
        "id": 2518714,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jv841y/error_code_429_with_proxy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Error code 429 with proxy",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-09T14:25:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I set up scraping of an e-com website looking at 3500 pages which take about 3 hours to cycle through the data. I&#39;m not crawling through the website the pages I&#39;m looking at are static urls. It occurred to me is there a way to set up multiple instances of selenium on a computer each one looking at a different URL and then programing them to refresh the page at a set interval? I&#39;m not sure how much bandwidth a refresh takes vs pulling the website as I am now by going one after the other through a list in my database. I also have read there is a difference in a soft vs hard refresh but I don&#39;t know particularly how that works or if it would mean any real difference in bandwidth usage. The bottom line I&#39;m trying to get at is first of all is it even possible to have for instance 100 selenium instances running on a single computer doing this. Second would there be any advantage to that (bandwidth usage wise) over setting up multiple sc",
        "id": 2518079,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1jv72s1/speed_up_scaling_up_webscraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Speed up & scaling up webscraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-04-09T05:33:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I am trying to use Python to click on the checkbox of Cloudflare, but it\u2019s not working. I have researched and found that the issue is because it cannot interact with the shadow root.</p> <p>I have looked into using SeleniumBase, but it cannot run on the VPS, only regular Selenium works. Below is the code I am using to click on the checkbox, but it doesn\u2019t work. Can anyone help me?</p> <pre><code>import time from undetected_geckodriver import Firefox from selenium.webdriver.common.by import By from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver.common.action_chains import ActionChains driver = Firefox() driver.get(&quot;https://pace.coe.int/en/aplist/committees/9/commission-des-questions-politiques-et-de-la-democratie&quot;) try: time.sleep(10) el = driver.find_element(By.ID, &quot;TAYH8&quot;) location = el.location x = location[&#39;x&#39;] y = locati",
        "id": 2514812,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1juygei/selenium_cloudflare_checkbox_needs_assistance",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Selenium Cloudflare Checkbox Needs Assistance",
        "vote": 0
    }
]