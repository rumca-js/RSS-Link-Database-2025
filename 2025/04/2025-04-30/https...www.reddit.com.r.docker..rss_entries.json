[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T22:12:40.181705+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T21:59:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve attempted docker in the past only to get frustrated and go an easier way, but recently got a NAS and putting my full focus on learning docker and getting it set up, but I have a few questions..</p> <p>From what I understand, you can&#39;t change an Environment Variable after the docker container is created, or at least not in Container Station.. and Portainer does allow you to change it, but it just deletes and rebuilds the container with the change variable. Do I have this right?</p> <p>That leads to my second question which is Plex related. Let&#39;s say I have a Plex container all set up with Movies/Music/TV and it&#39;s working perfectly. One day I decide to create a new library of Short Films, Home Movies, a 4K library(that is limited to me so people aren&#39;t trying to stream 4K outside my network). If I essentially have to rebuild the Plex container, what happens to my settings for the Plex Server that was there? From my testing so fa",
        "id": 2569318,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1kbsn4x/newbie_questions_about_plex_and_docker",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Newbie, questions about Plex and Docker",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T18:57:38.315431+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T18:45:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>I am currently workin on a backend API application in python (FastAPI, alembic, pydantic, sqlalchemy) and currently setting up the docker workflow for the app.</p> <p>I was wondering if it&#39;s better to set up a single multistage dockerfile for both dev (hot reloading, dev tools like ruff) and prod (non-root user, minimal image size) or set up a separate file for each usecase.</p> <p>Would love to know what is the best practices for this.</p> <p>Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Amgadoz\"> /u/Amgadoz </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1kbo398/one_multistage_docker_files_or_two_dockerfiles/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1kbo398/one_multistage_docker_files_or_two_dockerfiles/\">[comments]</a></span>",
        "id": 2567997,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1kbo398/one_multistage_docker_files_or_two_dockerfiles",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "One multistage docker files or two dockerfiles for dev and prod?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T15:42:49.835567+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T15:15:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi Everyone,</p> <p>Hoping someone can help with this one. I have two Docker hosts, RHEL servers with MachineA (Docker 20.10) and MachineB (20.10) I know they are V old but... reasons.</p> <p>The working MachineA sends DNS requests as itself to the DNS server (so the requests come from 10.1.10 for example rather than the actual docker network. I believe this to be standard practice as there is an internal DNS server/proxy server.</p> <p>However the faulty MachineB sends requests that appear to come from the internal docker network, ie 172.x.x.x, each one from a different container) The DNS server responds but it&#39;s just not right.</p> <p>Neither host has a daemon.json to force any alternate behavior. They are both on the same subnet, (should) be configured the same. </p> <p>Any ideas what I am missing?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ComputerIsBurning\"> /u/ComputerIsBurning </a> <br/> <span><a ",
        "id": 2565605,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1kbj03b/strange_dns_issue_one_host_works_correctly_one",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Strange DNS issue. One host works correctly. One doesn't",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T13:10:43.267260+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T12:53:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello!</p> <p>Does anyone have a good seccomp json file for minimal syscalls for nginx, mysql and php containers? Editing and testing hundreds of lines is very annoying.</p> <p>Or a way to see what syscalls are needed?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Quezacotli\"> /u/Quezacotli </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1kbfqo5/seccomp_rules_for_websites/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1kbfqo5/seccomp_rules_for_websites/\">[comments]</a></span>",
        "id": 2564796,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1kbfqo5/seccomp_rules_for_websites",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seccomp rules for websites",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T13:10:43.398322+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T12:19:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is there any simple way to tag all traffic from a container with a specific dscp tag?</p> <p>I was running a steam game server in a docker container and wanted to prioritize the container for less packet loss. The game server uses stun for game traffic (so payload actually goes through random high ports), only fixing the udp &quot;listen&quot; port.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/shangjiaxuan\"> /u/shangjiaxuan </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1kbf1gv/any_way_to_dscp_tag_a_containers_traffic_to/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1kbf1gv/any_way_to_dscp_tag_a_containers_traffic_to/\">[comments]</a></span>",
        "id": 2564797,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1kbf1gv/any_way_to_dscp_tag_a_containers_traffic_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any way to dscp tag a container's traffic to internet?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T12:05:53.101368+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T10:34:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I&#39;ve been frustrated that Docker Hub only shows the total all-time downloads for images with no way to track daily/weekly trends. So I built <strong>cf-hubinsight</strong> - a simple, free, open-source tool that tracks Docker Hub image pull counts over time.</p> <h1>What it does:</h1> <ul> <li>Records Docker Hub pull counts every 10 minutes</li> <li>Shows daily, weekly, and monthly download increases</li> <li>Simple dashboard with no login required</li> <li>Easy to deploy on Cloudflare Workers (free tier)</li> </ul> <h1>Why I built it:</h1> <p>For open-source project maintainers, seeing if your Docker image is trending up or down is valuable feedback. Questions like &quot;How many pulls did we get this week?&quot; or &quot;Is our image growing in popularity?&quot; are impossible to answer with Docker Hub&#39;s basic stats.</p> <h1>How it works:</h1> <ul> <li>Uses Cloudflare Workers to periodically fetch pull counts</li> <li>St",
        "id": 2564089,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1kbd82v/i_built_a_tool_to_track_docker_hub_pull_stats",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I built a tool to track Docker Hub pull stats over time (since Hub only shows total pulls)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T13:10:43.586654+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T08:33:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Good morning!</p> <p>I&#39;m trying to solve a problem that&#39;s driving me crazy.</p> <p>I have Unraid, and within it I have Docker Adguard, Nginx Proxy Manager, Authentik, Immich, etc. installed.</p> <p>All containers are connected internally to an internal network.</p> <p>Adguard is configured to point to npm on the local domains, and npm is configured with the container name on each domain (this works fine). The problem, for example, is with the local Unraid domain (it calls its IP address, not the container&#39;s, since it&#39;s not the container itself). So it can&#39;t resolve it.</p> <p>I&#39;m also having issues with paperless, immich, grafana, and all the containers I&#39;m trying to configure with Authentik OAuth2. When I try to log in to each Docker with Authentik, it gives an error (as if it&#39;s not resolving correctly).</p> <p>I&#39;m not finding the solution, although it&#39;s probably simple, but I don&#39;t see it.</p> <p>Thanks in",
        "id": 2564798,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1kbbjdf/resolutionconfiguration_issueadguard_nginx_proxy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Resolution/configuration issue/adguard - Nginx proxy manager - authentik - unraid...",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T09:05:55.470003+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T08:29:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I\u2019m working with Docker for my Node.js project, and I\u2019ve encountered a bit of confusion around installing npm packages.</p> <p>Whenever I install a package (e.g., npm install express) from the host machine\u2019s terminal, it doesn\u2019t reflect inside the Docker container, and the container&#39;s node_modules doesn\u2019t get updated. I see that the volume is configured to sync my app\u2019s code, but the node_modules seems to be isolated from the host environment.</p> <p>I\u2019m wondering:</p> <p>Why doesn\u2019t installing npm packages on the host update the container&#39;s node_modules?</p> <p>Should I rebuild the Docker image every time I install a new package to get it into the container?</p> <p>What is the best practice for managing package installations in a Dockerized Node.js project? Should I install packages from within the container itself to keep everything in sync?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.co",
        "id": 2563090,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1kbbhtu/need_advice_regarding_packages_installtion",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need advice regarding packages installtion",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T05:50:55.940279+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T05:29:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I tried putting a .env in my nas share with DIR=/path/to/location variable for my directory where i put multiple projects config.</p> <p>I added it with env_file option in compose files. But that doesn&#39;t work. </p> <p>What can I do to use the single file env file with my directory location? I want to do it this way so I can just change location in same place instead of multiple places.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/human_with_humanity\"> /u/human_with_humanity </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1kb8y1p/how_to_define_same_directory_location_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1kb8y1p/how_to_define_same_directory_location_for/\">[comments]</a></span>",
        "id": 2562261,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1kb8y1p/how_to_define_same_directory_location_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to define same directory location for different docker compose projects bind mounts from a single .env file?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T02:34:00.452463+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T02:02:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I&#39;ve spent the last few weeks learning about Docker and how to use it. I think I&#39;ve got a solid grasp of the concepts, except for one thing:</p> <p>What is an &quot;empty&quot; Docker container? What&#39;s in it? What does it consist of?</p> <p>For reference, when I say &quot;empty&quot;, I mean a container created using a Dockerfile such as the following:</p> <pre><code>FROM scratch </code></pre> <p>As opposed to a &quot;regular&quot; container such as the following:</p> <pre><code>FROM ubuntu </code></pre> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MaxJ345\"> /u/MaxJ345 </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1kb5bd9/what_is_an_empty_docker_container/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1kb5bd9/what_is_an_empty_docker_container/\">[comments]</a></span>",
        "id": 2561461,
        "language": null,
        "link": "https://www.reddit.com/r/docker/comments/1kb5bd9/what_is_an_empty_docker_container",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What is an empty Docker container?",
        "vote": 0
    }
]