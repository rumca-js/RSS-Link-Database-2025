[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T23:34:01.471540+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T23:06:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>All the other ones I tried all the pictures are blurred</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Confident_Low_2192\"> /u/Confident_Low_2192 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbu4z4/are_there_any_websites_that_allow_people_to/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbu4z4/are_there_any_websites_that_allow_people_to/\">[comments]</a></span>",
        "id": 2569859,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbu4z4/are_there_any_websites_that_allow_people_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are there any websites that allow people to download a deviantart artists premium content without it being blurred",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T23:34:01.194912+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T22:43:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m curious. Has anyone here ever used such a heavy back up solution that has saved your data when you had such a failure, in which a 3-2-1 solution which would have not allowed you to restore your files? We often here how 3-2-1 has saved your information, but has anyone prepared for being the .1%&#39;er and have succeeded against those odds, having suffered a catastrophic failure across a second disc/backup location or even a cloud service failure? Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/uraffuroos\"> /u/uraffuroos </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbtmqd/an_advanced_321_backup_question/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbtmqd/an_advanced_321_backup_question/\">[comments]</a></span>",
        "id": 2569858,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbtmqd/an_advanced_321_backup_question",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "An advanced 3-2-1 backup question",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T22:27:57.968451+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T22:18:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m in the market for a nas prices seems half of new for something 15 years old am I missing something? Feel better off throwing a bunch of drives in an old office pc at that rate</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/keylesschuck89\"> /u/keylesschuck89 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbt37m/ebay_bargains_or_ewaste/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbt37m/ebay_bargains_or_ewaste/\">[comments]</a></span>",
        "id": 2569541,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbt37m/ebay_bargains_or_ewaste",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ebay bargains or e-waste?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T22:27:58.128892+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T21:48:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m trying to find a free file compression tool that can handle a folder full of mixed files (like PNGs, JPGs, PDFs, etc.) and lets me specify a target size for each file \u2014 like 10MB max.</p> <p>Ideally, I want to drag in a folder, set a size limit, and have it compress each file individually to stay under that limit without too much hassle.</p> <p>Does anything like this exist? Bonus if it works on Windows or has a simple UI.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Superman557\"> /u/Superman557 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbse0l/looking_for_free_file_compression_software_that/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbse0l/looking_for_free_file_compression_software_that/\">[comments]</a></span>",
        "id": 2569542,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbse0l/looking_for_free_file_compression_software_that",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for free file compression software that lets me set a target size per file?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T22:27:58.259243+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T21:32:33+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbs0m9/any_reason_to_buy_an_external_drive_over_just/\"> <img src=\"https://a.thumbs.redditmedia.com/CJ5lM8v9W_z6UvUdQCaO_qhhxQRivSmR8vWpBAWJXd4.jpg\" alt=\"Any reason to buy an external drive over just getting an external NVME enclosure + computer drive?\" title=\"Any reason to buy an external drive over just getting an external NVME enclosure + computer drive?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Helping a friend buy a new external drive (mostly for art / graphic design) on her laptop. In the past, I&#39;ve just salvaged old HDs / SSDs and attached an adapter whenever I need USB external storage, is there any issue with this? I&#39;ve never had problems but don&#39;t wanna make a bad recommendation to my friend. See pictures attached as an example setup - this is like $145 vs $200+ for a premade external drive</p> <p><a href=\"https://preview.redd.it/h92ekvwui1ye1.png?width=540&amp;format=png&amp;auto=",
        "id": 2569543,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbs0m9/any_reason_to_buy_an_external_drive_over_just",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/CJ5lM8v9W_z6UvUdQCaO_qhhxQRivSmR8vWpBAWJXd4.jpg",
        "title": "Any reason to buy an external drive over just getting an external NVME enclosure + computer drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T21:23:17.335988+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T21:10:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I set up my NAS a while back and I just started backing stuff up. I plan to copy the files using TeraCopy to an external HDD since I mainly use Windows. That HDD will be turned off and only used when backing up.</p> <p>My question is how do I verify the files so that they don&#39;t have any silent corruption? In the unlikely event where I have to rebuild my NAS (I am using OMV + SnapRAID) from scrath, then that backup is my last copy. I want to make sure it doesn&#39;t have any corruption on it. I tried using ExactFile but it&#39;s very rudimentary, where if I add a file, or remove a file, or move a file, or update a file I have to rebuild the whole digest file, which can take days. I&#39;m looking for something very similar but can also handle incremental updates.</p> <p>Does anyone have any advice?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SfanatiK\"> /u/SfanatiK </a> <br/> <span><a href=\"https://www.reddi",
        "id": 2569066,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbrhy0/how_to_verify_backup_drives_using_checksum",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to verify backup drives using checksum?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T20:19:46.004858+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T19:41:46+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbpexr/just_received_these_seagate_30tb_drives/\"> <img src=\"https://b.thumbs.redditmedia.com/4elAS82f-s9ODtYRVt7fIMxDTVFYvDgV2V9jzCjC-fE.jpg\" alt=\"Just received these Seagate 30TB drives!\" title=\"Just received these Seagate 30TB drives!\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/41qebuuwx0ye1.png?width=2156&amp;format=png&amp;auto=webp&amp;s=8950d5b09895d9aa447894ac7465584506b0ccfc\">https://preview.redd.it/41qebuuwx0ye1.png?width=2156&amp;format=png&amp;auto=webp&amp;s=8950d5b09895d9aa447894ac7465584506b0ccfc</a></p> <p>I think I&#39;m one of the first people (normal consumer, not a business order) to successfully order and receive these 30TB Seagate drives. Pretty excited to get them\u2014now I can consolidate all my smaller hard drives onto these.</p> <p>I ordered March 3rd from Wiredzone, received them today (April 30th). Price was $540 per drive at the time of order.</p> ",
        "id": 2568655,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbpexr/just_received_these_seagate_30tb_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/4elAS82f-s9ODtYRVt7fIMxDTVFYvDgV2V9jzCjC-fE.jpg",
        "title": "Just received these Seagate 30TB drives!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T20:19:46.194879+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T19:21:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a large drive with a bunch of my favorite movies, shows, ebooks and games (all legally purchased by me). I keep this as a backup and in case I ever had to live without internet for an extended period of time (never know, amiright). </p> <p>I want to get software too. I want to prep for me needing to change my computer in the future, and possibly not having internet. I currently only use Windows. </p> <p>What should I get?</p> <p>I have: Kiwix Colibri Kodi VLV Launchbox (for games) Some .net stuff</p> <p>Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lolgreatjoke\"> /u/lolgreatjoke </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kboy9y/software_installers_i_should_hoard/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kboy9y/software_installers_i_should_hoard/\">[comments]</a></span>",
        "id": 2568656,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kboy9y/software_installers_i_should_hoard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Software / Installers I Should Hoard?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T19:13:52.344993+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T18:45:29+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbo35a/ghosthub_v12_is_out_swipebased_media_server_w/\"> <img src=\"https://preview.redd.it/saxc8a1lp0ye1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0729ebb809d312bbf7eae2451597e9c2f5b8501\" alt=\"GhostHub v1.2 is out: swipe-based media server w/ slash commands &amp; async indexing! \u2014 need feedback on transcoding for 1.3\" title=\"GhostHub v1.2 is out: swipe-based media server w/ slash commands &amp; async indexing! \u2014 need feedback on transcoding for 1.3\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Just dropped GhostHub v1.2. It\u2019s a self-hosted, mobile-first media server that lets you swipe through your folders like you\u2019re on TikTok. No accounts, no setup, just run it and share instantly. It has real-time sync, anonymous chat, and works offline too.</p> <p>This update added slash commands, improved indexing, and cleaned up some of the navigation flow.</p> <p>Right now I\u2019m planning v1.3 and need feedback",
        "id": 2568232,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbo35a/ghosthub_v12_is_out_swipebased_media_server_w",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/saxc8a1lp0ye1.jpeg?width=640&crop=smart&auto=webp&s=d0729ebb809d312bbf7eae2451597e9c2f5b8501",
        "title": "GhostHub v1.2 is out: swipe-based media server w/ slash commands & async indexing! \u2014 need feedback on transcoding for 1.3",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T19:13:52.476003+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T18:35:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I\u2019m pretty new to all of this. I just bought a new 12 tb HDD to replace my 2 TB HDD. I want clone all the contents on the 2TB HDD onto the 12 TB HDD; and some program files are included on that. I know that I\u2019ll have to expand the partition when I\u2019m done. </p> <p>I\u2019m just looking for a decent software. I already have IDrive, and they have a clone feature. Has anyone used IDrive clone, and would it do this adequately? I haven\u2019t been able to find much online in reviews of this service. I could use paragon hard disk manager if I want, but I\u2019d rather just save the 20 bucks if I already have access to a similar service. Thank you in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Dont_dreamits_over\"> /u/Dont_dreamits_over </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbnuu2/question_on_disk_cloning_and_idrive_clone/\">[link]</a></span> &#32; <span><a href=\"https://www.",
        "id": 2568233,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbnuu2/question_on_disk_cloning_and_idrive_clone",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Question on Disk Cloning and IDrive Clone",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T21:23:17.611645+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T18:22:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to follow the 3-2-1 backup rule for my photos. I currently have one copy on Google Photos, another on Google Drive, and a third on an external hard drive. Does this setup qualify as a true 3-2-1 backup? I&#39;m a bit unsure since Google Photos and Google Drive are both cloud services from the same provider. Would love to hear your thoughts!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Popular_Frosting2018\"> /u/Popular_Frosting2018 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbnj9t/do_copies_of_photos_on_google_photos_google_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbnj9t/do_copies_of_photos_on_google_photos_google_drive/\">[comments]</a></span>",
        "id": 2569067,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbnj9t/do_copies_of_photos_on_google_photos_google_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Do copies of photos on Google Photos, Google Drive, and an external hard drive count as the 3-2-1 backup method?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T18:08:23.560861+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T17:44:48+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbmm4q/remember_securom_we_did_a_deep_dive_into_gamings/\"> <img src=\"https://external-preview.redd.it/L6VXTrCRKomkGHgq_hpnxGJo92FBn42WDq62YzAWZ7o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1eee63c04a83cba3ccd080c4d1efb8ae1a9f9877\" alt=\"Remember SecuROM? We Did a Deep Dive into Gaming's Most Controversial DRM (Lawsuits, Rootkits, Bricked Drives)\" title=\"Remember SecuROM? We Did a Deep Dive into Gaming's Most Controversial DRM (Lawsuits, Rootkits, Bricked Drives)\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>If you gamed on PC, you probably encountered SecuROM. Beyond the frustrating activation limits, its history involves a major lawsuit (Spore), rootkit allegations, and even reports of damaging hardware. Find the full story here.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/raptorhunter22\"> /u/raptorhunter22 </a> <br/> <span><a href=\"https://thecybersecguru.c",
        "id": 2567645,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbmm4q/remember_securom_we_did_a_deep_dive_into_gamings",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/L6VXTrCRKomkGHgq_hpnxGJo92FBn42WDq62YzAWZ7o.jpg?width=640&crop=smart&auto=webp&s=1eee63c04a83cba3ccd080c4d1efb8ae1a9f9877",
        "title": "Remember SecuROM? We Did a Deep Dive into Gaming's Most Controversial DRM (Lawsuits, Rootkits, Bricked Drives)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T18:08:24.051076+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T17:35:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Does anyone know if you can take hard drives with data on them from a DAS and install them into a NAS without needing to wipe or otherwise lose all the data first?</p> <p>I&#39;m unsure if this is possible at all, but also wondered if it mattered whether or not in the DAS there was no RAID setup, RAID setup, or using Unraid; if any of those scenarios made a difference as to whether the hdd&#39;s could/couldn&#39;t be moved over to a NAS.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ShareGoodBeer\"> /u/ShareGoodBeer </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbmduk/move_hdds_from_das_to_nas_without_wiping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbmduk/move_hdds_from_das_to_nas_without_wiping/\">[comments]</a></span>",
        "id": 2567647,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbmduk/move_hdds_from_das_to_nas_without_wiping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Move HDD's from DAS to NAS without wiping?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T18:08:23.745831+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T17:27:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m looking for a portable SSD (1TB) for daily work use. It should be fast, compact, and reliable for backups. Water-resistant would be a bonus. I prefer brands like Lexar, SanDisk, or WD, but open to better options. Budget is not a problem, just want a solid, long-lasting product. Appreciate any suggestions</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Little_Accountant_81\"> /u/Little_Accountant_81 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbm7ay/best_portable_ssd_for_daily_use_and_backup/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbm7ay/best_portable_ssd_for_daily_use_and_backup/\">[comments]</a></span>",
        "id": 2567646,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbm7ay/best_portable_ssd_for_daily_use_and_backup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best Portable SSD for Daily Use and Backup?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T17:02:53.601997+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T16:29:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Here&#39;s the <a href=\"https://gist.github.com/tsilvs/a45206996ef77aa8c0ef0fee382d2770\">code</a>.</p> <p>Would appreciate your feedback and reviews.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tsilvs0\"> /u/tsilvs0 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbkse7/made_an_rclone_sync_systemd_service_that_runs_by/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbkse7/made_an_rclone_sync_systemd_service_that_runs_by/\">[comments]</a></span>",
        "id": 2566971,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbkse7/made_an_rclone_sync_systemd_service_that_runs_by",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Made an rclone sync systemd service that runs by a timer",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T17:02:53.254798+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T16:14:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have over 60,000 eBooks collected over the years \u2014 more than 300GB \u2014 all sitting in folders organized by author. Most of the files are named like author.title.epub, and I\u2019ve always wanted a way to actually see what I own.</p> <p>I\u2019d love to have a clean interface that shows the covers, organizes everything by author, genre, and maybe even lets me filter and export lists.</p> <p>I tried using Calibre years ago, but for most of my eBooks, it didn\u2019t pull any metadata at all \u2014 no covers, no titles \u2014 which meant I had to manually fill everything in, one by one. Unthinkable with a collection this size.</p> <p>So I\u2019m thinking about building something simple, modern, and focused only on organizing. Free for anyone who just wants to sort out their eBooks.</p> <p>Would anyone else find something like this useful?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/codfish351\"> /u/codfish351 </a> <br/> <span><a href=\"https://",
        "id": 2566970,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbkf0i/thinking_of_building_a_tool_to_organize_my",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Thinking of building a tool to organize my personal library \u2014 anyone else feel the same?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T15:57:56.326225+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T15:29:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Anyone run into this problem? I have two ORICO-9858T3 5 bay Thunderbolt 3 enclosures. These will be plugged into a Mini PC running Windows 11 Pro with two USB 4 ports.</p> <p>If I plug one into one USB4 port, it works fine. If I plug the second into the other USB 4 port, Windows 11 crashes with Bugcheck name: DRIVER_IRQL_NOT_LESS_OR_EQUAL in storahci.sys (storahci+68d8). </p> <p>If I plug one into a USB 4 port and the second one into the downstream port of the first one, Windows 11 crashes with the same error.</p> <p>In fact, the only way I can get both to work at the same time without Windows crashing is to plug a Thunderbolt 4 Hub (Either Pluggable or CalDigit Elements) into one USB 4 port and then both enclosures into the hub. That works great., but limits me to three enclosures.</p> <p>This has been reported to ORICO but I don&#39;t expect any solutions soon since it seems to be a Windows driver problem.</p> <p>If anyone has an idea, or knows of a",
        "id": 2566335,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbjbvj/windows_crash_when_daisychaining_thunderbolt",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Windows crash when daisychaining Thunderbolt enclosures",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T15:57:55.859114+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T15:04:21+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbiqj1/data_hoarding_is_more_important_than_ever/\"> <img src=\"https://external-preview.redd.it/OnwDrGHzOEylH7rrrRbYdPWeoj5Uyh6vqft3uMcMuss.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8ef6316beff58257a59d3b7d506fc9542340004e\" alt=\"Data hoarding is more important than ever\" title=\"Data hoarding is more important than ever\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Corbin_Davenport\"> /u/Corbin_Davenport </a> <br/> <span><a href=\"https://www.spacebar.news/data-hoarding-more-important-than-ever/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbiqj1/data_hoarding_is_more_important_than_ever/\">[comments]</a></span> </td></tr></table>",
        "id": 2566333,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbiqj1/data_hoarding_is_more_important_than_ever",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/OnwDrGHzOEylH7rrrRbYdPWeoj5Uyh6vqft3uMcMuss.jpg?width=640&crop=smart&auto=webp&s=8ef6316beff58257a59d3b7d506fc9542340004e",
        "title": "Data hoarding is more important than ever",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T21:23:17.984336+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T14:11:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>guys, who have Sabrent EC-DFFN, can somebody tell me, is it just cut the power, or it something like soft power off? i just want to change my seagate 22tb enclosure(cause its always like creep, and temp there is just awful) and i want to know, do i need every time to eject it from windows, or i can just turn it off from power button?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mrRoadSnake\"> /u/mrRoadSnake </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbhisk/sabrent_ecdffn/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbhisk/sabrent_ecdffn/\">[comments]</a></span>",
        "id": 2569068,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbhisk/sabrent_ecdffn",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Sabrent EC-DFFN",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T15:57:55.991345+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T14:03:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was archiving some images (posts in <a href=\"/r/vintagecomputing\">r/vintagecomputing</a>) and while doing research, found a scan of an IBM template in the <a href=\"https://www.reddit.com/r/vintagecomputing/comments/1kbgplt/1970_ibm_flowcharting_template_and_protective/\">collection of the Smithsonian Institution.</a> I noticed they had it tagged under the IIIF, the <a href=\"https://iiif.io/\">International Image Interoperability Framework.</a></p> <p>This seems like something the DataHoarder community ought to be involved in. Is anyone aware of this? It appears to be an extended metadata system intended for researchers and curators, as well as cataloguing and indexing collections of visual images. There is a large <a href=\"https://github.com/IIIF/awesome-iiif/\">GitHub collection</a> of open source tools for using the IIIF APIs. This looks amazing.</p> <p>I remember many years ago, working at a prestigious art institution, they boasted that they intend",
        "id": 2566334,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbhbqb/international_image_interoperability_framework",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "International Image Interoperability Framework",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T13:27:27.486407+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T13:14:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I\u2019m going to be replacing our NVR stack and will be getting (24tb) drives for the new system since all the old drives are only 8tb. This upgrade will leave me with 22 8TB unused drives\u2026. There is no way I\u2019ll be able to fit all 22 drives in my old gaming system as I have been doing with all my drives for years now. See my <a href=\"https://www.reddit.com/r/DataHoarder/comments/1hpsuaa/repurposed_gaming_pc\">current hoarder setup</a>. Now is the time to grow out of the gaming PC and into something a bit larger. Ideally a case that fits all the components of the current PC. I&#39;m not trying to buy a whole new system, just the case if possible. What rack mounted chassis could I get to fit over 40 drives that would replace my current gaming case? Is there any compatibility issues to look for like with motherboard fitment or something else I&#39;m not thinking about? Any advice would be greatly appreciated! </p> </div><!-- SC_ON --> &#32; submitted by &#",
        "id": 2565097,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbg6xo/rack_mounted_jbod_recommendations",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Rack mounted JBOD recommendations",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T13:27:28.040402+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T12:52:44+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbfq2e/is_this_still_acceptable_as_recertified/\"> <img src=\"https://preview.redd.it/w5wvfkdnyyxe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c437e28adf1d05fbf1e36b8b8ee40b6f8632ce9f\" alt=\"Is this still acceptable (as recertified)?\" title=\"Is this still acceptable (as recertified)?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi! I bought a recertified drive as backup of my data (EXOS X28 28TB). Is this damage still okay and does not affect the life duration? Thanks :)</p> <p>I put it in and it is not noticeable </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hungry-Wealth-6132\"> /u/Hungry-Wealth-6132 </a> <br/> <span><a href=\"https://i.redd.it/w5wvfkdnyyxe1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbfq2e/is_this_still_acceptable_as_recertified/\">[comments]</a></span> </td></tr></table>",
        "id": 2565099,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbfq2e/is_this_still_acceptable_as_recertified",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/w5wvfkdnyyxe1.jpeg?width=640&crop=smart&auto=webp&s=c437e28adf1d05fbf1e36b8b8ee40b6f8632ce9f",
        "title": "Is this still acceptable (as recertified)?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T13:27:27.617828+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T12:37:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve started using DupeGuru, but is there a way of excluding a type of file during its scans? To be specific, I don&#39;t want it to find duplicates of Premiere Pro files (PRPROJ File (.prproj)) and it would be really handy to just have it not find these. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/joseph814706\"> /u/joseph814706 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbfeuu/can_i_exclude_a_type_of_file_during_a_dupeguru/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbfeuu/can_i_exclude_a_type_of_file_during_a_dupeguru/\">[comments]</a></span>",
        "id": 2565098,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbfeuu/can_i_exclude_a_type_of_file_during_a_dupeguru",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can I exclude a type of file during a DupeGuru scan?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T12:22:12.766557+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T12:08:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Built a small experiment: one feed, no delete button. Every message costs more to post. No ads. No sorting.</p> <p>Just a linear, rising archive of digital thought \u2014 locked in place.</p> <p>Is this a kind of data preservation\u2026 or something else entirely?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/RobertHoodman\"> /u/RobertHoodman </a> <br/> <span><a href=\"https://thewall-ebac7.web.app/landing\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbetrm/the_wall/\">[comments]</a></span>",
        "id": 2564490,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbetrm/the_wall",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "// THE WALL //",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T12:22:12.898487+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T12:04:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Well my Synology Nas is dead dead.</p> <p>I ordered 2 X 22tb drives thinking a drive failed. </p> <p>Either way my d/l box is a mini PC (hp elitedesk G2) is it bad to run 2 external drives 24/7 as storage in there. I&#39;ll likely put them in a dual enclosure and run via USB c.</p> <p>I&#39;m just not sure on there life and do they ramp/spin down at all.</p> <p>I&#39;m thinking something like this <a href=\"https://www.simplecom.com.au/simplecom-se482-superspeed-usb-dual-bay-3-5-sata-hard-drive-raid-enclosure-usb-c-raid-0-1-jbod.html\">https://www.simplecom.com.au/simplecom-se482-superspeed-usb-dual-bay-3-5-sata-hard-drive-raid-enclosure-usb-c-raid-0-1-jbod.html</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Current_Inevitable43\"> /u/Current_Inevitable43 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kber66/hdd_in_external_case_instead_of_nas/\">[link]</a></span> &#32; <span><a href=\"h",
        "id": 2564491,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kber66/hdd_in_external_case_instead_of_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hdd in external case instead of Nas.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T15:57:56.603485+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T11:22:42+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbe02t/the_arctic_world_archive_can_data_last_forever/\"> <img src=\"https://external-preview.redd.it/yc8VCpiFPYI9Lf8_5l0HFdHOQ6LZiKJwRSffPKLrpqg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=54016ec51e5195c57ece40fa1ee68408d505b0ea\" alt=\"The Arctic World Archive: can data last forever?\" title=\"The Arctic World Archive: can data last forever?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi all, I&#39;m a journalist researching our growing data problem and I&#39;ve produced this documentary on the Arctic World Archive and PiqlFilm, a company which claims it can store the world&#39;s most precious data for thousands of years.</p> <p>We travelled to Svalbard in the Arctic Circle to find the Archive deep underground in a mine - the same mine as the Svalbard Seed Vault - where its keepers say the data is safe from floods, fire, and even nuclear war. </p> <p>Museums, companies and archives around the world hav",
        "id": 2566336,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbe02t/the_arctic_world_archive_can_data_last_forever",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/yc8VCpiFPYI9Lf8_5l0HFdHOQ6LZiKJwRSffPKLrpqg.jpg?width=320&crop=smart&auto=webp&s=54016ec51e5195c57ece40fa1ee68408d505b0ea",
        "title": "The Arctic World Archive: can data last forever?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T11:01:19.284743+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T09:58:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to use 3 meter long Sas cable it this ok? There is a lot of conflicting info. Sata specs allow 1m cable max, Sas up to 10m. Some people say that when I use Sas to Sata whole path from hba to HDD is treated as Sata and should be 1m max. Other say that Sas expander re-encodes signal so it should be ok.</p> <p>My setup: LSI 9207-9e HBA &gt; Sas cable 3m &gt; Adaptec 82885t Sas expander &gt; Sas to Sata breakout cable 0.5m &gt; Sata HDD.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Bladye\"> /u/Bladye </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbcok3/can_i_use_3_meter_long_sas_cable_from_hba_to/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbcok3/can_i_use_3_meter_long_sas_cable_from_hba_to/\">[comments]</a></span>",
        "id": 2563763,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbcok3/can_i_use_3_meter_long_sas_cable_from_hba_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can I use 3 meter long SAS cable from HBA to Expander?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T09:55:34.823059+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T09:44:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Slides from a surprisingly prescient and still relevant presentation in 2008 on how people archive their digital data (or don&#39;t) and how they think about it. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/didyousayboop\"> /u/didyousayboop </a> <br/> <span><a href=\"https://web.archive.org/web/20111112184253/http://www.usenix.org/events/fast08/tech/marshall.pdf\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbch4f/its_like_a_fire_you_just_have_to_move_on/\">[comments]</a></span>",
        "id": 2563323,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbch4f/its_like_a_fire_you_just_have_to_move_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "\u2018It\u2019s like a fire. You just have to move on\u2019: Rethinking personal digital archiving (Cathy Marshall, Microsoft Research, 2008)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T09:55:35.019761+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T09:27:52+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbc973/my_journey_starts_here_5tb_nvme_ssd/\"> <img src=\"https://a.thumbs.redditmedia.com/GWoxXPh4Yv5uU_2ZpgbRXCUp-omIHi102w4XjzWuxs0.jpg\" alt=\"My journey starts here - 5TB NVME SSD\" title=\"My journey starts here - 5TB NVME SSD\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Long time lurker of this sub and learnt a ton over the weeks/months (thanks all for that).</p> <p>Just wanted to share my ground zero setup to mark the start of my journey. If folks feel this is utterly useless, happy to delete the post.</p> <p>But this is where I start. I plan to assemble a stack piece by piece over time (still need to test these guys). </p> <p>Might not be a lot for many, but one has to start somewhere!</p> <p>Any advice is appreciated.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JonLivingston70\"> /u/JonLivingston70 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1kbc9",
        "id": 2563324,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbc973/my_journey_starts_here_5tb_nvme_ssd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/GWoxXPh4Yv5uU_2ZpgbRXCUp-omIHi102w4XjzWuxs0.jpg",
        "title": "My journey starts here - 5TB NVME SSD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T09:55:34.387816+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T09:08:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The author has 45 CD-Rs and DVD-Rs that are over 10 years old and the data on them is still good! Of course, this is a small sample size and we can&#39;t draw strong conclusions from just this.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/didyousayboop\"> /u/didyousayboop </a> <br/> <span><a href=\"https://blog.dshr.org/2024/08/2024-optical-media-durability-update.html\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbbzzy/some_anecdotal_data_on_cdr_and_dvdr_longevity/\">[comments]</a></span>",
        "id": 2563322,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbbzzy/some_anecdotal_data_on_cdr_and_dvdr_longevity",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Some anecdotal data on CD-R and DVD-R longevity",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T09:55:35.169449+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T08:58:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m not sure if this is too basic to ask in this sub, but I&#39;d like some guidance.</p> <p>I&#39;m running on a budget and need an external SSD for MacBook Air, which will be connected to it 24/7. I can either go the route of pre-made external SSDs, or NVMe M.2 with an enclosure.</p> <p>Right now, I&#39;m looking at Crucial X9 vs WD SN770 with an enclosure. I&#39;m not sure which one will be more reliable. I couldn&#39;t find any info on the Crucial to compare it with SN770.</p> <p>My usage will mostly be storage, regular work, music production, and maybe light video editing.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ani_107\"> /u/Ani_107 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbbv9q/premade_external_ssd_vs_nvme_enclosure/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbbv9q/premade_external_ssd_vs_nvme_enclosure/\">[comments]</a",
        "id": 2563325,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbbv9q/premade_external_ssd_vs_nvme_enclosure",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Pre-made External SSD vs. NVMe Enclosure",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T08:50:34.810923+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T07:51:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It wouldn&#39;t be a hoard without keeping excessive data, right?</p> <p>Once you&#39;ve watched a show, what do you do with it?</p> <p>Does it remain in the library taking up 3GB per episode, even though you&#39;re unlikely to rewatch that episode of Last Week Tonight, or Breaking Bad for at least the next few years?</p> <p>Do you just move it offline to a simple external hard drive, or is the pool just that big it doesn&#39;t matter?</p> <p>Besides, not every episode is available to get again once it&#39;s gone, so best to keep it just encase.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ufokid\"> /u/ufokid </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbazeo/where_do_watched_shows_go/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kbazeo/where_do_watched_shows_go/\">[comments]</a></span>",
        "id": 2562972,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kbazeo/where_do_watched_shows_go",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Where do watched shows go?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T06:40:34.807153+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T05:54:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently had a fairly insignificant drive die and I had quite a lot of content from Soundgasm on there. I&#39;ve noticed a lot of old accounts are no longer active, e.g. Angeloftemptation. There are archived copies of the actual Soundgasm page on Wayback, but the audio files don&#39;t seem to be there. I&#39;d like to rebuild this archive and make it more complete. My fault for not taking this more seriously, but oh well. Any advice on where to look, or is that all just gone now?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/StartledByCheesecake\"> /u/StartledByCheesecake </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kb9bsw/retrievingarchiving_deleted_soundgasm_posts/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kb9bsw/retrievingarchiving_deleted_soundgasm_posts/\">[comments]</a></span>",
        "id": 2562430,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kb9bsw/retrievingarchiving_deleted_soundgasm_posts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Retrieving/Archiving Deleted Soundgasm Posts",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T05:35:34.324923+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T05:13:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi Guys,</p> <p>i just got for 2x14TB WD HC530 HDD&#39;s, just unpacked them to get started, however, is there a way to test the hdd&#39;s via my Nas? It&#39;s a Ugreen 4800 Plus?</p> <p>It seems like the refurbishment process deleted all these infos, and everything is &quot;0&quot; in terms of bad sectors etc.</p> <p>I&#39;d appreciate some help to know if these hdd&#39;s are good to keep.</p> <p>Did anybody bought from this German Store:</p> <p><a href=\"https://www.jb-computer.de/komponenten-zubehoer/speicher/hdd/12011/western-digital-ultrastar-dc-hc530-14tb-3.5zoll-festplatte-sata-6gb/s-7200rpm-recertified-new-0f312\">https://www.jb-computer.de/komponenten-zubehoer/speicher/hdd/12011/western-digital-ultrastar-dc-hc530-14tb-3.5zoll-festplatte-sata-6gb/s-7200rpm-recertified-new-0f312</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DepartmentOk6440\"> /u/DepartmentOk6440 </a> <br/> <span><a href=\"https://www.re",
        "id": 2562143,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kb8ozx/rectified_hdd_testing_14tb_wd_hc530",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Rectified HDD testing? 14TB WD HC530",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T05:35:33.655261+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T04:49:13+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kb8bb0/found_these_in_a_box_while_cleaning_ill_see_if/\"> <img src=\"https://preview.redd.it/337pt33sjwxe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f3d85b0af947511007e7cd672fd744e02c0bcf7\" alt=\"Found these in a box while cleaning. I\u2019ll see if they\u2019re already available online and upload them if they aren\u2019t.\" title=\"Found these in a box while cleaning. I\u2019ll see if they\u2019re already available online and upload them if they aren\u2019t.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AxelsOG\"> /u/AxelsOG </a> <br/> <span><a href=\"https://i.redd.it/337pt33sjwxe1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kb8bb0/found_these_in_a_box_while_cleaning_ill_see_if/\">[comments]</a></span> </td></tr></table>",
        "id": 2562142,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kb8bb0/found_these_in_a_box_while_cleaning_ill_see_if",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/337pt33sjwxe1.jpeg?width=640&crop=smart&auto=webp&s=3f3d85b0af947511007e7cd672fd744e02c0bcf7",
        "title": "Found these in a box while cleaning. I\u2019ll see if they\u2019re already available online and upload them if they aren\u2019t.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T04:31:34.177308+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T03:57:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is anybody here working to archive Flickr? With the recent changes to the site (and more coming very soon) I almost expect a MySpace type situation to occur. It sucks, because flickr has a ton of images that seem to exist only on it.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/comatoseglow\"> /u/comatoseglow </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kb7gk0/plans_to_archive_flickr/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kb7gk0/plans_to_archive_flickr/\">[comments]</a></span>",
        "id": 2561825,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kb7gk0/plans_to_archive_flickr",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Plans to archive Flickr?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T04:31:34.423419+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T03:30:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, all,</p> <p>I&#39;ve done some reading on this but nothing really satisfied my situation. I got a B690 Asus mb and I used to have two disks running in raid 1 from the bios.</p> <p>I took one of them out, to move data somewhere else and my idea was to add the drive back before ever turning the PC on again. Well guess what, I forgot to add it back and moved on with my life. Now I&#39;m wondering if it is safe to just add it back and recreate the array, both disks are almost synced, minor to no data differences between them. </p> <p>Is it usually safe to just pop it back in, I have no Idea how Raid1 will handle eventual differences found. </p> <p>Thank you!</p> <p>Edit: typo</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Mr_Bille\"> /u/Mr_Bille </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kb6z5j/adding_hard_drive_back_to_raid_1_array/\">[link]</a></span> &#32; <span><a href=\"https:/",
        "id": 2561826,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kb6z5j/adding_hard_drive_back_to_raid_1_array",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Adding hard drive back to raid 1 array",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T03:25:35.202438+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T02:14:43+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1kb5jtq/just_picked_up_a_terramaster_f4424_pro_planning/\"> <img src=\"https://b.thumbs.redditmedia.com/pyv15TBnVeqVhLwb_P5kV-o1dzEJt0nPp49oPFU2t4A.jpg\" alt=\"Just picked up a TERRAMASTER F4-424 Pro \u2013 planning to run a few VMs at the office, anyone else using this model?\" title=\"Just picked up a TERRAMASTER F4-424 Pro \u2013 planning to run a few VMs at the office, anyone else using this model?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Just added the F4-424 Pro to our office setup. I\u2019ve been using the standard F4-424 here for general backups and file storage \u2014 solid performance so far.</p> <p>Decided to upgrade to the Pro version (Intel Core i3-N305 CPU, supports up to 32GB RAM)to handle some lightweight VMs. Planning to run things like Pi-hole, an internal Ubuntu Server, and maybe a couple of Docker containers to offload some tasks from workstations.</p> <p>Anyone here using TERRAMASTER for virtualization or s",
        "id": 2561645,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kb5jtq/just_picked_up_a_terramaster_f4424_pro_planning",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/pyv15TBnVeqVhLwb_P5kV-o1dzEJt0nPp49oPFU2t4A.jpg",
        "title": "Just picked up a TERRAMASTER F4-424 Pro \u2013 planning to run a few VMs at the office, anyone else using this model?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T03:25:35.557999+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T01:22:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recentally got a good deal on a Dell Optiplex 7050 MT on ebay. I plan on using for a home server, NAS, but it only has 2 hard drive bays. I would like to add more drives and am wondering what my best option for this would be to add more drives (4-5). Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Graydm16\"> /u/Graydm16 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kb4j7m/thoughts_on_adding_more_drives_to_a_dell_optiplex/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1kb4j7m/thoughts_on_adding_more_drives_to_a_dell_optiplex/\">[comments]</a></span>",
        "id": 2561646,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kb4j7m/thoughts_on_adding_more_drives_to_a_dell_optiplex",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Thoughts on Adding More Drives to a Dell Optiplex 7050 MT",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-04-30T01:14:01.928787+00:00",
        "date_dead_since": null,
        "date_published": "2025-04-30T01:13:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I currently have a file server running Windows 10/drivepool (8+ drives pooled together, approx 60TB in use, no RAID), and with support ending this October, I would like to upgrade the system to Windows 11. </p> <p>Unfortunately, the cpu does not support TPM (legacy AMD emachine lol), so I will likely completely replace the cpu/mobo with my current desktop (server could use the upgrade anyway). I think I&#39;m over 60% capacity on storage, so starting a smaller pool with the new system might not be feasible?</p> <p>What would be the best way to go about migrating my data from the old drivepool with a fresh install of Windows 11/drivepool on the newer hardware?</p> <p>I know there are workarounds to getting Windows 11 to run on an older cpu, but I&#39;d rather move my current desktop to server duties to open up more upgrade options all around. (9700k w/ 2070 Super built at the start of COVID). </p> <p>Maybe purchase a couple new larger hard drives to st",
        "id": 2561135,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1kb4cj9/upgrading_file_server_windowsdrivepool",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Upgrading file server. (Windows/Drivepool)",
        "vote": 0
    }
]