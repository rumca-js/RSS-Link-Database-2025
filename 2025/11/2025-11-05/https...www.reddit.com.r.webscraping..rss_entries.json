[
    {
        "age": null,
        "album": "",
        "author": "/u/Ok-Sky6805",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-05T21:35:07.718323+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-05T20:59:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I had been working on a selenium script that downloads a bunch of pdfs from an open site. During the process, the site would usually catch me almost always after downloading 20 pdfs exactly, irrespective of how slow I do them (so def. not rate limiting problems). Once caught, I had to solve a captcha and I could be on my way again to scrape the next 20, until the next captcha.</p> <p>The captcha text was simple enough, so I would just download that image and pass it to an LLM via an API call to solve and give the answer. What would happen then is, when I viewed this as an observer, the LLMs output would NOT match what&#39;s shown to ME as the captcha, but I would still be through</p> <p>I made sure that the captcha actually works, entering the wrong digits shouldn&#39;t and didn&#39;t let me through, so I am sure the LLM is giving the right answer (since I did get through), but at the same time, the image I am seeing didn&#39;t match with the text bei",
        "id": 3994628,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1opf121/weird_behaviour_while_automating_simple_captcha",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weird behaviour while automating simple captcha solves",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Imaginary_Complex910",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-05T22:36:23.607062+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-05T15:11:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is it possible to scrape this cars stuff?</p> <p>:Y </p> <p>For my (europoor sigh) student uni project, I need to make statistical analysis to evaluate the impact of several metrics on car price e.g. impact of year of release, kilometers count, diesel/electrical engine (and more lol)</p> <p>I want to scrape all accessible data from this french website:<br/> <a href=\"https://www.lacentrale.fr/\">https://www.lacentrale.fr/</a></p> <p>\u2014 but looks like protected by bot mitigation stuff, getting ClientError/403 all the time \u2014</p> <p>Any idea how to do it?</p> <p>I&#39;m more a R user \u2014 not crazy dev \u2014 I can a bit python but why not no code tool</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Imaginary_Complex910\"> /u/Imaginary_Complex910 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1op5fuk/how_can_i_scrape_lacentrale_fr_website/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r",
        "id": 3995144,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1op5fuk/how_can_i_scrape_lacentrale_fr_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can I scrape LaCentrale FR website?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/meowed_at",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-05T11:59:24.033922+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-05T11:20:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,<br/> I&#39;m building a recommendation algorithm for Reddit as my university project. the ML side is my concern (which will scrape data from reddit), but the UI is just a placeholder (not graded, and I have zero time to design from scratch). so I was Looking for the closest open-source Reddit UI clone that&#39;s:</p> <ul> <li>based on new not old Reddit style (preferably card based).</li> <li>Easy to integrate (HTML/CSS/JS or simple React/Next.js, I do prefer if it fetches JSON for posts, but I can still make it work</li> <li>Minimal frontend setup (I dont need auth nor backend; I can hook it to my own API for ranked posts, and I do not need every setting to work, just the Recommendation Algorithm, its a uni project not an actual app).</li> </ul> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/meowed_at\"> /u/meowed_at </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1op07fv/most_r",
        "id": 3989765,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1op07fv/most_realistic_open_source_reddit_ui_clone_for_my",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Most Realistic Open Source Reddit UI Clone for my Uni Project?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Calew_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-05T10:58:28.801811+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-05T10:08:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking for a backend dev who loves solving challenging problems and working with large-scale data.</p> <p>Skills we need: \u2022 Web scraping &amp; large-scale data collection (public YouTube data) \u2022 YouTube Data API / Google API integration \u2022 Python or Node.js backend development \u2022 Structuring &amp; parsing JSON, CSV, etc. \u2022 Database management (MongoDB / PostgreSQL / Firebase) \u2022 Proxy management &amp; handling rate limits \u2022 Automation pipelines &amp; scripting \u2022 Data analysis &amp; channel categorization logic</p> <p>Bonus points: \u2022 Cloud deployment (AWS / GCP) \u2022 Understanding YouTube SEO &amp; algorithm patterns \u2022 Building dashboards or analytics tools</p> <p>What you\u2019ll do: Build tools that help creators discover hidden opportunities and make smarter content decisions.</p> <p>\ud83d\udcbb Fully remote / flexible \ud83d\udce9 DM with portfolio or past projects related to large-scale data, scraping, or analytics</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"http",
        "id": 3989252,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ooz0v4/hiring_backend_developer_youtube_niche_finder_500",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[Hiring] Backend Developer \u2013 YouTube Niche Finder $500",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheCompMann",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-05T09:55:13.017873+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-05T08:55:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So basically, I am trying to capture mobile api endpoints on my android phone(V16) samsung, unrooted, so I decided to patch the apk using objection and I also used the apk-mitm library for ease. I had to manually fix some stuff of the keychain and trust things, but it finally worked and I was able to load the app and view stuff.</p> <p>The problem is that under certain endpoints, for example changing settings, or signing up, the app results in a 400 status code. Ive tried different methods like checking the smali code, analyzing the apk using jadx, and ive gotten to the point where the endpoint loads but it gives a different response than if I were to use the original app gotten from the google play store. What do you guys think is the problem here? Ive seen some things in jadx such as google play api integrety checks, ive tried skipping those. But I am not really sure what exactly could be the problem here.</p> <p>For context, I am using an unrooted ",
        "id": 3988861,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ooxvwy/app_detecting_ssl_pinning_bypasses_disallows",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "App detecting ssl pinning bypasses, disallows certain endpoints",
        "vote": 0
    }
]