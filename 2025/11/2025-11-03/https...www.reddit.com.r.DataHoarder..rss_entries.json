[
    {
        "age": null,
        "album": "",
        "author": "/u/Jaydarealone",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T23:51:05.221920+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T23:23:50+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1onrkk5/looking_for_anime_recordings_from_the/\"> <img src=\"https://b.thumbs.redditmedia.com/XI5hjLv3L-euDnhfJwTkAZRa4p6eVEOfOWmvzwwvtnM.jpg\" alt=\"Looking for anime recordings from the international channel\" title=\"Looking for anime recordings from the international channel\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>For context it&#39;s a tv channel that existed from the late 90s to 2005ish that played lots of media from European/Asian countries a huge one being anime which was usually always English subbed with Japanese audio,</p> <p>They had a lot of good stuff hell they even had all of dragon ball z and dragon ball gt on there way before the toonami premiere!</p> <p>Anyways I used to have personal recordings of this channel mostly of some of the anime movies they played which they had a lot of great ova&#39;s on there and a few tapes of I want to say about a dozen or so episodes of dbz arcs that weren&",
        "id": 3976194,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1onrkk5/looking_for_anime_recordings_from_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/XI5hjLv3L-euDnhfJwTkAZRa4p6eVEOfOWmvzwwvtnM.jpg",
        "title": "Looking for anime recordings from the international channel",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Lightweaver123",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T22:50:25.488297+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T21:44:26+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1onp1qe/ransomware_encryption_vs_standard_encoding_speed/\"> <img src=\"https://preview.redd.it/gojfjdpx34zf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=adc9aacf136f6a315afa3d99ae6c56a425dd4bef\" alt=\"Ransomware encryption vs. standard encoding speed (Veracrypt, Diskcryptor)\" title=\"Ransomware encryption vs. standard encoding speed (Veracrypt, Diskcryptor)\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>How come ransomware encryption is blazingly swift, while legally encoding files for security reasons utilizing conventional software requires literal days worth of time? The argument goes that ordinary encryption &#39;randomizes&#39; data thoroughly to obscure its nature and content, whereas malware only scrambles sections of each file to make it unprocessible while the majority of data remains unaffected. So is this partial encryption method trivial to breach then? \u2013 By no means! What&#39;s the effective ",
        "id": 3975820,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1onp1qe/ransomware_encryption_vs_standard_encoding_speed",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/gojfjdpx34zf1.jpeg?width=640&crop=smart&auto=webp&s=adc9aacf136f6a315afa3d99ae6c56a425dd4bef",
        "title": "Ransomware encryption vs. standard encoding speed (Veracrypt, Diskcryptor)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AdUnited1943",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T22:50:26.122103+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T21:09:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Segate has a ironwolf pro 14tb 5400rpm hd for 230</p> <p>Is this a good deal or is the price because there a problem with the drive.</p> <p>I will be us the for pc built nas to store my movie collection. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AdUnited1943\"> /u/AdUnited1943 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ono4c8/229_for_14tb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ono4c8/229_for_14tb/\">[comments]</a></span>",
        "id": 3975821,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ono4c8/229_for_14tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "229 for 14tb",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/abcbibi",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T20:48:34.411061+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T20:25:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been using WFdownloader for sometime now. And while with a few sites it does name the files as &#39;[Date] title by user&#39; some sites do not get the same treatment. I&#39;ve been looking for a way to code it using the programmable mode, but I don&#39;t know how to modify it to name the files how I want to, I know the bare minimum of html and JavaScript. No tutorial seems to be helping as well.</p> <p>Can anyone help or give me some tips?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/abcbibi\"> /u/abcbibi </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1onmwy4/how_to_get_wfdownloader_to_add_upload_date_to/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1onmwy4/how_to_get_wfdownloader_to_add_upload_date_to/\">[comments]</a></span>",
        "id": 3974929,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1onmwy4/how_to_get_wfdownloader_to_add_upload_date_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to get WFdownloader to add upload date to file names",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/thebwack",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T20:48:34.556117+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T20:20:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ll try to keep this short as possible.</p> <p>Current setup about 7 years worth of video footage and raw photos for our creative agency:</p> <ol> <li>70TB Truenas Server - 20x 8TB 12gb SAS drives in mirrored Vdevs - this is what we work off of. It&#39;s pretty dang fast over 10Gbs network (40Gbs trunks to switches). </li> </ol> <p>This routinely syncs via FreeFileSync (update left to right with database for changes) to:</p> <ol> <li>320TB Unraid Server - 24x 16TB EXOS drives with 2 as Parity that is on site. This is basically an ever growing duplicate and archive. </li> </ol> <p>When the 70TB server is getting near full I will go through and purge old projects and because it is &quot;left to right&quot; only I still have archival on the 320TB server.</p> <p>I KNOW THIS IS NOT A VERY SAFE SYSTEM AS OF TODAY but it is better than nothing (nervous &quot;hehe&quot;)</p> <ol> <li>I\u2019m currently waiting on drives to ship and have pretty much everything",
        "id": 3974930,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1onms8o/deploying_300tb_offsite_mirror_truenas_and_unraid",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Deploying 300TB offsite mirror. Truenas and Unraid questions - I currently use both.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Silent-OCN",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T20:48:34.222450+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T19:48:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all</p> <p>I\u2019m hoping this is a fairly simple question. I have a 4TB ssd with data on like photos etc. I have another 4TB drive. I want to set it so that I have a backup of the first drive and then if possible it auto updates regularly with just new data, so it\u2019s not constantly backing up the whole 4TB as if it\u2019s new data. </p> <p>Is this possible? I wasn\u2019t sure if windows backup or file history were any good so I just copied the entire drive file by file but I want to set it automatically going forward. </p> <p>Thanks for any insight. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Silent-OCN\"> /u/Silent-OCN </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1onlwtp/can_anyone_recommend_the_best_free_software_to/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1onlwtp/can_anyone_recommend_the_best_free_software_to/\">[comments]</a></span>",
        "id": 3974928,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1onlwtp/can_anyone_recommend_the_best_free_software_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can anyone recommend the best free software to auto backup only new data from one SSS to another please?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/RedneckSasquatch69",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T20:48:34.840665+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T19:15:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>One of my favorite childhood shows, Code Lyoko, is only available on YouTube in present day. Physical media for it is rare/doesn&#39;t exist.</p> <p>My goal is to rip the entire series off of YouTube and store it on an SSD, and then play the files back through my PS3 to my CRT in native 4:3. </p> <p>However, the YouTube videos are in 16:9 with black bars on each side. </p> <p>How do I remove the black bars and have it play natively in 4:3? Anyone know of any good tools to accomplish my goal with? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/RedneckSasquatch69\"> /u/RedneckSasquatch69 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1onl0ec/code_lyoko/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1onl0ec/code_lyoko/\">[comments]</a></span>",
        "id": 3974931,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1onl0ec/code_lyoko",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Code Lyoko",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/unquietwiki",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T18:46:54.227856+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T18:39:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.youtube.com/watch?v=v32gdnhAlFI\">&quot;My channel is getting terminated&quot; video</a></p> <p>Enderman posts stuff regarding various Windows errata and whatnot. His account got erroneously linked with some Japanese YouTuber with copyright strikes, so now he&#39;s had to file an appeal, else the content might disappear.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/unquietwiki\"> /u/unquietwiki </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1onk1n8/enderman_on_youtube_is_getting_removed_soon/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1onk1n8/enderman_on_youtube_is_getting_removed_soon/\">[comments]</a></span>",
        "id": 3973979,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1onk1n8/enderman_on_youtube_is_getting_removed_soon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "\"Enderman\" on YouTube is getting removed soon",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Factemius",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T18:46:54.062043+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T18:34:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1onjvx9/for_the_datacurious_micro_sd_to_sata_adapter/\"> <img src=\"https://preview.redd.it/3h37hlt063zf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d7f21b26c2024ac3478c67b72271ed0db46c199\" alt=\"For the data-curious: Micro SD to SATA adapter\" title=\"For the data-curious: Micro SD to SATA adapter\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Factemius\"> /u/Factemius </a> <br/> <span><a href=\"https://i.redd.it/3h37hlt063zf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1onjvx9/for_the_datacurious_micro_sd_to_sata_adapter/\">[comments]</a></span> </td></tr></table>",
        "id": 3973978,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1onjvx9/for_the_datacurious_micro_sd_to_sata_adapter",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/3h37hlt063zf1.jpeg?width=320&crop=smart&auto=webp&s=9d7f21b26c2024ac3478c67b72271ed0db46c199",
        "title": "For the data-curious: Micro SD to SATA adapter",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/pm_your_beats",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T18:46:54.316086+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T18:03:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am quite new to NAS building and network setup, and could use some advice from those more experienced in this field than me.</p> <p>I recently setup a NAS using an old pc case and mobo I had lying around, with TrueNAS Scale and 4x4 tb of storage in a RAID array. Long story short, I ran out of storage space very quickly. Probably should have seen that coming. I found a decent deal on 12tb drives on Newegg, and bought two more to add to the array, thinking I could just pop them right in. But after speaking to a friend of mine, it seems like having drives of different sizes is not going to work. </p> <p>Ideally, I&#39;d like to add as much space as possible to the existing RAID array, but failing that what other options are there?</p> <p>In your opinion, what would be the best way to proceed?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/pm_your_beats\"> /u/pm_your_beats </a> <br/> <span><a href=\"https://www.redd",
        "id": 3973980,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1onj0yq/ideal_configuration_of_nas_storage_using_hdds_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ideal Configuration of NAS Storage (Using HDDs of Vastly Different Sizes)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/bujbuj1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T16:43:39.926480+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T15:54:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys we are trying to upgrade our nas for our small business without nbuying a whole new system. </p> <p>We currently have a qnap tvs-x72XT nas with 6x hdds - we want it to be silent and use nvme or sata ssd drives - can we just switch all the drives to sata with some sort of adapter ? and run 6x sata drives or nvme drives like that?</p> <p>would we see speed improvements?</p> <p>many thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/bujbuj1\"> /u/bujbuj1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1onffxs/question_on_switching_out_disk_drives_to_ssds_on/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1onffxs/question_on_switching_out_disk_drives_to_ssds_on/\">[comments]</a></span>",
        "id": 3972794,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1onffxs/question_on_switching_out_disk_drives_to_ssds_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Question on switching out disk drives to ssds on a Qnap - TVS x72xt",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/vii_4u0",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T16:43:40.181330+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T14:26:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>As an archiver, I&#39;ve barely seen any tools that can be used for TikTok. Sure theres stuff like myfaveTT or TikWM but I really need stuff that give statistics and stuff automatically since these are manual. Maybe some kind of monitoring tool on accounts like what SocialBlade does, and yes, I know SB has some kind of TikTok monitoring system thats the same as YouTube but its pretty limited on TikTok let alone a free service.</p> <p>Once again, I&#39;m looking for an automatic TikTok archiving tool that is preferably automatic. If such thing doesn&#39;t exist, I can&#39;t do anything about that.. Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/vii_4u0\"> /u/vii_4u0 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ond5g2/any_archiving_tools_for_tiktok/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ond5g2/any_archiving_tools_for_tiktok/\">[comme",
        "id": 3972795,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ond5g2/any_archiving_tools_for_tiktok",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any archiving tools for TikTok",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LaundryMan2008",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T14:41:58.642591+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T14:18:02+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1oncxo6/in_case_anyone_missed_the_3d_model_for_the_ibm_hh/\"> <img src=\"https://a.thumbs.redditmedia.com/NXREn350xry5uDDiy1CfOfCEeYPw0hQj_wPc67zlc24.jpg\" alt=\"In case anyone missed the 3D model for the IBM HH bezel\" title=\"In case anyone missed the 3D model for the IBM HH bezel\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Here it is, I have made the button separately printable so you can make it any color you like and added a fancy version if you want a decorative bezel</p> <p>Ideally printed in PETG as the drives get very hot</p> <p>Model: <a href=\"https://www.printables.com/model/1465475-ibm-lto-half-height-tape-drive-bezel\">https://www.printables.com/model/1465475-ibm-lto-half-height-tape-drive-bezel</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LaundryMan2008\"> /u/LaundryMan2008 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1oncxo6\">[link]</a></spa",
        "id": 3971653,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1oncxo6/in_case_anyone_missed_the_3d_model_for_the_ibm_hh",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/NXREn350xry5uDDiy1CfOfCEeYPw0hQj_wPc67zlc24.jpg",
        "title": "In case anyone missed the 3D model for the IBM HH bezel",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NotAttractedToCats",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T14:41:58.778537+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T14:01:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>I am currently in the process of upgrading my NAS. So far I&#39;ve used two 8TiB Iron Wolf HDDs in RAID1 and I am planning on using TrueNAS with ZFS for my new NAS.</p> <p>For this, I am going to re-use both old HDDs plus some newly ordered HDDs for the parity. Now, I could either buy one new HDD and use those three HDDs in a RAIDZ1 setup or I could buy two used HDDs for the same price and put those 4 drives in a RAIDZ2 setup.</p> <p>I hope some of you could advice me which of those two setups is preferable regarding data security. Before someone asks, I am well aware that RAID is not a backup strategy, but this question is really only about which of those two setups is preferable.</p> <p>Thanks in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NotAttractedToCats\"> /u/NotAttractedToCats </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1oncjge/zfs_should_i_us",
        "id": 3971654,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1oncjge/zfs_should_i_use_2_used_1_new_hdd_in_raidz1_or_4",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "ZFS: Should I use 2 used + 1 new HDD in RAIDZ1 or 4 used HDDs in RAIDZ2 (ZFS)?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SuperbCelebration223",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T16:43:40.506171+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T12:38:02+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1onalx3/tool_for_archiving_files_from_telegram_channels/\"> <img src=\"https://external-preview.redd.it/BRsc1bZ5k5RwQ8dh0NNej-FHBkaQs6upFtXuhKZSPgI.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a13915da565f6452fe52fb471c0f311550ed4e05\" alt=\"Tool for archiving files from Telegram channels \u2014 Telegram File Downloader\" title=\"Tool for archiving files from Telegram channels \u2014 Telegram File Downloader\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi data hoarder friends, </p> <p>Here\u2019s a tool that might interest you: <strong>Telegram File Downloader</strong>. </p> <p><strong>What it does:</strong></p> <ul> <li>Connects to Telegram channels you have access to</li> <li>Downloads files shared in those channels (images, docs, videos\u2026)</li> <li>Lets you filter by file type and the number of files you wish to download. </li> </ul> <p><strong>Why I built it for hoarding:</strong> In many communities, large amounts of c",
        "id": 3972797,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1onalx3/tool_for_archiving_files_from_telegram_channels",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/BRsc1bZ5k5RwQ8dh0NNej-FHBkaQs6upFtXuhKZSPgI.png?width=640&crop=smart&auto=webp&s=a13915da565f6452fe52fb471c0f311550ed4e05",
        "title": "Tool for archiving files from Telegram channels \u2014 Telegram File Downloader",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Dunadan-F",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T16:43:40.931071+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T10:59:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all</p> <p>Does anybody have Terramaster D4-320 connected to minipc with Truenas and is using it with ZFS? RaidZ1 or RaidZ2?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Dunadan-F\"> /u/Dunadan-F </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on8raj/terramaster_d4320_with_truenas_zfs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on8raj/terramaster_d4320_with_truenas_zfs/\">[comments]</a></span>",
        "id": 3972799,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on8raj/terramaster_d4320_with_truenas_zfs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Terramaster D4-320 with Truenas (ZFS)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fantastic-Hair1554",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T11:36:08.398882+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T10:56:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>For some reason I cannot edit the Metadata details no matter how much I click. Really need a solution because I\u2019ve been needing to sort my files properly for weeks.</p> <p>Edit: It only works for JPG files but not my DNG or MOV files?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Fantastic-Hair1554\"> /u/Fantastic-Hair1554 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on8pwk/cant_name_metadata_details/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on8pwk/cant_name_metadata_details/\">[comments]</a></span>",
        "id": 3970269,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on8pwk/cant_name_metadata_details",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can\u2019t name Metadata details?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/OpenApartment1246",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T16:43:41.252494+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T09:55:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Bonjour \u00e0 tous,</p> <p>Je d\u00e9veloppe une application mobile <em>(Expo / React Native + backend Flask)</em> o\u00f9 il est affich\u00e9 les prix des stations carburants.</p> <p>Je consomme d\u00e9j\u00e0 le <strong>jeu de donn\u00e9es officiel</strong> <em>Prix des carburants en temps r\u00e9el</em> disponible sur <a href=\"http://data.gouv.fr/\"><em>data.gouv.fr</em></a>, qui fournit les <strong>identifiants, adresses, coordonn\u00e9es GPS et prix</strong>.</p> <p><strong>Probl\u00e8me :</strong> ce flux <strong>ne contient pas syst\u00e9matiquement le nom commercial (enseigne)</strong> des stations (ex : TotalEnergies, Leclerc, Intermarch\u00e9, Carrefour Market\u2026).</p> <p>Je cherche une <strong>solution l\u00e9gale et durable</strong>, sans scraping, pour <strong>associer chaque station \u00e0 son enseigne</strong>.<br/> Le but est d\u2019afficher dans l\u2019application :</p> <ul> <li>le <strong>nom de la station</strong>,</li> <li>son <strong>adresse compl\u00e8te</strong>,</li> <li>les <strong>prix actualis\u00e9s</strong> des c",
        "id": 3972800,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on7q53/aide_r\u00e9cup\u00e9ration_des_noms_commerciaux_enseignes",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[Aide] R\u00e9cup\u00e9ration des noms commerciaux (enseignes) des stations-service \u2014 sans scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/manzurfahim",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T09:32:54.050325+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T08:59:52+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1on6vtb/is_anyone_downloading_the_presidential_archives/\"> <img src=\"https://preview.redd.it/c7mr2w3db0zf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=676ca72d6eb52f94830684f8cc49e04f6b3c73ec\" alt=\"Is anyone downloading the presidential archives?\" title=\"Is anyone downloading the presidential archives?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Some of the presidential archives are there, rest will become available soon. Just wondering if anyone is going to hoard them?</p> <p><a href=\"https://sciop.net/datasets/\">https://sciop.net/datasets/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/manzurfahim\"> /u/manzurfahim </a> <br/> <span><a href=\"https://i.redd.it/c7mr2w3db0zf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on6vtb/is_anyone_downloading_the_presidential_archives/\">[comments]</a></span> </td></tr></tab",
        "id": 3969579,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on6vtb/is_anyone_downloading_the_presidential_archives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/c7mr2w3db0zf1.jpeg?width=640&crop=smart&auto=webp&s=676ca72d6eb52f94830684f8cc49e04f6b3c73ec",
        "title": "Is anyone downloading the presidential archives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Funtime60",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T16:43:41.491154+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T08:42:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking for a way to span an SSD with a HDD that leverages the performance difference of the two media like a cache drive. i.e. small, frequent files would be written to the SSD while old, stale, or large files would be written/moved to the HDD. Essentially using the SSD as a cache without losing any of its capacity.</p> <p>I can&#39;t seem to find what I&#39;m looking for on Google. Is this fundamentally impossible/impractical or just not desired and thus not developed? Is there another option I didn&#39;t think of?</p> <p>p.s. please let me know if there&#39;s a better place to ask this.</p> <p>Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Funtime60\"> /u/Funtime60 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on6mhv/spanned_volume_with_prioritizationcache/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on6mhv/spanned_volume_wit",
        "id": 3972802,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on6mhv/spanned_volume_with_prioritizationcache",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Spanned Volume with prioritization/cache?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/thegameksk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T07:30:33.185266+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T06:58:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The manual says to use the current rails from the 4u. They dont go in because of the front lip or tab to remove the original bay. The screw holes also dont lineup between the dock and the 4u case. Any advice?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/thegameksk\"> /u/thegameksk </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on52de/installing_rosewell_hot_swap_bay_into_the/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on52de/installing_rosewell_hot_swap_bay_into_the/\">[comments]</a></span>",
        "id": 3969069,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on52de/installing_rosewell_hot_swap_bay_into_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Installing rosewell hot swap bay into the rosewill 4u case",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Rare_Squash93",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T07:30:32.465273+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T06:38:35+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1on4quw/send_large_files_anywhere_with_this_opensource/\"> <img src=\"https://preview.redd.it/ngsgvha7mzyf1.gif?width=640&amp;crop=smart&amp;s=872bd881024c580f4be2b32537228aebc91682b7\" alt=\"Send large files anywhere with this open-source private file sharing cross-platform desktop application - Supports CLI endpoint\" title=\"Send large files anywhere with this open-source private file sharing cross-platform desktop application - Supports CLI endpoint\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I built a free and open-source file sharing application for the ordinary people that respects their privacy. </p> <p><a href=\"https://github.com/tonyantony300/alt-sendme\"><strong>https://github.com/tonyantony300/alt-sendme</strong></a> </p> <p>It&#39;s a simple desktop application that lets you connect to the other person directly and share files without storing it in intermediary servers. </p> <p>Send f",
        "id": 3969068,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on4quw/send_large_files_anywhere_with_this_opensource",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ngsgvha7mzyf1.gif?width=640&crop=smart&s=872bd881024c580f4be2b32537228aebc91682b7",
        "title": "Send large files anywhere with this open-source private file sharing cross-platform desktop application - Supports CLI endpoint",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Michal_4331",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T07:30:33.543752+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T06:33:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, I am trying to download 2 very specific spotify pocasts that only have sound. I have already tried spotDl and doubledouble and some other website based downloaders, but with no luck. Can someone please give me some advice? Here is one of the podcasts if it helps:</p> <p><a href=\"https://spotify.link/OUR5r6diZXb\">https://spotify.link/OUR5r6diZXb</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Michal_4331\"> /u/Michal_4331 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on4o7w/need_some_help_with_specific_podcasts/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on4o7w/need_some_help_with_specific_podcasts/\">[comments]</a></span>",
        "id": 3969070,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on4o7w/need_some_help_with_specific_podcasts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need some help with specific podcasts",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Rare_Squash93",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T06:29:52.483561+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T06:11:14+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1on4bej/transfer_large_files_in_private_with_ease_works/\"> <img src=\"https://preview.redd.it/4tfzgdeq1oyf1.gif?width=640&amp;crop=smart&amp;s=0c91bac7b9edcdd1ae19648e0e336889e1e81bbc\" alt=\"Transfer large files in private with ease works with CLI also\" title=\"Transfer large files in private with ease works with CLI also\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Rare_Squash93\"> /u/Rare_Squash93 </a> <br/> <span><a href=\"https://i.redd.it/4tfzgdeq1oyf1.gif\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on4bej/transfer_large_files_in_private_with_ease_works/\">[comments]</a></span> </td></tr></table>",
        "id": 3968792,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on4bej/transfer_large_files_in_private_with_ease_works",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/4tfzgdeq1oyf1.gif?width=640&crop=smart&s=0c91bac7b9edcdd1ae19648e0e336889e1e81bbc",
        "title": "Transfer large files in private with ease works with CLI also",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Eko_Mister",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T06:29:52.910002+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T05:43:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have several WD My Passports and other similarly sized portable hard drives that can&#39;t be shucked. Does anyone know of a cage or rack or enclosure or something that I could put them all into?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Eko_Mister\"> /u/Eko_Mister </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on3uh4/enclosurerack_for_portable_hdds/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on3uh4/enclosurerack_for_portable_hdds/\">[comments]</a></span>",
        "id": 3968793,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on3uh4/enclosurerack_for_portable_hdds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Enclosure/Rack for Portable HDDs?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/staline123213",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T05:29:12.454879+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T04:59:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>my dumbass bought an Optane M10 16GB for cheap like 2 USD and I formatted it in Windows for trying to use it as a fast Windows installer drive, long story short it is now not recognized by Windows or anything else. Ordered a PCIe to NVMe and it did got recognized by Intel MAS tool CLI and showed &quot;disable logical state&quot; and using the Intel MAS GUI it said degraded SSD at 20% health which is not true since before I formated it, it still show 100%. Under Linux it did showed up using lspci but I am unable to do anything with it.</p> <p>Does anyone know how can I revive it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/staline123213\"> /u/staline123213 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on33i1/fyi_do_not_use_intel_optane_m10_with_any_usb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on33i1/fyi_do_not_use_intel_optane_m10_with_an",
        "id": 3968576,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on33i1/fyi_do_not_use_intel_optane_m10_with_any_usb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "FYI: DO NOT USE Intel Optane M10 with any USB enclosure. Now unable to use the Optane.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SuperDan_x",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T05:29:12.240365+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T04:32:43+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1on2mg3/its_a_modest_platter_collection_who_else_has_one/\"> <img src=\"https://preview.redd.it/ntkxumvezyyf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f9e98f710e669696acdff08159e883ac02268d9d\" alt=\"It's a modest platter collection. Who else has one?\" title=\"It's a modest platter collection. Who else has one?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hobbyist data hoarder here. I&#39;ve been collecting these for years! I have a collection of the magnets to go with this. Dude for scale </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SuperDan_x\"> /u/SuperDan_x </a> <br/> <span><a href=\"https://i.redd.it/ntkxumvezyyf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on2mg3/its_a_modest_platter_collection_who_else_has_one/\">[comments]</a></span> </td></tr></table>",
        "id": 3968575,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on2mg3/its_a_modest_platter_collection_who_else_has_one",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ntkxumvezyyf1.jpeg?width=640&crop=smart&auto=webp&s=f9e98f710e669696acdff08159e883ac02268d9d",
        "title": "It's a modest platter collection. Who else has one?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/looklook876",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T04:28:37.826380+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T04:15:25+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1on2awt/hard_drive/\"> <img src=\"https://preview.redd.it/3n8rs70twyyf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d483fb3e382d22ecdc7bc7a2b6b8647a063960b7\" alt=\"Hard drive\" title=\"Hard drive\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Can I just connect this in my desktop like any other hard drive?</p> <p>Came from an old TV box. Has probably never been used.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/looklook876\"> /u/looklook876 </a> <br/> <span><a href=\"https://i.redd.it/3n8rs70twyyf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on2awt/hard_drive/\">[comments]</a></span> </td></tr></table>",
        "id": 3968357,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on2awt/hard_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/3n8rs70twyyf1.jpeg?width=640&crop=smart&auto=webp&s=d483fb3e382d22ecdc7bc7a2b6b8647a063960b7",
        "title": "Hard drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jpchen1224",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T05:29:12.785546+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T03:21:29+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1on194m/qsan_xn4_review_unified_storage_that_outperforms/\"> <img src=\"https://external-preview.redd.it/7w8u5qkuSbqipgQ0Xn_JAG18TYCY6K7zaruur0AJPhM.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=66e5aca47a1a3121d32a74cefba61f7889c6bcaa\" alt=\"QSAN XN4 Review: Unified Storage That Outperforms Expectations\" title=\"QSAN XN4 Review: Unified Storage That Outperforms Expectations\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jpchen1224\"> /u/jpchen1224 </a> <br/> <span><a href=\"https://youtube.com/watch?v=9a5sNs3BNu0&amp;si=dBsHu0A51wZRgeUB\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on194m/qsan_xn4_review_unified_storage_that_outperforms/\">[comments]</a></span> </td></tr></table>",
        "id": 3968577,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on194m/qsan_xn4_review_unified_storage_that_outperforms",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/7w8u5qkuSbqipgQ0Xn_JAG18TYCY6K7zaruur0AJPhM.jpeg?width=320&crop=smart&auto=webp&s=66e5aca47a1a3121d32a74cefba61f7889c6bcaa",
        "title": "QSAN XN4 Review: Unified Storage That Outperforms Expectations",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/riv777",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T05:29:13.029903+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T02:58:14+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1on0scc/hpe_apollo_4510_gen10_did_i_waste_100/\"> <img src=\"https://b.thumbs.redditmedia.com/jKhNb3mLHr6j8iQtHmf38plJnsZXJznfBrenFoKR4lo.jpg\" alt=\"HPE Apollo 4510 gen10. Did I waste $100\" title=\"HPE Apollo 4510 gen10. Did I waste $100\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Just bought a HpE Apollo 4510 gen10 for $100. Is this still usable or does it use to much power?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/riv777\"> /u/riv777 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1on0scc\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1on0scc/hpe_apollo_4510_gen10_did_i_waste_100/\">[comments]</a></span> </td></tr></table>",
        "id": 3968578,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1on0scc/hpe_apollo_4510_gen10_did_i_waste_100",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/jKhNb3mLHr6j8iQtHmf38plJnsZXJznfBrenFoKR4lo.jpg",
        "title": "HPE Apollo 4510 gen10. Did I waste $100",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/antdude",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-03T05:29:13.200899+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-03T02:01:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>USB thumb flash drives are slow especially with their writes (e.g., copying many files (huge ISOs, medias, etc.)! I wonder if there are anything faster out there these days, but still small and light to fit on a keychain and in tiny pockets like in my wallet. Also, USB A and C dual connector ends without using adapters, cables, etc. if possible to use with many devices like smartphones, computers, tablets, TVs, etc.</p> <p>Thank you for reading and hopefully answering soon. :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/antdude\"> /u/antdude </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1omzlld/what_are_the_smallest_lightest_and_fastest_usb_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1omzlld/what_are_the_smallest_lightest_and_fastest_usb_a/\">[comments]</a></span>",
        "id": 3968579,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1omzlld/what_are_the_smallest_lightest_and_fastest_usb_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What are the smallest, lightest, and fastest USB (A & C dual connectors) drives out there these days?",
        "vote": 0
    }
]