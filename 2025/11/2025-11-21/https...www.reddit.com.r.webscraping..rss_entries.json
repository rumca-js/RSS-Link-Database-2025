[
    {
        "age": null,
        "album": "",
        "author": "/u/paamayim1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-21T22:22:55.458096+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-21T21:38:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1p3b5vr/i_made_an_extension_for_generating_selectors/\"> <img src=\"https://preview.redd.it/a9fz5zkrbo2g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1e1e9bd16c19696f32248bdd03f3ba8f354b5c1e\" alt=\"I made an extension for generating selectors (Xpath only for now)\" title=\"I made an extension for generating selectors (Xpath only for now)\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I recall it being mentioned here the ails of selector generation. Knowing which combinations work best for elements can be difficult to pin down, especially on websites with dynamic content.</p> <p>I&#39;ve spent some time to create and release the first version of a tool to solve this.</p> <p><a href=\"https://github.com/paamayim/QuickSel\">Quicksel</a> is a selector generator that works by looping through known combinations of surrounding context to generate selectors based on node count.</p> <p>Features:</p> <ul> <li>Basic UI (",
        "id": 4133106,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p3b5vr/i_made_an_extension_for_generating_selectors",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/a9fz5zkrbo2g1.png?width=640&crop=smart&auto=webp&s=1e1e9bd16c19696f32248bdd03f3ba8f354b5c1e",
        "title": "I made an extension for generating selectors (Xpath only for now)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Much-Journalist3128",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-21T19:11:59.397862+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-21T18:28:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Here&#39;s what my bot does: Logs into my webshop account and looks for my deleted orders because the webshop hasn&#39;t implemented webhooks, so if they delete the order, I&#39;ll never know unless I check. This can happen at any time of the day.</p> <p>My bot&#39;s code works IF I run it on my home PC (residential IP, real browser fingerprint, TSL, etc). If I run it, SAME CODE, via github actions - for example -, it fails 90% of the time if not 100% of the time.</p> <p>The site uses AKAMAI. I use Selenium. I&#39;ve tried undetected chromedriver and nodriver to no avail. I know without posting my code I can&#39;t get much help, but what could it be? I&#39;ve tried using residential proxies to no avail. I must be doing something wrong. AKAMAI seems to be such a PITA</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Much-Journalist3128\"> /u/Much-Journalist3128 </a> <br/> <span><a href=\"https://www.reddit.com/r/websc",
        "id": 4131734,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p36brj/i_cant_get_my_bot_to_work_through_akamai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I can't get my bot to work through AKAMAI",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/No-Competition6691",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-21T17:03:59.007356+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-21T16:41:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am in an AI start up and we are looking to generate leads in house. We have previously paid but we want to start doing it ourselves.</p> <p>We Target beauty, dental and health clinics and we need the business owners verified number and email.</p> <p>How can we do this in house, how much will it cost for what results, what tools should we use?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No-Competition6691\"> /u/No-Competition6691 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p33hq3/how_do_do_i_get_verified_business_owner_emails/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p33hq3/how_do_do_i_get_verified_business_owner_emails/\">[comments]</a></span>",
        "id": 4130538,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p33hq3/how_do_do_i_get_verified_business_owner_emails",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do do I get verified business owner emails cheap?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jedenjuch",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-21T14:54:50.805556+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-21T14:36:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.npmjs.com/package/puppeteer-extra-plugin-stealth\">https://www.npmjs.com/package/puppeteer-extra-plugin-stealth</a> is no longer in maintance </p> <p>I wonder if any of you find some replacement for stealth plugin, i found this one but didnt use</p> <p><a href=\"https://github.com/rebrowser/rebrowser-patches/tree/main/patches/playwright-core\">https://github.com/rebrowser/rebrowser-patches/tree/main/patches/playwright-core</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jedenjuch\"> /u/jedenjuch </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p308jq/stealth_plugin_for_playwright_crawlee/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p308jq/stealth_plugin_for_playwright_crawlee/\">[comments]</a></span>",
        "id": 4129375,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p308jq/stealth_plugin_for_playwright_crawlee",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Stealth plugin for playwright crawlee",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/flowlikecoffejelly2",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-21T13:51:10.002089+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-21T13:36:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How do you even load a captcha from one browser onto another/ even see the problem?</p> <p>does anyone have code examples how you can sort of stream captchas from a page to a secondary page? or just even load someone&#39;s captcha in a environment to solve manually in another, im tryna see how captcha solving services work.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/flowlikecoffejelly2\"> /u/flowlikecoffejelly2 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p2ysmz/how_do_captcha_solving_services_view_your_captcha/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p2ysmz/how_do_captcha_solving_services_view_your_captcha/\">[comments]</a></span>",
        "id": 4128815,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p2ysmz/how_do_captcha_solving_services_view_your_captcha",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do captcha solving services view your captcha?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/noreagaaa",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-21T12:49:47.116675+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-21T12:11:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I\u2019m currently running a dropshipping side hustle on a French marketplace called Leboncoin, but my workflow is completely manual and it\u2019s becoming a bottleneck. I want to scale this up but I have zero coding experience.</p> <p>I\u2019m trying to figure out if I can rely on AI to write the scripts for me, or if this project is too complex and requires me to actually sit down and learn Python from scratch.</p> <p>The Workflow I want to build:</p> <p>AliExpress Scraper:</p> <ul> <li>Input: A list of product URLs.</li> <li>Output: Titles, descriptions, prices, and the review Images.</li> </ul> <p>Leboncoin Auto-Lister:</p> <ul> <li>Input: The data scraped above (processed via a Google Sheet).</li> <li>Action: Log in to Leboncoin and post the listings automatically.</li> </ul> <p>The problem is that Leboncoin uses Datadome anti-bot protection.</p> <p>Is it realistic for a total beginner to build a Datadome-bypassing bot using only AI-generate",
        "id": 4128349,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p2x018/is_ai_enough_or_do_i_need_to_learn_python",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is AI enough or do I need to learn Python?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NegotiationOk888",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-21T12:49:47.380175+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-21T12:03:09+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1p2wu38/scraping_using_ai_for_literally_free/\"> <img src=\"https://b.thumbs.redditmedia.com/Z87ga6nj1HiBvhYhO-raGfwcQlDV5QhUpZ_ebt9iU9c.jpg\" alt=\"Scraping using ai for literally FREE\" title=\"Scraping using ai for literally FREE\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/zc9uhhmunl2g1.png?width=1865&amp;format=png&amp;auto=webp&amp;s=e2cb3fc372a985c2afc5cd23fc5a18ffed59f566\">https://preview.redd.it/zc9uhhmunl2g1.png?width=1865&amp;format=png&amp;auto=webp&amp;s=e2cb3fc372a985c2afc5cd23fc5a18ffed59f566</a></p> <p>Someone wanted a list of lawyers in PU, SG and their emails. Figured I could use a cheap ai subscription (2000 req per day) that I otherwise use for LARPing into good use. Guess what, in 10 mins I&#39;ve got myself a semi functional scraper. It gets the thing done. </p> <p>Here&#39;s the workflow. Scrape homepage + about us page + career -&gt; analyze it using deeps",
        "id": 4128351,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p2wu38/scraping_using_ai_for_literally_free",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/Z87ga6nj1HiBvhYhO-raGfwcQlDV5QhUpZ_ebt9iU9c.jpg",
        "title": "Scraping using ai for literally FREE",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AccomplishedSuit1582",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-21T14:54:50.956757+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-21T10:28:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I built a tiny proxy relay because Chrome and some automation tools still can\u2019t handle authenticated SOCKS5 proxies properly.</p> <p>Right now:</p> <p>\u2022 Chrome still doesn\u2019t support SOCKS5 proxy authentication. </p> <p>\u2022 DrissionPage doesn\u2019t support username/password proxies at all. </p> <p>\u2022 Many residential / datacenter providers only give you user:pass SOCKS5 endpoints.</p> <p>So I wrote **proxy-relay**:</p> <p>\u2022 Converts upstream HTTP/HTTPS/SOCKS5/SOCKS5H with auth into a local HTTP or SOCKS5 proxy **without** auth. </p> <p>\u2022 Works with Chrome, Playwright, Selenium, DrissionPage, etc. \u2014 just point them at the local proxy. </p> <p>\u2022 Pure Python, zero runtime dependencies, with sync &amp; async APIs. </p> <p>\u2022 Auto\u2011cleanup on process exit, safe for scripts, tests and long\u2011running services.</p> <p>It\u2019s still a small project, but it already solved my main headache:</p> <p>I can plug any username/password SOCKS5 into proxy-relay,</p> <p>and all my tool",
        "id": 4129376,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p2v73k/tired_of_tools_not_supporting_socks5_auth_i_built",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tired of tools not supporting SOCKS5 auth? I built a tiny proxy relay",
        "vote": 0
    }
]