[
    {
        "age": null,
        "album": "",
        "author": "/u/neos7m",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-02T22:04:27.579442+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-02T21:32:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all, hope someone will be able to solve my conundrum.</p> <p>My setup involves a docker-compose where two containers, one for Wireguard and one for Mullvad. The containers share a network called wg, defining a subnet 10.42.42.0/24 where Wireguard is on IP 42 and Mullvad on 50.</p> <p>The containers work. I can connect to Wireguard without issues and Wireguard can exit on the Internet. At the same time, running the appropriate curl through docker exec inside the Mullvad container shows that it&#39;s connected to Mullvad.</p> <p>Now the missing piece is that I want the Wireguard container to exit through the Mullvad one, effectively allowing my devices connecting to Wireguard to also use Mullvad at the same time.</p> <p>I&#39;ve been trying for two days now and believe me, I&#39;m desperate. I thought forcing the default ip route of the Wireguard container to pass through 10.42.42.50 would be enough, but that just makes the Internet unreachable. So ",
        "id": 3966939,
        "language": "en",
        "link": "https://www.reddit.com/r/docker/comments/1omtkhm/passing_container_traffic_through_another",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Passing container traffic through another container",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/leeleewonchu",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-02T19:02:01.549039+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-02T18:29:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello Everyone,<br/> As a guy who likes to self host everything from side project backends to multiple arr&#39;s for media hosting, it has always bugged me that for checking logs, starting containers etc. I had to open my laptop and ssh into the server. And while solutions like sshing from termux exist, it&#39;s really hard to do on a phone&#39;s screen. </p> <p>Docker manager solves that. Docker Manager lets you manage your containers, images, networks, and volumes \u2014 right from your phone. Do whatever you could possibly want on your server from your phone all with beautiful Material UI. </p> <p>You can get it on play store here: <a href=\"https://play.google.com/store/apps/details?id=com.pavit.docker\">https://play.google.com/store/apps/details?id=com.pavit.docker</a> </p> <p>Key Features<br/> - Add multiple servers with password or key-based SSH auth<br/> - Seamlessly switch between multiple servers<br/> - Manage containers \u2014 start, stop, restart, ins",
        "id": 3966025,
        "language": "en",
        "link": "https://www.reddit.com/r/docker/comments/1omovfs/i_made_an_android_app_to_manage_my_docker",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I made an Android app to manage my Docker containers on the go",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/reditlater",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-02T12:58:05.130287+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-02T11:59:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Greetings!</p> <p>I have a <em>tiny</em> bit of experience with Docker on my Synology, where I followed <a href=\"https://www.reddit.com/r/synology/comments/1f6744c/simple_cloud_backup_guide_for_new_synology_users/\">this guide for installing CrashPlan on my Synology</a>. My NAS is too under-powered for this, I&#39;m finding, and I also am planning to add an additional Docker container for something else. My Windows 11 Pro machine is plenty powerful (eg, i9, fast SSD, 64GB RAM), so I want to switch to using it.</p> <p>From my perusing of the Docker Reddit, my impression is that it would be better to setup Docker <em>within</em> the Ubuntu instance inside of WSL2 (as opposed to installing Docker directly via Windows...do we call that &quot;Windows Docker??&quot;).</p> <p>So my question is, what are the recommended methods/procedures for permanently (ie, persisting through reboots) mounting the network shares from my Synology NAS within the Ubuntu WSL2 in",
        "id": 3963787,
        "language": "en",
        "link": "https://www.reddit.com/r/docker/comments/1omfg7j/recommended_methods_for_mapping_network_shares",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Recommended Method(s) for Mapping Network Shares (from a Synology NAS on LAN) in Ubuntu (within WSL2, Windows 11 Pro), so that Shares are Accessible to Multiple Docker Containers (in Ubuntu)?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/divyeshp_ftw",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-02T04:27:51.529794+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-02T04:20:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Error response from daemon: failed to resolve reference &quot;docker.io/library/mysql:latest&quot;: failed to do request: Head &quot;<a href=\"https://registry-1.docker.io/v2/library/mysql/manifests/latest%22:\">https://registry-1.docker.io/v2/library/mysql/manifests/latest&quot;:</a> context deadline exceeded</p> <p>I tried to change my network, restart the docker deskltop app, how should i solve this error</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/divyeshp_ftw\"> /u/divyeshp_ftw </a> <br/> <span><a href=\"https://www.reddit.com/r/docker/comments/1om83f2/how_should_i_solve_this_problem/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/docker/comments/1om83f2/how_should_i_solve_this_problem/\">[comments]</a></span>",
        "id": 3961945,
        "language": "en",
        "link": "https://www.reddit.com/r/docker/comments/1om83f2/how_should_i_solve_this_problem",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 580,
        "source_url": "https://www.reddit.com/r/docker/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How should i solve This problem",
        "vote": 0
    }
]