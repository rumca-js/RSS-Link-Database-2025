[
    {
        "age": null,
        "album": "",
        "author": "/u/babysmokesalot",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-12T22:08:46.791349+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-12T21:34:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My boss has a medium sized legal business. He is demanding i start doing web scraping. He wants me to scrape phone numbers and emails from visitors going to other firms. Is this possible? And how can this be done? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/babysmokesalot\"> /u/babysmokesalot </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ovi9bb/web_scraping_need_help/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ovi9bb/web_scraping_need_help/\">[comments]</a></span>",
        "id": 4053861,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ovi9bb/web_scraping_need_help",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Web scraping need help!!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/taksto",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-12T21:08:18.920810+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-12T20:40:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Does anybody know any good resources to scrape profile pics from tinder that would be an uncatchable way, cuz im worried ill get banned if I do it</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/taksto\"> /u/taksto </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ovgses/tindercom_profile_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ovgses/tindercom_profile_scraping/\">[comments]</a></span>",
        "id": 4053388,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ovgses/tindercom_profile_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "tinder.com profile scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cashiu",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-12T18:05:50.292564+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-12T17:46:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Since yesterday, I cannot bypass the Walmart Bot detection using undetected-chromedriver. I have tried with different IPs and looks like they have upgraded their Bot detection. Can anybody help with a solution, looks like the package is abandoned with their latest commit 4 months ago.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cashiu\"> /u/cashiu </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ovbzg3/walmart_robot_detection_upgrade/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ovbzg3/walmart_robot_detection_upgrade/\">[comments]</a></span>",
        "id": 4051680,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ovbzg3/walmart_robot_detection_upgrade",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Walmart Robot Detection upgrade",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Armed_Muppet",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-12T17:05:05.710461+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-12T16:50:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m working on a Puppeteer script. </p> <p>My goal is to visit a Cloudflare-protected site, scrape product data, and bypass all bot detections.</p> <p>Previously, I was launching with <code>headless: false</code> no problems but I believe this cloudflare setup is new. </p> <p>I\u2019ve tried:</p> <pre><code>-Using full Chrome binary in Program Files -Adding puppeteer-extra-plugin-stealth -Waiting 5\u201310s with waitForTimeout() after goto() -Checking DOM changes with waitForFunction() after navigation </code></pre> <p>Launch Args:</p> <pre><code>&#39;--no-sandbox&#39; &#39;--disable-setuid-sandbox&#39; &#39;--disable-blink-features=AutomationControlled&#39; &#39;--start-maximized&#39; &#39;--disable-dev-shm-usage&#39; &#39;--disable-gpu&#39; &#39;--disable-infobars&#39; &#39;--window-position=0,0&#39; &#39;--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.89 Safari/537.36&#39; </code></pre> <p>S",
        "id": 4051099,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ovae4x/looking_for_assistance_with_js_scraper_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for assistance with JS Scraper on cloudflare protected site.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dim_goud",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-12T11:51:31.347108+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-12T11:33:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all, </p> <p>Very recently, I was asked to scrape data from Spotify for Artists, a platform where data is highly protected and not available through any API. </p> <p>I used the MCP server from a scraping library to build a workflow on my Claude desktop, and it worked amazingly. </p> <p>On Friday, November 14, 1pm EST, run a Zoom meetup to present the solution and talk about challenges and opportunities. </p> <p>It would be amazing to join and share your experiences, and your challenges</p> <p><a href=\"https://luma.com/8gm30u1y\">https://luma.com/8gm30u1y</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dim_goud\"> /u/dim_goud </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ov2rur/scraping_data_from_high_strict_platforms_like/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ov2rur/scraping_data_from_high_strict_platforms_like/\">[comments]</a></sp",
        "id": 4048141,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ov2rur/scraping_data_from_high_strict_platforms_like",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping data from high strict platforms like Spotify",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Less_Insurance3731",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-12T12:52:05.504832+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-12T01:38:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Greetings, </p> <p>I run a real estate marketplace portal in which brokers can post their listing for free. In an effort to ease their listing uploads, I offer &quot;scraping&quot; so they do not have to manually enter every listing. This allows them to only maintain listings on their office site, and not have to do redundant work on our site for listing maintenance. I&#39;m a solo founder, and not a developer. The scraping we have done on two sites has been a sluggish approach, and I&#39;m told does not work for every different brokerage site. On top of that, it appears as a sub-par approach when more developed sites have established xml feeds for listing syndication. Is there a path forward not on my radar? In a sci-fi description, it would be ideal to be able to email a browser plugin that we designed and it automatically synced their site with ours. Easy, transparent, and direct. Thanks for the consideration. </p> </div><!-- SC_ON --> &#32; submit",
        "id": 4048609,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ous49v/nondev_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Non-dev scraping",
        "vote": 0
    }
]