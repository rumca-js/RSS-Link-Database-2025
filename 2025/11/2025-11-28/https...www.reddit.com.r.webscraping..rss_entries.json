[
    {
        "age": null,
        "album": "",
        "author": "/u/izolekerberos",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-28T18:50:25.080726+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-28T16:35:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m trying to scrape some public data from Bet365, but as you know their antiscraping system is extremely aggressive. I\u2019d prefer to avoid using selenium or any browser automation because of performance and overhead. tried using the android api for this but didnt really work lol planning to build some kind of automatic betting thing so i kinda need a cleaner solution.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/izolekerberos\"> /u/izolekerberos </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p8zb1j/how_can_i_scrape_bet365_without_selenium/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p8zb1j/how_can_i_scrape_bet365_without_selenium/\">[comments]</a></span>",
        "id": 4189700,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p8zb1j/how_can_i_scrape_bet365_without_selenium",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can I scrape Bet365 without Selenium?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ok_Trick_8750",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-28T18:50:25.286169+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-28T11:21:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am testing different ways to scrape Google Search, and I am running into 429 errors almost immediately. Google is blocking fast, even with proxies and slow intervals. </p> <p><strong>Even if I unblock the IP by solving a captcha, the IP gets blocked again fast.</strong> </p> <p>What works for you now? </p> <p>\u2022 Proxy types you rely on<br/> \u2022 Rotation patterns<br/> \u2022 Request delays<br/> \u2022 Headers or fingerprints that help<br/> \u2022 Any tricks that reduce 429 triggers</p> <p>I want to understand what approaches still hold up today and compare them with my own tests.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok_Trick_8750\"> /u/Ok_Trick_8750 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p8sgku/scraping_google_search_how_do_you_avoid_429_today/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p8sgku/scraping_google_search_how_do_you_avoid_429_today/",
        "id": 4189701,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p8sgku/scraping_google_search_how_do_you_avoid_429_today",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Google Search. How do you avoid 429 today?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Peace_Soul",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-28T08:53:52.142296+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-28T08:40:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I tried every possible way to bypass hCaptcha but It only allows max 2 times verification from same browser.</p> <p>Have you tried??</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Peace_Soul\"> /u/Peace_Soul </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p8pxry/why_its_impossible_to_bypass_hcaptcha/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p8pxry/why_its_impossible_to_bypass_hcaptcha/\">[comments]</a></span>",
        "id": 4185217,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p8pxry/why_its_impossible_to_bypass_hcaptcha",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WHY IT'S IMPOSSIBLE TO BYPASS hCaptcha.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/bnt_zpt",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-28T07:51:37.744179+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-28T07:34:11+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1p8ox8b/scraping_from_azure_container_apps/\"> <img src=\"https://b.thumbs.redditmedia.com/0D9mH3xEcMk8NHU1n3RzJqn7jXdy6E05ak3K7-hnc0c.jpg\" alt=\"Scraping from Azure Container Apps\" title=\"Scraping from Azure Container Apps\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I need to scrape concurrently a few websites when an event occurs and for doing this I thought about &quot;Azure Container Apps Jobs&quot;. Basically when the event happens I spin up a few docker containers that crawls the websites concurrently and then shut down when done. The reasoning behind this is that I need the information for all websites ASAP but only a few times a day (let&#39;s say 10 times from 9am to 5pm).</p> <p>I have already set this up and is working okay but a few websites gets blocked by Cloudflare (see image below).</p> <p>I just learned about &quot;<strong>stealth&quot; browsers</strong> and <strong>residential proxies</stro",
        "id": 4184884,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p8ox8b/scraping_from_azure_container_apps",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/0D9mH3xEcMk8NHU1n3RzJqn7jXdy6E05ak3K7-hnc0c.jpg",
        "title": "Scraping from Azure Container Apps",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cloutboicade_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-28T04:37:38.652971+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-28T04:15:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have many accounts with millions of followers and billions of views that I\u2019ve done extensive testing on.</p> <p>I\u2019ve already built a scraper + editor so the content looks original. Uploading via api limits reach. Uploading manually I go viral. Building a system that can automate the uploading would be a game changer. </p> <p>Looking for someone who can build/built this!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cloutboicade_\"> /u/cloutboicade_ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p8lhyl/upload_to_social_media_mimic_human_posting_to_go/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1p8lhyl/upload_to_social_media_mimic_human_posting_to_go/\">[comments]</a></span>",
        "id": 4184000,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1p8lhyl/upload_to_social_media_mimic_human_posting_to_go",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Upload to social media, mimic human posting to go viral",
        "vote": 0
    }
]