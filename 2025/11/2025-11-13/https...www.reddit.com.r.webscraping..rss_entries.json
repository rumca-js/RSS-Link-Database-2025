[
    {
        "age": null,
        "album": "",
        "author": "/u/xkiiann",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T22:25:36.367903+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T22:16:30+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1owesud/vercel_botid_reverse_engineered_implemented_in/\"> <img src=\"https://external-preview.redd.it/CjQ8YKfxXOcYw80aeOmvtAWPm_527RprhoDbng6468A.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=773f0a8332fd0286df8093a228c611f0b3b0bd4b\" alt=\"Vercel BotID reverse engineered &amp; implemented in 100% Golang\" title=\"Vercel BotID reverse engineered &amp; implemented in 100% Golang\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I used go-fAST.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/xkiiann\"> /u/xkiiann </a> <br/> <span><a href=\"https://github.com/xKiian/vercel-botid\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1owesud/vercel_botid_reverse_engineered_implemented_in/\">[comments]</a></span> </td></tr></table>",
        "id": 4063692,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1owesud/vercel_botid_reverse_engineered_implemented_in",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/CjQ8YKfxXOcYw80aeOmvtAWPm_527RprhoDbng6468A.png?width=640&crop=smart&auto=webp&s=773f0a8332fd0286df8093a228c611f0b3b0bd4b",
        "title": "Vercel BotID reverse engineered & implemented in 100% Golang",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/1337ingDisorder",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T20:24:11.578358+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T19:37:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a personal script I use to save time when I have a dozen or two new TV shows or films that I need to search for details about on IMDB.</p> <p>It basically just performs the searches and summarizes the results on a single page.</p> <p>The method of scraping is by using PHP&#39;s get_file_contents() to pull the HTML from an IMDB search results page, and then perform various querySelector() operations in JS to isolate the page elements with the details like title, release year, etc.</p> <p>This week IMDB changed the way their search results page displays.</p> <p>Now instead of getting the same HTML that I see on the page when I manually do a search, all I get is:</p> <pre><code>&lt;html&gt; &lt;head&gt;&lt;/head&gt; &lt;body&gt;&lt;/body&gt; &lt;/html&gt; </code></pre> <p>But if I open the page manually I can even inspect the page and see the full HTML that was previously getting downloaded by file_get_contents().</p> <p>Has anyone encountered thi",
        "id": 4062747,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1owaows/anyone_found_a_way_to_scrape_imdbs_new_search",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone found a way to scrape IMDB's new search results page code?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PINKINKPEN100",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T19:23:31.324088+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T18:29:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I used to track products with custom scrapers, and it worked fine\u2026 until the list grew. Once I started monitoring hundreds of URLs across different sites, everything fell apart: layout changes, blocks, selectors failing, and way too many late-night fixes.</p> <p>I ended up rebuilding the entire process around a more automated workflow. One part handles scheduling and looping through URLs, another part fetches the page in a more resilient way, then a parser extracts the fields I need (price, stock, rating, etc.). The results get pushed into a sheet, and the workflow sends me a heads-up when something changes.</p> <p>The best part is that I barely touch the scraper side anymore. The whole setup finally scales without turning into a maintenance nightmare.</p> <p>If you\u2019re curious about the <a href=\"https://crawlbase.com/blog/how-to-automate-ecommerce-product-research/\">full process</a> and the workflow structure, here&#39;s a reference.</p> <p>How are yo",
        "id": 4062250,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ow8v2r/how_i_finally_made_product_research_stop_eating",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How I Finally Made Product Research Stop Eating My Entire Week",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Osprey6767",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T18:23:04.736701+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T18:22:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I use n8n and other automation tech to build ai automations. And scraping is a huge part of that. Recently I had projects that I use puppeteer and js to scrape websites but indeed does not work with puppeteer. Cannot get the correct data.</p> <p>My plan is to get the job posting data for each posting, and then get an ai to analyze it 1 to 10 based on my resume. So I thought crawl4ai would be pretty good since it states that it gives llm ready data. But I want some help from people that have used it before, how to pass captchas like cloudfare etc. </p> <p>I am a first time user and just installed everything so if you have any useful info I would like to hear it!</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Osprey6767\"> /u/Osprey6767 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ow8odf/how_to_set_up_crawl4ai_for_indeed_job_postings/\">[link]</a></span> &#32; <span><a href",
        "id": 4061771,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ow8odf/how_to_set_up_crawl4ai_for_indeed_job_postings",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to set up Crawl4Ai for Indeed job postings.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/judge_manos",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T17:22:18.401838+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T17:08:44+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1ow6o9o/im_developing_lovable_for_scraping/\"> <img src=\"https://b.thumbs.redditmedia.com/Fg30qvmSSbsaIzSEdzCa7cXPHvzoTOdju9XAFN6FnNA.jpg\" alt=\"I'm developing lovable for scraping\" title=\"I'm developing lovable for scraping\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey everyone, </p> <p>I recently joined the unemployment list, so I decided to get creative and work on something ambitious, maybe not doable at first thought, but within my expertise. I\u2019m a software engineer with almost nine years of experience in backend development, web scraping, bypassing bots, and reverse-engineering websites and apps.</p> <p>The idea is to do what lovable, bolt, and all the other AI app builders do, but for developing scrapers. Instead of a prompt, the user gives a URL and the fields he/she wants to collect, and then magic happens. The process includes the analysis of the webpage (identifying selectors, protection method",
        "id": 4061093,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ow6o9o/im_developing_lovable_for_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/Fg30qvmSSbsaIzSEdzCa7cXPHvzoTOdju9XAFN6FnNA.jpg",
        "title": "I'm developing lovable for scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BigBrotherJu",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T11:18:44.378891+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T10:27:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Are there any tools for detecting whether a website uses browser fingerprinting and the kind of fingerprints collected?</p> <p>The only relevant tool I found is <a href=\"https://github.com/freethenation/DFPM\">https://github.com/freethenation/DFPM</a>, but it hasn&#39;t been updated for years. Is it still good enough?</p> <p>I also know that Scraping Enthusiasts discord has a antibot-test. But it has also been down for months. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BigBrotherJu\"> /u/BigBrotherJu </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ovxnje/tools_for_detecting_browser_fingerprinting/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ovxnje/tools_for_detecting_browser_fingerprinting/\">[comments]</a></span>",
        "id": 4057869,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ovxnje/tools_for_detecting_browser_fingerprinting",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tools for detecting browser fingerprinting",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Coding-Doctor-Omar",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T10:18:14.236930+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T09:51:31+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1ovx2re/the_proper_way_of_talking_to_chatgpt/\"> <img src=\"https://preview.redd.it/8nsivh5wxz0g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=916abe5336e4fccf065f0ddbe817c6c1e6a83f80\" alt=\"The proper way of talking to ChatGPT\" title=\"The proper way of talking to ChatGPT\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>You can try other response types, such as &quot;bool&quot;.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Coding-Doctor-Omar\"> /u/Coding-Doctor-Omar </a> <br/> <span><a href=\"https://i.redd.it/8nsivh5wxz0g1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ovx2re/the_proper_way_of_talking_to_chatgpt/\">[comments]</a></span> </td></tr></table>",
        "id": 4057467,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ovx2re/the_proper_way_of_talking_to_chatgpt",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/8nsivh5wxz0g1.png?width=640&crop=smart&auto=webp&s=916abe5336e4fccf065f0ddbe817c6c1e6a83f80",
        "title": "The proper way of talking to ChatGPT",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/taksto",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T07:14:37.394942+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T07:12:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I\u2019m practicing web scraping and wanted to get advice on scraping <strong>public images</strong> from this site:</p> <p><strong>Website URL:</strong><br/> <a href=\"https://unsplash.com/s/photos/landscape\">https://unsplash.com/s/photos/landscape</a><br/> (Just an example site with freely available images.)</p> <p><strong>Data Points I want to extract:</strong></p> <ul> <li>Image URLs</li> <li>Photographer name (if visible in DOM)</li> <li>Tags visible on the page</li> <li>The high-resolution image file</li> <li>Pagination / infinite scroll content</li> </ul> <p><strong>Project Description:</strong><br/> I\u2019m learning how to scrape JS-heavy, dynamically loaded pages. This site uses infinite scroll and loads new images via XHR requests. I want to understand:</p> <ul> <li>the best way to wait for new images to load</li> <li>how to scroll programmatically with Puppeteer/Playwright</li> <li>downloading images once they appear</li> <li>how ",
        "id": 4056607,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1ovun7m/scraping_images_from_a_jsrendered_gallery_need",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping images from a JS-rendered gallery \u2013 need advice",
        "vote": 0
    }
]