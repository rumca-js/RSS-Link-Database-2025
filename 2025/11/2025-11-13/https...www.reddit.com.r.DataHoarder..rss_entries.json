[
    {
        "age": null,
        "album": "",
        "author": "/u/Zealousideal-Bet-950",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T23:02:15.357852+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T22:11:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>(2nd attempt at posting 1st one evaporated prior to hitting &#39;Post&#39;)</p> <p>Synology DS423+ DiskStation 4-Bay NAS</p> <p><a href=\"https://www.centralcomputer.com/synology-ds423-diskstation-4-bay-nas-intel-celeron-j4125-2gb-ddr4-non-ecc-sodimm-2x-rj-45-2x-usb-3-2-gen-1.html\">https://www.centralcomputer.com/synology-ds423-diskstation-4-bay-nas-intel-celeron-j4125-2gb-ddr4-non-ecc-sodimm-2x-rj-45-2x-usb-3-2-gen-1.html</a></p> <p>I&#39;m calculating the current DATA set is about 2 to 3Gigs, so I doubled that, looked to using RAID 5 w/ 4x 2T drives (8T total, 6Terabytes usable space).</p> <p>Am I really prohibited from using any brand hard drive in this enclosure? I like the idea of having four the same in use w/ a Spare or two drive on the shelf. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Zealousideal-Bet-950\"> /u/Zealousideal-Bet-950 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comment",
        "id": 4063949,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1oweoln/drive_recommends_for_a_synology_ds423_can_i_use",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Drive Recommends for a Synology DS423 - Can I use other brand drives, or Just Theirs?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cosmoschtroumpf",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T23:02:15.467078+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T22:07:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi! Over time, I have made partial backup copies of usb drives. Then added/removed files on one of them, then forgot I had a copy so made changes to the original disk... Over the time, I have accumumated duplicates files sorted in similar-looking folders and it&#39;s a mess.</p> <p>I know tools that can find duplicate files based on name, date, size or hash) but it would be a huge work and it may actually spread the mess even more (eg. half science ebooks somewhere, half elsewhere)</p> <p>Is there a tool that can find similarities between folders (based on content and subfolders) and show differences before offering a merge ?</p> <p>Such algorithm may be slow but it&#39;s ok. Maybe AI could help gauge folders similarities in a more fuzzy way ?</p> <p>As a first step I wouldn&#39;t be copying everything I have on a 8TB drive, then delete duplicates by merging folders within the disk.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://ww",
        "id": 4063950,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owekna/find_similar_folders_for_duplicates",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Find similar folders for duplicates",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Zero00Shadow",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T22:01:39.011908+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T21:49:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>As the title says I am looking for recommednations for a 24TB drive. Have seen that the Seagate ones have mixed reviews due to performance of the drive but is there any other that you recommend? </p> <p>Thanks for all the help with my various posts. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Zero00Shadow\"> /u/Zero00Shadow </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owe439/advice_needed_recommedation_for_24tb_external/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owe439/advice_needed_recommedation_for_24tb_external/\">[comments]</a></span>",
        "id": 4063459,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owe439/advice_needed_recommedation_for_24tb_external",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Advice Needed: Recommedation for 24TB External Drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/nyc-noise",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T22:01:38.673808+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T21:48:54+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nyc-noise\"> /u/nyc-noise </a> <br/> <span><a href=\"https://ep-nov-12.greg.technology\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owe3rs/epstein_files_searchable_database_of_23000_house/\">[comments]</a></span>",
        "id": 4063458,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owe3rs/epstein_files_searchable_database_of_23000_house",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Epstein Files: Searchable Database of ~23,000 House Oversight Image Files",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Critical_Estate1922",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T21:01:07.548112+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T21:00:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>this is probably the wrong sub to ask a question like this but if someone couls atleast point me to a direction to go to, to find an answer</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Critical_Estate1922\"> /u/Critical_Estate1922 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owcugz/is_there_a_way_for_me_to_recover_old_deleted/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owcugz/is_there_a_way_for_me_to_recover_old_deleted/\">[comments]</a></span>",
        "id": 4062900,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owcugz/is_there_a_way_for_me_to_recover_old_deleted",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a way for me to recover old deleted tiktoks from around 5 years ago? is there like a slight possibility bc i\u2019d really do anything.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Wonderful-Ad-5952",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T21:01:07.307979+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T20:00:34+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Wonderful-Ad-5952\"> /u/Wonderful-Ad-5952 </a> <br/> <span><a href=\"/r/DataCops/comments/1owazjn/why_delete_my_data_companies_services_are_a_lie/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owbapi/why_delete_my_data_companies_services_are_a_lie/\">[comments]</a></span>",
        "id": 4062899,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owbapi/why_delete_my_data_companies_services_are_a_lie",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Why 'Delete My Data\u2019 Companies Services Are a Lie",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Bobbykev",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T18:58:06.079369+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T18:57:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking for recommendations for a case that can store 10 x 3.5 hard drives. Not fussed about overall size or hot swap. Even the massive gaming cases seem to only have room for a couple of 3.5 drives. Was looking at the fractal node cases, but thought I\u2019d ask if anything better on the market anyone would recommend. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Bobbykev\"> /u/Bobbykev </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow9ml1/recommendations_for_pc_case/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow9ml1/recommendations_for_pc_case/\">[comments]</a></span>",
        "id": 4061978,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ow9ml1/recommendations_for_pc_case",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Recommendations for pc case",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dazmatai",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T18:58:06.288614+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T18:34:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>hi, not sure if this actually belongs here, but if not do direct me to the right place</p> <p>trying to find a solid place to buy a metric ton of older 4 gig, 8 gig or 16 gig micro SD cards for a couple of projects and also because yummy sd card</p> <p>literally cannot find anywhere good for it. amazon is trash for bulk buying, aliexpress is unreliable and the prices change when i put it in the basket (tried to buy 90 8 gig &quot;sample&quot; sets from some chinese company and price went from 0.07 pence per unit, totaling like \u00a32.10 and 25 pound shipping, ended up with a basket totalling \u00a3400 somehow) and ebay has barely any UK sellers selling micro SD card joblots.</p> <p>any suggestions?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dazmatai\"> /u/dazmatai </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow90gy/how_to_buy_tons_of_micro_sd_cards/\">[link]</a></span> &#32; <span><a href=\"h",
        "id": 4061979,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ow90gy/how_to_buy_tons_of_micro_sd_cards",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "how to buy tons of micro SD cards?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/t3hwUn",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T20:00:38.019654+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T18:32:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking for some assistance on interpreting the SMART data on this re certified drive I got from GoHardDrive. Its a 14 TB WDC Ultrastar DC HC530. Long Smart test is showing a Read failure with no LBA_of_first_error value and also says &quot;1 of 1 failed self-tests are outdated by newer successful extended offline self-test # 2&quot;. Does this mean subsequent tests were OK? The drive also passed a full 4 pass of badblocks with no errors.</p> <p><code>SMART Self-test log structure revision number 1</code></p> <p><code>Num Test_Description Status Remaining LifeTime(hours) LBA_of_first_error</code></p> <p><code># 1 Short offline Completed without error 00% 209 -</code></p> <p><code># 2 Extended offline Completed without error 00% 209 -</code></p> <p><code># 3 Extended offline Completed without error 00% 27 -</code></p> <p><code># 4 Short offline Completed without error 00% 47561 -</code></p> <p><code># 5 Vendor (0x70) Completed without error 00% 47489 -",
        "id": 4062414,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ow8y4f/recert_wdc_disk_read_failure_long_test_but_smart",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "ReCert WDC Disk - Read Failure Long Test but SMART OK?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SaltyPalmettoPluff",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T20:00:38.398626+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T17:50:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>To make it short, I have a number of books that don\u2019t have any available ebooks that I want to scan and frankly I don\u2019t have the time in my schedule to be able to physically scan them myself(or get into scanning for that matter). What book scanning services have people used and found success with? I am hoping for a service that provides scans that are as close as possible to what a publisher would release as an official ebook/PDF. Most of the posts related to this topic are slightly outdated so I wanted to see if anyone has any recommendations they\u2019ve used somewhat recently. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SaltyPalmettoPluff\"> /u/SaltyPalmettoPluff </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow7sfm/what_book_scanning_services_would_you_recommend/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow7sfm/what_book_scanning_services_w",
        "id": 4062415,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ow7sfm/what_book_scanning_services_would_you_recommend",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What Book Scanning Services Would You Recommend?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/eternalmortal",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T17:57:27.362891+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T17:47:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m sure this isn&#39;t your average post here but I figured you guys could help.</p> <p>I inherited a ton of printed photographs and picture slides from a photographer relative who recently passed away, along with CDs from what looks to be previous attempts at digitization as well as old film reels from home videos. Right now it&#39;s sitting in many many boxes in a basement. </p> <p>I would love to get all this stuff onto a hard drive or the cloud in case they get damaged by water/mold/fire/age. I&#39;ve seen ads for digitization services but if possible would prefer to do it on my own. Any ideas on how/where to start? Best storage practices for scanned files? Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/eternalmortal\"> /u/eternalmortal </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow7pq4/working_on_digitizing_family_photographsold/\">[link]</a></span> &#32; <span><a href",
        "id": 4061352,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ow7pq4/working_on_digitizing_family_photographsold",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Working on digitizing family photographs/old school slides/CDs/film tape. Any how to guides or resources that might help?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Queasy-Cherry7764",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T16:56:56.447382+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T16:53:19+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Queasy-Cherry7764\"> /u/Queasy-Cherry7764 </a> <br/> <span><a href=\"/r/sysadmin/comments/1ow64ul/our_biggest_roadblock_to_digitization_is_security/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow68xy/our_biggest_roadblock_to_digitization_is_security/\">[comments]</a></span>",
        "id": 4060748,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ow68xy/our_biggest_roadblock_to_digitization_is_security",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Our biggest roadblock to digitization is security. How do you ensure digital documents and assets are protected during and after migration?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Acelsp",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T20:00:37.232299+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T16:11:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I have just bought a second hand Synology HAT3310-16T for my NAS in Amazon. SMART seems normal except for <strong>g-sense raw value: 41</strong>. I&#39;m worried about this because I don&#39;t know if it can be a problem in the future. The hdd has ony 121 working hours and I got a very good price. Now I am passing a full sectors scan (it will take 15-20 hours).</p> <p>What is your recomendation? Should I return it to Amazon and get my money back? How serious is this problem now or in the future? If after the scan there are no bad sectors, shoud I consider it safe?</p> <p>Thanks :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Acelsp\"> /u/Acelsp </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow54tr/high_gsense_value/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow54tr/high_gsense_value/\">[comments]</a></span>",
        "id": 4062413,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ow54tr/high_gsense_value",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "High G-Sense value",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Catatonic00Cat",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T14:55:35.051946+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T14:46:39+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow2ycz/should_i_avoid_these_wd_hdd_that_has_a_180tbyear/\"> <img src=\"https://b.thumbs.redditmedia.com/hUwKaWxWnlOiXn3KK2ckxg4nZW8p8mrox-mLd0EYCdE.jpg\" alt=\"Should I avoid these WD HDD that has a 180TB/year limit?\" title=\"Should I avoid these WD HDD that has a 180TB/year limit?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/3h4wcnrtd11g1.png?width=1150&amp;format=png&amp;auto=webp&amp;s=b872f60153004988da05737effd72000edb47578\">https://preview.redd.it/3h4wcnrtd11g1.png?width=1150&amp;format=png&amp;auto=webp&amp;s=b872f60153004988da05737effd72000edb47578</a></p> <p>Why is there a a very low Workload? it is equivalent of writing 12 times the capacity. What am I missing here?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Catatonic00Cat\"> /u/Catatonic00Cat </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow2ycz/sho",
        "id": 4059505,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ow2ycz/should_i_avoid_these_wd_hdd_that_has_a_180tbyear",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/hUwKaWxWnlOiXn3KK2ckxg4nZW8p8mrox-mLd0EYCdE.jpg",
        "title": "Should I avoid these WD HDD that has a 180TB/year limit?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/thekashmiriking",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T14:55:35.196306+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T14:42:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>Just won an eBay auction for the above items, opened never used, for \u00a3420ish. </p> <p>This has got to be too good to be true right? Or there must be a catch. Or is it just a good deal? Seller has 100% feedback as well. </p> <p>What do you guys think? </p> <p>FYI going to be using them in a new NAS build. Thanks. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/thekashmiriking\"> /u/thekashmiriking </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow2uf9/4_x_seagate_exos_x18_sata_10tb_won_bargain/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow2uf9/4_x_seagate_exos_x18_sata_10tb_won_bargain/\">[comments]</a></span>",
        "id": 4059506,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ow2uf9/4_x_seagate_exos_x18_sata_10tb_won_bargain",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "4 x Seagate Exos X18 SATA 10tb WON - Bargain?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Zero00Shadow",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T13:54:29.217120+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T13:19:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking to get some opinions on two drives that I found and trying to figure out the best direction to go. Prices are about the same for each and I am purchasing 4 of them. These will be going into a QNAP NAS. </p> <p>Seagate 6TB ST6000NM0115 - New - no warranty </p> <p>HGST HDN726060ALE610 - Refrub - 5 year warranty (from goHardDrive on ebay) </p> <p>I have read on here that a lot of people have had good experiences with goHardDrive, would the warranty beat out the New no warranty of the Seagates? </p> <p>Thanks for your help really appreciate it. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Zero00Shadow\"> /u/Zero00Shadow </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow0v5d/advice_needed_seagate_exos_new_or_hgst_refrub/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ow0v5d/advice_needed_seagate_exos_new_or_hgst_refrub/\">[comments]</a></span>",
        "id": 4058998,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ow0v5d/advice_needed_seagate_exos_new_or_hgst_refrub",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Advice Needed: Seagate Exos New or HGST Refrub",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/R3PAIRS",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T13:54:29.435306+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T12:59:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I\u2019m trying to track down the latest firmware for an <strong>IBM ULT3580-HH5 / 46X2476 LTO-5 Half-Height Fibre Channel tape drive</strong>, but I\u2019m hitting dead ends.</p> <p>IBM\u2019s Fix Central no longer seems to host a public link for this specific model, and their firmware delivery pages for older LTO drives have been removed or require entitlement access. I\u2019ve already checked:</p> <ul> <li>IBM Fix Central</li> <li>Lenovo / IBM TS3100-TS3200 support pages</li> <li><a href=\"http://Archive.org\">Archive.org</a> snapshots of IBM\u2019s firmware pages</li> </ul> <p>I know the correct firmware file is something like:</p> <pre><code>HH_LTO_Gen_5.FC.H971 </code></pre> <p>(possibly found in <code>HHLTO5.bin</code> or <code>TapeHHLTO5-H971-01.rpm</code> packages).</p> <p>If anyone has a <strong>copy of the IBM LTO-5 HH FC firmware (H971 level)</strong> or knows where it can still be downloaded, I\u2019d really appreciate it.</p> <p>Drive details:</p> ",
        "id": 4058999,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ow0f0j/need_help_finding_firmware_for_ibm_46x2476_lto5",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help finding firmware for IBM 46X2476 (LTO-5 HH FC) tape drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DesperateSell1554",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T11:53:31.142259+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T11:09:09+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DesperateSell1554\"> /u/DesperateSell1554 </a> <br/> <span><a href=\"/r/buildapc/comments/1ovya3o/can_ptm_be_used_under_a_heat_sink_for_an_nvme/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovyc10/can_ptm_be_used_under_a_heat_sink_for_an_nvme/\">[comments]</a></span>",
        "id": 4058049,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovyc10/can_ptm_be_used_under_a_heat_sink_for_an_nvme",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can PTM be used under a heat sink for an NVME drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Key-Poetry5657",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T20:00:40.406952+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T10:19:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have been using wfdownloader to download my favorite Artists and cosplayers. But I kept the suspected botting message and kept doing it anyway so I got myself account banned. I can&#39;t just make new mail since there is a limit to how many sim you can purchase to one person. </p> <p>I want to ask people with large instagram wfdownloader list, How do you do it? Do you rotate the accounts cookie while scraping? </p> <p>I don&#39;t have to problem with X but there is sometime rating limiting I have beenn scraping too much but the problem I have with is X limiting how much you can scroll down to old accounts with many posts, they would just limit you. so I can&#39;t scrape accounts since their inception.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Key-Poetry5657\"> /u/Key-Poetry5657 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovxio1/instagram_downloading/\">[link]</a></span> &#32; <s",
        "id": 4062416,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovxio1/instagram_downloading",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Instagram downloading",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/__mongoose__",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T09:51:33.755117+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T09:42:39+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovwxur/to_public_domain_early_used_to_be_popular_stock/\"> <img src=\"https://preview.redd.it/xekozoy0wz0g1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=78919232315ddfb1b8cb0fdea166d7b2016e49e5\" alt=\"To public domain early ... used to be popular stock images in the 2010s, now in public domain.\" title=\"To public domain early ... used to be popular stock images in the 2010s, now in public domain.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://lb3d.co/archives/\">https://lb3d.co/archives/</a></p> <p>These are useful for everything from graphic design to games. Someone stated they are kind of like the vault boy in vibe (Fallout). <a href=\"https://lb3d.co/orange-man-sightings/\">These used to be all over the place.</a> I got a special thrill one day when I was playing EVE Online and saw an in-game corp using them.</p> <p>Have fun with them. No more restrictions. Animate them, modify them, and g",
        "id": 4057211,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovwxur/to_public_domain_early_used_to_be_popular_stock",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/xekozoy0wz0g1.jpeg?width=640&crop=smart&auto=webp&s=78919232315ddfb1b8cb0fdea166d7b2016e49e5",
        "title": "To public domain early ... used to be popular stock images in the 2010s, now in public domain.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/hollywoodhandshook",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T09:51:33.422125+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T09:31:10+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovwrse/a_13gb_zip_with_all_33572_images_from_the_epstein/\"> <img src=\"https://external-preview.redd.it/-E51aU_vgSHX_tlKt_GpJ1HkgYjlEtZiB0mPaCX8lAg.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2026c02aef35519d591cbe765e176cf9c42095fe\" alt=\"A 13GB zip with all 33,572 images from the Epstein doc dump, converted to pdf and OCR'd\" title=\"A 13GB zip with all 33,572 images from the Epstein doc dump, converted to pdf and OCR'd\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hollywoodhandshook\"> /u/hollywoodhandshook </a> <br/> <span><a href=\"https://archive.org/details/epstein-pdf\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovwrse/a_13gb_zip_with_all_33572_images_from_the_epstein/\">[comments]</a></span> </td></tr></table>",
        "id": 4057210,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovwrse/a_13gb_zip_with_all_33572_images_from_the_epstein",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/-E51aU_vgSHX_tlKt_GpJ1HkgYjlEtZiB0mPaCX8lAg.png?width=320&crop=smart&auto=webp&s=2026c02aef35519d591cbe765e176cf9c42095fe",
        "title": "A 13GB zip with all 33,572 images from the Epstein doc dump, converted to pdf and OCR'd",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Appropriate-Meal-422",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T09:51:34.243229+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T09:04:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So... I had this ancient Toshiba Satellite collecting dust - AMD E-240, 2GB RAM, 320GB HDD.</p> <p>I threw OpenMediaVault on it just for fun, and somehow it&#39;s been serving my movie collection for a month straight.</p> <p>No gigabit Ethernet, no fancy hardware, just pure stubbornness.</p> <p>It&#39;s actually working fine (??) which makes me both proud and slightly concerned</p> <p>I pulled the battery and it&#39;s been running 24/7 without a hiccup.</p> <p>Now I&#39;m wondering - should I just let this little survivor keep doing its thing, or is it time to get a cheap mini PC and retire the old beast before it catches fire or something?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Appropriate-Meal-422\"> /u/Appropriate-Meal-422 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovwdjq/my_frankenstein_nas/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comm",
        "id": 4057212,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovwdjq/my_frankenstein_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "My Frankenstein NAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Peter8File",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T08:50:58.604400+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T07:55:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So my external HDD started failing so I fetched all the data with TestDisk and Photorec.</p> <p>I want to delete all the duplicates in the Photorec recovery folder and add all its unique files to the testdisk folder. </p> <p>I have Ubuntu 24 lts as OS, and so far I&#39;ve tried several ways but nono worked. The last one is Czkawska, which keep finding new duplicates at every scan, even tho I delete them all every time. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Peter8File\"> /u/Peter8File </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovvb0o/apps_for_mergingsync_2_data_sets_on_linux/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovvb0o/apps_for_mergingsync_2_data_sets_on_linux/\">[comments]</a></span>",
        "id": 4056949,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovvb0o/apps_for_mergingsync_2_data_sets_on_linux",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Apps for merging/sync 2 data sets on Linux?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/QuestionAsker2030",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T07:50:21.392315+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T07:43:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I know in a ASRock B550 Pro4, ECC has been said to be supported, but it&#39;s not exactly official(?) like with a server grade motherboard. </p> <p>But people say it still works. </p> <p>Though just running the ECC confirmation test won&#39;t prove it&#39;ll actually fully work if there is a flipped bit, i.e. a real world scenario.</p> <p>Has anyone tested something like a ASRock B550 Pro4 + Ryzen 7 PRO 4750G, by forcing a flipped bit or something similar, to see if ECC fixes it and reports errors, and acts how ECC <em>should</em> act?</p> <p>-------------------</p> <p>Building my first TrueNAS and really trying to rack my brain around all this.</p> <p>I know I could get server grade, but trying to keep noise and energy costs down for my first build, if possible. (And cost, hence the mobo + cpu combo).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/QuestionAsker2030\"> /u/QuestionAsker2030 </a> <br/> <span><a hre",
        "id": 4056709,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovv4nn/truly_confirming_ecc_works_on_consumer_board_like",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Truly confirming ECC works on consumer board? (Like ASRock B550 Pro4)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Personal-Bet-3911",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T05:49:08.288950+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T05:24:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>24 in the front, 12 in the back and low profile MB setup. Something like <a href=\"https://www.alibaba.com/product-detail/Super-Big-Data-4U-Rack-Storage_60624379029.html?spm=a2700.galleryofferlist.normal_offer.d_image.2df013a0SZFENe&amp;priceId=2b15adc7df95452f90ce8ec2bf4eda23\">this</a>, anyone order one or know of anyone who has? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Personal-Bet-3911\"> /u/Personal-Bet-3911 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovstj4/seeing_some_4u_36_drive_hotswap_cases_on_alibaba/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovstj4/seeing_some_4u_36_drive_hotswap_cases_on_alibaba/\">[comments]</a></span>",
        "id": 4056195,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovstj4/seeing_some_4u_36_drive_hotswap_cases_on_alibaba",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seeing some 4U 36 drive hotswap cases on Alibaba. Anyone get one yet?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ebol4anthr4x",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T05:49:08.467956+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T05:23:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have my music library stored on my NAS and exposed over the network via an SMB share. This works great on Windows, which just seems to handle SMB shares well in general, so most media players just work.</p> <p>What clients do you recommend for MacOS and Android? I can&#39;t seem to find a good solution that supports streaming over SMB for either of these platforms. The best I&#39;ve found on MacOS is Swinsian, but it seems to struggle due to the way MacOS handles the SMB connection.</p> <p>Alternatively, if there is a better solution available for hosting my music library besides SMB, what do you recommend?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ebol4anthr4x\"> /u/ebol4anthr4x </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovssyc/mac_and_android_music_player_recommendations/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovssyc/mac_and_an",
        "id": 4056196,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovssyc/mac_and_android_music_player_recommendations",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Mac and Android music player recommendations?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/1sep1969",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T04:48:48.856913+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T03:59:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I know this topic has already been covered in the past on Reddit, but I&#39;m still a bit confused.</p> <p>I wanted to scan strictly old family pictures (60s to 90s) for archival purposes. I just need a scanner that scans very well and close to the original print (doesn&#39;t have to be super perfect like a pro). Is Epson Perfection V370 good enough for this purpose?</p> <p>Or will Perfection V550 or V600 scan them in significantly better quality? I read that V370 may not scan too well glossy pictures (etc), but I don&#39;t know if it&#39;s really something to be concerned about.</p> <p>Can we say that for photo prints, the difference between V370 and the other two in terms of quality is insignificant? Or it&#39;s still worth spending more for V550 or V600, for example?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/1sep1969\"> /u/1sep1969 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1o",
        "id": 4055908,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovr6ow/v370_vs_v600_question_about_scanning_old_family",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "V370 vs V600: Question about scanning old family photos for archival purposes",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Former_Argument3120",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T04:48:49.199736+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T03:50:39+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovr0k6/bent_metal_piece_on_a_helium_hdd/\"> <img src=\"https://b.thumbs.redditmedia.com/xtBws4cOnIM7SLJhmMBwJqeJE34e58fHZ2jdBGWgIms.jpg\" alt=\"Bent metal piece on a helium HDD\" title=\"Bent metal piece on a helium HDD\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I accidentally bent the metal flap on the top of a WD Ultrastar DC HC530 pulling it out of an enclosure (dumb, I know).</p> <p>Since this is a helium filled drive, is this a problem? Will it cause a leak? I\u2019m new to helium drives so my main concern is that this metal piece is part of the helium seal or related to its integrity.</p> <p>Any insight would be greatly appreciated.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Former_Argument3120\"> /u/Former_Argument3120 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1ovr0k6\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/commen",
        "id": 4055909,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovr0k6/bent_metal_piece_on_a_helium_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/xtBws4cOnIM7SLJhmMBwJqeJE34e58fHZ2jdBGWgIms.jpg",
        "title": "Bent metal piece on a helium HDD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Potential-Month-9695",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-13T04:48:49.481486+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-13T03:00:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Last year 8Tb Samsung QVOs were widely available for purchase, and cost around $900AUD. Now, the only place I can find them are one store in the US and they&#39;re $1300. What happened, is it just a temporary shortage? I really wanted to buy one for my 2 bay RAID to accompany the 8tb I already have so I can make a 16tb SSD RAID without having to reinvest in a new enclosure. Is noone manufacturing them anymore?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Potential-Month-9695\"> /u/Potential-Month-9695 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovpygu/are_there_gonna_be_more_8tb_sata_ssds/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ovpygu/are_there_gonna_be_more_8tb_sata_ssds/\">[comments]</a></span>",
        "id": 4055910,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ovpygu/are_there_gonna_be_more_8tb_sata_ssds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are there gonna be more 8tb SATA SSDs?",
        "vote": 0
    }
]