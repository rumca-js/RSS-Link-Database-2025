[
    {
        "age": null,
        "album": "",
        "author": "/u/Tomek839839",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T23:30:40.752151+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T23:05:06+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1oxbj2u/where_to_find_the_shelf_for_drives_like_in_this/\"> <img src=\"https://preview.redd.it/c2setmaiya1g1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=38b68c94c13bc282095639764d9f20d5dc2c101e\" alt=\"Where to find the shelf for drives like in this picture?\" title=\"Where to find the shelf for drives like in this picture?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I found this image in opinions of some SATA-USB adapter on a Polish online marketplace. I wonder, does such shelf have its specific name and where can I find and order such ones? Thanks for help in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tomek839839\"> /u/Tomek839839 </a> <br/> <span><a href=\"https://i.redd.it/c2setmaiya1g1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1oxbj2u/where_to_find_the_shelf_for_drives_like_in_this/\">[comments]</a></sp",
        "id": 4073230,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1oxbj2u/where_to_find_the_shelf_for_drives_like_in_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/c2setmaiya1g1.jpeg?width=640&crop=smart&auto=webp&s=38b68c94c13bc282095639764d9f20d5dc2c101e",
        "title": "Where to find the shelf for drives like in this picture?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LobsterTooButtery",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T22:30:02.734693+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T21:42:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i need around a dozen, idk if it&#39;s cheaper online somewhere compared to irl</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LobsterTooButtery\"> /u/LobsterTooButtery </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox9hhx/cheapest_place_to_buy_usb_flash_drives_in_europe/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox9hhx/cheapest_place_to_buy_usb_flash_drives_in_europe/\">[comments]</a></span>",
        "id": 4072837,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox9hhx/cheapest_place_to_buy_usb_flash_drives_in_europe",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "cheapest place to buy usb flash drives in europe?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cogitatingspheniscid",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T21:29:29.340537+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T21:15:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have some digital magazines that were purchased and become accessible only through Zinio. I want to get rid of the Zinio app to (1) downsize the number of apps in my machines, and (2) actually have a way to back up those issues locally.</p> <p>Most guides I have seen are for Zinio 4, and the one supposed tool (Zinigo) on GitHub has also been unmaintained for ~5 years, on top of being devoid of a GUI or instructions for non-coders.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cogitatingspheniscid\"> /u/cogitatingspheniscid </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox8su7/extract_zinio_files_to_pdf_for_storage/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox8su7/extract_zinio_files_to_pdf_for_storage/\">[comments]</a></span>",
        "id": 4072450,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox8su7/extract_zinio_files_to_pdf_for_storage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Extract Zinio files to pdf for storage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Overstimulated_moth",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T21:29:28.956667+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T20:47:33+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox8384/i_will_never_financially_recover_from_this/\"> <img src=\"https://preview.redd.it/qdm2waquba1g1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=58a08382de1c3b9e19ab0817ea6c1866f3a6af65\" alt=\"I will never financially recover from this\" title=\"I will never financially recover from this\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Just authorized payment on this bad boy. I feel like i just made one of the dumbest decisions of my life and have nobody to share this with that&#39;ll understand the love for hoarding data. This&#39;ll put me at just under 1.6PB</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Overstimulated_moth\"> /u/Overstimulated_moth </a> <br/> <span><a href=\"https://i.redd.it/qdm2waquba1g1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox8384/i_will_never_financially_recover_from_this/\">[comments]</a></s",
        "id": 4072449,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox8384/i_will_never_financially_recover_from_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/qdm2waquba1g1.jpeg?width=640&crop=smart&auto=webp&s=58a08382de1c3b9e19ab0817ea6c1866f3a6af65",
        "title": "I will never financially recover from this",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/VeryLargeCucumber",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T21:29:29.438150+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T20:28:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>About a year ago I was looking for a cheap NAS case that had specific requirements:</p> <ul> <li>At least 8 HDD slots</li> <li>mATX support</li> <li>Must not be ugly</li> <li>Must fit inside an Ikea Kallax shelf</li> </ul> <p>I found the <a href=\"https://caseend.com/data/space/space-sagittarius\">Space Sagittarius</a> which turned out to be a good fit. There are some reviews on reddit already:</p> <ul> <li><a href=\"https://old.reddit.com/r/DataHoarder/comments/1d0z2l3/sagittarius_nas_case_review_and_build_tips/\">Sagittarius NAS Case Review and Build Tips</a></li> <li><a href=\"https://old.reddit.com/r/homelab/comments/1nbjomz/my_new_homelab_with_the_8bay_sagittarius_case/\">My new homelab with the 8-bay Sagittarius case</a></li> <li><a href=\"https://old.reddit.com/r/HomeServer/comments/1ndo3pt/sagittarius_8bay_nas_case_installation_manual/\">Sagittarius 8-bay NAS case installation manual</a></li> </ul> <p>For reference, <a href=\"https://postimg.cc/n9fVTk4",
        "id": 4072451,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox7llg/ursa_minor_4bay_nas_case_a_quick_review",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ursa Minor 4-bay NAS case: a quick review",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Xiardark",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T19:27:07.172697+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T18:52:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Working on building an attachment device that will host a combination of 10 laptop DVD and Blu Ray drives. </p> <p>I have the drives, a repurposed USB cloning tower (gutted of all except the PSU). </p> <p>I\u2019m looking for a device that can receive SATA and connect via USB (A or C is fine). I saw a video that mentioned the iStarUSA ZAGE-D-ESAU3 device but couldn\u2019t locate them for sale. In the video the guy mentioned he had to use the eSATA port to a USB adapter, which is fine. </p> <p>Does anyone know of a similar device that would work with windows?</p> <p>Thank you in advance. </p> <p>Any</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Xiardark\"> /u/Xiardark </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox52ty/dvd_blu_ray_machine/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox52ty/dvd_blu_ray_machine/\">[comments]</a></span>",
        "id": 4071524,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox52ty/dvd_blu_ray_machine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "DVD & Blu Ray machine",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/octopusairplane",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T18:26:40.512480+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T18:07:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It got taken down. I found a remake of it in python. does anyone have a fork of the original or know where i can find it? why is it gone?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/octopusairplane\"> /u/octopusairplane </a> <br/> <span><a href=\"https://github.com/DvorakDwarf/Infinite-Storage-Glitch\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox3ui4/who_remembers_the_infinite_storage_glitch_from_a/\">[comments]</a></span>",
        "id": 4071082,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox3ui4/who_remembers_the_infinite_storage_glitch_from_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "who remembers the infinite storage glitch from a few years ago",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/pairabolics",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T18:26:40.607146+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T17:53:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I\u2019ve searched this sun\u2019s history and found a few posts that previously explored this. However, it seems that Patreon may have updated how they present videos because none of the options seem to work anymore.</p> <p>They seem to be splitting videos into multiple little portions (which would be tedious to download for 60m videos), and even these are not able to be downloaded using free 3rd parties I\u2019ve tried, or the terminal (suggestions from the post from 3 years ago).</p> <p>Anyone have suggestions? Even a trusted paid solution is welcome - but obviously preference for free.</p> <p>Thanks in advance </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/pairabolics\"> /u/pairabolics </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox3hiz/saving_patreon_videos_revisit/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox3hiz/saving_patreon_videos_revisit",
        "id": 4071083,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox3hiz/saving_patreon_videos_revisit",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Saving Patreon videos (revisit)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PoweredBy555",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T17:26:08.461717+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T17:20:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox2l1e/advice_on_digitizing_these_old_dc6150_data/\"> <img src=\"https://b.thumbs.redditmedia.com/qNRCTFGiP7L_TS_s2c4H8zeQgvnquJ93PqB27w55QoU.jpg\" alt=\"Advice on digitizing these old DC6150 data cartridge tapes found in the trash.\" title=\"Advice on digitizing these old DC6150 data cartridge tapes found in the trash.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I have recently come into possession of a large collection of tape drives from a recycling center. I thought they were interesting so I packed as many as I could and took the home. Does anyone have any advice on how I could possibly preserve these on IA? I would like to spend as little as possible and if someone else would like to take them off my hands i\u2019m okay with that too.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PoweredBy555\"> /u/PoweredBy555 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1o",
        "id": 4070474,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox2l1e/advice_on_digitizing_these_old_dc6150_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/qNRCTFGiP7L_TS_s2c4H8zeQgvnquJ93PqB27w55QoU.jpg",
        "title": "Advice on digitizing these old DC6150 data cartridge tapes found in the trash.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Pretty_Object5895",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T17:26:08.590622+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T17:20:00+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox2kwf/got_several_old_phones_that_still_power_on_is/\"> <img src=\"https://preview.redd.it/vj3woicta91g1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e1cd6f8d0793f423883aa6e3ae43f4b27d65de7b\" alt=\"Got several old phones that still power on is there anything I can extract or preserve?\" title=\"Got several old phones that still power on is there anything I can extract or preserve?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I have several old phones that still power on, including an Ericsson T206 that I think is pretty rare. Any advice on what\u2019s worth archiving and how to do it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Pretty_Object5895\"> /u/Pretty_Object5895 </a> <br/> <span><a href=\"https://i.redd.it/vj3woicta91g1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox2kwf/got_several_old_phones_that_still_power_on_is",
        "id": 4070475,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox2kwf/got_several_old_phones_that_still_power_on_is",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/vj3woicta91g1.jpeg?width=640&crop=smart&auto=webp&s=e1cd6f8d0793f423883aa6e3ae43f4b27d65de7b",
        "title": "Got several old phones that still power on is there anything I can extract or preserve?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/alpacaMyToothbrush",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T17:26:08.943584+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T16:37:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been thinking a while now about buying a NAS, but I&#39;m not sure if something like a uGreen NAS would actually meet my needs, I don&#39;t want to over pay, but I&#39;m also worried that it could get more expensive in the future (tariffs, DC demand)</p> <p>My needs:</p> <ul> <li>I want something that supports encryption</li> <li>I want something that can run a torrent client, jellyfin, and audioBookShelf</li> <li>I want something which can use a wireguard vpn, and lock traffic to that vpn</li> </ul> <p>I currently just host all this on an old laptop with a 1TB ssd, but I realize that&#39;s a flawed solution. I&#39;ve considered getting a NAS with 4x 12TB hdds and raid 5 (or whatever).</p> <p>So I guess, my questions:</p> <ol> <li> Would a reasonably priced consumer nas meet my needs? I&#39;m assuming I need something with enough hardware to run a number of docker containers</li> <li> Are NAS / HDD prices inflated now compared to 2024?</li> <",
        "id": 4070476,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox1f0d/to_nas_or_not_to_nas_needs_timing_and_hdd_prices",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "To NAS or not to NAS?: Needs, timing, and HDD prices",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/wespiard",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T16:25:28.473557+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T16:08:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am about to buy some high-capacity drives and the best deal I&#39;m finding now is this from SPD: <a href=\"https://serverpartdeals.com/products/seagate-exos-st26000nm000c-26tb-7-2k-rpm-sata-6gb-s-512e-cmr-3-5-recertified-hard-drive\">https://serverpartdeals.com/products/seagate-exos-st26000nm000c-26tb-7-2k-rpm-sata-6gb-s-512e-cmr-3-5-recertified-hard-drive</a></p> <p>$13.27/TB, 5-year warranty. </p> <p>I&#39;ve read around this subreddit and there are a lot of comments about these drives and the main concerns seem to be the lower specs (~190 MB/s speeds) and potentially lower reliability due to newer HAMR technology, etc. </p> <p>My current storage setup is a ZFS pool with 3-4 mirror vdevs and the main functionality is as a media server. So I don&#39;t think the lower sustained speeds will affect that, especially since these would just be one of the vdevs. </p> <p>Regarding the potential reliability issues, a 5-year warranty makes that less of a conc",
        "id": 4069880,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox0mea/exos_recertified_highcapacity_nm000c_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Exos Recertified High-capacity *NM000C Drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/WOLF_S10N3",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T16:25:28.942734+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T15:53:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I&#39;m completely new to ripping DVDs and 1080p blu rays, I&#39;m going to start ripping since I just got myself a dvd player to rip. While looking up how to use makemkv and jelly in server. I came across a video talking and setting up ARM on a Debian PC. I want to use my bazziteOS htpc to host my jellyfin server so I thought maybe I can run it on bazziteOS since it&#39;s in a docker container and I can use docker (or podman) on bazziteOS. But before I attempt it, has anyone tried running ARM on bazziteOS or Fedora 41+? I can also just run it on my Windows PC then just transfer the External Hard Drive to the bazziteOS PC.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/WOLF_S10N3\"> /u/WOLF_S10N3 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ox07g0/will_arm_automated_riping_machine_run_in_fedora_41/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments",
        "id": 4069882,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ox07g0/will_arm_automated_riping_machine_run_in_fedora_41",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Will ARM (Automated Riping Machine) run in Fedora 41+?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Powerful-Aspect-2760",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T16:25:28.596770+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T15:33:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, sorry if this has been asked before. I bought a DAS a couple of months ago, a TERRAMASTER D5-300. I have three different 3.5 hard drives in it. I have been turning it off when I don&#39;t use it. Roughly turn it on once a week to backup files. </p> <p>Today when I turned it on I couldn&#39;t access all of the files on it. So I turned off the DAS and then restarted my PC and during the start up it said it was repairing damaged files.</p> <p>So is this because I have been turning it off and should I leave it on from now on?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Powerful-Aspect-2760\"> /u/Powerful-Aspect-2760 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owzne1/das_turn_off_or_keep_on/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owzne1/das_turn_off_or_keep_on/\">[comments]</a></span>",
        "id": 4069881,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owzne1/das_turn_off_or_keep_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "DAS Turn off or keep on?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Artistic-Cap-1076",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T15:18:33.737184+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T15:05:00+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1owywbf/watching_ugreen_nas_for_a_while_and_this_early/\"> <img src=\"https://preview.redd.it/npzk7jggm81g1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0d29430bb018d4e9656262f27f09f262f0adbfe7\" alt=\"Watching UGREEN NAS for a while and this Early Bird drop got my attention\" title=\"Watching UGREEN NAS for a while and this Early Bird drop got my attention\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been circling around the idea of getting a NAS for months while rotating between a bunch of USB drives. Saw that the NASync DH4300 Plus is included in the Early Bird sale and it actually made me stop and reconsider my timing.</p> <p>Specs-wise it checks what I personally need: four bays, decent CPU, enough RAM for basic services, just something stable for a home setup.</p> <p>I&#39;m thinking of pairing it with a small UPS so I don&#39;t have to worry about sudden outages messing with the drives. Still",
        "id": 4069291,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owywbf/watching_ugreen_nas_for_a_while_and_this_early",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/npzk7jggm81g1.png?width=320&crop=smart&auto=webp&s=0d29430bb018d4e9656262f27f09f262f0adbfe7",
        "title": "Watching UGREEN NAS for a while and this Early Bird drop got my attention",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/i_xxy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T15:18:34.207258+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T15:03:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys I&#39;m not sure if this is the right place to ask but if you have any advice lmk! so amidst the new update where you have to pay for memories I would like to just download all of mine so I don&#39;t have to. I have two issues though, I&#39;m able to download the photos but i have to download them all separately and safari basically makes me verify each one even though l&#39;ve changed the settings to allow downloads. My second issue is that none of the photos have timestamps so l can&#39;t see when they were taken, from my research if I download the JSON file I can possibly attach the timestamps after? But I don&#39;t know how to do that and can&#39;t find any online tutorials for that. Has anyone had any success with this or is it even possible? Any help is greatly appreciated :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/i_xxy\"> /u/i_xxy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoar",
        "id": 4069292,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owyudh/help_with_downloading_snap_memories",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help with downloading snap memories",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/supermariojerma",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T15:18:34.581695+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T14:45:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hoping this is the right place to post this, I figure people here have experience with the subject. I&#39;m trying to find a &quot;good enough&quot; capture card. I&#39;m mostly trying to record from Hi8, VHS, and Betamax, all in composite RCA. I&#39;m looking for low budget and usb, since I&#39;m currently a student in a dorm with a macbook. Right now I have a cheap EasyCap usb, which doesn&#39;t even record in the right frame rate. </p> <p>I need something as cheap possible that will bare minimum give me the right fps, preferably no deinterlacing but thats less of an issue. What&#39;s recommended for this situation?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/supermariojerma\"> /u/supermariojerma </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owyddw/good_enough_composite_capture_device/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owyddw/goo",
        "id": 4069293,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owyddw/good_enough_composite_capture_device",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "\"Good Enough\" Composite Capture Device",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CartoonTRP",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T13:12:27.472295+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T12:50:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Often, when I&#39;m looking for information about old books or records, someone has put them up for sale and I can find some rudimentary information.</p> <p>Did they help write a scraping/archiving script?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CartoonTRP\"> /u/CartoonTRP </a> <br/> <span><a href=\"https://allegro.pl/pomoc/aktualnosci/zamkniemy-archiwum-allegro-O36m6egKPcm\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owvn8u/allegro_archive_will_be_vanished_pl/\">[comments]</a></span>",
        "id": 4068217,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owvn8u/allegro_archive_will_be_vanished_pl",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Allegro archive will be vanished [PL]",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/stormcomponents",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T13:12:27.142152+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T12:21:59+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1owv1jw/got_to_love_how_cheap_lto_tape_can_be/\"> <img src=\"https://preview.redd.it/ymbsrz95s71g1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8ba140e631563169b8a2ab7945b37cea99c2843d\" alt=\"Got to love how cheap LTO tape can be!\" title=\"Got to love how cheap LTO tape can be!\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I recently found some Sony LTO5 (1.5TB) tapes on eBay for \u00a31.50 each, and with a life-time warranty via &#39;Restore&#39;. Bought up 24x of them to fill my tape library, and removing the old set of 20 I had for archiving (pictured). Just over 60TB of usable tape storage, half of which is now in the attic for safe keeping. My library actually has an LTO6 drive in there, but for what storage I currently need and the cost of the tapes, I&#39;m happy with LTO5 for now.</p> <p>As much as I love the blinking lights on 2.5&quot; / 3.5&quot; media, nothing comes close to the satisfaction of tape",
        "id": 4068216,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owv1jw/got_to_love_how_cheap_lto_tape_can_be",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ymbsrz95s71g1.jpeg?width=640&crop=smart&auto=webp&s=8ba140e631563169b8a2ab7945b37cea99c2843d",
        "title": "Got to love how cheap LTO tape can be!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Georgy-H",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T12:11:32.859828+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T11:11:27+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1owtp1l/wait_what_wd_red_pro_spec_sheets/\"> <img src=\"https://preview.redd.it/qq2miq6gd71g1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c3d03f64829509db6e04747a4dfdca2c39ae96fa\" alt=\"Wait!? What?? - WD Red Pro spec sheets\" title=\"Wait!? What?? - WD Red Pro spec sheets\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Am I losing my mind here?? Is WD121KFBX air or helium filled?</p> <p>I have a few WD120EFBX, wanted to get more, and discovered (thanks to <a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4sp7m/mixing_wd_red_plus_wd120efbx_and_wd120efgx/\">this post</a>) that they are being replaced by WD120EFGX which are much louder (because air filled), a very important criteria for me.</p> <p>Looking up the specs of the Red Pro line, I see some drives being suitable for my needs, like WD121KFBX.</p> <p>But <a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/weste",
        "id": 4067781,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owtp1l/wait_what_wd_red_pro_spec_sheets",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/qq2miq6gd71g1.png?width=320&crop=smart&auto=webp&s=c3d03f64829509db6e04747a4dfdca2c39ae96fa",
        "title": "Wait!? What?? - WD Red Pro spec sheets",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Kitchen_Gold952",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T11:09:36.641128+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T10:49:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, i\u2019m new and decided to hoard now all my data now. I bought 2 bay DAS but still not sure if barracuda or ironwolf is better for my setup. </p> <p>I turned on my server in the morning and off it in the night to save some electricity. </p> <p>The price of drives are same in my area but still I am not knowledgeable in the world of HDD so I can\u2019t decide which is better for my setup. </p> <p>Please help me guys! Thanks! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kitchen_Gold952\"> /u/Kitchen_Gold952 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owtaw9/barracuda_or_ironwolf_same_price_for_das/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owtaw9/barracuda_or_ironwolf_same_price_for_das/\">[comments]</a></span>",
        "id": 4067353,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owtaw9/barracuda_or_ironwolf_same_price_for_das",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Barracuda or ironwolf? same price for DAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/blessedindomee",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T11:09:36.765449+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T10:34:03+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1owt1x5/is_this_ironwolf_pro_worth_to_buy/\"> <img src=\"https://b.thumbs.redditmedia.com/d8zMenW7m-51X5W_jES80tFYLFcR-fNvzuLnXWo-3kU.jpg\" alt=\"Is this ironwolf pro worth to buy?\" title=\"Is this ironwolf pro worth to buy?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking for a new HDD to store videos, images and documents. Im currently using WD My Passport Ultra 4tb and it started to fail.</p> <p>Im interested to buy ironwolf, and found this used ironwolf pro 4tb. You can see that the performance and health is still excellent. But, the power on time is 381 days and Total start/stop count is 3,510. The price is around $107, and the new one is $167. The warranty is still active until September 2027.</p> <p>Do you think this hdd wort to buy?</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/blessedindomee\"> /u/blessedindomee </a> <br/> <span><a href",
        "id": 4067354,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owt1x5/is_this_ironwolf_pro_worth_to_buy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/d8zMenW7m-51X5W_jES80tFYLFcR-fNvzuLnXWo-3kU.jpg",
        "title": "Is this ironwolf pro worth to buy?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SnooBananas1979",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T09:08:06.855207+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T09:05:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is dupeguru broken for anyone else? Happened a week ago. I get this error anytime I do an image search. The last update seems to be in 2022. Was the project abandoned?</p> <p>Application Name: dupeGuru</p> <p>Version: 4.3.1</p> <p>Python: 3.8.13</p> <p>Operating System: Windows-10-10.0.26200-SP0</p> <p>Traceback (most recent call last):</p> <p>File &quot;hscommon\\gui\\progress_window.py&quot;, line 107, in pulse</p> <p>File &quot;core\\app.py&quot;, line 332, in _job_error</p> <p>File &quot;hscommon\\jobprogress\\performer.py&quot;, line 46, in _async_run</p> <p>File &quot;core\\app.py&quot;, line 820, in do</p> <p>File &quot;core\\scanner.py&quot;, line 152, in get_dupe_groups</p> <p>File &quot;core\\pe\\scanner.py&quot;, line 27, in _getmatches</p> <p>File &quot;core\\pe\\matchblock.py&quot;, line 184, in getmatches</p> <p>File &quot;core\\pe\\matchblock.py&quot;, line 69, in prepare_pictures</p> <p>File &quot;core\\pe\\cache_shelve.py&quot;, line 128, in purge_o",
        "id": 4066669,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owrmm8/dupeguru_broken",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dupeguru broken?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Master-Gate2515",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T09:08:06.969783+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T08:57:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Recently i have seen an Post with 13GB of Epstein Files. What does this mean? I would really like to know, what happens if i torrent them? I hope there are only emails and Metadata or any logs inside. No pictures, that would be\u2026illegal ig (ofc because he rpd but yea idk)</p> <p>Thx in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Master-Gate2515\"> /u/Master-Gate2515 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owri67/is_this_safe/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owri67/is_this_safe/\">[comments]</a></span>",
        "id": 4066670,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owri67/is_this_safe",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is this safe?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/vw_bugg",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T09:08:07.144044+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T08:14:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Redoing my home server setup from scratch. Just bought an HP 800 g4. It has room for 2 hard drives and an ssd. Have an ssd coming already. I plan to set up a simple mirror between the two (unless there some recommendation im not aware of) and have an external run a backuo to periodically. Now its been a very long time since ive purchased loose hard drives and i have no idea whats good anymore. </p> <p>Need something quick quiet reliable and able to withstand the 24/7 in the home server. i guess what is the largest pair i can get and not break the budget? so many styles of each brand and most guids focus on lowest cost per tb. Thats all great if i had a higher budget. 200, i could maybe squeeze uo to 250 for the right amount of TB.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/vw_bugg\"> /u/vw_bugg </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owqusd/budget_200_total_for_pair_of_35_inte",
        "id": 4066671,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owqusd/budget_200_total_for_pair_of_35_internal_hard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Budget $200 total for pair of 3.5\" internal hard drives for home server",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BloomerBoomerDoomer",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T08:07:30.974940+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T07:35:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m using the Asus BW-16D1HT and the discs I&#39;m using to burn with are <a href=\"https://www.amazon.ca/dp/B00IMS58LI?ref=ppx_yo2ov_dt_b_fed_asin_title\"></a><a href=\"https://www.amazon.ca/dp/B00IMS58LI?ref=ppx_yo2ov_dt_b_fed_asin_title\">PLEXDISC 645-213 50 GB 6X Blu-ray Double Layer Recordable BD-R DL</a> , it&#39;s my first time burning media on it so please bear with me... Just wondered if I need a specialized program to burn with? I just used the Windows built in burner software.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BloomerBoomerDoomer\"> /u/BloomerBoomerDoomer </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owq8ub/im_trying_to_burn_a_bluray_disc_that_says_it_has/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owq8ub/im_trying_to_burn_a_bluray_disc_that_says_it_has/\">[comments]</a></span>",
        "id": 4066435,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owq8ub/im_trying_to_burn_a_bluray_disc_that_says_it_has",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I'm trying to burn a Bluray disc that says it has 50gb of storage but when I put something above 25gb it says it can't burn it?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Dyndunbun",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T07:07:03.177932+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T06:03:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was recently trying to find a video on YouTube only to find out that it&#39;s been deleted and nowhere to be found again anywhere else. I am certain the members of this sub all understand the feeling of grief and loss when things are lost to history and heart.</p> <p>But also while attempting to find the video I realized that a lot of the videos are served algorithmly and quite redundant without much choice. After a certain amount of scrolling you either no longer get relevant results or you reach the end of the page via rate limit even though there is an near infinite amount of content beyond. Especially older content that don\u2018t show up at all and can\u2018t be searched for either unless you already have it saved or have a link</p> <p>The same is true for Reddit. You can find top post for THIS month and THIS year but anything inbetween and anything beyond 1 year is effectively lost and inaccessible.</p> <p>Same for Twitter and Instagram unless you\u2019re se",
        "id": 4066178,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owoqei/is_there_any_way_to_reliably_scrape_old_posts_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there any way to reliably scrape old posts and video across different social media platforms?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/nailproblemZz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T06:06:32.341185+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T05:32:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all -- I&#39;ve decided as a beginner to homelab, I will use basic external deskop drives (Seagate? Western Digital). But does anyone know which ones will work with DriveDX for Mac disk health monitoring? Much appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nailproblemZz\"> /u/nailproblemZz </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owo6kj/mac_what_usb_external_hddssd_will_work_with/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owo6kj/mac_what_usb_external_hddssd_will_work_with/\">[comments]</a></span>",
        "id": 4065907,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owo6kj/mac_what_usb_external_hddssd_will_work_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Mac: What USB external HDD/SSD will work with DriveDX (Mac disk health monitoring)?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PomegranateBasic7388",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T06:06:32.673613+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T05:26:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I browse a local 2nd market and have been seeing hdd manufactured in 2016, 2012. It\u2019s crazy to me that people dare to put these on the market.</p> <p>I also have been to shops and many hdd are out of stock. I know AI data centers have been buying hdd but actually seeing the impact is wild.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PomegranateBasic7388\"> /u/PomegranateBasic7388 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owo31p/its_crazy_seeing_hdd_with_manufacturing_date/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owo31p/its_crazy_seeing_hdd_with_manufacturing_date/\">[comments]</a></span>",
        "id": 4065908,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owo31p/its_crazy_seeing_hdd_with_manufacturing_date",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "It\u2019s crazy seeing hdd with manufacturing date before 2016 on 2nd hand market",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MyNameCannotBeSpoken",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T04:05:30.238822+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T04:02:57+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1owmgyp/we_created_a_searchable_database_with_all_20000/\"> <img src=\"https://external-preview.redd.it/WbVbklmp26GVlx_tx-uXeH8j2FR6FoqVLX2tEsfXAY0.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e7a8f076e7a76ad559c00912ea404c1329099ee9\" alt=\"We created a searchable database with all 20,000 files from Epstein\u2019s Estate\" title=\"We created a searchable database with all 20,000 files from Epstein\u2019s Estate\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MyNameCannotBeSpoken\"> /u/MyNameCannotBeSpoken </a> <br/> <span><a href=\"https://couriernewsroom.com/news/we-created-a-searchable-database-with-all-20000-files-from-epsteins-estate/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owmgyp/we_created_a_searchable_database_with_all_20000/\">[comments]</a></span> </td></tr></table>",
        "id": 4065426,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owmgyp/we_created_a_searchable_database_with_all_20000",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/WbVbklmp26GVlx_tx-uXeH8j2FR6FoqVLX2tEsfXAY0.jpeg?width=640&crop=smart&auto=webp&s=e7a8f076e7a76ad559c00912ea404c1329099ee9",
        "title": "We created a searchable database with all 20,000 files from Epstein\u2019s Estate",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/hell-on-wheelz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T04:05:31.268538+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T03:22:55+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1owlnxg/would_you_accept_this_drive_from_amazon_or_send/\"> <img src=\"https://b.thumbs.redditmedia.com/KMoUBjkzvDW4GoM8W2IQ7z9lv3QXKVfZJR97r9RcJFc.jpg\" alt=\"Would you accept this drive from Amazon or send it back?\" title=\"Would you accept this drive from Amazon or send it back?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Ordered 2 hard drives, one from amazon and one from B&amp;H. This is how they shipped them. Do you think the retail box is enough protection for shipping? </p> <p>B&amp;H shipped bubble wrapped and in a box with additional wrap.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hell-on-wheelz\"> /u/hell-on-wheelz </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1owlnxg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owlnxg/would_you_accept_this_drive_from_amazon_or_send/\">[comments]</a></span> </td></tr></ta",
        "id": 4065427,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owlnxg/would_you_accept_this_drive_from_amazon_or_send",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/KMoUBjkzvDW4GoM8W2IQ7z9lv3QXKVfZJR97r9RcJFc.jpg",
        "title": "Would you accept this drive from Amazon or send it back?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Shift_Underscore",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T03:05:02.171466+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T02:53:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My current set up is to have an internal 4tb HDD with a cold backup using Robocopy to duplicate the drive. Unfortunately, my PC refused to boot properly and I had to power it off without getting into my OS.</p> <p>I have had a power outage scramble an HDD before, so I was afraid of this happening again. I had the idea to verify to run a Robocopy /L to list all the new/extra/different files, comparing my drive to its backup to validate that nothing was corrupted. And from what I saw, only files I know I changed or added since my last backup were listed.</p> <p>What do we think about using Robocopy for validation like this? Is there some reason this would be ineffective?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Shift_Underscore\"> /u/Shift_Underscore </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owl2a2/using_robocopy_to_verify_my_drive/\">[link]</a></span> &#32; <span><a href=\"https:",
        "id": 4065176,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owl2a2/using_robocopy_to_verify_my_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Using Robocopy to verify my drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Peter8File",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T03:05:01.929925+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T02:17:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I managed to recover most of my data from a faulty HD(I&#39;d preferred a total recovery tho, if you know any better could you suggest me?)</p> <p>Problem is there a lot of duplicates since I recovered the same data with 2 different app, testdisk(which is weaker but preserves filenames and folder structure) and photorec(more effective in theory, but doesn&#39;t preserve filenames and folder structure.).</p> <p>Moreover I had several copies of my original data for safety, so what was 50gb worth of data occupies now 500gb.</p> <p>I&#39;ve tried so far fdupes, jdupes, rsync and czawska 10.0, none of which worked properly (Czawska in particular proved to be dangerous since it marked as copy unique files)</p> <p>SPECS:</p> <ul> <li>OS: Ubuntu 24.04.3 LTS HD, FS ext4</li> <li>Faulty HD: Toshiba Canvio 1TB, FS ntfs</li> <li>Recovery SW: TestDisk 7.1, TestDisk 7.1.</li> <li>Merging SW: Czkawska 10.0</li> </ul> </div><!-- SC_ON --> &#32; submitted by &#32; ",
        "id": 4065175,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owkag7/how_to_recover_and_eliminate_duplicates_data_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to recover and eliminate duplicates data from a faulty HD on linux",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/siegevjorn",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T01:03:26.055174+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T00:33:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey folks,</p> <p>I got some question while eyeing on the recent barracuda 24tb drives deals:</p> <p><a href=\"https://www.newegg.com/seagate-barracuda-st24000dm001-24tb-for-daily-computing-7200-rpm/p/N82E16822185109\">https://www.newegg.com/seagate-barracuda-st24000dm001-24tb-for-daily-computing-7200-rpm/p/N82E16822185109</a></p> <p>So it seems that they have 1 out of 10<sup>14</sup> URE, which means 1 every 12.5TB:</p> <p><a href=\"https://www.seagate.com/content/dam/seagate/en/content-fragments/products/datasheets/barracuda-3-5-hdd/barracuda-3-5-hddDS2131-3-US2411-en_US.pdf\">https://www.seagate.com/content/dam/seagate/en/content-fragments/products/datasheets/barracuda-3-5-hdd/barracuda-3-5-hddDS2131-3-US2411-en_US.pdf</a></p> <p>Does it mean that there is at least one, and most likely two URE bound to happen even with Raid 1 (or ZFS mirror)? Because when reconstructing a mirroring drive, 24TB worth of data (almost 2*10<sup>14</sup> bits of data) need ",
        "id": 4064700,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owi15j/unrecoverable_error_need_to_spec_it_out_for_large",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Un-Recoverable Error: Need to spec it out for large drives? (10^14 vs 10^15)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/kyoanime3",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-14T01:03:26.351341+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-14T00:07:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys! So working on our usual archiving and backups , But does anyone have a way to archive ao3 if it\u2019s not already backed up? Been worried more lately about fan sites like that</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/kyoanime3\"> /u/kyoanime3 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owhfup/backing_up_ao3_and_other_fic_sites/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1owhfup/backing_up_ao3_and_other_fic_sites/\">[comments]</a></span>",
        "id": 4064701,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1owhfup/backing_up_ao3_and_other_fic_sites",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Backing up ao3 and other fic sites",
        "vote": 0
    }
]