[
    {
        "age": null,
        "album": "",
        "author": "/u/JasDawg",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T23:47:31.922892+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T23:10:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey folks! I hope this doesn&#39;t break any rules, but I don&#39;t think it will.</p> <p>I currently have lifetime subs to Althub, Ninja, Geek, Planet, and Crawler. I also have a sub to Slug. I&#39;ve tried many of the others and found that they don&#39;t pick up as much as my main indexers.</p> <p>I have not used Miatrix in the past because I don&#39;t believe their Member/VIP download and API limits are very good for their yearly price. </p> <p>Buuuut, I sort of want to add it to my Lifetime collection. Is that crazy? Are they good enough to warrant the price? I don&#39;t see much discussion of Miatrix on this sub.</p> <p>Anyway, thank you for any response!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JasDawg\"> /u/JasDawg </a> <br/> <span><a href=\"https://www.reddit.com/r/usenet/comments/1pawhjx/add_miatrix_to_my_collection_of_lifetime_subs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/u",
        "id": 4204086,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pawhjx/add_miatrix_to_my_collection_of_lifetime_subs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Add Miatrix to my collection of Lifetime subs?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/needjelprandolaxxoin",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T23:47:32.463880+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T23:09:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am setting up everything (new user) </p> <p>Provider Newshosting </p> <p>Do I need to get a second provider and if so which one you recommend ? </p> <p>Indexers: </p> <p>I want to pull the trigger on a couple of them Althub 20 lifetime Ninja central 50 lifetime Geek 60 lifetime Planet 30 lifetime Crawler 20 lifetime Drunkenslug 15 for 15 months </p> <p>Are any of these redundant I\u2019m thinking of getting 2-3 of them. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/needjelprandolaxxoin\"> /u/needjelprandolaxxoin </a> <br/> <span><a href=\"https://www.reddit.com/r/usenet/comments/1pawg0r/provider_and_indexer_advice/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/usenet/comments/1pawg0r/provider_and_indexer_advice/\">[comments]</a></span>",
        "id": 4204087,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pawg0r/provider_and_indexer_advice",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Provider and indexer advice",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Stephen1729",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T22:46:57.502565+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T21:53:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I can&#39;t login to Easynews today. I get an authentication failed message. So I try to change my password. Get a new password emailed to me (that&#39;s hope they do it) login with the new password. Itbworks. Then change the password to complex password of my own. That supposedly works. That new pasword then fails authentication. I have done this several times and I know I not making a mistake. </p> <p>I tried sending an email to support from the support web page. Does not work. When I press create ticket nothing happens. So I can&#39;t even get any support. </p> <p>Is Easynews having authetication problems? I have had an account for a while and never had issues like this before. Has anyone else seen this? </p> <p>This is all through the easynews web site not through a news application</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Stephen1729\"> /u/Stephen1729 </a> <br/> <span><a href=\"https://www.reddit.com/r/",
        "id": 4203845,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1paun7o/is_anyone_having_problems_logging_in_to_easynews",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is anyone having problems logging in to Easynews today?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Shack70",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T20:45:58.480340+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T20:10:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I just picked up a year on Newshosting and haven\u2019t used Usenet in 20ish years. I\u2019m not automating anything, just grabbing stuff as I want it. Do I need to buy an indexer too or am I good? Seems a bit overkill for my needs but I want some advice </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Shack70\"> /u/Shack70 </a> <br/> <span><a href=\"https://www.reddit.com/r/usenet/comments/1pas3bb/are_indexers_needed_for_casual_users/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/usenet/comments/1pas3bb/are_indexers_needed_for_casual_users/\">[comments]</a></span>",
        "id": 4203279,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pas3bb/are_indexers_needed_for_casual_users",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are Indexers Needed For Casual Users?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Tasty-Carbon",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T18:44:00.410405+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T18:17:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Got AltHub for my first indexer and looking to add more to it. Since Ninja and DS have BF sales going what should I get? Any other alternatives to these two that are just as good?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tasty-Carbon\"> /u/Tasty-Carbon </a> <br/> <span><a href=\"https://www.reddit.com/r/usenet/comments/1pap883/looking_for_second_indexer_to_add_to_althub/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/usenet/comments/1pap883/looking_for_second_indexer_to_add_to_althub/\">[comments]</a></span>",
        "id": 4202533,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pap883/looking_for_second_indexer_to_add_to_althub",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for second indexer to add to AltHub",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/-JustAsking4AFriend",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T13:25:32.563008+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T12:36:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello all, </p> <p>I did a search and didn&#39;t find anything conclusive, I&#39;m wondering what your suggestions are to get coverage of all the largest backbones for the highest completion rates? </p> <p>I understand that completion is highly subjective based on the groups and posts/post typs themselves, but I am wondering what the reddit hive mind opinion is..</p> <p>Using <a href=\"http://whatsmyuse.net\">whatsmyuse.net</a> I came up with a shortlist of</p> <ul> <li>Frugal Usenet (NetNews + Usenet.farm)</li> <li>Eweka (arguably the best option for Omicron)</li> <li>UsenetExpress (UsenetExpress) - Or possibly UsenetPrime to also get Abavia?</li> </ul> <p>I currently have Frugal, Eweka, and UsenetExpress and get good completion but am always looking for that extra edge for postings to some niche groups.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/-JustAsking4AFriend\"> /u/-JustAsking4AFriend </a> <br/> <span><",
        "id": 4200662,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pahadx/cheapest_coverage_of_all_backbones_for_highest",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cheapest coverage of all backbones for highest completions rates?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Illustrious_One_2403",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T10:07:08.495545+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T09:17:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone, Are you also having problems with tweaknews right now? I can&#39;t establish a connection. The VPN from privadovpn isn&#39;t working either.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Illustrious_One_2403\"> /u/Illustrious_One_2403 </a> <br/> <span><a href=\"https://www.reddit.com/r/usenet/comments/1pae0jx/newstweaknewseu_down/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/usenet/comments/1pae0jx/newstweaknewseu_down/\">[comments]</a></span>",
        "id": 4199708,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pae0jx/newstweaknewseu_down",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "news.tweaknews.eu down",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Seizy_Builder",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T04:42:10.812492+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T03:50:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Why do providers bundle VPN with their service? I thought using a VPN is pointless since we use an SSL connection to the servers.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Seizy_Builder\"> /u/Seizy_Builder </a> <br/> <span><a href=\"https://www.reddit.com/r/usenet/comments/1pa8frc/provider_vpn_bundles/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/usenet/comments/1pa8frc/provider_vpn_bundles/\">[comments]</a></span>",
        "id": 4198768,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pa8frc/provider_vpn_bundles",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Provider VPN bundles",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Kash_0",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T03:38:18.431379+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T02:56:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>DS is amazing for this and my primary indexer for manual downloads. Sadly, ninja doesn&#39;t have this. I have dog but also doesn&#39;t have it.</p> <p>Any good indexer with a preview?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kash_0\"> /u/Kash_0 </a> <br/> <span><a href=\"https://www.reddit.com/r/usenet/comments/1pa7dav/indexer_with_a_video_thumbnail_preview/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/usenet/comments/1pa7dav/indexer_with_a_video_thumbnail_preview/\">[comments]</a></span>",
        "id": 4198583,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pa7dav/indexer_with_a_video_thumbnail_preview",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Indexer with a video thumbnail preview?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Trick-Yogurtcloset45",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T01:32:16.218495+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T00:42:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have overseerr set up with Radarr and Sonarr and NZBGet with Newshosting.</p> <p>Normally everything works great except there are times when I choose a movie in Overseerr and NZBGet doesn&#39;t download it as if the movie isn&#39;t on Newshosting, but then if I do a manual search using the Newshosting app it finds the file. This happened just now with an Indian movie.</p> <p>Why is that, and is there settings I need to change?</p> <p>TIA</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Trick-Yogurtcloset45\"> /u/Trick-Yogurtcloset45 </a> <br/> <span><a href=\"https://www.reddit.com/r/usenet/comments/1pa4nky/file_not_found/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/usenet/comments/1pa4nky/file_not_found/\">[comments]</a></span>",
        "id": 4198122,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pa4nky/file_not_found",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "File not found",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/road_hazard",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T01:32:16.531012+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T00:38:19+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/usenet/comments/1pa4kfi/eweka_and_newsdemon_are_beyond_slow_at_the_moment/\"> <img src=\"https://b.thumbs.redditmedia.com/zfpQtbZnYKQ6re9qYn11uetad8ST9qzLMkuwEX9U1sM.jpg\" alt=\"Eweka and Newsdemon are beyond slow at the moment, anyone else?\" title=\"Eweka and Newsdemon are beyond slow at the moment, anyone else?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"http://Speedtest.net\">Speedtest.net</a> from the same PC maxes out my 1 gig fiber connection but both Usenet servers are crawling.</p> <p><a href=\"https://preview.redd.it/m8jh95jeia4g1.png?width=1284&amp;format=png&amp;auto=webp&amp;s=ea8f73090fdf04efa0adc4a0d3c7a4c4a6e16e27\">https://preview.redd.it/m8jh95jeia4g1.png?width=1284&amp;format=png&amp;auto=webp&amp;s=ea8f73090fdf04efa0adc4a0d3c7a4c4a6e16e27</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/road_hazard\"> /u/road_hazard </a> <br/> <span><a href=\"https://www.reddit.com/r",
        "id": 4198123,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pa4kfi/eweka_and_newsdemon_are_beyond_slow_at_the_moment",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/zfpQtbZnYKQ6re9qYn11uetad8ST9qzLMkuwEX9U1sM.jpg",
        "title": "Eweka and Newsdemon are beyond slow at the moment, anyone else?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Retooned_yt",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T00:24:28.909312+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T00:17:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am working on trying to create a new indexer i have tried to do as best as i can using the scripts available on GitHub as reference i have managed to make a site and indexer using Node.js using the tailwind CSS framework to keep it clean and mobile friendly as possible</p> <p>Currently everything is working perfect from registrations to invoicing i have created a system that support multiple Usenet servers in the backend with distributed load balancing between them when scanning.</p> <p>it is currently scanning and picking up complete Binaries but my problem starts when it comes to trying to gather all the information needed to extract proper names especially from obfuscated posts </p> <p>i plan on using TMDB for movie and TV show information i have a paid developer API from them, i use in other projects i also have an API for the game database to grab game information from them for my metadata, but this is unless if i can&#39;t get it to parse the ",
        "id": 4197912,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pa4409/creating_a_new_indexer_in_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Creating A New Indexer in 2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Eraldorh",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-11-30T00:24:29.260404+00:00",
        "date_dead_since": null,
        "date_published": "2025-11-30T00:08:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Does anyone know if you can stack block accounts? like if i buy 2 12tb blocks will they stack?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Eraldorh\"> /u/Eraldorh </a> <br/> <span><a href=\"https://www.reddit.com/r/usenet/comments/1pa3x9q/bulknews_block_accounts/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/usenet/comments/1pa3x9q/bulknews_block_accounts/\">[comments]</a></span>",
        "id": 4197913,
        "language": "en",
        "link": "https://www.reddit.com/r/usenet/comments/1pa3x9q/bulknews_block_accounts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 550,
        "source_url": "https://www.reddit.com/r/usenet/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Bulknews block accounts",
        "vote": 0
    }
]