[
    {
        "age": null,
        "album": "",
        "author": "IBM Technology",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-07T18:27:41.729380+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-07T16:30:10+00:00",
        "description": "AI agents can plan, but they need a human in the loop to avoid chaos (and tungsten cubes). The future is hybrid and hilariously imperfect.\n\n#ai #aiagents",
        "id": 3106242,
        "language": null,
        "link": "https://www.youtube.com/shorts/VDF82wabPkg",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 432,
        "source_url": "https://www.youtube.com/feeds/videos.xml?channel_id=UCKWaEZ-_VweaEx1j62do_vQ",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://i3.ytimg.com/vi/VDF82wabPkg/hqdefault.jpg",
        "title": "AI agents needs supervision",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "IBM Technology",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-07T15:41:58.338114+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-07T13:33:40+00:00",
        "description": "Ready to become a certified watsonx AI Assistant Engineer? Register now and use code IBMTechYT20 for 20% off of your exam \u2192 https://ibm.biz/BdeBdr\n\nLearn more about Attention Mechanism here \u2192 https://ibm.biz/BdeBdj\n\nImagine AI models swapping skills like a game console loading new cartridges \ud83c\udfae. Aaron Baughman explains how attention mechanisms and ALoRA enable large language models (LLMs) to adapt dynamically using techniques like key-value caching and flash attention. \ud83d\ude80 Explore the cutting edge of scalable AI innovation!\n\nAI news moves fast. Sign up for a monthly newsletter for AI updates from IBM \u2192 https://ibm.biz/BdeBdY",
        "id": 3104606,
        "language": null,
        "link": "https://www.youtube.com/watch?v=qmUWsFCnsz4",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 432,
        "source_url": "https://www.youtube.com/feeds/videos.xml?channel_id=UCKWaEZ-_VweaEx1j62do_vQ",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://i2.ytimg.com/vi/qmUWsFCnsz4/hqdefault.jpg",
        "title": "Hot Swapping AI Skills: Attention Mechanisms & ALoRA Explained",
        "vote": 0
    }
]