[
    {
        "age": null,
        "album": "",
        "author": "/u/GullibleEngineer4",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-01T21:29:47.625493+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-01T21:24:45+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1lpdxfw/trapping_misbehaving_bots_in_ai_generated_content/\"> <img src=\"https://external-preview.redd.it/95sakwUZ5niLE_EWLolYQjAnnYNytF-BKXNVW6552DU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cf9360cf4fbeda4707023792c950bbab4f44e2b4\" alt=\"Trapping misbehaving bots in AI generated content\" title=\"Trapping misbehaving bots in AI generated content\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GullibleEngineer4\"> /u/GullibleEngineer4 </a> <br/> <span><a href=\"https://blog.cloudflare.com/ai-labyrinth/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lpdxfw/trapping_misbehaving_bots_in_ai_generated_content/\">[comments]</a></span> </td></tr></table>",
        "id": 3062576,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lpdxfw/trapping_misbehaving_bots_in_ai_generated_content",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/95sakwUZ5niLE_EWLolYQjAnnYNytF-BKXNVW6552DU.png?width=640&crop=smart&auto=webp&s=cf9360cf4fbeda4707023792c950bbab4f44e2b4",
        "title": "Trapping misbehaving bots in AI generated content",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Strong-Explorer-6927",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-01T20:26:12.443501+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-01T15:15:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to enter a Half Marathon and have a scraper using Home Assistant&#39;s &quot;Scrape&quot; integration.</p> <p>I am checking this website (<a href=\"https://secure.onreg.com/onreg2/bibexchange/?eventid=6736&amp;language=us\">https://secure.onreg.com/onreg2/bibexchange/?eventid=6736&amp;language=us</a>) every 15 seconds and when notified of a new ticket I am there within 60 seconds. The problem is the ticket is always (In Progress) so someone has got there first.</p> <p>My question is: Are there some more effective techniques to check website or the data behind it or are they just in progress before they are even posted?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Strong-Explorer-6927\"> /u/Strong-Explorer-6927 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lp4aa4/available_tickets_always_gone_by_the_time_i_get/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com",
        "id": 3060195,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lp4aa4/available_tickets_always_gone_by_the_time_i_get",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Available tickets always gone by the time I get there",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/madredditscientist",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-01T20:26:12.054415+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-01T14:49:27+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1lp3mf0/cloudflare_to_introduce_paypercrawl_for_ai_bots/\"> <img src=\"https://external-preview.redd.it/tG0tHVEzt3GiPv1qKZJjofKJfzW4kvsoTiVYC0T1HTU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d1950acc8f8068749a76cfe85b285b4ba461ee8d\" alt=\"Cloudflare to introduce pay-per-crawl for AI bots\" title=\"Cloudflare to introduce pay-per-crawl for AI bots\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/madredditscientist\"> /u/madredditscientist </a> <br/> <span><a href=\"https://blog.cloudflare.com/introducing-pay-per-crawl/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lp3mf0/cloudflare_to_introduce_paypercrawl_for_ai_bots/\">[comments]</a></span> </td></tr></table>",
        "id": 3060193,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lp3mf0/cloudflare_to_introduce_paypercrawl_for_ai_bots",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/tG0tHVEzt3GiPv1qKZJjofKJfzW4kvsoTiVYC0T1HTU.png?width=640&crop=smart&auto=webp&s=d1950acc8f8068749a76cfe85b285b4ba461ee8d",
        "title": "Cloudflare to introduce pay-per-crawl for AI bots",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/chemoltv",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-01T20:26:12.638432+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-01T14:46:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, recently I&#39;ve dabbled a lot in the world of sports gambling scraping, most of the sites use some kind of REST/WebSocket API which I understand, but a lot of sites also use gRPC Web, and the sites&#39; APIs I&#39;m trying to crack make me go insane, no matter how many tutorials and chatbots I use, I just can&#39;t figure them out.</p> <p>Can you give me an example of a website that uses protobufs/grpc and is relatively easy to figure out? Or some good resources which will explain how this all works from the basics?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/chemoltv\"> /u/chemoltv </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lp3jln/where_to_learn_protobufsgrpc/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lp3jln/where_to_learn_protobufsgrpc/\">[comments]</a></span>",
        "id": 3060196,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lp3jln/where_to_learn_protobufsgrpc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Where to learn protobufs/grpc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Empty_Hospital7434",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-01T20:26:12.877846+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-01T13:39:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Any ideas how to monitor amazon for restocks?</p> <p>They dont use any public (from what i can see) http requests.</p> <p>Only tip iv been given is to perform an action that only succeeds if an item is in stock.</p> <p>Iv tried constantly adding to cart, but this doesnt seem to work or is very slow.</p> <p>Any ideas? Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Empty_Hospital7434\"> /u/Empty_Hospital7434 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lp1xp4/amazon_restock_monitor/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lp1xp4/amazon_restock_monitor/\">[comments]</a></span>",
        "id": 3060197,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lp1xp4/amazon_restock_monitor",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Amazon restock monitor",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-01T20:26:11.849803+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-01T13:01:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels\u2014whether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>If you&#39;re new to web scraping, make sure to check out the <a href=\"https://webscraping.fyi\">Beginners Guide</a> \ud83c\udf31</p> <p>Commercial products may be mentioned in replies. If you want to promote your own products and services, continue to use the <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">monthly thread</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 3060192,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lp130x/weekly_webscrapers_hiring_faqs_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weekly Webscrapers - Hiring, FAQs, etc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/junai-",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-01T20:26:12.244923+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-01T12:33:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been using the <code>requests</code> module and <code>http.client</code> for web scraping for a while, but I&#39;m looking to upgrade to more advanced or modern packages to better handle bot detection mechanisms. I&#39;m aware that websites implement various measures to detect and block bots and I&#39;m interested in hearing about any Python packages or tools that can help bypass these detections effectively.</p> <p>looking for normal request package and framework not any browser frameworks </p> <p>What libraries or frameworks do you recommend for web scraping ? Any tips on using these tools to avoid getting blocked or flagged?</p> <p>looking for normal request package and framework not any browser frameworks</p> <p>Would love to hear about your experiences and suggestions!</p> <p>Thanks in advance! \ud83d\ude0a</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/junai-\"> /u/junai- </a> <br/> <span><a href=\"https://www",
        "id": 3060194,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lp0gus/discussion_alternate_for_request_httpclient_module",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[Discussion] Alternate for request & httpclient module",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-01T03:09:44.788609+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-01T03:00:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello and howdy, digital miners of r/webscraping!</p> <p>The moment you&#39;ve all been waiting for has arrived - it&#39;s our once-a-month, no-holds-barred, show-and-tell thread!</p> <ul> <li>Are you bursting with pride over that supercharged, brand-new scraper SaaS or shiny proxy service you&#39;ve just unleashed on the world?</li> <li>Maybe you&#39;ve got a ground-breaking product in need of some intrepid testers?</li> <li>Got a secret discount code burning a hole in your pocket that you&#39;re just itching to share with our talented tribe of data extractors?</li> <li>Looking to make sure your post doesn&#39;t fall foul of the community rules and get ousted by the spam filter?</li> </ul> <p>Well, this is your time to shine and shout from the digital rooftops - Welcome to your haven!</p> <p>Just a friendly reminder, we like to keep all our self-promotion in one handy place, so any promotional posts will be kindly redirected here. Now, let&#39;s get ",
        "id": 3057802,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1loqzmm/monthly_selfpromotion_july_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Monthly Self-Promotion - July 2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jomjesse",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-01T02:04:37.351865+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-01T00:17:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m fairly new to web scraping so looking for knowledge, advice, etc. I&#39;m building a program that I want to be able to give a device model number to (toaster oven, washing machine, TV, etc.) and it returns the closest PDF it can find to that device and model number. I&#39;ve been looking at the basics of scraping with Playwright but keep running into bot blockers when trying to access any sites. I just want to be able to get to the URLs of PDFs on these sites so I can reference them from my program, not download the PDF or anything. </p> <p>Whats the best way to go about this? Any recommendations on products I should use or general frameworks on collecting this information. Open to recommendations to get me going to learn more about this. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jomjesse\"> /u/jomjesse </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lonpbe/scraping_for_devi",
        "id": 3057550,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lonpbe/scraping_for_device_manual_pdfs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping for device manual PDFs",
        "vote": 0
    }
]