[
    {
        "age": null,
        "album": "",
        "author": "/u/falling-waters",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T23:31:58.061846+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T23:20:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m a private user who has never backed up a PC before. I got a pretty severe BSOD last week, most likely from recently upgraded hardware, and have to take precautions while I run tests. </p> <p>I want to exclude my massive amount of installed games. I know Macrium can do this but as far as I can tell the ability to install the free version has finally been killed.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/falling-waters\"> /u/falling-waters </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2ml7o/looking_for_a_free_macrium_reflect_alternative_to/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2ml7o/looking_for_a_free_macrium_reflect_alternative_to/\">[comments]</a></span>",
        "id": 3193137,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2ml7o/looking_for_a_free_macrium_reflect_alternative_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a free Macrium Reflect alternative to disk image backups that allows for exceptions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PrivacyPolicyRead",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T23:31:57.811280+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T23:09:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey DataHoarders,</p> <p>I built a small linux CLI tool in Python called <strong>remap-badblocks</strong>. It scans a block device for bad sectors and creates a device-mapper that skips them. It also reserves extra space to remap future badblocks dynamically.</p> <p>Useful if you want to keep using slightly-damaged drives without losing data or dealing with manual remapping.</p> <p>Check it out:</p> <ul> <li>GitLab: <a href=\"https://gitlab.com/Luigi-98/remap_badblocks\">https://gitlab.com/Luigi-98/remap_badblocks</a></li> <li>PyPI: <code>pip install remap-badblocks</code></li> </ul> <p>Would love feedback, bug reports, contributions, help shaping the roadmap or even rethinking everything all over again!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PrivacyPolicyRead\"> /u/PrivacyPolicyRead </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2mcod/remapbadblocks_give_your_damaged_drives_a_sec",
        "id": 3193136,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2mcod/remapbadblocks_give_your_damaged_drives_a_second",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "remap-badblocks \u2013 Give your damaged drives a second life (and help improve the tool!)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/irresponsiblehippo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T23:31:58.776110+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T22:41:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi DataHoarder,</p> <p>I&#39;m wondering if you have any advice on the largest 5,400 RPM (5,900 RPM is probably fine as well) CMR drive that has a single platter.</p> <p>My reasoning is that a single platter should use the least power. My storage needs are not tremendous, so wondering what options I would have in this camp. Wanting to use these in a software raid 1 setup.</p> <p>I&#39;d like a reputable drive, although I suspect these single platter drives are tested a bit less than the multi-platter drives.</p> <p>It sounds like the WD Red Plus 2TB is a single platter, but I haven&#39;t found tons of information on it. If I went for a RE4 drive, not GP, it&#39;d be 7,200 RPM and I&#39;d only get a single platter at 500GB. Which is maybe fine for some servers, but not others.</p> <p>Thank you!</p> <p>Related: <a href=\"https://rml527.blogspot.com/\">https://rml527.blogspot.com/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.r",
        "id": 3193139,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2low3/largest_single_platter_5400_rpm_cmr_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Largest single platter 5,400 RPM CMR drives available",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PubicPlant",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T21:17:57.850522+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T21:12:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I really like the idea of having a fast thumb drive sized external SSD (I use my laptop on the couch a lot and have accidentally unplugged my cable multiple times) but all of the 2230 NVME small enclosures I\u2019ve found max out around 1 Gb/s.</p> <p>Why are they so much slower compared to larger enclosures? And are there any small enclosures (preferably with built-in male port) that are faster than 1 Gb/s?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PubicPlant\"> /u/PubicPlant </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2jiz0/m2_2230_nvme_ssd_enclosures/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2jiz0/m2_2230_nvme_ssd_enclosures/\">[comments]</a></span>",
        "id": 3192278,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2jiz0/m2_2230_nvme_ssd_enclosures",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "M.2 2230 NVMe SSD Enclosures?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Erykus102938",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T23:31:58.270306+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T20:45:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, as a game dev I need a good way to store my files in a good and secure way. I prefer it to be physical storage like an HDD or USB stick (however I&#39;ve read that USBs can lose data over time). I would backup my game once every 2 days to not lose progress in case my PC gets damaged or something else happenes. Any recommendations?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Erykus102938\"> /u/Erykus102938 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2itum/whats_the_best_way_to_store_backup_files/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2itum/whats_the_best_way_to_store_backup_files/\">[comments]</a></span>",
        "id": 3193138,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2itum/whats_the_best_way_to_store_backup_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's the best way to store backup files?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sushi-And-The-Beast",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T20:10:24.383764+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T19:56:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need to convert 2GBs of EML/MSG emails to PDF.</p> <p>I have Stirling PDF Setup and Paperless but they dont support EML and MSG files.</p> <p>I have the PST files as well.</p> <p>Any ideas?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sushi-And-The-Beast\"> /u/Sushi-And-The-Beast </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2hl2i/eml_or_msg_to_pdf/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2hl2i/eml_or_msg_to_pdf/\">[comments]</a></span>",
        "id": 3191840,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2hl2i/eml_or_msg_to_pdf",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "EML or MSG TO PDF",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheSpacePope42",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T20:10:24.553869+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T19:30:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Ok heres the situation.<br/> I presently have a 70tb data load and growing.<br/> Presently I am running a PCIE RAID controller and 8 10tb platter drives.<br/> As you can imagine building and growing this array from machine to machine is getting tricky. </p> <p>I am looking for an external DAS solution that can be more portable, especially as I am staring down the barrel of needing to make some upgrades as Win11 refuses to allow for the use of the 1st gen threadripper chips. </p> <p>My limitations are as follows:<br/> Needs hardware RAID ( I simply dont like software raid and this complicates portability)<br/> Must register to the OS as an internal or external hard drive and not as a Network Drive or USB Flash drive. (limitation of my backup software/service)<br/> Must run on desktop Windows OS, not server (another limitation of the backup product)</p> <p>I have been looking at the Qnap TL-D800C-US which appears to be USB connected and the TL-D1600S-US",
        "id": 3191841,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2gx8t/looking_for_a_reliable_das_solution",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a reliable DAS solution.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ReallyBugged0ut",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T19:05:14.153859+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T18:44:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2fpn7/senate_votes_to_kill_entire_public_broadcasting/\"> <img src=\"https://external-preview.redd.it/DvWSg6nI_PpGIYjGKq7f_C4AYdtZ5KJlu3_Q8liCQAE.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1b6d171b71bcfd4d295c48f9319771c08d767210\" alt=\"Senate votes to kill entire public broadcasting budget in blow to NPR and PBS\" title=\"Senate votes to kill entire public broadcasting budget in blow to NPR and PBS\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ReallyBugged0ut\"> /u/ReallyBugged0ut </a> <br/> <span><a href=\"https://arstechnica.com/tech-policy/2025/07/senate-votes-to-kill-entire-public-broadcasting-budget-in-blow-to-npr-and-pbs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2fpn7/senate_votes_to_kill_entire_public_broadcasting/\">[comments]</a></span> </td></tr></table>",
        "id": 3191332,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2fpn7/senate_votes_to_kill_entire_public_broadcasting",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/DvWSg6nI_PpGIYjGKq7f_C4AYdtZ5KJlu3_Q8liCQAE.jpeg?width=640&crop=smart&auto=webp&s=1b6d171b71bcfd4d295c48f9319771c08d767210",
        "title": "Senate votes to kill entire public broadcasting budget in blow to NPR and PBS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Francisco_Mlg",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T19:05:15.271123+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T18:41:55+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2fnlg/was_wondering_why_my_2tb_ssd_only_had_90gb_left/\"> <img src=\"https://preview.redd.it/r7plcgzibhdf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=98660638f271d693e5ff1aa3be9ecd61f44ae8d4\" alt=\"Was wondering why my 2TB SSD only had 90GB left...\" title=\"Was wondering why my 2TB SSD only had 90GB left...\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Francisco_Mlg\"> /u/Francisco_Mlg </a> <br/> <span><a href=\"https://i.redd.it/r7plcgzibhdf1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2fnlg/was_wondering_why_my_2tb_ssd_only_had_90gb_left/\">[comments]</a></span> </td></tr></table>",
        "id": 3191335,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2fnlg/was_wondering_why_my_2tb_ssd_only_had_90gb_left",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/r7plcgzibhdf1.png?width=640&crop=smart&auto=webp&s=98660638f271d693e5ff1aa3be9ecd61f44ae8d4",
        "title": "Was wondering why my 2TB SSD only had 90GB left...",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fractal-Infinity",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T19:05:14.592322+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T18:24:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I consider a WD Red Plus 4TB to be pretty quiet, so that&#39;s the baseline. I bought the 8TB version and it was significantly louder and annoying, so I relegated it as a backup drive. I don&#39;t really care about the performance, since it will be mostly idle and used to store media files. I&#39;d prefer either WD or Seagate. I&#39;m using it for a desktop PC (inside its case), so that&#39;s why it needs to be quiet.</p> <p>Edit: thoughts on <a href=\"https://www.westerndigital.com/products/internal-drives/wd-blue-desktop-sata-hdd?sku=WD80EAAZ\">this WD Blue 8TB CMR</a> (WD80EAAZ)?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Fractal-Infinity\"> /u/Fractal-Infinity </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2f6ss/im_looking_for_a_quiet_8tb_internal_hdd_cmr/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2f6ss/im_looking_for_a_quiet_8tb_inter",
        "id": 3191333,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2f6ss/im_looking_for_a_quiet_8tb_internal_hdd_cmr",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I'm looking for a quiet 8TB internal HDD (CMR)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NewsFromHell",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T19:05:14.762863+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T18:13:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My 6TB Toshiba X300 is so loud during read/writes that I can&#39;t be in the same room. I&#39;m looking to upgrade to a 16-25TB drive for general media storage, downloading, and streaming, but noise is my #1 concern.</p> <p>What are the quietest drives in this size range based on your real-world experience? I&#39;ve heard helium drives are better. Are models like the WD Red Pro or Seagate IronWolf Pro any good for quiet operation?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NewsFromHell\"> /u/NewsFromHell </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2ew59/looking_for_a_quiet_1426tb_hdd_my_toshiba_x300_is/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2ew59/looking_for_a_quiet_1426tb_hdd_my_toshiba_x300_is/\">[comments]</a></span>",
        "id": 3191334,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2ew59/looking_for_a_quiet_1426tb_hdd_my_toshiba_x300_is",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a QUIET 14-26TB HDD. My Toshiba X300 is driving me insane.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PhilipRiversCuomo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T18:00:15.641688+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T17:52:36+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2echq/a_decade_strong_shout_out_to_wd/\"> <img src=\"https://preview.redd.it/iv3ffis12hdf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=28a9fed71245773d6dc1891b407e293b29438d87\" alt=\"A decade strong! Shout out to WD.\" title=\"A decade strong! Shout out to WD.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Bought this WD Red 3TB in 2015 for $219. A decade straight of non-stop uptime for personal NAS and Plex server duty, with nary a hiccup. She&#39;s still going strong, I just ran out of space and my JBOD enclosure is out of empty drive bays. Replaced with a 20TB WD from serverpartdeals for $209, what a time to be alive!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PhilipRiversCuomo\"> /u/PhilipRiversCuomo </a> <br/> <span><a href=\"https://i.redd.it/iv3ffis12hdf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2echq/a_de",
        "id": 3190769,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2echq/a_decade_strong_shout_out_to_wd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/iv3ffis12hdf1.jpeg?width=640&crop=smart&auto=webp&s=28a9fed71245773d6dc1891b407e293b29438d87",
        "title": "A decade strong! Shout out to WD.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ChoiceDirect",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T18:00:16.058950+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T17:48:38+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ChoiceDirect\"> /u/ChoiceDirect </a> <br/> <span><a href=\"/r/homelab/comments/1m2e7c4/pm1725b_and_intel_4608/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2e8ri/pm1725b_and_intel_4608/\">[comments]</a></span>",
        "id": 3190770,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2e8ri/pm1725b_and_intel_4608",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Pm1725b and Intel 4608",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/randopop21",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T18:00:16.267146+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T17:43:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Way back, RAID controllers could notify you via an email that there was a disk failure or that your RAID array was in jeopardy.</p> <p>Today, IT is just a hobby for me and I have a bunch of ex-corporate PCs at home that are SSD boot/primary drive + a small SATA drive. </p> <p>I use the small SATA drive to hold periodic image backups of the SSD primary drive so that if there is ever a catastrophic failure of the SSD, I can plop in a new one and reimage it and carry on. (I realize that I could image them to a shared drive on the network but the ex-corp PCs each have a 500GB SATA drive in them already and so why not use them.)</p> <p>This backup/recovery scheme does require that the small SATA drive is working properly and has been receiving the periodic SSD images.</p> <p>With just the motherboard SATA chipset and sata controller of the ex-corp PC, is there a way to receive a notification that something has or is about to go wrong?</p> <p>I want the sam",
        "id": 3190771,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2e46a/how_to_get_notified_of_either_a_hard_disk_failure",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to get notified of either a hard disk failure or, better, a hard drive that's about to fail?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mikestergame01",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T18:00:16.437702+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T17:26:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been storing stuff on mega creating a bunch of free accounts and had no real problems till today. Megabasterd all of a sudden will upload the file then at the end after it&#39;s done give me &quot;Fatal Error! Mega API Error: -2&quot; It&#39;ll create the folder in the mega account but the files do not upload. I can upload them manually just fine. Anyone else having a problem with Megabasterd to upload files?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mikestergame01\"> /u/mikestergame01 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2dnjv/megabasterd_can_no_longer_upload_files/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2dnjv/megabasterd_can_no_longer_upload_files/\">[comments]</a></span>",
        "id": 3190772,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2dnjv/megabasterd_can_no_longer_upload_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Megabasterd can no longer upload files",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Shane57F1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T18:00:16.607219+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T17:03:20+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2d1tr/help_do_i_need_to_return_these_hard_drives/\"> <img src=\"https://b.thumbs.redditmedia.com/fIME_23Ae51ywDdP-Cz_aAHgER7F8ZZPF9LNlPe6XFk.jpg\" alt=\"Help - Do I need to return these Hard Drives? Reallocated Sectors\" title=\"Help - Do I need to return these Hard Drives? Reallocated Sectors\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hello, I ran a scan on my Plex server this morning (running on windows 11) and got the following errors. Reallocated Sector Count. Both drives are performing as expected. There&#39;s about 10/12TB&#39;s of media data on them each. Should I reach out to Amazon to return these? They are just over a year old at this point. Brought new. </p> <p>Any help would be amazing, thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Shane57F1\"> /u/Shane57F1 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1m2d1tr\">[link]</a></span> &#32; ",
        "id": 3190773,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2d1tr/help_do_i_need_to_return_these_hard_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/fIME_23Ae51ywDdP-Cz_aAHgER7F8ZZPF9LNlPe6XFk.jpg",
        "title": "Help - Do I need to return these Hard Drives? Reallocated Sectors",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Merkel77101",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T16:55:34.903604+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T16:43:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Im curious how many of you have a NAS and those that do what is your volume structure? How big is your setup? How do you keep all of your stuff organized?</p> <p>I see alot of guides suggesting setting up a media volume but Id like to be more granular, and have TV and Movies on separate volumes. </p> <p>Whats your NAS setup look like for hoarding? I just grabbed a Terramaster F4-424 Pro and 3 10TB Toshiba N300s. I mainly hoard movies, TV, books and educational stuff. Im hoping to finally get it all organized better with this NAS. </p> <p>On a side note I am little sad because about a year ago I tried to stop hoarding and now I regret deleting some stuff I deleted, in particular I had almost 20 years of Howard Stern shows which alot will never be heard anywhere again. So dont delete stuff and continue hoarding because someday you might regret the decision. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Merkel771",
        "id": 3190110,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2ciii/taking_my_hoarding_to_a_new_level_nas_setup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Taking my hoarding to a new level - NAS setup",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/iSniffMyPooper",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T16:55:35.203725+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T16:28:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a 14TB harddrive with 12TB of data on it (E:).</p> <p>I just added another 14TB harddrive and want to extend that E drive so that my E drive is essentially 28TB. I&#39;m aware that I can mount my new drive as an NTFS volume, but was hoping that I could just extend it, instead of it just being a &quot;folder&quot; in my exisiting drive. </p> <p>Is there a way to do this without formatting my original drive?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/iSniffMyPooper\"> /u/iSniffMyPooper </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2c4o5/added_a_new_14tb_harddrive_to_my_computer_28tb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2c4o5/added_a_new_14tb_harddrive_to_my_computer_28tb/\">[comments]</a></span>",
        "id": 3190111,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2c4o5/added_a_new_14tb_harddrive_to_my_computer_28tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Added a new 14TB harddrive to my computer (28TB total). Can I extend my other 14TB drive that has 12TB of data on it so that both drives act as a single drive without formatting my original?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/nov845",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T22:24:54.610846+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T16:20:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2bxfp/26tb_drive_on_sale_at_bestbuy/\"> <img src=\"https://b.thumbs.redditmedia.com/dAk7Z_RZv7-FOxv_FlLbrmUJPU1Pi83BR4_eIctl6eQ.jpg\" alt=\"26TB Drive On Sale at BestBuy\" title=\"26TB Drive On Sale at BestBuy\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/012t4x8pmgdf1.jpg?width=800&amp;format=pjpg&amp;auto=webp&amp;s=480d81f1fb8073655db21ae897f2ad2587e8480d\">https://preview.redd.it/012t4x8pmgdf1.jpg?width=800&amp;format=pjpg&amp;auto=webp&amp;s=480d81f1fb8073655db21ae897f2ad2587e8480d</a></p> <p>Awesome deal!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nov845\"> /u/nov845 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2bxfp/26tb_drive_on_sale_at_bestbuy/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2bxfp/26tb_drive_on_sale_at_bestbuy/\">[comments]</a></span> </td></tr>",
        "id": 3192702,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2bxfp/26tb_drive_on_sale_at_bestbuy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/dAk7Z_RZv7-FOxv_FlLbrmUJPU1Pi83BR4_eIctl6eQ.jpg",
        "title": "26TB Drive On Sale at BestBuy",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/thandepapaa",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T23:31:58.983794+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T15:32:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>A fast, no-nonsense Express-based scraping API to extract direct video links, images, and metadata from various adult content websites \u2014 including XVideos, XNXX, XHamster, SpankBang, ZBPorn, Tik .Porn, PornHeal, and more.</p> <p><a href=\"https://github.com/AmateurBusty/nsfw-scraper-api\">https://github.com/AmateurBusty/nsfw-scraper-api</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/thandepapaa\"> /u/thandepapaa </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2aoh8/nsfw_scraper_api/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2aoh8/nsfw_scraper_api/\">[comments]</a></span>",
        "id": 3193140,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2aoh8/nsfw_scraper_api",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "NSFW Scraper API",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Duldain",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T15:51:50.187577+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T15:23:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I always thought me going nuts on HDD space makes me some kind of nutter, but it seems I am a small fish in a huge sea :)</p> <p>I am building my own custom PC&#39;s since the end of the &#39;90 and HDD space was always a top priority for me. And, it was enough once to have a disk die on me without having a backup to make me a back-up freak as well.</p> <p><strong>My current setup:</strong></p> <ul> <li>1TB SSD drive for Windows</li> <li>250GB SSD drive for Ubuntu (dual-boot)</li> <li>1TB SSD + 2TB SSD for games installed, used under Windows</li> <li>3 Data storage SATA DISKS: 3TB + 2x4TB = 10TB</li> </ul> <p><strong>Back-up strategy:</strong></p> <p>I&#39;ve written my custom rsync scripts that I run in Ubuntu to back-up:</p> <ul> <li>the 3 data disks are backing up between each other selected folders (manual RAID simulation, I guess :))</li> <li>the backed up folders are then in turn rsync&#39;ed to 4 external WD passport HDDs (a total of 12TB).</li",
        "id": 3189450,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2ag4k/i_never_knew_i_was_a_hoarder_until_i_found_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I never knew I was a Hoarder until I found this sub reddit!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MuchSrsOfc",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T23:31:59.192018+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T14:46:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Heya! I thought about asking <a href=\"/r/techsupport\">/r/techsupport</a> but I feel like you guys specialize in this stuff to a T and each and every single one might have even been in the same scenario</p> <p>I have a drive that seems to work well for now, it previously had C5, C6, Current pending sector count and Uncorrectable sector count issues. It&#39;s passing some quite basic tests and a full windows wipe. Speeds n what not seem solid.</p> <p>AI and google just give me the immediate response of &#39;stay on safe side just buy new stuff&#39;. Which trust me I get that. But I&#39;m wondering about the ACTUAL risk of purely putting stuff onto a HDD as a backup and then leaving it for quite literally years. Surely if it&#39;s not even plugged in or anything of the sort it is not going to suffer any degradation laying dormant? And that&#39;s what it comes down to, surely it won&#39;t suffer further issues while just being dormant and therefor to me t",
        "id": 3193141,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m29gsa/drive_as_backup_that_previously_had_c5c6_issues",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Drive as backup that previously had C5/C6 issues?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/godsence",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T15:51:50.398766+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T14:46:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m29gr2/do_you_think_its_ok_for_an_external_hdd_to_be/\"> <img src=\"https://preview.redd.it/ti5xdyvx5gdf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db4be22b4b8a4516caa550c0e819e44f4aed94fd\" alt=\"Do you think it\u2019s ok for an external HDD to be sitting upright like this\" title=\"Do you think it\u2019s ok for an external HDD to be sitting upright like this\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Newbie here, I have a Seagate Expansion 2 TB HDD that I plug into my laptop. I mostly use it on a lap desk which has this small space for phones/tablet to be put in but l decided to put the external HDD there while it is plugged in so l can use them while I&#39;m sitting on my bed or couch.</p> <p>My question is, is this ok for the HDD? I&#39;ve read that external HDDs shouldn&#39;t be moved around and just be laid on a stable surface while it is plugged in.</p> <p>And while the lap desk nook is deep enough to wh",
        "id": 3189451,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m29gr2/do_you_think_its_ok_for_an_external_hdd_to_be",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ti5xdyvx5gdf1.jpeg?width=640&crop=smart&auto=webp&s=db4be22b4b8a4516caa550c0e819e44f4aed94fd",
        "title": "Do you think it\u2019s ok for an external HDD to be sitting upright like this",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/soyaaaabean",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T14:45:40.235074+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T14:12:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m starting my data hoarding/archiving journey with my social media history (posts, stories, chat history). (lowkey struggling... seems that if I delete my account I won&#39;t be able to access the instagram HTML data :( )</p> <p>I&#39;m planning on getting a portable wireless scanner &amp; digitize all my journals, letters and other sentimental items like film photos.</p> <p>What are you archiving? I&#39;m looking for ideas :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/soyaaaabean\"> /u/soyaaaabean </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m28ma9/im_new_to_data_hoarding_what_all_do_you_hoard/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m28ma9/im_new_to_data_hoarding_what_all_do_you_hoard/\">[comments]</a></span>",
        "id": 3188826,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m28ma9/im_new_to_data_hoarding_what_all_do_you_hoard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I'm new to data hoarding. What all do you hoard?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/exiledfan",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T14:45:40.548782+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T14:02:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve figured out a way to use WGET on login-only Tumblr blogs for mirroring, and I&#39;ve figured out a script that removes the privacy popup that seems to be inescapable, so each individual HTML file needs to be revised, but this is still a massive win in my book.</p> <p>However, the problem is now that it only scrapes a handful of posts--presumably being tripped up by the pagination. </p> <p>Does anyone have any ideas on how this can be worked around? </p> <p>(Tumblthree is not a viable alternative as it only downloads a fraction of the posts in the first place...)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/exiledfan\"> /u/exiledfan </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m28d7l/dashboard_only_tumblr_blog_mirror_pagination/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m28d7l/dashboard_only_tumblr_blog_mirror_pagination/\">[comment",
        "id": 3188827,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m28d7l/dashboard_only_tumblr_blog_mirror_pagination",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dashboard Only Tumblr Blog Mirror - pagination hurdle",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Quesonoche",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T14:45:40.721135+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T13:56:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The past few months I&#39;ve been downloaded tens of thousands of my saved reddit posts via BDFR and then running them throught bdfr-html to view on my server. The problem is as my number of posts downloaded has grown and grown, running bdfr-html consumes more and more RAM. Are there any options for turning downloaded jsons and media into htmls that don&#39;t consume so much ram but trying to run the whole thing at once?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Quesonoche\"> /u/Quesonoche </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m287ua/alternatives_to_bdfrhtml_for_viewing_downloaded/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m287ua/alternatives_to_bdfrhtml_for_viewing_downloaded/\">[comments]</a></span>",
        "id": 3188828,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m287ua/alternatives_to_bdfrhtml_for_viewing_downloaded",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Alternatives to BDFR-HTML for viewing downloaded reddit posts from BDFR?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Big-Wolverine-6238",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T13:40:14.503328+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T13:06:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am looking to restore two channels that were deleted by me which I heavily regret looking back on it </p> <p>I have come to a sad realization that any content that is not archived or has no snapshots of any media (video, picture, or audio) is gone forever. However terrible a loss this is, I managed to restore videos from my second channel which had 7 videos 5 of which are recoverable.</p> <p>So I was thinking is there any other I can at least try to restore the two that only have metadata I tried looking into wayback machine archives and ironically they were saved as webpages...... not as video snapshots......</p> <p>So is there any way I can try converting them into video format</p> <p>and what of the channel that was deleted in 2016 with only webpage saved on the wayback</p> <p>and also for anyone looking one main advice from this post</p> <p>DON&#39;T DELETE YOUR YOUTUBE CHANNEL WITHOUT ARCHIVING YOUR VIDEOS ESPECIALLY IF IT IS A SMALL YOUTUBE CH",
        "id": 3188242,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m272h6/hello_i_am_looking_to_restore_a_yt_channel_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hello I am looking to restore a yt channel from 2016",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Charcookiecumbs",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T13:40:14.673109+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T13:06:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I try using wfdownloader but it keeps stopping super early </p> <p>what is the most effective way to do it ? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Charcookiecumbs\"> /u/Charcookiecumbs </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m271o6/best_way_to_get_all_twitter_likes_downloaded/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m271o6/best_way_to_get_all_twitter_likes_downloaded/\">[comments]</a></span>",
        "id": 3188243,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m271o6/best_way_to_get_all_twitter_likes_downloaded",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best way to get all twitter likes downloaded ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BobThePlantGuy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T13:40:14.843745+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T12:40:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need to replace the backplane on a Supermicro CSE-743 case. I found one screw and removed it, but the blue plastic piece has tabs holding the backplane in place. The manual doesn&#39;t provide instructions. I&#39;m sure there&#39;s an easy trick, I just can&#39;t figure it out. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BobThePlantGuy\"> /u/BobThePlantGuy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m26gw8/supermicro_cse743_backplane_replacement_help/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m26gw8/supermicro_cse743_backplane_replacement_help/\">[comments]</a></span>",
        "id": 3188244,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m26gw8/supermicro_cse743_backplane_replacement_help",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Supermicro CSE-743 Backplane Replacement Help",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/KafkaaTamura_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T12:37:00.016394+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T12:33:52+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m26c2g/built_a_tool_that_bulk_downloads_any_type_of_file/\"> <img src=\"https://external-preview.redd.it/Zm9hN2t5bTdpZmRmMXmTHQBU6K6by92MlL-lQ7b5kCWjAmOEp59zn58xW_rS.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e1eab3889cf34661f59140e02777db8110835ff5\" alt=\"built a tool that bulk downloads ANY type of file from websites using natural language\" title=\"built a tool that bulk downloads ANY type of file from websites using natural language\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/KafkaaTamura_\"> /u/KafkaaTamura_ </a> <br/> <span><a href=\"https://v.redd.it/o862ptm7ifdf1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m26c2g/built_a_tool_that_bulk_downloads_any_type_of_file/\">[comments]</a></span> </td></tr></table>",
        "id": 3187687,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m26c2g/built_a_tool_that_bulk_downloads_any_type_of_file",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/Zm9hN2t5bTdpZmRmMXmTHQBU6K6by92MlL-lQ7b5kCWjAmOEp59zn58xW_rS.png?width=640&crop=smart&auto=webp&s=e1eab3889cf34661f59140e02777db8110835ff5",
        "title": "built a tool that bulk downloads ANY type of file from websites using natural language",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Urban_Predator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T12:37:00.190884+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T12:28:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I currently bought a Seagate BarraCuda internal HDD of 24TB. They are cheaper than the HDD that I currently buy for my Synology NAS. My two bays are currently full and I\u2019m thinking to add a second DX1215. I currently use two drives for Raid, so I will need 4 for the initial sync.</p> <p>I see in the specification sheet of Seagate that these 24TB BarraCuda HDD\u2019s are CMR. Can I use these to fill the additional enclosure, now they\u2019re CMR instead of SMR?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Urban_Predator\"> /u/Urban_Predator </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m26837/barracuda_drives_in_nas/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m26837/barracuda_drives_in_nas/\">[comments]</a></span>",
        "id": 3187688,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m26837/barracuda_drives_in_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "BarraCuda drives in NAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sirerf",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T12:37:00.361055+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T12:21:33+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m262yo/turn_entire_youtube_playlists_to/\"> <img src=\"https://preview.redd.it/x1nwnf53gfdf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=94fe6bc70db1363e5ca09c51787c8f95cb4aeff7\" alt=\"Turn Entire YouTube Playlists to Markdown-Formatted and Refined Text Books (in any language)\" title=\"Turn Entire YouTube Playlists to Markdown-Formatted and Refined Text Books (in any language)\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><ul> <li>This completely free Python tool, turns entire YouTube playlists (or single videos) into clean, organized, Markdown-Formatted and customizable text files.</li> <li>It supports <strong>any language to any language</strong> (input and output), as long as the video has a transcript.</li> <li>You can choose from multiple refinement styles, like balanced, summary, educational format (with definitions of key words!), and Q&amp;A.</li> <li>It&#39;s designed to be <strong>precise and comp",
        "id": 3187689,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m262yo/turn_entire_youtube_playlists_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/x1nwnf53gfdf1.jpeg?width=640&crop=smart&auto=webp&s=94fe6bc70db1363e5ca09c51787c8f95cb4aeff7",
        "title": "Turn Entire YouTube Playlists to Markdown-Formatted and Refined Text Books (in any language)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GillysDaddy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T11:32:02.098228+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T10:36:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m considering a backup NAS that starts up only once a week, runs its backups, does some maintenance / system updates, then shuts down again. Are enterprise drives still the best option for that? Or is there something that&#39;s more purpose-built / optimized for handling many spin cycles and longer offline times?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GillysDaddy\"> /u/GillysDaddy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m243xc/drives_for_spin_cycles_rather_than_uptime/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m243xc/drives_for_spin_cycles_rather_than_uptime/\">[comments]</a></span>",
        "id": 3186786,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m243xc/drives_for_spin_cycles_rather_than_uptime",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Drives for spin cycles rather than uptime",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Tricky_Sky_7389",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T11:32:02.374043+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T10:25:38+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m23xph/need_help_on_used_hdd/\"> <img src=\"https://a.thumbs.redditmedia.com/TJNB9b6NU9QyW3cXLtfzB6FBG4PbsrTSK1WH1JJ2HZ8.jpg\" alt=\"Need help on used HDD\" title=\"Need help on used HDD\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Just found this on FB marketplace listing near me. </p> <p>What do i need to look out for when buying used HDD?</p> <p>Should i be worried about the 17k hours of power on? </p> <p>1 TB for about 20 usd.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tricky_Sky_7389\"> /u/Tricky_Sky_7389 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1m23xph\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m23xph/need_help_on_used_hdd/\">[comments]</a></span> </td></tr></table>",
        "id": 3186787,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m23xph/need_help_on_used_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/TJNB9b6NU9QyW3cXLtfzB6FBG4PbsrTSK1WH1JJ2HZ8.jpg",
        "title": "Need help on used HDD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/princejsl",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T11:32:02.542522+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T10:24:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I run a small business related to architecture and graphics for which I need a storage solution. I will also use some storage for my photos as well (probably immich). I am not able to decide which OS should be good in the long run. Some of my work related files are around 700MB. I tried UNRAID trail and truenas core. I know there are pros and cons of each but is there anything that check all the points. Also I am not very good at networking and IT things.</p> <p>\ud83d\udd39UNRAID: comparatively slower than Truenas \ud83d\udd39Truenas core : No docker system. \ud83d\udd39Truenas Scale: not reliable yet? Complicated to use? \ud83d\udd39Synology: too expensive for the hardware they offer</p> <p>Can you suggest any OS that should be a good fit for my needs? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/princejsl\"> /u/princejsl </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m23wvn/help_choose_me_nas_os/\">[link]</a></span> &#32; <sp",
        "id": 3186788,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m23wvn/help_choose_me_nas_os",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help choose me NAS OS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Various-Tension8050",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T11:32:01.931441+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T08:51:27+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m22gh2/who_else_hoards_thousands_of_old_apks/\"> <img src=\"https://preview.redd.it/c06resxmeedf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=515c0b98a1e03e34b5e7e4d0e86f5a59dcf3c960\" alt=\"who else hoards thousands of old apks?\" title=\"who else hoards thousands of old apks?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Various-Tension8050\"> /u/Various-Tension8050 </a> <br/> <span><a href=\"https://i.redd.it/c06resxmeedf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m22gh2/who_else_hoards_thousands_of_old_apks/\">[comments]</a></span> </td></tr></table>",
        "id": 3186785,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m22gh2/who_else_hoards_thousands_of_old_apks",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/c06resxmeedf1.jpeg?width=640&crop=smart&auto=webp&s=515c0b98a1e03e34b5e7e4d0e86f5a59dcf3c960",
        "title": "who else hoards thousands of old apks?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Rrrrila",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T11:32:02.946405+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T07:20:25+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Rrrrila\"> /u/Rrrrila </a> <br/> <span><a href=\"/r/webdevelopment/comments/1m20tc2/free_privacyfirst_file_sharing_webapp_no/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m212ef/free_privacyfirst_file_sharing_webapp_no/\">[comments]</a></span>",
        "id": 3186789,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m212ef/free_privacyfirst_file_sharing_webapp_no",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Free, privacy-first file sharing webapp \u2013 no registration, no limits, no tracking (feedback wanted!)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PusheenHater",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T11:32:03.177062+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T06:30:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Note: For various reasons I must work with built-in tools (that means no CrystalDisk etc) on Windows 10.</p> <p>To check SMART data, I use these commands:</p> <p>On command prompt:</p> <p><code>wmic diskdrive get * /format:list</code></p> <p>and on PowerShell as administrator:</p> <p><code>Get-PhysicalDisk | Get-StorageReliabilityCounter | Format-List</code></p> <p>These commands give general info like model, serial number, power-on hours, size, etc.</p> <p>Now, I bought 4 brand new WD Elements external hard drives on Amazon.<br/> I know it is extremely common for a scammer to shuck the drive, replace the hard drive with a used or inferior drive, unshuck, then return it. Then Amazon just re-lists them as brand new and innocent people like us get scammed when we buy them.</p> <p>How common is it to have falsified SMART data such that the commands output whatever the scammer wants?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.r",
        "id": 3186790,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m209rd/smart_data_validity",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SMART data validity",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DeusWeebLegendary",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T06:02:30.865981+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T05:49:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I have a phone that lacks an sd card slot and have been hoarding flac files for music on poweramp. Unfortunately having a usb stick out of my phone is both unreliable and uncomfortable.</p> <p>Is there a 1tb+ storage device which can act as a wireless mounted drive with an android phone?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DeusWeebLegendary\"> /u/DeusWeebLegendary </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1zlqh/portable_wireless_storage_device/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1zlqh/portable_wireless_storage_device/\">[comments]</a></span>",
        "id": 3185578,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1zlqh/portable_wireless_storage_device",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Portable Wireless Storage Device",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MiniSpip",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T06:02:31.037166+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T05:44:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Ordered two new 12TB (WD Red Plus EFGX, with 512 MB cache) and one of them was just DOA. Making no noise, no vibration and giving a &quot;cyclic redundancy check&quot; error when trying to initialize.</p> <p>It is a new product line as these models are available since ~3 months only; the 256 MB cache version (EFBX) is much older.</p> <p>Out of all the HDDs that I ordered, and I ordered many..., this is my first DOA but also the first time that I take a chance on a brand new model.</p> <p>Should I avoid new models as a rule or is this just plain bad luck ? What&#39;s your take or experience in the matter ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MiniSpip\"> /u/MiniSpip </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1zif4/should_a_brand_new_hdd_model_be_avoided_in_the/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1zif4/should_a_brand_new_h",
        "id": 3185579,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1zif4/should_a_brand_new_hdd_model_be_avoided_in_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Should a brand new HDD model be avoided in the beginning ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Jiffy_Wu",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T06:02:31.205616+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T05:35:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>im looking to develop an app but wanted to see if there was demand for something like this</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Jiffy_Wu\"> /u/Jiffy_Wu </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1zcws/just_wondering_if_a_simple_buy_it_for_life_web/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1zcws/just_wondering_if_a_simple_buy_it_for_life_web/\">[comments]</a></span>",
        "id": 3185580,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1zcws/just_wondering_if_a_simple_buy_it_for_life_web",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "just wondering if a simple buy it for life web crawler/scraper app is something that sounds appealing",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Universal_Cognition",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T04:56:35.473356+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T04:55:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>When I was young, I did site networking at a large campus for a major tech company. One day, we were working in the warehouse area and saw pallets of brand new, state of the art, 4.7GB hard drives being unloaded. Being the nerds we were, my coworkers and I stood around staring wide-eyed at the loot we beheld before us. These weren&#39;t yet available for purchasing by the public, and we were in awe! They seemed almost magical.</p> <p>For the next couple of days, the topic of HDD space was prevalent in our discussions. &quot;That&#39;s almost limitless space!&quot; &quot;You could spend the next several years downloading and never fill that up!&quot; When I finally got my hands on one of them, I was in nerd heaven. I thought I&#39;d never need more space in my life.</p> <p>Fast forward to today: I can download more than 4.7GB in a few minutes and I&#39;m sitting on 150TB+ of HDDs. Technology advancement is crazy.</p> </div><!-- SC_ON --> &#32; submitte",
        "id": 3185336,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1yo3o/naive_young_me_and_my_47gb_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Naive young me and my 4.7GB HDD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ge4020",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T04:56:35.813713+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T03:52:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>As stated in the title, HDD works fine on another sytem, Z170 can detect a 2T HDD on the same sata port.</p> <p>Tried to consult AI but not very helpful, so I am turning to real people in this sub. XD </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ge4020\"> /u/ge4020 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1xif9/help_needed_z170hd3_not_detecting_12t_hdd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1xif9/help_needed_z170hd3_not_detecting_12t_hdd/\">[comments]</a></span>",
        "id": 3185338,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1xif9/help_needed_z170hd3_not_detecting_12t_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help needed! Z170-HD3 not detecting 12T HDD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/yush-pb",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T03:50:34.533490+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T03:40:43+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1xamb/hard_drive_recovery_by_reinsertion_failed/\"> <img src=\"https://b.thumbs.redditmedia.com/CVbYXheZJRpoiENS00XcGkGnVYOSeshtZ-5MmgBhDks.jpg\" alt=\"Hard drive recovery by reinsertion failed\" title=\"Hard drive recovery by reinsertion failed\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/26twhn37vcdf1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=1514b071523c96ff36d0cd06e9c3659bb032a284\">https://preview.redd.it/26twhn37vcdf1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=1514b071523c96ff36d0cd06e9c3659bb032a284</a></p> <p>Hey everyone,<br/> I had an old laptop that I recently upgraded by installing a new SSD. I removed the old HDD from that laptop and placed it in a USB enclosure so I could use it as an external drive and access my previous data.</p> <p>When I connect the enclosure to my current system, Windows does detect it as a mass storage device (I can see it in",
        "id": 3185063,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1xamb/hard_drive_recovery_by_reinsertion_failed",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/CVbYXheZJRpoiENS00XcGkGnVYOSeshtZ-5MmgBhDks.jpg",
        "title": "Hard drive recovery by reinsertion failed",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Environmental-Loan51",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T04:56:35.287764+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T02:16:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Alrighty let me explain a bit about my set up and plans.</strong></p> <p>I have a typical pc gaming set up with my bed right behind me so i can turn the tv and lay in bed to watch tv. I&#39;m looking to start what i like to call &quot;The Library&quot;. A giant collection of every piece and type of media I have ever enjoyed. I don&#39;t know how big of a collection this will be but i don&#39;t think it will go over 100tb.</p> <p><strong>Now for what I&#39;m looking for.</strong></p> <p>I need something for mass storage and back ups so nothings lost. i would like it to connect to my pc and basically be easily accessible to download and move things from my pc to it. i also don&#39;t really need it to be ran as a server since its for personal use and used in only one room.</p> <p>So that&#39;s everything in a nutshell. i don&#39;t know what to get at all and could use some guidance from some of you, who have home storage so big that it makes my p",
        "id": 3185335,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1vmd0/please_help_me_find_the_best_storage_route_for_my",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Please help me find the best storage route for my set up",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Zquirrel04",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T02:45:33.845654+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T02:09:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently got tired of being a cash cow for streaming services. A friend helped me setup a Jellyfin server and when I got things running smoothly, I bought myself a 12TB HDD to replace my old 2TB that I started with. </p> <p>Well, right when I was heading to bed, my dog got stuck with the powercord and my HDD dropped on the floor. I heard the noise and got in there just to see the murder scene: The murdered was terrified and knew he&#39;d done something and I could hear the hard drive doing a clicking noise it didn&#39;t do before. After reading a bit. I knew it was too late. </p> <p>Also, stupid and inexperienced me cleared the old 2TB after I took 8 hours transfering the files. My mother wanted a hard drive to store pictures and I gave it to her. So no backup...</p> <p>Anyway, I&#39;m now back at the beginning. 3TB of data is lost and I&#39;m now HDD-less. I don&#39;t know if you guys have any cheap suggestions to replace it. </p> </div><!-- SC_ON ",
        "id": 3184813,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1vh7b/back_to_the_beginning",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Back to the beginning",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sharp-Thing5184",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T02:45:34.019578+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T01:58:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking for a service that I can use to turn old camcord videos from the 90s digital. I don\u2019t own a vhs player and prefer to not do the work myself as it looks like it can be costly. I have the vhs converter and the mini cassette tapes and just looking for a service that can do it for like 20-30 a tape. Located in the US</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sharp-Thing5184\"> /u/Sharp-Thing5184 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1v8r7/turning_vhs_tapes_digital/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1v8r7/turning_vhs_tapes_digital/\">[comments]</a></span>",
        "id": 3184814,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1v8r7/turning_vhs_tapes_digital",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Turning VHS tapes digital ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/pugboy1321",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T01:37:26.987466+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T01:03:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey y\u2019all, I need your help!</p> <p>I&#39;ve posted this around in a few camera/photo subs as well as DHExchange but I figured I&#39;d throw it here too to try and get as many eyes on it as possible since it&#39;s time sensitive, hope that&#39;s alright, otherwise I&#39;m happy to delete this! Sorry for the wording in this post, I wrote it mostly for the target of camera/photo subs to understand easier. </p> <p>For the past ~two years I\u2019ve been working on a project to archive and preserve the Sony Play Memories Camera Apps for older cameras so they don\u2019t get lost forever. In 2023 they ended new sales of paid apps, and on August 31st of 2025 they will end support for downloading free apps, AND downloading any previously purchased apps.</p> <p>I\u2019m so close to completing the archive, but time is running out and I need your help! </p> <p>If you own any of the following apps on your Sony cameras, please see <a href=\"https://www.reddit.com/r/SonyAlpha/comme",
        "id": 3184619,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1u356/own_a_sony_camera_you_might_be_able_to_help",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Own a Sony camera? You might be able to help preserve features Sony is taking away! (PMCA Apps Archive Project)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Outrageous-Citron31",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T04:56:36.303066+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T00:59:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I have Orico 9758C3 (5Bay) and recently bricked it by flashing wrong firmware. From my research, Orico 9758C3 is just like any other cheap chinese enclosures, JMS-567 chip with Sata multiplier (although I am not sure which combination of exact microcontrollers it uses) I managed to semi-unbrick it by shorting flash pins, then flashing a firmware from similar enclosure product, as a temporary fix. Since the new firmware is not official, it lacks the multi-drive support, only 1 drive at a time shows up. Because of this I have to swap disks on demand, and a little concerned about sata port integrity. </p> <p>I am aware I made mistake of not extracting the original firmware, and I can not find original firmware anywhere on the web. </p> <p>I emailed offical Chinese Orico Support for Firmware request, and they sent me screenshot of JmsMPtools(flasher software) instead of actual binary flash file. They keep sending my wrong file anyway, so it is hard",
        "id": 3185340,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1tzoc/fixing_orico_enclosure",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Fixing ORICO enclosure",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Apprehensive-Peak127",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T04:56:36.472264+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T00:47:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone! First of all thank you for helping.</p> <p>I just bought a Terramaster D4-320 use as storage while video editing. I&#39;m editing in Davinci and I would like to use this unit as external drive to edit trhough it. I planned to test RAID 0 and RAID 5 to check speeds, I bought 4x 8TB WD BLUE.</p> <p>The problem is, I can&#39;t make the RAID. I thought Windows could help me with it buy when I try to make the stripe RAID the speeds are less than 200mb\\s.</p> <p>Is there a possible way to solve it? Or should I return it and buy a dedicated RAID case?</p> <p>Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Apprehensive-Peak127\"> /u/Apprehensive-Peak127 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1tqog/how_to_raid_terramaster_d4320/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m1tqog/how_to_raid_terramaster_d4320/\">[comments]</",
        "id": 3185341,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m1tqog/how_to_raid_terramaster_d4320",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to RAID Terramaster D4-320",
        "vote": 0
    }
]