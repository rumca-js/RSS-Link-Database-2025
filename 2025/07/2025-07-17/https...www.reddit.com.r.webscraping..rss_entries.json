[
    {
        "age": null,
        "album": "",
        "author": "/u/Pleasant_Syllabub591",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T19:37:49.574665+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T19:29:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I&#39;m working on a project that allows you to deploy browser instances on your own and control them using LangChain and other frameworks. It\u2019s basically an open-source alternative to Browserbase.</p> <p>I would really appreciate any feedback and am looking for open source contributors.</p> <p>Check out the repo here: <a href=\"https://github.com/operolabs/browserstation?tab=readme-ov-file\">https://github.com/operolabs/browserstation?tab=readme-ov-file</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Pleasant_Syllabub591\"> /u/Pleasant_Syllabub591 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1m2gvz6/open_source_alternative_to_browserbase/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1m2gvz6/open_source_alternative_to_browserbase/\">[comments]</a></span>",
        "id": 3191557,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1m2gvz6/open_source_alternative_to_browserbase",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "open source alternative to browserbase",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Bitter_Tie_2387",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T20:53:36.431685+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T18:47:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is it even posible?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Bitter_Tie_2387\"> /u/Bitter_Tie_2387 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1m2fsoa/any_way_to_scrape_telegram_groups_links_from/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1m2fsoa/any_way_to_scrape_telegram_groups_links_from/\">[comments]</a></span>",
        "id": 3192066,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1m2fsoa/any_way_to_scrape_telegram_groups_links_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any way to scrape telegram groups (links) from reddit?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NinjaShmurtle",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T16:22:50.798989+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T16:15:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Anyone using it with successe ? I used it with burner accounts I eventually ended up getting suspended. Wondering if anyone here uses it before I try it with a residential proxy</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NinjaShmurtle\"> /u/NinjaShmurtle </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1m2bt2b/instagrapi/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1m2bt2b/instagrapi/\">[comments]</a></span>",
        "id": 3189756,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1m2bt2b/instagrapi",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Instagrapi",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ansleis333",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T15:17:45.381756+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T14:14:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello. I&#39;ve been trying to scrape <a href=\"http://sephora.me\">sephora.me</a> recently. Problem is this gives me a limited amount of products, not all the available products. The goal was to get all Skincare product details and their stock levels but right now it&#39;s not giving me all the links. Appreciate any help. </p> <p>```python from selenium import webdriver from selenium.webdriver.chrome.options import Options from selenium.webdriver.common.by import By import time</p> <p>try: driver = setup_chrome_driver()</p> <pre><code>driver.get(&quot;https://www.sephora.me/ae-en/brands/sol-de-janeiro/JANEI&quot;) print(&quot;Page title:&quot;, driver.title) print(&quot;Page loaded successfully!&quot;) product_links = driver.find_elements(By.CSS_SELECTOR, &#39;div.relative a[href^=&quot;/ae-en/p&quot;]&#39;) if product_links: print(f&quot;Found {len(product_links)} product links on this page:&quot;) for link in product_links: product_url = link.get_att",
        "id": 3189211,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1m28oc7/trying_to_scrape_all_product_details_but_only",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to scrape all product details but only getting 38 out of 61",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/IIIItoto",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T14:12:39.457270+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T14:02:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>For a website that doesn&#39;t have a sitemap. Every method I&#39;ve found either just downloads all of the files, has too low of a limit, or requires you to manually go through the site.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/IIIItoto\"> /u/IIIItoto </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1m28drc/is_there_a_way_i_could_just_get_a_raw_list_of/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1m28drc/is_there_a_way_i_could_just_get_a_raw_list_of/\">[comments]</a></span>",
        "id": 3188561,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1m28drc/is_there_a_way_i_could_just_get_a_raw_list_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a way I could just get a raw list of urls on a website?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/KafkaaTamura_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T13:06:33.501187+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T12:38:14+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1m26fcv/built_a_tool_that_bulk_downloads_any_type_of_file/\"> <img src=\"https://external-preview.redd.it/azg1eGwwYzRqZmRmMXmTHQBU6K6by92MlL-lQ7b5kCWjAmOEp59zn58xW_rS.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a803138338fa8b86aeacfc2d316e69da6cfae977\" alt=\"built a tool that bulk downloads ANY type of file from websites using natural language\" title=\"built a tool that bulk downloads ANY type of file from websites using natural language\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/KafkaaTamura_\"> /u/KafkaaTamura_ </a> <br/> <span><a href=\"https://v.redd.it/5qgkhzb4jfdf1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1m26fcv/built_a_tool_that_bulk_downloads_any_type_of_file/\">[comments]</a></span> </td></tr></table>",
        "id": 3187923,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1m26fcv/built_a_tool_that_bulk_downloads_any_type_of_file",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/azg1eGwwYzRqZmRmMXmTHQBU6K6by92MlL-lQ7b5kCWjAmOEp59zn58xW_rS.png?width=640&crop=smart&auto=webp&s=a803138338fa8b86aeacfc2d316e69da6cfae977",
        "title": "built a tool that bulk downloads ANY type of file from websites using natural language",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/UsefulShip4821",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-17T12:00:05.253435+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-17T09:51:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need a opensource, free project , tool which can scrape most social media account of my competitor company . i need their post , comments , other data and this is to be done regularly to be updated. </p> <p>Can anyone suggest some tools for this . also i need to know about Incremental Scraping </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/UsefulShip4821\"> /u/UsefulShip4821 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1m23dsg/best_trending_social_media_scraper_for_competitor/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1m23dsg/best_trending_social_media_scraper_for_competitor/\">[comments]</a></span>",
        "id": 3187453,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1m23dsg/best_trending_social_media_scraper_for_competitor",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best / trending Social Media Scraper for competitor analysis ?",
        "vote": 0
    }
]