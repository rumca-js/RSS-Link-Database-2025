[
    {
        "age": null,
        "album": "",
        "author": "/u/autiwara",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T23:31:06.899253+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T23:01:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have no idea if this is the right sub to ask this in but I can&#39;t think of anything else... I&#39;m trying to download a playlist with 2k songs with spotdl, it got to 350 songs in the span of a few hours. Is there any way I can start where it left off so I don&#39;t have to redownload every song? I know spotdl has a sync function but I don&#39;t know how to use it or how it works.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/autiwara\"> /u/autiwara </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m3gpfh/help_with_spotdl/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m3gpfh/help_with_spotdl/\">[comments]</a></span>",
        "id": 3201684,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m3gpfh/help_with_spotdl",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help with spotDL?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ph0tone",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T22:24:25.149099+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T21:58:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I&#39;ve just pushed a new version of a project I&#39;ve been building: <a href=\"https://github.com/hyperfield/ai-file-sorter\">AI File Sorter</a> \u2013 a fast, open source desktop tool that helps you automatically organize large, messy folders using locally run LLMs, like Mistral (7b) and LLaMa (3b) models.</p> <p>Works on Windows, macOS, and Linux. The Windows version has an installer or a stand-alone archive. The macOS and Linux binaries are coming up.</p> <p>The app runs local LLMs via <code>llama.cpp</code>, currently supports CUDA, OpenCL, OpenBLAS, Metal, etc.</p> <h1>\ud83e\udde0 What it does</h1> <p>If your <code>Downloads</code>, <code>Desktop</code>, <code>Backup_Drive</code>, or <code>Documents</code> directory is somewhat unorganized, this app can:</p> <ul> <li>Easily download an LLM and switch between LLMs in Settings.</li> <li>Categorize files and folders into folders and subfolders based on category and subcategory assignment with ",
        "id": 3201335,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m3f8y3/ai_file_sorter_090_now_with_offline_llm_support",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI File Sorter 0.9.0 - Now with Offline LLM Support",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Log_Dogg",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T21:19:24.658439+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T21:06:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a python script that runs once a day and checks a list of ~200 Instagram profiles for new posts. Currently I&#39;m logging into a throwaway account with selenium and extracting the cookies, and then using Instaloader to scrape the profiles. This kind of works, but the accounts get flagged and suspended very quickly (after a few runs max), and even while they&#39;re working they often get rate-limited, and it&#39;s only a matter of time before I get IP-banned.</p> <p>Are there any reliable and cheap services for this? I tried Apify&#39;s scraper and it seems to work fine for what I need, but for my use case it would come to around ~$40/mo which is quite a bit, especially considering I plan to scale to more accounts in the future. Are there any cheaper alternatives?</p> <p>Thank you in advance</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Log_Dogg\"> /u/Log_Dogg </a> <br/> <span><a href=\"https://www.reddit.",
        "id": 3200935,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m3e0h7/how_to_reliably_scrape_instagram_posts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to reliably scrape Instagram posts?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/elsbeth-salander",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T21:19:24.205934+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T20:58:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>People may differ in their viewpoints on the quality or perspective of PBS programming in recent years, but there\u2019s no denying that it has produced a lot of memorable series that many viewers enjoyed and which did have an intent to inform and/or educate the populace, including children.</p> <p>Some of these shows ran for decades and therefore might not be on DVD box sets. For instance NOVA has aired since 1974. I\u2019ve already noticed that some of the children\u2019s series like The Puzzle Place are considered partially lost media due to being \u201ccopyright abandonware\u201d (the original IP holder temporarily licensed it to public broadcasting but then went bankrupt, leaving the rights essentially in limbo).</p> <p>With Paramount having obliterated all of its Daily Show archive from the website, it\u2019s probably only a matter of time before something similar happens to those PBS series that are viewable in streaming format. Is there an effort under way to 1) download w",
        "id": 3200934,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m3dsz4/with_pbs_on_the_chopping_block_is_anyone_going_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "With PBS on the chopping block, is anyone going to be sending all the reels and tapes from various public broadcasters to some kind of preservation / restoration service?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PusheenHater",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T21:19:24.902365+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T20:15:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve got a bunch of external/internal hard drives, SSDs, flash drives, etc.<br/> I&#39;m using a cardboard box but I have so many hard drives that it&#39;s sagging. Not very sturdy.<br/> I know plastic is static-y which is really bad for the hard drives.</p> <p>So I ask if there&#39;s a container:</p> <ul> <li>Big, that can hold many hard drives</li> <li>Anti-static</li> <li>Not plastic or cardboard</li> <li>Sturdy</li> <li>Preferably allows you to lock it up with a lock</li> </ul> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PusheenHater\"> /u/PusheenHater </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m3crbz/how_to_securely_store_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m3crbz/how_to_securely_store_drives/\">[comments]</a></span>",
        "id": 3200936,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m3crbz/how_to_securely_store_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to securely store drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Alphabethur",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T20:11:42.385252+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T19:54:22+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m3c85m/10tb_wd_hgst_ultrastar_dc_hc510_refurb_for_125/\"> <img src=\"https://external-preview.redd.it/rTIwEaPVs4W-9pVdd48SHzaP058Ypa-RVDQpZtwbPSo.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a6d02475099c685c638c41187dac05621ffaa25\" alt=\"10TB WD HGST Ultrastar DC HC510 refurb for 125\u20ac from digital emporium. Good deal?\" title=\"10TB WD HGST Ultrastar DC HC510 refurb for 125\u20ac from digital emporium. Good deal?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Alphabethur\"> /u/Alphabethur </a> <br/> <span><a href=\"https://www.ebay.de/itm/356725675595?itmmeta=01K0FH7BNDZ279PCGW4C8Q7GRX\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m3c85m/10tb_wd_hgst_ultrastar_dc_hc510_refurb_for_125/\">[comments]</a></span> </td></tr></table>",
        "id": 3200535,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m3c85m/10tb_wd_hgst_ultrastar_dc_hc510_refurb_for_125",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/rTIwEaPVs4W-9pVdd48SHzaP058Ypa-RVDQpZtwbPSo.jpeg?width=216&crop=smart&auto=webp&s=5a6d02475099c685c638c41187dac05621ffaa25",
        "title": "10TB WD HGST Ultrastar DC HC510 refurb for 125\u20ac from digital emporium. Good deal?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Repulsive_Market_728",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T19:06:03.875282+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T18:21:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just in case there&#39;s anyone who may be interested and who might have the space/resources to use something like this, I saw this up for auction. It closes at around 9pm eastern today (Friday the 18th). </p> <p><a href=\"https://www.allsurplus.com/en/asset/1021/13971\">https://www.allsurplus.com/en/asset/1021/13971</a></p> <p>I also found this article which provides a pretty good overview of the system.</p> <p><a href=\"https://www.itpro.com/155268/quantum-scalar-i2000-tape-library\">https://www.itpro.com/155268/quantum-scalar-i2000-tape-library</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Repulsive_Market_728\"> /u/Repulsive_Market_728 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m39v9k/quantum_scaler_tape_library_available/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m39v9k/quantum_scaler_tape_library_available/\">[comments]</a></span>",
        "id": 3200099,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m39v9k/quantum_scaler_tape_library_available",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Quantum Scaler Tape library available",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AshleyAshes1984",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T18:01:03.157404+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T17:35:28+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m38onx/once_a_month_i_hit_ebay_with_terms_like_discovery/\"> <img src=\"https://preview.redd.it/4bmbipht4odf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b179e8320b86abe9df816f478ae5e4cfa84dfa9c\" alt=\"Once a month I hit eBay with terms like 'Discovery Channel DVD' or 'National Geographic DVD', sort by cheapest, and just buy whatever seems like it vibes with early 2000's Edutainment networks.\" title=\"Once a month I hit eBay with terms like 'Discovery Channel DVD' or 'National Geographic DVD', sort by cheapest, and just buy whatever seems like it vibes with early 2000's Edutainment networks.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AshleyAshes1984\"> /u/AshleyAshes1984 </a> <br/> <span><a href=\"https://i.redd.it/4bmbipht4odf1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m38onx/once_a_month_i_hit_ebay_with_terms_like_discovery/\">",
        "id": 3199577,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m38onx/once_a_month_i_hit_ebay_with_terms_like_discovery",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/4bmbipht4odf1.png?width=640&crop=smart&auto=webp&s=b179e8320b86abe9df816f478ae5e4cfa84dfa9c",
        "title": "Once a month I hit eBay with terms like 'Discovery Channel DVD' or 'National Geographic DVD', sort by cheapest, and just buy whatever seems like it vibes with early 2000's Edutainment networks.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/palepatriot76",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T18:01:03.759525+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T17:23:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I have used DVDFab for well over 40 DVD boxed sets, no issues but I have an issue with my Benny Hill Megaset</p> <p>I am crating ISO files fine, but when I try to watch I can hear but not see, and when I can see very messed up, pixelated and green screen</p> <p>When I use those ISO files and Make MKV, same thing, just a mess</p> <p>Is this a DVD protection thing? If so what is my next step?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/palepatriot76\"> /u/palepatriot76 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m38cvf/i_am_making_iso_files_with_some_dvd_sets_but_once/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m38cvf/i_am_making_iso_files_with_some_dvd_sets_but_once/\">[comments]</a></span>",
        "id": 3199579,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m38cvf/i_am_making_iso_files_with_some_dvd_sets_but_once",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I am making ISO files with some DVD sets but once complete they are unwatchable, is this due to protection?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/aJakalope",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T19:06:04.158086+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T17:18:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m mostly making this post because I googled the differences between these a lot before purchasing and wish I had seen a post like this before I had.</p> <p>I currently use a Beelink Mini S12 as a Plex server and although I had been using external drives, I was running out of USB ports on the Beelink. So I was looking into a DAS to use and found very similar reviews for both products named in the title. The Terramaster was a little cheaper so I went with it, especially since I was not looking for proper RAID functionality since I use the drives for easily replaceable media files. </p> <p>I used WD Red Pro 18TB drives for this.</p> <p>The first drive I put in it seemed to function alright, but when I attached a second drive, there seemed to be issues. Drives randomly disconnecting, errors while transferring large files, qBitTorrent error messages I had never seen before, etc. I read that it was likely a cord issue, so I bought a nicer data cable. ",
        "id": 3200100,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m388cd/terramaster_d4320_vs_qnap_tr004",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Terramaster D4-320 vs. QNAP TR-004",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Gunfighter1776",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T18:01:03.929727+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T17:15:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have never had a NAS. I know what it is, and I have used them in work environments - never from home network pov.</p> <p>Question and Comment: </p> <p>I have a PC with several hdd&#39;s -- I have data duplicated across the drives for redundancies in case one of the drives fail -- I have a total of 30tb - ish this includes all drives and duplicated data - so my conundrum is do I use this number to calculate how much actual drive space I need in my NAS setup? </p> <p>Or do I just take ONE COPY of everything - and dump it onto my NAS... I ask because I don&#39;t know how the NAS -- in what will be most likely a RAID5 configuration -- will treat the data if I have several copies of the data also on my NAS... or will it just be that the duplicated data will be all spanned across all drives -- just like any other deployment of data in a NAS... </p> <p>I guess I am asking -- what is best practice -and which is a best stragegy? ONE COPY of everything on my ",
        "id": 3199580,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m385pb/setting_up_a_nas_have_question",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Setting up a NAS... have question.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ThePirer",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T19:06:04.366383+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T16:33:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys,</p> <p>In the past, I just used VLC as a player for watching movies and series. However, since last year, I&#39;ve been running an emby server in my laptop, since it is always on, and it&#39;s been amazing. Because of that, I want to buy a NAS in like 2-3 years, since right now it is not possible for different reasons.</p> <p>When looking at NAS, I found them to be very limiting. What if I needed more disks, more ram, a more powerful CPU or whatever in the future? If I do something, I optimize the shit out of it. In the end, I thought that a custom NAS would be the best option. But the cases are very expensive, or too big, or too small or too loud, or too ugly... So, I have an old pc tower with a ton of 5.2 and 3.5 slots. I removed those racks and 3D printed a 12 bay rack in TPU with an attachment for 4 fans on the side, as well as an hexagon front mesh in PETG for airflow. A bit of walnut vinyl and now it looks like something made by Fractal",
        "id": 3200101,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m371mb/your_advice_for_future_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Your advice for future NAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/roscone",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T16:56:15.688410+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T15:58:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>With the news of Microsoft ending new sales via their video store (<a href=\"https://www.theverge.com/news/709737/microsoft-movies-tv-store-closure-xbox-windows\">https://www.theverge.com/news/709737/microsoft-movies-tv-store-closure-xbox-windows</a>), it seems like it&#39;ll only be a matter of time before they shut down the ability to play the things you&#39;ve purchased there as well. Some things can sync to Movies Anywhere, but I have a lot of older stuff going back to the Xbox 360 era that I&#39;d like to keep.</p> <p>Are there any ways to keep backups of videos from Microsoft&#39;s store?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/roscone\"> /u/roscone </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m3659u/ways_to_back_up_microsoft_movies_tv_purchases/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m3659u/ways_to_back_up_microsoft_movies_tv_",
        "id": 3199098,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m3659u/ways_to_back_up_microsoft_movies_tv_purchases",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ways to Back Up Microsoft Movies & TV Purchases?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/purplechemist",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T16:56:16.568981+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T15:57:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I don\u2019t see much love for Toshiba drives, but I don\u2019t see any hatred for them either. Our local has a deal on the 14TB MG07ACA14TE ex-enterprise use - \u00a3140ish with three month warranty. </p> <p>Should I pull the trigger?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/purplechemist\"> /u/purplechemist </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m364lr/are_toshiba_drives_any_good/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m364lr/are_toshiba_drives_any_good/\">[comments]</a></span>",
        "id": 3199100,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m364lr/are_toshiba_drives_any_good",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are Toshiba drives any good?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/itsbentheboy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T18:01:03.514576+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T15:51:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have created a set of bashRC aliases for use with YT-DLP. </p> <p>These make some longer commands more easily accessible without the need of calling specific scripts.</p> <p>These should also be translatable to Windows as well since the commands are all in the yt-dlp binary - but I have not tested that. </p> <p>Usage is simple, just use the alias that correlates with what you want to do - and paste the URL of the video, for example: </p> <p><code>yt-dlp-archive https://my-video.url.com/video</code> to use the basic archive alias.</p> <p>You may use these in your shell by placing them in a file located at <code>~/.bashrc.d/yt-dlp_alias.bashrc</code> or similar bashrc directories. Simply copy and paste the code block below into an alias file and reload your shell to use them. </p> <p>These preferences are opinionated for my own use cases, but should be broadly acceptable. however if you wish to change them I have attempted to order the command flags f",
        "id": 3199578,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m35ys1/some_ytdlp_aliases_for_common_tasks",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Some yt-dlp aliases for common tasks",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AlternateWitness",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T15:51:30.638497+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T14:53:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Xfinity launched their new tier structure, and if you signed a contract you can still switch within 45 days of signing on. I have one day left to decide.</p> <p>I am currently paying $30 a month for 400Mbps and a 1.2TB data cap. I only have June\u2019s usage to compare how much data I use in my house, which is ~900GB.</p> <p>The option I am mainly considering to switch to is $40 a month, 300Mbps, but <em>unlimited data</em>.</p> <p>I just wanted to ask how important unlimited data is to you, and if it\u2019s worth a slowdown in speed and higher price? I <em>may</em> be more frivolous with my network usage, and download some more stuff if I don\u2019t have a cap shadowing over my head, but I don\u2019t know if that would go over my previous cap or not, so it may just be wasted money, and I only have a day left to decide.</p> <p>Another note - I may have to pay for an extra month if I sign the $40 contract since it would be a month after what I planned, and I may be moving",
        "id": 3198528,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m34gcn/slower_internet_more_expensive_unlimited_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Slower internet - more expensive - unlimited data?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/hrukzt",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T14:45:31.402458+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T14:28:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My usage would be like this: backup all my files to the backup drive, including personal photos which must not be lost, store it in a closet, repeat a few times a year.</p> <p>What kind of drive would be sufficient? Also, do drives get old, as in, if they stay in closet for years but very little usage, do they still degrade?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hrukzt\"> /u/hrukzt </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m33thj/what_are_good_and_cheap_drives_for_personal_pc/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m33thj/what_are_good_and_cheap_drives_for_personal_pc/\">[comments]</a></span>",
        "id": 3197959,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m33thj/what_are_good_and_cheap_drives_for_personal_pc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What are good and cheap drives for personal PC backup?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/reatsomeyon",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T14:45:31.579763+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T14:25:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It seems the site suddenly went down. No reason whatsoever and can&#39;t find anyone talking about it.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/reatsomeyon\"> /u/reatsomeyon </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m33qfg/is_it_just_me_or_archivedmoe_is_down/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m33qfg/is_it_just_me_or_archivedmoe_is_down/\">[comments]</a></span>",
        "id": 3197960,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m33qfg/is_it_just_me_or_archivedmoe_is_down",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is it just me or archived.moe is down?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/redditunderground1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T13:41:36.598003+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T13:08:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://cinematography.com/index.php?/forums/topic/103621-book-disassembly-of-3144-page-book-for-scanning/\">Book disassembly of 3144 page book for scanning - Off Topic - Cinematography.com</a></p> <p>Scanning a 3144 page book...here is how to do it!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/redditunderground1\"> /u/redditunderground1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m31w3z/book_disassembly_of_3144_page_book_for_scanning/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m31w3z/book_disassembly_of_3144_page_book_for_scanning/\">[comments]</a></span>",
        "id": 3197371,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m31w3z/book_disassembly_of_3144_page_book_for_scanning",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Book disassembly of 3144 page book for scanning",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Illustrious_Heart951",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T15:51:31.097648+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T08:42:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>I asked this question in the Terramaster community but unfortunately never received an answer.<br/> I think this issue may also apply to other DAS manufacturers.</p> <p>So, here\u2019s my setup:</p> <ul> <li>Terramaster D4-320</li> <li>WD Purple HDD (WD43PURZ)</li> <li>Beelink Mini S12 Pro running Proxmox 8.4.x</li> </ul> <p>When I shut down the computer, the DAS continues running. To turn it off, I have to press and hold the power button for about 3 seconds, as stated in the official documentation.</p> <p>Now, about SMART:<br/> After every DAS shutdown, the <strong>Power-Off_Retract_Count</strong> parameter increases.<br/> Some sources say this indicates an emergency disk shutdown, while others consider it normal for the counter to increment.</p> <p>Can someone finally clarify\u2014is this bad? If so, why would the manufacturer knowingly release a DAS that behaves this way?</p> <p>Before buying, I read many reviews about the Terramaster ",
        "id": 3198530,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2x1zw/emergency_disk_shutdown",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Emergency Disk Shutdown",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Difficult-Scheme4536",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T15:51:30.814369+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T08:35:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I wanted to share something unexpected that came out of a filesystem project I&#39;ve been working on, ZeroFS: <a href=\"https://github.com/Barre/zerofs\">https://github.com/Barre/zerofs</a></p> <p>I built ZeroFS, an NBD + NFS server that makes S3 storage behave like a real filesystem using an LSM-tree backend. While testing it, I got curious and tried creating a ZFS pool on top of it... and it actually worked!</p> <p>So now we have ZFS running on S3 object storage, complete with snapshots, compression, and all the ZFS features we know and love. The demo is here: <a href=\"https://asciinema.org/a/kiI01buq9wA2HbUKW8klqYTVs\">https://asciinema.org/a/kiI01buq9wA2HbUKW8klqYTVs</a></p> <p>This gets interesting when you consider the economics of &quot;garbage tier&quot; S3-compatible storage. You could theoretically run a ZFS pool on the cheapest object storage you can find - those $5-6/TB/month services, or even archive tiers if your use ca",
        "id": 3198529,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2wy7j/zfs_running_on_s3_object_storage_via_zerofs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "ZFS running on S3 object storage via ZeroFS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Worried_Claim_3063",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T15:51:32.041116+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T08:20:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So like, to make it short.. my friend (not me lol) is trying to download a bunch of videos off Pornhub. They just got into data hoarding stuff and have a drive setup for it.</p> <p>I don&#39;t usually mess with this kind of thing cause it just seems sketchy af, but they asked me to help find an app or something that works, cause most of the sites they found just seem full of popups or malware traps. I&#39;m honestly kinda stuck now cause there&#39;s like a million tools out there and no clue which are actually safe.</p> <p>They use a Mac btw, and I tried showing them yt-dlp but it just confused them, so unless theres an easier way, Id have to set it up for them. Anyone got recs for something safer and not a virus pit?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Worried_Claim_3063\"> /u/Worried_Claim_3063 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2wq0u/best_pornhub_video_download",
        "id": 3198534,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2wq0u/best_pornhub_video_downloader",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best pornhub video downloader?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Quantum_Crusher",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T08:16:36.739504+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T07:36:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>CBS is ending &#39;The Late Show with Stephen Colbert&#39;, calling it &#39;a financial decision&#39; <a href=\"https://youtu.be/qoT3dDivWSE\">https://youtu.be/qoT3dDivWSE</a></p> <p>Stephen Colbert Announces The Cancellation Of &quot;The Late Show&quot; <a href=\"https://youtu.be/AuqEZx6TmfI\">https://youtu.be/AuqEZx6TmfI</a></p> <p>I&#39;m worried that they might delete everything (or at least some videos that our supreme leader doesn&#39;t like) including some of my favorite videos that witnessed some of the most important history.</p> <p>I can&#39;t even with this timeline...</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Quantum_Crusher\"> /u/Quantum_Crusher </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2w1zq/never_thought_one_day_i_would_have_to_hoard_this/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2w1zq/never_thought_one_day_i_would_have",
        "id": 3195211,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2w1zq/never_thought_one_day_i_would_have_to_hoard_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Never thought one day I would have to hoard this...",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/yesiwonagain",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T06:06:36.146985+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T05:43:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>im looking to archive some smaller streaming platforms (eternal family) and wondering if theres any way to automate this. my usual way to download from these is to use ytmp3 on the m3u8 files for each episode/movie. wondering if there would be any way to make it faster since i need to start playing each episode before i can get a link to download. would there be any way to script this or any apps i could use to automate it? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/yesiwonagain\"> /u/yesiwonagain </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2u8jv/faster_way_to_archive_full_streaming_platforms/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2u8jv/faster_way_to_archive_full_streaming_platforms/\">[comments]</a></span>",
        "id": 3194688,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2u8jv/faster_way_to_archive_full_streaming_platforms",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "faster way to archive full streaming platforms?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Kennyw88",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T05:02:37.747972+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T04:51:00+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2tbql/obviously_a_different_meaning_but_i_thought_it/\"> <img src=\"https://preview.redd.it/2x785pspckdf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b7c4cd6c032c38f10e066fd375a11a55babca9d0\" alt=\"Obviously a different meaning, but I thought it was cool.\" title=\"Obviously a different meaning, but I thought it was cool.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kennyw88\"> /u/Kennyw88 </a> <br/> <span><a href=\"https://i.redd.it/2x785pspckdf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2tbql/obviously_a_different_meaning_but_i_thought_it/\">[comments]</a></span> </td></tr></table>",
        "id": 3194429,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2tbql/obviously_a_different_meaning_but_i_thought_it",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/2x785pspckdf1.jpeg?width=640&crop=smart&auto=webp&s=b7c4cd6c032c38f10e066fd375a11a55babca9d0",
        "title": "Obviously a different meaning, but I thought it was cool.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Idocabo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T15:51:31.381359+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T03:56:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m currently trying Arq Premium on my Mac. They have their own cloud storage option (uses Google Cloud) as well as the option to use B2, Wasabi, etc. But I\u2019m wondering if there\u2019s a cheaper option for my needs. </p> <p>My backups are &lt;500gb and they\u2019re just important files and photos I want to store. My day to day primarily involves web apps, so it\u2019s rare I have daily file changes, let alone hourly. </p> <p>I think it\u2019d be fine if I connected to my external HDD and Arq/B2 once a week or even once a month. </p> <p>Does this make sense? Would Backblaze B2 still be the best solution or is there something that would be more cost efficient?</p> <p>(The primary reason I\u2019m considering B2 over continuing Arq Premium\u2019s cloud option is for immutability)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Idocabo\"> /u/Idocabo </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2sbgy/is_backblaze_b2_the_",
        "id": 3198531,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2sbgy/is_backblaze_b2_the_right_backup_destination_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is Backblaze B2 the right backup destination for this?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Pepe_Gemelle",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T15:51:31.626809+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T01:06:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I got a WD PR2100 for free recently with about 12TB of space in it. I have done a full factory reset went through the process of setting it up and I can access it just fine through the web page but I can&#39;t get it to map the drive in network. Let me get the first lines of questioning out of the way.</p> <ol> <li><p>Yes network sharing is turned on the main computer I&#39;m trying to use it on.</p></li> <li><p>Yes i Enabled SMB 1.0 under features and programs and rebooted.</p></li> <li><p>I have an extra user created for the drive (even though for mapping it not sure that needed)</p></li> </ol> <p>Currently it shows up in Network but when I click on it, It just says network path doesn&#39;t exist. Any help would be appreciated.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Pepe_Gemelle\"> /u/Pepe_Gemelle </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2owd4/wd_pr2100_cant_map_the_driv",
        "id": 3198532,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2owd4/wd_pr2100_cant_map_the_drive_on_w11",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WD PR2100 Can't Map the Drive on W11",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/N4ADZ",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-18T15:51:31.796695+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-18T01:01:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,<br/> Wondering if anyone has suggestions on upgrading from a Drobo-FS. The unit work amazingly. But with Drobo out of business, there is no support is something goes sideways.</p> <p>Right now I am leaning toward a Unifi UNAS Pro. I don&#39;t have the need to run a bunch of apps and such that a Synology would offer. The price point on the UNAS seems great, especially being a 7 bay unit. So that&#39;s the way I lean.</p> <p>Is there a killer app that I don&#39;t know I need, in the Synology ecosystem, that would be worth an extra $100 for a 5 bay unit?</p> <p>Thanks </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/N4ADZ\"> /u/N4ADZ </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2osh7/upgrade_from_drobofs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m2osh7/upgrade_from_drobofs/\">[comments]</a></span>",
        "id": 3198533,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m2osh7/upgrade_from_drobofs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Upgrade from Drobo-FS",
        "vote": 0
    }
]