[
    {
        "age": null,
        "album": "",
        "author": "/u/Expensive-Total-312",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T23:57:41.009473+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T23:44:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking to use my daily driver PC for some data hoarding (4k Film and FLAC),<br/> I&#39;ve recently got a PC case that supports 15+ drives, I&#39;m running windows 11 pro so I&#39;m considering windows storage spaces, is my logic correct below?</p> <p>I can pool 3 / 5 drives using parity / dual parity, and lose 1/2 drives before the entire pool is gone. If the windows install fails the pool should be fine after I either move it to another system or reinstall windows.</p> <p>Say if I start with 3 drives in parity mode I can continue adding drives ( with a rebalancing step) to expand my storage</p> <p>To connect them I&#39;m thinking the LSI SAS 9300 HBA should support 16 SATA or SAS drives,<br/> HD Mini SAS (SFF-8643 Host) to 4X SATA should work to connect SATA drives.</p> <p>My PSU (1250W) should have enough wattage and SATA power outputs for 16 drives (4x 4 SATA power daisy chained)</p> <p>I&#39;ll do some more reading before I dump money int",
        "id": 3136685,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwrzbg/setting_up_a_hoard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Setting up a hoard",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/kevinback4real",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T22:52:40.744662+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T22:24:48+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/kevinback4real\"> /u/kevinback4real </a> <br/> <span><a href=\"/r/homelab/comments/1lwq4j0/turning_old_gaming_pc_into_20g_nas_for_video/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwq5gp/turning_old_gaming_pc_into_20g_nas_for_video/\">[comments]</a></span>",
        "id": 3136331,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwq5gp/turning_old_gaming_pc_into_20g_nas_for_video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Turning old gaming PC into 20G NAS for video editing",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Melodic-Network4374",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T22:52:40.512430+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T22:05:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Figured this might be interesting for those of you running Ceph clusters for your storage. The next release (Tentacle) will have some massive improvements to EC pools.</p> <ul> <li>3-4x improvement in random read</li> <li>significant reduction in IO latency</li> <li>Much more efficient storage of small objects, no longer need to allocate a whole chunk on all PG OSDs.</li> <li>Also much less space wastage on sparse writes (like with RBD).</li> <li>And just generally much better performance on all workloads</li> </ul> <p>These will be opt-in, once upgraded a pool cannot be downgraded again. But you&#39;ll likely want to create a new pool and migrate data over because the new code works better on pools with larger chunk sizes than previously recommended.</p> <p>I&#39;m really excited about this, currently storing most of my bulk data on EC with things needing more performance on a 3-way mirror.</p> <p>Relevant talk from Ceph Days London 2025: <a href=\"ht",
        "id": 3136330,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwpohj/massive_improvements_coming_to_erasure_coding_in",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Massive improvements coming to erasure coding in Ceph Tentacle",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jburgs22",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T22:52:40.923645+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T22:00:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>May not be the right subreddit but I download a lot of HLS/.m3u8 broadcasts and other web videos/non YT videos from web browsers using browser extensions, Video Downloadhelper, yt-dlp, 4k Video Downloader+ (rarely due to limits).</p> <p>I&#39;ve tried to research iOS specific Shortcuts and apps for doing the same thing but no luck other than writing my own Shortcut (I barely know how to code let alone script something).</p> <p>Does anyone have anything they use? Does not have to be specific to Safari, I can use any number of mobile browsers but browser extensions are limited in iOS/iPadOS so it would have to be an app or Shortcut.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jburgs22\"> /u/jburgs22 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwpkj8/hls_downloading_on_mobile_iosipados/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwpkj8/hls_d",
        "id": 3136332,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwpkj8/hls_downloading_on_mobile_iosipados",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "HLS Downloading on Mobile, iOS/iPadOS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Spektre99",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T21:47:40.223538+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T21:16:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have two 20TB drives in a Windows Server 2019 Disk Management mirrored set. The boot drive is separate.</p> <p>I would like to move to new server hardware. </p> <p>Is there a way to just relocate the drives and have Windows recognize them as Mirrored? If so what are the steps?</p> <p>I have a backup of the data, but I don&#39;t want to lose the redundancy on the data. </p> <p>Worst case, I can rebuild the mirrored drives and pull data from backup but I&#39;d like to avoid this if possible.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Spektre99\"> /u/Spektre99 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwoi68/moving_windows_disk_management_mirrored_set_to_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwoi68/moving_windows_disk_management_mirrored_set_to_a/\">[comments]</a></span>",
        "id": 3135852,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwoi68/moving_windows_disk_management_mirrored_set_to_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Moving Windows Disk Management mirrored set to a new server (non boot)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Interesting_Ad5748",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T21:47:41.187713+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T21:03:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How can I get the drive to accept the 128 GB of files without getting the message drive too small, need 2gb more room? What I&#39;m trying to do is get the drive to load the 128GBs without me having to /delete/move 2 GB of files.:edit I know a 128 GB drive doesn&#39;t have 128 GB available.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Interesting_Ad5748\"> /u/Interesting_Ad5748 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwo6zx/have128gb_thumb_drive_and_130_gb_files/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwo6zx/have128gb_thumb_drive_and_130_gb_files/\">[comments]</a></span>",
        "id": 3135856,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwo6zx/have128gb_thumb_drive_and_130_gb_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Have128gb thumb drive and 130 GB files",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AdWestern1261",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T21:47:40.407469+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T21:01:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>hello!! </p> <p>our team created a free-for-life tool called Downlodr that allows you to download in bulk, and is completely hassle-free. I wanted to share this in here after seeing the impressive collaborative archiving projects happening in this community. we hope this tool we developed can help you with archiving and protecting valuable information.</p> <p>Downlodr offers features that work well for various downloading needs:</p> <ul> <li>bulk download functionality for entire channels/playlists</li> <li>multi-platform support across different services</li> <li>Ccean interface with no ads/redirects to interrupt your workflow</li> </ul> <p>here&#39;s the link to it: <a href=\"https://downlodr.com/\">https://downlodr.com/</a> and here is our subreddit: <a href=\"/r/Downlodr\">r/Downlodr</a></p> <p>view the code or contribute: <a href=\"https://github.com/Talisik/Downlodr\">https://github.com/Talisik/Downlodr</a> </p> <p>we value proper archiving, making co",
        "id": 3135853,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwo55v/we_built_a_freeforever_video_downloading_tool",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "We built a free-forever video downloading tool",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Admirable_Letter7900",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T21:47:40.589780+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T20:34:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I just want to store my pictures and some video long term. here is my plan right now. get a 2 bay enclosure, get 2 8tb hard drives and search all of my drives and get all of my pictures and video and put them on one of the hard drives. then copy that harddrive to the 2nd hard drive as a back up. then remove the back up drive and store it powered down. once a year add the additional photos to it. </p> <p>will this be ok? is there a better solution.</p> <p>what hard drives should I use? red, ironwolf exoc?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Admirable_Letter7900\"> /u/Admirable_Letter7900 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwnfza/long_term_storage/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwnfza/long_term_storage/\">[comments]</a></span>",
        "id": 3135854,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwnfza/long_term_storage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "long term storage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Intelligent_Series46",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T20:42:48.493601+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T20:27:06+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwn9j7/wd_my_book_duo_36tb/\"> <img src=\"https://preview.redd.it/3nlwfxdbw3cf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dcff936e9bd5ab24c49d9d5f1292ab984aabc8a1\" alt=\"WD My Book Duo 36TB\" title=\"WD My Book Duo 36TB\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Has anyone got this drive? Need a pic of its PSU</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Intelligent_Series46\"> /u/Intelligent_Series46 </a> <br/> <span><a href=\"https://i.redd.it/3nlwfxdbw3cf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwn9j7/wd_my_book_duo_36tb/\">[comments]</a></span> </td></tr></table>",
        "id": 3135497,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwn9j7/wd_my_book_duo_36tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/3nlwfxdbw3cf1.jpeg?width=640&crop=smart&auto=webp&s=dcff936e9bd5ab24c49d9d5f1292ab984aabc8a1",
        "title": "WD My Book Duo 36TB",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Appropriate_Quiet189",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T21:47:40.776367+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T20:23:19+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Appropriate_Quiet189\"> /u/Appropriate_Quiet189 </a> <br/> <span><a href=\"/r/PleX/comments/1lwn5j5/new_to_this_looking_for_tipssuggestions_on_diy/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwn5x0/new_to_this_looking_for_tipssuggestions_on_diy/\">[comments]</a></span>",
        "id": 3135855,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwn5x0/new_to_this_looking_for_tipssuggestions_on_diy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New to this, looking for tips/suggestions on diy Plex server",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ok_Tea_3275",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T19:36:13.151377+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T19:35:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am trying to find the best codec to rip mp4 files to, so they will play on normal dvd players from early 2000s.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok_Tea_3275\"> /u/Ok_Tea_3275 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwlyhi/what_codec_should_i_rip_a_dvdrw_into/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwlyhi/what_codec_should_i_rip_a_dvdrw_into/\">[comments]</a></span>",
        "id": 3135005,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwlyhi/what_codec_should_i_rip_a_dvdrw_into",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What codec should I rip a dvd-rw into?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/breathein_standstill",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T18:30:00.995515+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T17:42:06+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwj1sh/find_date_and_time_stamp_on_photo/\"> <img src=\"https://b.thumbs.redditmedia.com/ej41A-NGtrHff4Cm-lU_3yEfh-YB3V7qGKcf6DpFgVI.jpg\" alt=\"Find date and time stamp on photo?\" title=\"Find date and time stamp on photo?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I apologize if I\u2019m in the wrong place, but I\u2019m lost. My landlord is trying to claim these photos were taken after the move out clean I hired. Suspiciously, there is no time or date stamp on the photos that I can see. I\u2019m wondering if anyone knows how to find this/can find it for me?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/breathein_standstill\"> /u/breathein_standstill </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1lwj1sh\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwj1sh/find_date_and_time_stamp_on_photo/\">[comments]</a></span> </td></tr></table>",
        "id": 3134443,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwj1sh/find_date_and_time_stamp_on_photo",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/ej41A-NGtrHff4Cm-lU_3yEfh-YB3V7qGKcf6DpFgVI.jpg",
        "title": "Find date and time stamp on photo?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/parkerdhicks",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T17:24:01.787879+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T16:55:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey, everyone!</p> <p>I&#39;m working on getting my first home media server and general storage solution set up, and I&#39;ve got some nerves. The plan is to pretty much follow Alex Kretzschmar&#39;s build at perfectmediaserver.com. I&#39;m no stranger to building a PC, but this will be my first real Linux experience and my first time working with any kind of redundancy or data checking like ZFS and mergerfs. </p> <p>Would you let me know what you think of this prospective build?</p> <ul> <li>Motherboard: Gigabyte B760 DS3H AX V2</li> <li>RAM Patriot Viper 2x16GB PVV532G600C30K (DDR5)</li> <li>Boot drive: WD_Black SN7100 M.2, 500GB</li> <li>PSU EVGA SuperNOVA 750G5</li> <li>Initial storage: Seagate BarraCuda 16TB. I&#39;ll either get 2 or throw in a different 16TB from another manufacturer when I find a good price. And then hopefully, using mergerfs will mean I can expand easily later?</li> <li>Case: Rosewill R4000U (I&#39;ve got a rack already for ne",
        "id": 3133914,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwhtrk/babys_first_media_serverdata_hoard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Baby's First Media Server/Data Hoard",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/snowfall04",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T16:18:52.308633+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T16:00:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m a SOAR case worker. The shortest way I can explain this is that SOAR is a model that doubles the chances that someone is approved for SSI/SSDI.</p> <p>Yesterday, the SOAR TA Center informed us that SAMHSA is pulling all of its funding and that the website will be deleted on August 18th.</p> <p>The Library &amp; Tools section on the website is absolutely invaluable to the work that we do. What is the best way that I can back this up and make it available for others to access?</p> <p>I appreciate any responses. I am very concerned about this.</p> <p>Website for reference: <a href=\"https://soarworks.samhsa.gov/library-and-tools\">https://soarworks.samhsa.gov/library-and-tools</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/snowfall04\"> /u/snowfall04 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwgg0s/help_best_way_to_backup_share_invaluable_ssissdi/\">[link]</a></span> &#32; <sp",
        "id": 3133265,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwgg0s/help_best_way_to_backup_share_invaluable_ssissdi",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help! Best way to backup & share invaluable SSI/SSDI website before it's deleted?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/-Istvan-5-",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T16:18:52.478756+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T15:53:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My old server chassis (rosewill) has a crappy design. The handles on the front block the server from sliding into my rack. </p> <p>Looking online the only solution is to remove the handles, which removes the filter and front cover. </p> <p>I can buy magnetic fan filters, so no problem. </p> <p>Now I have a question on if dust actually matters for HDDs? They are sealed right? </p> <p>Obviously air flow is super important for high density HDDs stacked one on top of another. </p> <p>So I&#39;m thinking a filter isn&#39;t even that big of a deal? </p> <p>The magnetic air filters all come in various diameter holes, so leaning towards either not needing one (for max air flow) or getting something with larger holes to catch the largest of dust bunnies / hairs etc.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/-Istvan-5-\"> /u/-Istvan-5- </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwg9q2/how",
        "id": 3133266,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwg9q2/how_important_is_dust_filtering_for_hdds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How important is dust filtering for HDDs?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Hefty_Management_863",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T16:18:52.649566+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T15:44:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a Macbook which i use for watching movies &amp; internet surfing only, since there is no way to increase internal storage, i bought extenal SSD which is fine &amp; all but keeps getting disconnected whenever i try to move the macbook even slightly, maybe due to loose usb cable or port, even i were to change the usb cable, i am sure it will start behaving the same way after some time, so, i was thinking about getting some sort of wireless storage solution, like connecting the SSD with some router with usb port or using a NAS or raspberry pi, although i think a NAS would be overkill for my usage since i&#39;ll be using it to store movies only, nothing else &amp; i don&#39;t even need a cloud soultion, just local access, what do you guys i should opt for?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hefty_Management_863\"> /u/Hefty_Management_863 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarde",
        "id": 3133267,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwg1su/external_storage_solution_for_macbook_nas_or",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "External Storage solution for Macbook (NAS or Otherwise)?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Noctisx09",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T16:18:51.951166+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T15:35:58+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwftvq/need_an_hdd_for_backing_up_media_which_out_of/\"> <img src=\"https://preview.redd.it/duu3vzohg2cf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc6b61da972285e4023212792b92c7b584473085\" alt=\"Need an HDD for backing up media.. Which out of these are the best choice??\" title=\"Need an HDD for backing up media.. Which out of these are the best choice??\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>My budget is limited.. So I chose 4tb.. Which out of these are the best choice for me?? I currently have 4 2tb WD Passports.. But 1 of the older ones died and another one is making a clicking sound so I guess that will die soon too.. </p> <p>Checked recent amazon reviews and most of them are negative for all of these drives.. I guess that&#39;s because of the seller.. Even Amazon is not trustable anymore.. </p> <p>Anyway.. Please tell me which one to buy??</p> </div><!-- SC_ON --> &#32; submitted by &#32; <",
        "id": 3133264,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwftvq/need_an_hdd_for_backing_up_media_which_out_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/duu3vzohg2cf1.jpeg?width=640&crop=smart&auto=webp&s=bc6b61da972285e4023212792b92c7b584473085",
        "title": "Need an HDD for backing up media.. Which out of these are the best choice??",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EmiliaRoth",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T16:18:52.819160+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T15:33:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>does someone own the Samsung 9100 Pro SSD? I&#39;m wondering if its single- oder double sided?</p> <p>I do have a couple of Samsung 990 PRO NVMe M.2 SSD, 4 TB; and they are single sided (Good for notebooks or mini pcs)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EmiliaRoth\"> /u/EmiliaRoth </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwfs0f/samsung_9100_pro_ssd_4tb_single_sided_or_double/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwfs0f/samsung_9100_pro_ssd_4tb_single_sided_or_double/\">[comments]</a></span>",
        "id": 3133268,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwfs0f/samsung_9100_pro_ssd_4tb_single_sided_or_double",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Samsung 9100 Pro SSD (4TB) Single Sided or Double Sided?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/furlysails",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T21:47:41.649404+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T15:31:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a large amount of video files I need to carry with me for work, near 30TB. I usually work in places without reliable internet access, so I carry this data in a rather unwieldy set of a dozen+ 2-4 tb external SSD drives. </p> <p>I don&#39;t really need high transfer speeds here, just high capacity and the ability to jostle around in a backpack a bit. Regular disk drives end up dying quickly, but the more durable standard portable SSDs are still quite small for my needs.</p> <p>Recently I found out about the existence of U.2 SSDs that have really high capacities and no moving parts, but since I use a laptop I cannot really use them as intended. Then I found out about adapters that let you plug U.2 drives to a USB port. </p> <p>Even though they are hideously expensive I&#39;m seriously considering getting a Solidigm 61.44 TB drive (assuming I can find one) and a decent adapter (assuming it would work on a drive this large?) and freeing myself of t",
        "id": 3135857,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwfpt2/using_a_u2_ssd_with_a_usb_adapter_as_a_high",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Using a U.2 SSD with a USB adapter as a high capacity portable drive -- possible?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Phil_Goud",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T16:18:51.772696+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T15:29:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone !</p> <p>Mostly lurker and little data hoarder here</p> <p>I was fed up with the complexity of Tdarr and other softwares to keep the size of my (legal) videos on check.</p> <p>So I did that started as a small script but is now a 600 lines, kind of turn-key solution for everyone with basic notions of bash... or and NVIDIA card</p> <p>You can find it on my Github, it was tested on my 12TB collection of (family) videos so must have patched the most common holes (and if it is not the case, I have timeout fallbacks)</p> <p>Hope it will be useful to any of you ! No particular licence, do what you want with it :)</p> <p><a href=\"https://github.com/PhilGoud/H265-batch-encoder/\">https://github.com/PhilGoud/H265-batch-encoder/</a></p> <p>(If it is not the good subreddit, please be kind^^)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Phil_Goud\"> /u/Phil_Goud </a> <br/> <span><a href=\"https://www.reddit.com/r/",
        "id": 3133263,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwfoi8/a_batch_encoder_to_convert_all_my_videos_to_h265",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "A batch encoder to convert all my videos to H265 in a Netflix-like quality (small size)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Jaib4",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T21:47:41.833823+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T15:16:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Vidmate</p> <p>You&#39;ll have to download the APK from Google but after you install it you can use it to easily download entire playlists from YouTube on android devices, both as video files and audio files and you can set custom resolutions for download </p> <p>I thought I&#39;d just post about it since I was looking for something like this for a while and had trouble finding something that works</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Jaib4\"> /u/Jaib4 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwfc3o/android_app_for_bulk_downloading_music/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwfc3o/android_app_for_bulk_downloading_music/\">[comments]</a></span>",
        "id": 3135858,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwfc3o/android_app_for_bulk_downloading_music",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Android app for bulk downloading music",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Aromatic_Cash_6579",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T21:47:42.010405+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T15:14:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I\u2019m building a post-production setup to edit immersive video shot on the Blackmagic URSA Cine Immersive. The goal is to be able to edit in real-time in DaVinci Resolve, without proxies or lag. 1 hour of footage takes about 8tb of space which means I will need a huge storage system.</p> <p>Here\u2019s what I have in mind so far:</p> <p>Mac Studio M3 Ultra<br/> RAID storage system with at least 70 TB usable (so around 96 TB raw)</p> <p>I\u2019m totally new to the Raid storage system, what should I be looking for to edit without lag on DaVinci footage stored on the drive ? Is it necessarily SSD ? Do you have any specific models you recommend ?</p> <p>Any insight or experience would be really helpful! Thanks \ud83d\ude4f</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Aromatic_Cash_6579\"> /u/Aromatic_Cash_6579 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwfabl/best_raid_setup_for_editing_",
        "id": 3135859,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwfabl/best_raid_setup_for_editing_immersive_video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best RAID setup for editing immersive video (Blackmagic URSA Cine) on a Mac Studio?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Dry-Temporary5815",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T15:14:49.321866+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T14:19:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone</p> <p>I have been using Synology products for more than 15 years - and have been very satisfied so far. I didn&#39;t buy Synology products because of the hardware in particular, but because I found Synology&#39;s software to be very, very good (it has almost no weaknesses and everything works seamlessly and reliably.)</p> <p>There is certainly much better hardware out there.</p> <p>Like the current NAS from Ugreen, for example.</p> <p>Since it&#39;s time to change my NAS, I came across the Ugreen DXP6800 PRO, NAS here.</p> <p>Hardware technically far more attractive than Synology - and also a lot cheaper. What keeps me from buying this product is the software... I use many services on my Synology NAS, which I believe are unique to Synology. e.g. Hyper Backup, Snapshots...</p> <p>Are there programs that can do the same in terms of simplicity and reliability as these two programs mentioned? In Hyper Backup I use the OpenStack service... ",
        "id": 3132624,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwdxn6/synology_vs_ugreen",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Synology vs Ugreen",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/McLawyer",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T14:09:49.066179+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T13:25:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hoping someone here will know how to help me. I have created a 12tb virtual drive on my external drive and have been using it flawlessly for about a month, but today it seems to be having this odd problem. If I try to write to the VHD the drive dismounts immediately. I can copy from and read from the VHD but copying to it causes it to disappear and require re-mounting.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/McLawyer\"> /u/McLawyer </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwcnx0/seagate_external_14tb_hdd_created_vhd_on_this/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lwcnx0/seagate_external_14tb_hdd_created_vhd_on_this/\">[comments]</a></span>",
        "id": 3132040,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lwcnx0/seagate_external_14tb_hdd_created_vhd_on_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seagate External 14TB HDD, Created VHD on this Drive Disappears when Writing",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/YesThisIsi",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T11:57:32.883967+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T11:06:20+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw9xb1/the_sound_of_pain_and_suffering/\"> <img src=\"https://external-preview.redd.it/ZHdjeTBkOTk0MWNmMcNCHrZqJY0y29X3XlWl6QauZU9SNaPzrKwxU2Xl6Swg.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a62e4b92ce4d903bf39a1f322ce891b7bdc98364\" alt=\"The sound of pain and suffering\" title=\"The sound of pain and suffering\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/YesThisIsi\"> /u/YesThisIsi </a> <br/> <span><a href=\"https://v.redd.it/8izaxc9941cf1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw9xb1/the_sound_of_pain_and_suffering/\">[comments]</a></span> </td></tr></table>",
        "id": 3130970,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw9xb1/the_sound_of_pain_and_suffering",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/ZHdjeTBkOTk0MWNmMcNCHrZqJY0y29X3XlWl6QauZU9SNaPzrKwxU2Xl6Swg.png?width=640&crop=smart&auto=webp&s=a62e4b92ce4d903bf39a1f322ce891b7bdc98364",
        "title": "The sound of pain and suffering",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DiamondDudez",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T10:52:27.837818+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T10:41:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys, just saw this pcloud storage deal and thought some of you might appreciate. They&#39;re offering lifetime plans again, up to 70% off and free password manager included. These are the prices:</p> <ul> <li>1TB \u2013 \u20ac199</li> <li>2TB \u2013 \u20ac279</li> <li>10TB \u2013 \u20ac799</li> </ul> <p>Here&#39;s a link: <a href=\"https://landing.pcloud.com/France2025\">https://landing.pcloud.com/France2025</a>. Hope this helps :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DiamondDudez\"> /u/DiamondDudez </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw9hsv/pcloud_lifetime_storage_deal_1tb_to_10tb_france/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw9hsv/pcloud_lifetime_storage_deal_1tb_to_10tb_france/\">[comments]</a></span>",
        "id": 3130474,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw9hsv/pcloud_lifetime_storage_deal_1tb_to_10tb_france",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "pCloud lifetime storage deal (1TB to 10TB) \u2013 France Day",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/manolid",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T10:52:28.006853+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T10:12:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am planning on using Dariks Boot and Nuke to erase the drives before I drill them and throw them out. Just wondering if there is any other software I should consider using.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/manolid\"> /u/manolid </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw9112/good_tool_for_nuking_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw9112/good_tool_for_nuking_drives/\">[comments]</a></span>",
        "id": 3130475,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw9112/good_tool_for_nuking_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Good tool for nuking drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GrasSchlammPferd",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T10:52:28.341503+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T09:58:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, I&#39;ve been getting stuck on the verification stage for PatreonDownloader (using the latest version) this year, and I&#39;m unable to figure out why.</p> <p>I&#39;ve raised it with app dev and he suggested it&#39;s a VPN/connection issue. I&#39;ve tried using it with or without VPN, on different networks, different PCs, and the issue persists. </p> <p>I was wondering if anyone had similar issues and how they solved them.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GrasSchlammPferd\"> /u/GrasSchlammPferd </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw8sz5/patreondownloader_stuck_on_verifying/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw8sz5/patreondownloader_stuck_on_verifying/\">[comments]</a></span>",
        "id": 3130476,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw8sz5/patreondownloader_stuck_on_verifying",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "PatreonDownloader stuck on verifying",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SimonHoskingAuthor",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T09:47:28.621883+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T09:32:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi All</p> <p>I&#39;m well aware I&#39;m a very junior data-hoarder. My PC has a mere 34TB of storage across 5 mechanical hard-drives. I currently have everything backed up off-site using the backblaze unlimited storage (I think they&#39;re making a loss on my account!).</p> <p>I like to get something like a NAS - but I&#39;d like it to be attached to the PC via USB-C (plenty of performance for my needs) and be recognised another drive - or drives.</p> <p>I&#39;d like the device to accept multiple drives that I supply. RAID isn&#39;t desired. If each HD was a drive on the PC that would be fine.</p> <p>Does such a category of device exist and what is it called?</p> <p>Thank you to all the true data hoarders doing god&#39;s work!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SimonHoskingAuthor\"> /u/SimonHoskingAuthor </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw8es3/what_do_they_call",
        "id": 3130018,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw8es3/what_do_they_call_an_external_device_with_a_lot",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What do they call an external device with a lot of hard drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/war6763",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T09:47:28.185159+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T08:48:34+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw7rdz/ready_to_upgrade_1_of_3_vdevs/\"> <img src=\"https://preview.redd.it/hz74842tf0cf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6ef2524c210c893d191a522c9eef7d993694fab7\" alt=\"Ready to upgrade 1 of 3 VDEVs\" title=\"Ready to upgrade 1 of 3 VDEVs\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>The first round of 26TB drives just arrived!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/war6763\"> /u/war6763 </a> <br/> <span><a href=\"https://i.redd.it/hz74842tf0cf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw7rdz/ready_to_upgrade_1_of_3_vdevs/\">[comments]</a></span> </td></tr></table>",
        "id": 3130017,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw7rdz/ready_to_upgrade_1_of_3_vdevs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/hz74842tf0cf1.jpeg?width=640&crop=smart&auto=webp&s=6ef2524c210c893d191a522c9eef7d993694fab7",
        "title": "Ready to upgrade 1 of 3 VDEVs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AristFrost",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T08:42:27.093997+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T08:14:31+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw79xp/hoarders_paradise/\"> <img src=\"https://preview.redd.it/lixgibfe90cf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cff32e78cc520662821c7a52b4ea8ec8d9c4cd09\" alt=\"Hoarder's Paradise\" title=\"Hoarder's Paradise\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AristFrost\"> /u/AristFrost </a> <br/> <span><a href=\"https://i.redd.it/lixgibfe90cf1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw79xp/hoarders_paradise/\">[comments]</a></span> </td></tr></table>",
        "id": 3129618,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw79xp/hoarders_paradise",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/lixgibfe90cf1.png?width=640&crop=smart&auto=webp&s=cff32e78cc520662821c7a52b4ea8ec8d9c4cd09",
        "title": "Hoarder's Paradise",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Girl_Sexy_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T08:42:27.704770+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T07:38:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I&#39;m looking for several applications that would allow me to bulk download content from Instagram, Reedit, and Twitter On Android and for free </p> <p>Give me the best suggestions you have </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Girl_Sexy_\"> /u/Girl_Sexy_ </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw6qqx/download_photos_videos_and_gifs_in_mass/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw6qqx/download_photos_videos_and_gifs_in_mass/\">[comments]</a></span>",
        "id": 3129619,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw6qqx/download_photos_videos_and_gifs_in_mass",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Download photos, videos and GIFs In mass",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DullishPlum",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T06:32:06.615268+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T06:29:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a large collection of STLs (~2tb). I need to come up with a way of keeping track of all of them. I would like a way that lets me tag them all by type, artist, character\u2026etc. preferably a web UI where any preview renders of the files can be displayed. Any suggestions?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DullishPlum\"> /u/DullishPlum </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw5pde/stl_organization_system/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw5pde/stl_organization_system/\">[comments]</a></span>",
        "id": 3129062,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw5pde/stl_organization_system",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "STL organization system",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/skylinestar1986",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T06:32:06.105124+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T05:56:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to setup a simple backup operation for my old dad. His PC currently has an SSD. I will addon a SSD/HDD and use a backup program (probably the old Macrium Reflect free edition) to backup (imaging) the drive weekly. The backup process should be transparent to him as it is running silently at the background. However, there is something that I may worry. What happen to the backup process if he shutdown the PC? Or he does a restart with Windows Update?</p> <p>I also think of just using Clonezilla/Rescuezilla to clone manually myself. How long does it take to clone 1TB of SSD? In Windows, is it possible to permanently hide the cloned backup drive (so it doesn&#39;t appear in File Explorer)?</p> <p>Is there better solution?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/skylinestar1986\"> /u/skylinestar1986 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw56r5/silent_and_hidden_b",
        "id": 3129061,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw56r5/silent_and_hidden_backup_solution",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Silent and hidden backup solution",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Current_Inevitable43",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T03:15:45.993697+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T02:52:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Well I&#39;m going to stay with windows for my simple media server Plex And download PC </p> <p>I have a few 24tb hard drives (media collection is ~15tb)</p> <p>Should I throw both drives in and clone them so I have a full automatic back up. Or use it as xternal drive to back it up every now and then to keep the hrs down on the drive. </p> <p>Yes I should/could go true Nas but it&#39;s simple and works. My old 6500t system I&#39;ll start to play with true Nas. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Current_Inevitable43\"> /u/Current_Inevitable43 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw1x4b/backing_up_windows_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw1x4b/backing_up_windows_data/\">[comments]</a></span>",
        "id": 3128292,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw1x4b/backing_up_windows_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Backing up Windows data.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/angelhuntr",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T03:15:46.167344+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T02:19:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I would like to ask for some recommendations, or maybe some examples of existing working setups from someone that has similar requirements to mine.</p> <p>I&#39;m looking to set up a NAS/Server and security system able to:</p> <ul> <li> Store photos/videos (ideally with backups across drives, but not necessarily across different devices)</li> <li> Store recordings from security cameras (which I&#39;m also yet to buy, so I&#39;m flexible on which cameras)</li> <li> Being able to access files and videos (as well as camera recordings) from outside the home network</li> <li> Host a bunch of docker containers: <ul> <li> Plex server able to serve up to 4K movies for 5-6 users, rarely more than 2 users at the same time</li> <li> The Arrs stack</li> <li> Home Assistant</li> <li> Minecraft</li> </ul></li> </ul> <p>Maybe a bit outside the scope of this subreddit, but for the cameras I&#39;m mostly looking for something with no subscription fees, ",
        "id": 3128293,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw19pg/looking_for_recommendations_for_an_everything_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for recommendations for an 'Everything' NAS System",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fearless_Show_5080",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T04:22:33.357033+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T02:05:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone.</p> <p>I am a pretty big fan of the Goo Goo Dolls, and I bought a couple CDs at a record shop the other day. Two of the CDs were like &quot;enhanced&quot; or something, which with some research I saw was a pretty common feature for CDs in that late 90s to late 00s era.</p> <p>I loaded both CDs on my disc drive and to access that &quot;Enhanced&quot; bonus content, you were to run an .exe that was to take you to a special registration page. However, that page is offline. It just redirects me to MSN.</p> <p>So this had me thinking about bonus content like this. With some research I found out that a lot of these Enhanced CDs have the bonus content directly on the disc. Mine was hosted on a website.</p> <p>Using The Wayback Machine, I looked for some URLs about Gutterflower. (googoodolls.com and then I just searched every URL containing &quot;gutter&quot;) And I was able to get all of the bonus images this way! (That were archived at least)</",
        "id": 3128486,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw0zwz/anyone_know_anything_about_enhanced_cds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone know anything about Enhanced CDs? (Gutterflower and Goo Goo Dolls' EOAC compilation)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BigPandaCloud",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T02:10:45.414733+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T01:57:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m not sure what sub to post this question on. I can&#39;t stream a video file from my ASUSTOR AS6302T NAS to my TV or directly from the HDMI port. It&#39;s just to choppy. It is a 4k UHD movie i ripped from a bluray. How do people do this from their NAS servers? Is my NAS not powerful enough to stream the data? Any advice? Could a device like a roku or firestick play the file from the network if my nas can&#39;t play it directly? Thanks!</p> <p>Here is the data from the video file</p> <p>The Big Lebowski (1998) 4kUHD.mkv</p> <p>Format : Matroska</p> <p>Format version : Version 2</p> <p>File size : 56.0 GiB</p> <p>Duration : 1 h 57 min</p> <p>Overall bit rate mode : Variable</p> <p>Overall bit rate : 68.4 Mb/s</p> <p>Frame rate : 23.976 FPS</p> <p>Movie name : The Big Lebowski</p> <p>Writing application : MakeMKV v1.14.2 win(x64-release)</p> <p>Writing library : libmakemkv v1.14.2 (1.3.5/1.4.7) win(x64-release)</p> <p>Video</p> <p>ID : 1</p> <p>I",
        "id": 3128056,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw0tks/playing_a_large_50gb_mkv_file_over_the_network_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Playing a large 50GB MKV file over the network to TV.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/srgsng25",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T02:10:45.585096+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T01:28:48+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1lw08kt/hba_card_for_30_drive_aray/\"> <img src=\"https://b.thumbs.redditmedia.com/Za4Qxd7z5OY9I0atdutQxS61jaxykzH4USK_MI9b_So.jpg\" alt=\"HBA card for 30 drive aray\" title=\"HBA card for 30 drive aray\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Looking to replace my current 16 -4tb drive setup after may years of service i found this case on fleebay today and this would actually work in our new Apartment and as a bonus the seller is local to me so cheaper. Now the question is what HBA do i use if i wanted to have 40ish drives isa raid configuration using trusnas unless i am feeling brave and stay on windows server </p> <p><a href=\"https://preview.redd.it/ae07rmrw8ybf1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=c359283c2584c539ee2b49184256d93485e720c6\">https://preview.redd.it/ae07rmrw8ybf1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=c359283c2584c539ee2b49184256d93485e720c6</a></p> <p><a href=\"htt",
        "id": 3128057,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lw08kt/hba_card_for_30_drive_aray",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/Za4Qxd7z5OY9I0atdutQxS61jaxykzH4USK_MI9b_So.jpg",
        "title": "HBA card for 30 drive aray",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/eggys82",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T02:10:45.053810+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T01:14:50+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1lvzy9e/finally_recursive_archiving_of_domains_with/\"> <img src=\"https://external-preview.redd.it/oAUIH4oD1AoBai_T7Z4Y1LUo9Xiq0RsOplGvYFIMGXU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7532f8ca7e8da7cd8cffd618a2d1522da201b8bb\" alt=\"FINALLY: Recursive archiving of domains, with ArchiveBox 0.8.0+\" title=\"FINALLY: Recursive archiving of domains, with ArchiveBox 0.8.0+\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/eggys82\"> /u/eggys82 </a> <br/> <span><a href=\"https://github.com/egg82/archivers\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lvzy9e/finally_recursive_archiving_of_domains_with/\">[comments]</a></span> </td></tr></table>",
        "id": 3128055,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lvzy9e/finally_recursive_archiving_of_domains_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/oAUIH4oD1AoBai_T7Z4Y1LUo9Xiq0RsOplGvYFIMGXU.png?width=640&crop=smart&auto=webp&s=7532f8ca7e8da7cd8cffd618a2d1522da201b8bb",
        "title": "FINALLY: Recursive archiving of domains, with ArchiveBox 0.8.0+",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Blebm",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T02:10:45.754490+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T01:07:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Previously considered DS1621+ but decided to add plex/jellyfin to my family use case (also audio server, iphone/ipad/mac/pc backup mainly photos) which flopped me over to ds423+ given transcoding.</p> <p>Now looking at the discount on the Ugreen during Prime Days, and considering the &quot;drive issue&quot; I am thinking F synology even tho I have a ds213j gathering dust and disconnected with our entire music library (for years / and yeah I need to do something hence this post).</p> <p>My ask: - Is Ugreen sw easy enough for casual user to set up properly? (built 5 PCs in the 90&#39;s, figured out the 213) - What is the Ugreen alternative to SHR, and how painful is it to upgrade drives (i have 6 4tb ironwolf NAS drives from LAST prime day, which should be a good start for us) - How is the Ugreen software ecosystem - for access to audio (iOS, pc, Samsung tv, Alexa), video (all but alexa but mostly Samsung), photos, other? My biggest concern is this - th",
        "id": 3128058,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lvzt3r/ugreen_dxp4800_plus_over_ds423_for_casual_family",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ugreen DXP4800 plus over DS423+ for casual family?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Paulroberto",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T01:06:29.163060+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T00:55:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have an SSD with 1TB of photos that I want to transfer to another SSD. I plan to use the second one as a backup in case anything ever happens to the first one (it&#39;s a different brand, 2nd device, etc).</p> <p>What would be the best way to do that? Simple click and drag on file-explorer between the two devices? Or is there a better method? It&#39;ll take about an hour with 260-ish MB/s, which I don&#39;t mind, but just wondering if there&#39;s a more effective way or if it&#39;s possibly unsafe for some reason through file explorer? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Paulroberto\"> /u/Paulroberto </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lvzjvn/transfer_1tb_of_photos_between_two_ssds/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lvzjvn/transfer_1tb_of_photos_between_two_ssds/\">[comments]</a></span>",
        "id": 3127747,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lvzjvn/transfer_1tb_of_photos_between_two_ssds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Transfer 1TB of Photos Between Two SSD's?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AggravatingTear4919",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T01:06:29.348198+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T00:47:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>please i really really want to watch and collect these videos but i cant find their origin and asking here is legit the last thing i can think of </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AggravatingTear4919\"> /u/AggravatingTear4919 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lvzdmn/where_can_i_find_the_original_marcus_the_worm/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lvzdmn/where_can_i_find_the_original_marcus_the_worm/\">[comments]</a></span>",
        "id": 3127748,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lvzdmn/where_can_i_find_the_original_marcus_the_worm",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "where can i find the original marcus the worm?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Kino45",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T01:06:29.569986+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T00:16:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I\u2019m kinda new to this kind of systems. I heard that synology seems to be the main used brand(although Iateley I\u2019ve been seeing it has a bad reputation but I\u2019m not sure why). </p> <p>I found this offer that consists of a Ds920+ Nas with 4x4tb ironwolf HDD included(around 25k hours each) for 530\u20ac and I wanted to know if it is a good offer. </p> <p>I\u2019m not really sure where to start with this but I guess having 4x4tb drives in a raid 5 setup seems a good option. If one of them breaks I can easily buy another one or just upgrade. </p> <p>My idea is to have a setup that lets me dump important files and have everything saved for a long time just in case I lose files if one of those disks breaks. Also I wanted to use it as a home media server to use it with plex. I shoot 4k and 6k video and this could work as a backup for the files of completed projects and I don\u2019t need but don\u2019t want to lose either. </p> <p>Lastly I also heard about going the DIY route ",
        "id": 3127749,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lvyqye/ds920_with_4x4tb_ironwolf_for_530_is_it_a_good",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ds920+ with 4x4tb ironwolf for 530\u20ac is it a good offer?",
        "vote": 0
    }
]