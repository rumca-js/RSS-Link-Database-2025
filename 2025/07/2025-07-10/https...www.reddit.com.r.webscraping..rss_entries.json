[
    {
        "age": null,
        "album": "",
        "author": "/u/pinkandfizzy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T21:17:57.330307+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T16:55:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey Scrapers</p> <p>I wanted to scrape the <a href=\"https://www.aweber.com/integrations/\">Aweber integrations partners</a>.</p> <p>Grab the business name, logo and description.</p> <p>How would I go about scraping something simple like that?</p> <p>The page loads in parts so I can&#39;t just copy and paste.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/pinkandfizzy\"> /u/pinkandfizzy </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lwhu4m/scrape_integrations_partners/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lwhu4m/scrape_integrations_partners/\">[comments]</a></span>",
        "id": 3135691,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lwhu4m/scrape_integrations_partners",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scrape Integrations Partners",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Extension_Grocery701",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T16:57:42.297157+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T16:13:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Im new to webscraping and i wanted to know which of these i could use to create a database of phone specs and laptop specs, around 10,000-20,000 items.</p> <p>First started learning BeautifulSoup then came to a roadblock when a load more button needed to be used</p> <p>Then wanted to check out selenium but heard everyone say it&#39;s outdated and even the tutorial i was trying to follow vs what I had to code were completely different due to selenium updates and functions not matching</p> <p>Now I&#39;m going to learn Playwright because tutorial guy is doing smth similar to what I&#39;m doing</p> <p>and also I saw some people saying using requests by finding endpoints is the easiest way</p> <p>Can someone help me out with this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Extension_Grocery701\"> /u/Extension_Grocery701 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lwgs6m/beautifulsoup_",
        "id": 3133576,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lwgs6m/beautifulsoup_selenium_playwright_or_puppeteer",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "BeautifulSoup, Selenium, Playwright or Puppeteer?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Key_Perspective6112",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T16:57:42.506049+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T16:09:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi</p> <p>I want to scrape the data on this page <a href=\"https://artemis.co/find-a-provider\">https://artemis.co/find-a-provider</a></p> <p>The goal is to get all locations info - name, phone, site. </p> <p>Only problem is that this loads dynamically as you scroll. </p> <p>Any ideas on how to do this ? Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Key_Perspective6112\"> /u/Key_Perspective6112 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lwgona/get_store_locations_from_elementor_widget/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lwgona/get_store_locations_from_elementor_widget/\">[comments]</a></span>",
        "id": 3133577,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lwgona/get_store_locations_from_elementor_widget",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Get store locations from elementor widget",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Leon_Goz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T14:47:37.417987+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T13:46:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So for context I used cursor to build myself a WebScript which should scrape some company\u2019s data from their website so far so good. Cursor used. json to build it everything fine scraper works awesome. So now I want to see the data which it scrapes in an webapp which cursonbuild aswell and I swear since I don\u2019t have coding experience I don\u2019t know how to fix it, but basically everytime Cursor gives me a local web test app the data is wrong even tho the original scraped data is correct this is manly because the frontend tried to parse the JSON file to get the needed data it then can\u2019t find it and uses random data it finds in that file or a syntax error and cursor fix it (that problem exist for a month now) I\u2019m running out of ideas I just don\u2019t know how to do it and there isn\u2019t really anyone I can ask and I don\u2019t have the funds to let someone look over it. So I\u2019m justvlooking for tips for how to store the data and how to get to it and let the front end ge",
        "id": 3132353,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lwd4zg/connecting_frontend_with_back_end",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Connecting Frontend with back end",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Character_Dream_2271",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T13:42:27.183241+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T12:42:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have used Python and LML searches to build scripts to scrape various sites. Most of the sites are technical documentation that I then use as part of writing solution documents that are in my field, which I then review and validate.</p> <p>Problem: I find that some sites make it difficult to scrape. I think it may be intentional.</p> <p>Is there a library out there that will analyze a site to recommend a best approach or several approaches to take?</p> <p>I find that I have to use one type of script for one set of documents in a site and another set of scripts for other sites. I would like to combine into one script that can detect the type of page and go with a given methodology.</p> <p>Example, on a side project I want to scrape the <a href=\"http://lds.org\">lds.org</a> website. And even more specific all of the content from <a href=\"https://www.churchofjesuschrist.org/study?lang=eng\">https://www.churchofjesuschrist.org/study?lang=eng</a>.</p> <p>I ",
        "id": 3131721,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lwbqtj/new_at_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New at Scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Agitated_Issue_1410",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T12:37:16.156338+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T12:21:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m building a bot to monitor(stock) and auto-checkout 1\u20133 products on a smaller webshop (nothing like Amazon). I\u2019m using requests + BeautifulSoup. I plan to run the bot 5\u201310x daily under normal conditions, but much more frequently when a product drop is expected, in order to compete with other bots. </p> <p>To avoid bans, I want to use proxies, but I\u2019m unsure how many IPs I\u2019ll need, and whether to go with residential sticky or rotating proxies.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Agitated_Issue_1410\"> /u/Agitated_Issue_1410 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lwbbbc/how_many_proxies_do_i_need/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lwbbbc/how_many_proxies_do_i_need/\">[comments]</a></span>",
        "id": 3131246,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lwbbbc/how_many_proxies_do_i_need",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How many proxies do I need?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ClassFine3562",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T11:32:08.319520+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T11:23:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Firstly I can&#39;t offer you any money or financial stuff you will get solid code for job portal which is ready to scrape but needs scaling and deployment i need some one to do for me you get learning and solid code for job portal (which i usually sell to my clients)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ClassFine3562\"> /u/ClassFine3562 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lwa8bk/i_need_someone_to_upscale_my_job_portal_scraper/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lwa8bk/i_need_someone_to_upscale_my_job_portal_scraper/\">[comments]</a></span>",
        "id": 3130773,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lwa8bk/i_need_someone_to_upscale_my_job_portal_scraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I need someone to upscale my job portal scraper",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Illustrious-Today686",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T10:20:38.139491+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T09:55:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone, i run a small business where we provide services of fire and safety to all shops or mall out there . So my question is how can i get phone number of all kind of shops wheather it is restaurant, coffee shop , clothing, shoe, bike , car and everything? I just want to get phone number so i can ask them if they need my services? I tried with Google map with an extension called &quot; instant data scrapper&quot; but it didn&#39;t work very well to me. So please give me any suggestions Thankyou </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Illustrious-Today686\"> /u/Illustrious-Today686 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lw8r19/how_to_scrape_phone_number_from_google_map/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lw8r19/how_to_scrape_phone_number_from_google_map/\">[comments]</a></span>",
        "id": 3130255,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lw8r19/how_to_scrape_phone_number_from_google_map",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape Phone number from Google map ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ChipRad",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T08:10:33.576296+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T07:18:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I&#39;ve done a bit of research, but can&#39;t figure out what&#39;s best for my needs.<br/> I need to scrape about 1000 to 2000 URLs once or twice a month to compare prices of competitors to ours.<br/> It&#39;s well-known UK retailers, so they have either CloudFlare or bot blockers enabled, and simple curl requests get blocked.<br/> Can someone recommend a reliable and low-cost service to use?<br/> What sort of price am I looking for something like that?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ChipRad\"> /u/ChipRad </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lw6gou/scraping_service_recommendations/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lw6gou/scraping_service_recommendations/\">[comments]</a></span>",
        "id": 3129534,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lw6gou/scraping_service_recommendations",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Service Recommendations",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Extension_Grocery701",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T08:10:33.745158+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T07:10:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve just started learning webscraping and was following a tutorial, but the website i was trying to scrape returned 403 when i did requests.get, i did try adding user agents but i think the website uses much more headers and has cloudflare protection- can someone explain in simple terms how to bypass it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Extension_Grocery701\"> /u/Extension_Grocery701 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lw6c8m/new_to_webscraping_how_do_i_bypass_403/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lw6c8m/new_to_webscraping_how_do_i_bypass_403/\">[comments]</a></span>",
        "id": 3129535,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lw6c8m/new_to_webscraping_how_do_i_bypass_403",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New to webscraping, how do i bypass 403?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/hangenma",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T07:05:34.961619+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T07:00:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m looking to build a bot that mirrors someone whenever they post something on thread (meta). Has anyone manage to do this? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hangenma\"> /u/hangenma </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lw66ri/is_anyone_able_to_set_up_a_real_time_threads_meta/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lw66ri/is_anyone_able_to_set_up_a_real_time_threads_meta/\">[comments]</a></span>",
        "id": 3129236,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lw66ri/is_anyone_able_to_set_up_a_real_time_threads_meta",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is anyone able to set up a real time Threads (Meta) monitoring?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/divided_capture_bro",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T07:05:34.747809+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T06:41:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m currently all about SeleniumBase as a go-to. Wonder how long until we can get the same thing, but driving Comet (or if it would even be worth it).</p> <p><a href=\"https://comet.perplexity.ai/\">https://comet.perplexity.ai/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/divided_capture_bro\"> /u/divided_capture_bro </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lw5w8r/comet_webdriver_plz/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lw5w8r/comet_webdriver_plz/\">[comments]</a></span>",
        "id": 3129235,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lw5w8r/comet_webdriver_plz",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Comet Webdriver Plz",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Actual-Poetry6326",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-10T01:40:33.281407+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-10T00:16:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys<br/> I&#39;m making an app where users enter a prompt and then LLM scans tons of news articles on the web, filters the relevant ones, and provides summaries.</p> <p>The sources are mostly Google News, Hacker News, etc, which are already aggregators. I don\u2019t display the full content but only title, summaries, links back to the original articles.</p> <p>Would it be illegal to make a profit from this even if I show a disclaimer for each article? If so, how does Google News get around this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Actual-Poetry6326\"> /u/Actual-Poetry6326 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lvyqeg/is_it_illegal_to_make_an_app_that_web_scrapes_and/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lvyqeg/is_it_illegal_to_make_an_app_that_web_scrapes_and/\">[comments]</a></span>",
        "id": 3127978,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lvyqeg/is_it_illegal_to_make_an_app_that_web_scrapes_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is it illegal to make an app that web scrapes and summarize using AI?",
        "vote": 0
    }
]