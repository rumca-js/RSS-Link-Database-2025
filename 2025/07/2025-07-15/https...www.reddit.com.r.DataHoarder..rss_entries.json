[
    {
        "age": null,
        "album": "",
        "author": "/u/Kyxstrez",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T21:52:55.770373+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T21:44:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m going to buy a brand new Toshiba 24TB drive and I&#39;m wondering how I should test that everything is fine on it. Doing a full scan with HD Tune Pro I think would take more than a day.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kyxstrez\"> /u/Kyxstrez </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0us8l/how_to_test_a_new_24tb_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0us8l/how_to_test_a_new_24tb_drive/\">[comments]</a></span>",
        "id": 3174319,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0us8l/how_to_test_a_new_24tb_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to test a new 24TB drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/likeOMGAWD",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T21:52:55.368039+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T21:01:34+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0tp8b/just_got_hardcore_scammed_by_amazon_warehouse/\"> <img src=\"https://b.thumbs.redditmedia.com/zVz7LtGvHD5HZazNX2eVPU-s-zuMDR_A1F68NzC0xOA.jpg\" alt=\"Just got hardcore scammed by Amazon Warehouse! Bought a 24TB WD Elements drive; received a 1TB Seagate Barracuda.\" title=\"Just got hardcore scammed by Amazon Warehouse! Bought a 24TB WD Elements drive; received a 1TB Seagate Barracuda.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I just got scammed HARD by an Amazon Warehouse &quot;Used - Like New&quot; 24TB WD Elements drive I purchased during Prime Day. Immediately upon unboxing it I was already suspicious because all the cords looked brand new/never used but the drive did not. When I went to attach the cords I couldn&#39;t even plug them in because both ports were smashed too far up inside the case:</p> <p><a href=\"https://preview.redd.it/03bjaukqm3df1.jpg?width=3011&amp;format=pjpg&amp;auto=webp&amp;s",
        "id": 3174318,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0tp8b/just_got_hardcore_scammed_by_amazon_warehouse",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/zVz7LtGvHD5HZazNX2eVPU-s-zuMDR_A1F68NzC0xOA.jpg",
        "title": "Just got hardcore scammed by Amazon Warehouse! Bought a 24TB WD Elements drive; received a 1TB Seagate Barracuda.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/duh1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T21:52:56.314464+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T20:55:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Isn&#39;t that cray cray?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/duh1\"> /u/duh1 </a> <br/> <span><a href=\"https://www.amazon.com/Amazon-Photos/b?ie=UTF8&amp;node=13234696011\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0tjl5/fyi_amazon_prime_members_get_unlimited_photo/\">[comments]</a></span>",
        "id": 3174320,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0tjl5/fyi_amazon_prime_members_get_unlimited_photo",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "FYI Amazon Prime Members Get UNLIMITED Photo Storage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GretaFromUS",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T20:46:57.461302+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T20:34:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello hoarders,<br/> I used to love visiting <a href=\"http://SweetHentai.com\"><strong>SweetHentai.com</strong></a>, but it&#39;s been offline for a while now. I recently bought the <strong>same domain</strong> and want to <strong>bring it back as close to the original as possible</strong>.</p> <p>The only version I have access to is via the Wayback Machine:<br/> \ud83d\udd17 <a href=\"https://web.archive.org/web/20191022121943/https://sweethentai.com/\">https://web.archive.org/web/20191022121943/https://sweethentai.com/</a></p> <p>Could anyone help me figure out how to <strong>extract the old template (.js .css .HTML files)</strong> from there? I\u2019m not super experienced with scraping archived pages, so any tips or tools would be appreciated!</p> <p>\u26a0\ufe0f <strong>NSFW warning</strong>: This is an adult site, so please only click if you&#39;re okay with explicit content.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GretaFromUS\"",
        "id": 3173855,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0szuq/trying_to_revive_old_site_need_help_pulling_old",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to revive old site \u2013 need help pulling old HTML",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/thinvanilla",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T20:46:56.929434+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T20:05:46+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0s8v1/wetransfer_updates_tcs_to_allow_it_to_use_your/\"> <img src=\"https://external-preview.redd.it/AHzEDtfEyoQuS68RLdhGYBL_wgQG7ozafaXgYd8zvU4.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9c481b2f50b10c66d562d76f88c71e74f7885595\" alt=\"WeTransfer updates T&amp;Cs to allow it to use your data for AI training\" title=\"WeTransfer updates T&amp;Cs to allow it to use your data for AI training\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/thinvanilla\"> /u/thinvanilla </a> <br/> <span><a href=\"https://filmstories.co.uk/news/wetransfer-updates-tcs-allows-it-to-use-your-data-to-train-ai/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0s8v1/wetransfer_updates_tcs_to_allow_it_to_use_your/\">[comments]</a></span> </td></tr></table>",
        "id": 3173853,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0s8v1/wetransfer_updates_tcs_to_allow_it_to_use_your",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/AHzEDtfEyoQuS68RLdhGYBL_wgQG7ozafaXgYd8zvU4.jpeg?width=640&crop=smart&auto=webp&s=9c481b2f50b10c66d562d76f88c71e74f7885595",
        "title": "WeTransfer updates T&Cs to allow it to use your data for AI training",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CanisMajoris85",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T20:46:57.215723+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T19:55:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Luckily no loss off anything since I have backup and Raid5 worked but had two issues in the past week.</p> <p>First I ordered two 24tb refurb drives from GoHardDrive and when they arrived one was making a knocking sound like 2x a second and not reading at all so have to return that. Still waiting for them to ackownledge receiving it since it&#39;s been 5 days since the package arrived according to tracking. I only ordered from them because ServerPartDeals was sold out at the moment and when I&#39;d posted asking about if I should expect restocks quickly once inventory sells out people here basically told me to go check a magic 8ball. Of course SPD restocked like the next day with 200 quantity and any time the inventory has dipped low it just seems to have gone back up but I hadn&#39;t started following stock levels until maybe 3 weeks ago.</p> <p>Then part way through copying files to the new 5x 24tb setup in Raid5 from my 5x 12tb in Raid5, I got a no",
        "id": 3173854,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0rz28/of_course_when_things_go_bad_they_happen_in_pairs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Of course when things go bad they happen in pairs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Living-Damage4250",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T20:46:57.632133+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T19:45:23+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0rpb5/not_sure_if_this_has_been_posted_but_heres_the/\"> <img src=\"https://external-preview.redd.it/g3zjeVMTjmEAUDQLW3tyYJvsKkZnADI6aNhQinJMtjY.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e899d83e50d53dc8503b3bb3850158ca2ab33702\" alt=\"Not sure if this has been posted, but here\u2019s the link to Jeffrey Epstein\u2019s \u201cLittle Black Book.\u201d\" title=\"Not sure if this has been posted, but here\u2019s the link to Jeffrey Epstein\u2019s \u201cLittle Black Book.\u201d\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Living-Damage4250\"> /u/Living-Damage4250 </a> <br/> <span><a href=\"https://archive.org/details/jeffrey-epstein-39s-little-black-book-unredacted/mode/1up\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0rpb5/not_sure_if_this_has_been_posted_but_heres_the/\">[comments]</a></span> </td></tr></table>",
        "id": 3173856,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0rpb5/not_sure_if_this_has_been_posted_but_heres_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/g3zjeVMTjmEAUDQLW3tyYJvsKkZnADI6aNhQinJMtjY.jpeg?width=108&crop=smart&auto=webp&s=e899d83e50d53dc8503b3bb3850158ca2ab33702",
        "title": "Not sure if this has been posted, but here\u2019s the link to Jeffrey Epstein\u2019s \u201cLittle Black Book.\u201d",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EsskAY_bEE",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T19:41:55.218700+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T19:20:11+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0r0vz/wd_my_passport_standard_vs_seagate_one_touch/\"> <img src=\"https://preview.redd.it/9wq15rt193df1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=38ee9c69e8ef7fe47458202bf0448a47bf002090\" alt=\"WD my passport Standard vs Seagate One touch?\" title=\"WD my passport Standard vs Seagate One touch?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Which one would be best for normal Android phone and other backups?</p> <p>WD my passport Standard vs Seagate One touch?</p> <p>Any other one?</p> <p>Looking for 2 TB portable HDD. Should I buy Online or Offline?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EsskAY_bEE\"> /u/EsskAY_bEE </a> <br/> <span><a href=\"https://i.redd.it/9wq15rt193df1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0r0vz/wd_my_passport_standard_vs_seagate_one_touch/\">[comments]</a></span> </td></tr></table>",
        "id": 3173364,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0r0vz/wd_my_passport_standard_vs_seagate_one_touch",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/9wq15rt193df1.png?width=640&crop=smart&auto=webp&s=38ee9c69e8ef7fe47458202bf0448a47bf002090",
        "title": "WD my passport Standard vs Seagate One touch?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/sirduke456",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T18:36:53.547942+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T18:28:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I run a small business with large quantities of customer data that needs to be archived. I only have one other employee and am leaning toward just setting up a Linux file server with two 24TB disks in RAID1 and call it good. However of course this would be on-site, and I imagine an offsite backup would be needed as well.</p> <p>I don&#39;t need to access the data very often. A good portion of it would be write-once read-many. I imagine even consumer-grade disks would be sufficient and intend to let the disks sleep most the time. I have a bunch of cronjobs that need to run in the middle of the night.</p> <p>Does anyone have a recommendation for a simple strategy for maintaining this quantity of data? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sirduke456\"> /u/sirduke456 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0pmy6/storage_archive_architecture/\">[link]</a></span> &#32; <span>",
        "id": 3172859,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0pmy6/storage_archive_architecture",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Storage Archive Architecture",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ZippyVtuber",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T18:36:53.968418+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T18:17:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Despite Youtube having permanent storage options, I always liked having my streams on my own hardware, which is why for the last 3, 3 and a half years or so I&#39;ve stored almost every single stream I did, each around 5 hours long, into hdds.</p> <p>Now, my 10TB hdd is becoming full. (I don&#39;t only store video in there but my pc and other pc as well). I have compressed the drives and will wait to see how much more space becomes available, but sooner or later it&#39;ll be full regardless. I searched for tape storage, figuring it would be cheaper than buying a 500$ CAD 10TB external hdd again, but seems the tape driver is not so cheap. I don&#39;t care about speed, I just want storage capacity.</p> <p>Do I have any other option other than just...buying another 10TB HDD?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ZippyVtuber\"> /u/ZippyVtuber </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/com",
        "id": 3172861,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0pcka/what_would_you_recommend_for_long_term_video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What would you recommend for long term video stream storage?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/sqrt_gm_over_r",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T18:36:53.722536+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T17:53:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi. I&#39;m hoping to get some recommendations for an enclosure for this hard drive: Crucial BX500 1TB 3D NAND SATA 2.5-Inch Internal SSD, up to 540MB/s - CT1000BX500SSD1, Solid State Drive.</p> <p>I bought this hard drive to replace the failed drive in my old laptop. Since getting a new laptop, I&#39;d like to take the Crucial drive out of the old laptop and put it in an enclosure to use it as an external hard drive for backing up files and such. I&#39;ve never looked into or bought a hard drive enclosure before so I&#39;d like some guidance on what to look for or look out for. I&#39;d like budget recommendations as this is not part of any kind of setup. I just want to be able to use the drive and get rid of the laptop it&#39;s currently in. Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sqrt_gm_over_r\"> /u/sqrt_gm_over_r </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0op98/ss",
        "id": 3172860,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0op98/ssd_enclosure_recs_removing_drive_from_laptop_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SSD Enclosure Recs - Removing drive from laptop and using as external drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CosmicGorilla",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T17:30:58.824992+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T17:28:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am an artist and record my process on video. I upload these in an edited format to various social media but I am looking to store the original files. I really just want to keep them for nostalgia or as a just in case, for example if a social media nuked my page for no apparent reason, which does happen, at least I could still grab the original files. I probably will keep local versions of the uploaded streamable compressed versions anyway since those will be smaller and more manageable.</p> <p>Once added to AWS, I plan to never touch them again, it would only be in extreme circumstances. Some of these videos can reach close to 60gb but on average would be about 30gb every week or two. So the $1/tb sounds very attractive.</p> <p>I do understand the PUT costs. Which these are large videos so negligible fee here and I don&#39;t intend to access the data; though the bulk retrieval doesn&#39;t look too expensive. The only thing that looks bad is the egre",
        "id": 3172201,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0o1h9/aws_glacier_for_long_term_storage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AWS Glacier for long term storage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/srgsng25",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T17:30:58.999356+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T17:17:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>what is the fastest way to migrate huge amount of data located on server 1 to server 2? </p> <p>each server has HBA cards and dual 10gig cards </p> <p>mainly video content </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/srgsng25\"> /u/srgsng25 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0nqqk/migrating_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0nqqk/migrating_data/\">[comments]</a></span>",
        "id": 3172202,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0nqqk/migrating_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "migrating data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Technical-Top4187",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T16:08:34.595489+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T15:58:20+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0ll4f/worth_it/\"> <img src=\"https://b.thumbs.redditmedia.com/VTvlaGy7q_tugqNOkJ9wuuUzf4_bjWFmRhebl5JM5yA.jpg\" alt=\"Worth it?\" title=\"Worth it?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Saw someone selling these on FB. Too risky? Worth it? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Technical-Top4187\"> /u/Technical-Top4187 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1m0ll4f\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0ll4f/worth_it/\">[comments]</a></span> </td></tr></table>",
        "id": 3171452,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0ll4f/worth_it",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/VTvlaGy7q_tugqNOkJ9wuuUzf4_bjWFmRhebl5JM5yA.jpg",
        "title": "Worth it?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/JadeLuxe",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T15:01:53.352718+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T14:26:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey Guys,</p> <p>I&#39;m Memo, founder of <strong><em>InstaTunnel</em></strong>, I built this tool for us to overcome and fix everything that&#39;s wrong with popular ones like Ngrok, Localtunnel etc, <a href=\"http://www.instatunnel.my/\">www.instatunnel.my</a></p> <p><strong>InstaTunnel: The Best Solution for Localhost Tunneling</strong></p> <p>Sharing your local development server with the world (\u201clocalhost tunneling\u201d) is a common need for demos, remote testing, or webhook development. InstaTunnel makes this <em>trivial</em>: one command spins up a secure public URL for your localhost without any signup or config. In contrast to legacy tools like Ngrok or LocalTunnel, InstaTunnel is built for modern developers. It offers lightning-fast setup, generous free usage, built\u2011in security, and advanced features\u2014all at a fraction of the cost of alternatives.</p> <p>Please read more here &gt; <a href=\"https://instatunnel.my/blog/why-wwwinstatunnelmy-is-the-bes",
        "id": 3170773,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0j733/built_an_ngrok_alt_that_offers_much_more_for_free",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Built An Ngrok Alt That Offers Much More For Free - InstaTunnel",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Daalma7",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T11:46:53.260151+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T11:42:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi there. I&#39;m trying to run a small Instagram scraping project focused only on my mutual followers, that is, people I follow and who follow me back (around 900 users). My goal is to analyze my own social network using Gephi.</p> <p>I&#39;m only interested in mutual connections <em>within</em> this group, I don&#39;t care about external links to people outside the 900. So far, I\u2019ve used <strong>Instaloader in Python</strong> to get the user IDs of my mutuals, then accessed their profiles to fetch their following lists. I then compare those lists to my mutuals list in order to build the network graph.</p> <p>To stay safe, I added random delays of 2\u20135 minutes between each profile lookup. On day 1, I analyzed 45 people; on day 2, I did 70. I always ran the script during my usual Instagram usage hours (not overnight or anything suspicious). However, when I logged in on day 3, I received a warning from Instagram saying they&#39;d detected automated beha",
        "id": 3169128,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0fjdf/trying_to_analyze_my_mutual_followers_network",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to analyze my mutual followers network with Gephi, but got flagged by Instagram, what now?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/nadal0221",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T11:46:53.430803+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T11:32:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Given that external hard drives are contemporary hard drives enclosed in a <em>casing and connect to the PC via a USB cable and are powered through an external power source such as the WD My Book range</em>, if they were removed from the casing and connected to the motherboard directly via a SATA cable, would it be decrypted using Bitlocker?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nadal0221\"> /u/nadal0221 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0fcep/are_external_hard_drive_that_offer_password/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0fcep/are_external_hard_drive_that_offer_password/\">[comments]</a></span>",
        "id": 3169129,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0fcep/are_external_hard_drive_that_offer_password",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "are external hard drive that offer password protection encrypted using Bitlocker?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Jupit-72",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T11:46:53.013904+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T11:31:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>You know, the ones that are too small (I recently discovered some old 200GB in and old drawer...) or those that are broken beyond repair?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Jupit-72\"> /u/Jupit-72 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0fblv/what_do_you_do_with_your_old_harddrives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0fblv/what_do_you_do_with_your_old_harddrives/\">[comments]</a></span>",
        "id": 3169127,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0fblv/what_do_you_do_with_your_old_harddrives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What do you do with your old harddrives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/UwUnabomber_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T11:46:52.800219+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T11:22:25+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0f5u4/was_the_foia_vault_deleted/\"> <img src=\"https://preview.redd.it/brmunhdnv0df1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4e6e02d2647551bb2851e01f2e22007159e8f5f8\" alt=\"Was the FOIA vault deleted?\" title=\"Was the FOIA vault deleted?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/UwUnabomber_\"> /u/UwUnabomber_ </a> <br/> <span><a href=\"https://i.redd.it/brmunhdnv0df1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0f5u4/was_the_foia_vault_deleted/\">[comments]</a></span> </td></tr></table>",
        "id": 3169126,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0f5u4/was_the_foia_vault_deleted",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/brmunhdnv0df1.png?width=640&crop=smart&auto=webp&s=4e6e02d2647551bb2851e01f2e22007159e8f5f8",
        "title": "Was the FOIA vault deleted?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/marioaiden1234",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T11:46:53.601579+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T10:51:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I was looking for some advice/help on getting a new hard drive. The PC it is going to be used as mainly a media server/living room emulation station and I was wondering as to what people would say about my choices. I was thinking of buying a WD Blue 8tb drive and a sata to usb adapter, however I saw better reviews on a Seagate Barracuda drive and I was wondering if there&#39;s one that&#39;s better than the other in what I need. I&#39;d prefer if it&#39;s under $150 (USD) or so but I can work with what I&#39;m given with.</p> <p>Thank you</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/marioaiden1234\"> /u/marioaiden1234 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0elmr/best_8tb_hard_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0elmr/best_8tb_hard_drive/\">[comments]</a></span>",
        "id": 3169130,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0elmr/best_8tb_hard_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best 8tb Hard drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sweaty-Toe-6211",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T10:43:12.319681+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T10:01:24+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0dr81/south_park_creators_matt_stone_and_trey_parker/\"> <img src=\"https://external-preview.redd.it/Mxv4kfJOUwa0hZr4pHnO9Ia6vJ-2-v_CntEo4BnHTTE.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a42e15177e3584d49d4c78d051fc8796fb6296e4\" alt=\"\u2018SOUTH PARK\u2019 creators Matt Stone and Trey Parker have hired litigator Bryan Freedman amid their dispute with the upcoming new owners of Paramount - A lawsuit is reportedly looking likely.\" title=\"\u2018SOUTH PARK\u2019 creators Matt Stone and Trey Parker have hired litigator Bryan Freedman amid their dispute with the upcoming new owners of Paramount - A lawsuit is reportedly looking likely.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sweaty-Toe-6211\"> /u/Sweaty-Toe-6211 </a> <br/> <span><a href=\"https://watchinamerica.com/news/paramount-faces-legal-threat-as-south-park-creators-push-back/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com",
        "id": 3168651,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0dr81/south_park_creators_matt_stone_and_trey_parker",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/Mxv4kfJOUwa0hZr4pHnO9Ia6vJ-2-v_CntEo4BnHTTE.jpeg?width=640&crop=smart&auto=webp&s=a42e15177e3584d49d4c78d051fc8796fb6296e4",
        "title": "\u2018SOUTH PARK\u2019 creators Matt Stone and Trey Parker have hired litigator Bryan Freedman amid their dispute with the upcoming new owners of Paramount - A lawsuit is reportedly looking likely.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Competitive-Art-5455",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T09:38:24.312828+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T09:28:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>hey guys i want to download a video from Patreon, however while i hit F12 and check network/media there are no video files links showing up - is there any way to download the video from patreon?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Competitive-Art-5455\"> /u/Competitive-Art-5455 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0d849/how_to_download_a_video_from_patreon/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0d849/how_to_download_a_video_from_patreon/\">[comments]</a></span>",
        "id": 3168136,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0d849/how_to_download_a_video_from_patreon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "how to download a video from Patreon?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/3Domse3",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T09:38:24.027321+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T09:01:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Running a DS220+ with 2 WD220EDGZ 22TB drives. So far didn&#39;t have the courage to delete some stuff but at the current rate, I&#39;ll have 2, maybe 3 weeks left...</p> <p>It&#39;s a disease! xD</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/3Domse3\"> /u/3Domse3 </a> <br/> <span><a href=\"https://i.redd.it/rc7xabew50df1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0ctiw/forced_to_look_at_this_since_more_than_3_months/\">[comments]</a></span>",
        "id": 3168135,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0ctiw/forced_to_look_at_this_since_more_than_3_months",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Forced to look at this since more than 3 months now... x_x",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Judgement_92",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T09:38:24.519790+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T08:47:18+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Judgement_92\"> /u/Judgement_92 </a> <br/> <span><a href=\"/r/software/comments/1m0clgj/advice_on_how_to_reduce_my_file_size_on_pc_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0clpg/advice_on_how_to_reduce_my_file_size_on_pc_for/\">[comments]</a></span>",
        "id": 3168137,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0clpg/advice_on_how_to_reduce_my_file_size_on_pc_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Advice on how to reduce my file size on pc for movies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Snickrrr",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T08:31:54.539492+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T08:14:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m looking for a 2 bay DAS (I don\u2019t need NAS). I understand that it\u2019s basically a SATA to USB machine. </p> <p>The problem is that most stuff is overpriced (ffs it\u2019s literally a plastic box with some cheap internals straight out of the 80s).</p> <p>In addition they all seem to have fans that blow into the motherboard with no access to the actual HDDs. Like for real who designed them lol. The fan is just cooling the motherboard. This is pretty much the case for all ORICO &amp; similar machines.</p> <p>Has anyone got a 2 bay DAS recommendation with actual good fan design where the air reaches the HDDs? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Snickrrr\"> /u/Snickrrr </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0c4qc/any_2_bay_das_with_fans_that_actually_work/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0c4qc/any_2_bay_das_with_fans_tha",
        "id": 3167715,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0c4qc/any_2_bay_das_with_fans_that_actually_work",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any 2 bay DAS with fans that actually work?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ddd102",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T08:31:54.714441+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T07:45:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It doesn&#39;t work since 8 hours ago.<br/> Please... repair it...</p> <p>Anyone use it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ddd102\"> /u/ddd102 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0bo2h/what_happen_in_the_may_air_bridgecom/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0bo2h/what_happen_in_the_may_air_bridgecom/\">[comments]</a></span>",
        "id": 3167716,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0bo2h/what_happen_in_the_may_air_bridgecom",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What happen in the May Air Bridge.com?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CrackedDaLibertyBell",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T17:30:59.209946+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T07:31:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Seagate just rolled out 30TB Exos M and IronWolf Pro drives using their Mozaic 3+ platform and HAMR tech. These are real, shipping now, and aimed at massive local storage for AI, NAS, and edge workloads.</p> <p>The Exos version targets data centers and hyperscale setups, while IronWolf Pro is for NAS users like many of us here. Both drives are 7200 RPM, CMR, and supposedly the densest HDDs available right now.</p> <p>Pricing isn\u2019t budget-tier, but it\u2019s not totally outrageous for the capacity: \u2022 30TB: $599.99 \u2022 28TB: $569.99</p> <p>I wrote up a full breakdown here if anyone wants details, quotes, and links: \ud83d\udd17 <a href=\"https://nerds.xyz/2025/07/seagate-30tb-exos-ironwolf-pro-hamr-storage-ai/\">https://nerds.xyz/2025/07/seagate-30tb-exos-ironwolf-pro-hamr-storage-ai/</a></p> <p>Would love to hear thoughts from anyone who\u2019s used Seagate\u2019s Mozaic-based HAMR drives. Are they solid for long-term hoarding?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a h",
        "id": 3172203,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0bgr7/seagate_launches_30tb_exos_and_ironwolf_pro_hard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seagate launches 30TB Exos and IronWolf Pro hard drives using HAMR",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/deatheater02",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T07:26:50.625693+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T06:40:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I wanted to setup my own NAS for which i needed hard drives. Now the problem is I an from India where importing cost as much as the drive. So i wanted to find some alternatives. Mostly I wanted to find if there was a company based here which sell these. Or if there is a place or person I can find. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/deatheater02\"> /u/deatheater02 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0an96/looking_for_serverpartdeals_alternatives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m0an96/looking_for_serverpartdeals_alternatives/\">[comments]</a></span>",
        "id": 3167426,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m0an96/looking_for_serverpartdeals_alternatives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for serverpartdeals alternatives.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Melodic_Use_926",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T05:18:11.252321+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T04:56:12+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Melodic_Use_926\"> /u/Melodic_Use_926 </a> <br/> <span><a href=\"/r/camcorders/comments/1m02nrb/need_help_with_hi8_digitizing_please/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m08wcb/need_help_with_hi8_digitizing_please/\">[comments]</a></span>",
        "id": 3166873,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m08wcb/need_help_with_hi8_digitizing_please",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help with hi8 digitizing please!!!!!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/sops343",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T17:30:59.828480+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T04:09:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey fellow datahoarders,</p> <p>I&#39;ve just open-sourced CallFS, a high-performance REST API filesystem that I think some of you might find interesting. It provides standard Linux filesystem access over various storage backends, including local disks and Amazon S3.</p> <p>I built this out of a need for a more straightforward and unified way to manage and access large, distributed datasets across different storage types. If you&#39;re constantly juggling multiple drives or cloud storage, and wish for a single, consistent filesystem interface to your entire collection, CallFS aims to provide that, with a focus on efficiency.</p> <p>Check it out and let me know what you think!</p> <p>Repo: <a href=\"https://github.com/ebogdum/callfs\">https://github.com/ebogdum/callfs</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sops343\"> /u/sops343 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1m081",
        "id": 3172204,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m081kg/ann_callfs_opensourcing_a_new_approach_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[ANN] CallFS: Open-Sourcing a New Approach to Accessing Distributed Hoards",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Air-Flo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T03:06:35.720915+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T02:20:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a Synology NAS and a 3.5&quot; USB enclosure which I backup the NAS to using HyperBackup. I have two 16TB drives, and I keep one drive in the garden shed in a Peli case and one indoors, and then rotate them every week or so as an offsite backup. But the backup itself is only about 8TB so I don&#39;t really have a massive amount of data.</p> <p>I found out you can include external hard drives in Backblaze backups (I always thought the &quot;unlimited&quot; aspect was <em>only</em> the internal drive). So now I&#39;m wondering, if I just took the USB enclosure I have and plug it into my computer, I could then upload the HyperBackup file to Backblaze right? And get a proper offsite backup?</p> <p>Actually my backup drives are formatted as ext4 which isn&#39;t natively read on a Mac, so I&#39;d probably get a third drive to do this and format it to exFAT. So, let&#39;s say I get a third drive (Then I can continue my normal method of rotating the tw",
        "id": 3166422,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m05vof/can_i_backup_my_nas_to_an_external_drive_and_then",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can I backup my NAS to an external drive and then back that up to Backblaze?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ritz11111",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T18:36:54.466744+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T02:02:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey fellow hoarders,</p> <p>I\u2019ve been thinking a lot about the <em>other side</em> of hoarding\u2014<strong>retrieval.</strong></p> <p>Storing terabytes is one thing, but when you\u2019re looking for a specific video, PDF, or project from 2017, what\u2019s your go-to method?</p> <ul> <li>Do you rely on folder structures?</li> <li>Filename conventions?</li> <li>Some kind of local indexing or tagging system?</li> <li>Or just memory + brute force?</li> </ul> <p>I\u2019m exploring smarter storage systems (maybe object storage + metadata + local AI indexing) and wondering if people like us even face this problem regularly.</p> <p><strong>Curious to know:</strong></p> <ol> <li>How do you search and retrieve data in your archive?</li> <li>Are there any tools (open source or self-built) you swear by?</li> <li>What\u2019s the biggest friction point when you need to \u201cfind that one thing\u201d?</li> <li>Would a local, privacy-first search assistant (like AI-over-your-archive) be overkill or ",
        "id": 3172862,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m05hm4/for_those_with_large_personal_archiveshow_do_you",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "For those with large personal archives\u2014how do you actually retrieve what you\u2019re looking for?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/iObserve2",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T02:02:38.945061+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T01:44:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It&#39;s a rhetorical question asked in this forum as a self-congratulatory fist pump. because we all know the answer. Carnage. It just happened again. Whenever I do a project, I file and hoard every piece of data. Every email, letter contract receipt, meeting note. Everything. I don&#39;t use a document management system just a file naming convention and a logical folder hierarchy. ProjectA/Consultants/UI-Design/2025-01-23-Design meeting 1.pdf. This year there was trouble with a project as a result of a series of poor decisions made by one of the team leaders a few years back. However, when the trouble landed, it landed on me. Unfortunately for the finger pointer (who naturally was the one responsible) when the moment of accountability arrived, they were armed with a few lines from emails taken out of context in a single page and a totally credible narrative. I came armed with a dossier over an inch thick and didn&#39;t have to say a word. It was not",
        "id": 3166194,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m053y6/what_happens_when_a_nondata_hoarder_starts_an",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What happens when a non-data hoarder starts an information war with a data hoarder?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ligerzeronz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-15T00:56:35.531392+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-15T00:15:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need some help on how to proceed forward after hardware failures have left me abit hanging. </p> <p>I used to run a NAS setup, then onto 2 servers. </p> <p>The one i have which runs all my apps is a HP ML350P G8. I then had a HP DL180 G6. I got these both 2nd hand.</p> <p>The problems has started on the DL180. The Backplane has decided to just give up the ghost one night. I&#39;ve pulled everything out, and it does boot, just that the backplane has no power at all. </p> <p>Being aggrevated by this, I&#39;ve decided to just build my own. This server also had some fan issues where it was operating at 100% nearly all the time even tho it was stone cold, and no other peripherals attached. </p> <p>All I want for this is to be storage, kinda like a jbox. I already have a case (Corsair Graphite 600T) with a modified drive bay to house more drives.</p> <p>The problem tho is my path to parts. I have a mixture of SAS and SATA drives. 3x 6TB SAS, 2x 4TB SAS, a",
        "id": 3165967,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1m036he/first_diy_build_help",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "First DIY build help!",
        "vote": 0
    }
]