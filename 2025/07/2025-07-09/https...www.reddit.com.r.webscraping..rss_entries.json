[
    {
        "age": null,
        "album": "",
        "author": "/u/smokedX",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-09T20:15:43.575693+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-09T19:58:48+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1lvsn42/datadome_captcha_wall_need_help_getting_around_it/\"> <img src=\"https://preview.redd.it/r2q21m5fmwbf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=10ddbe1a85f1fe5ed2e2e9fb729aeb648ac488d8\" alt=\"DataDome CAPTCHA Wall ; Need Help Getting Around It (Willing to Pay)\" title=\"DataDome CAPTCHA Wall ; Need Help Getting Around It (Willing to Pay)\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Trying to scrape data from the a portal, but I&#39;m getting blocked by DataDome with captchas and 403 errors. See screenshots below.</p> <p>Anyone know a reliable way to bypass this? Happy to pay for solid guidance or direction (captcha solving, browser automation, token handling, etc.).</p> <p>Comment or DM if you\u2019ve dealt with this before. Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/smokedX\"> /u/smokedX </a> <br/> <span><a href=\"https://i.redd.it/r2q21m5fmwbf1.jpe",
        "id": 3125952,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lvsn42/datadome_captcha_wall_need_help_getting_around_it",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/r2q21m5fmwbf1.jpeg?width=640&crop=smart&auto=webp&s=10ddbe1a85f1fe5ed2e2e9fb729aeb648ac488d8",
        "title": "DataDome CAPTCHA Wall ; Need Help Getting Around It (Willing to Pay)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/-pawix",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-09T20:15:43.407664+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-09T19:46:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey folks,</p> <p>I\u2019ve fully reverse engineered an app\u2019s entire signature system and custom headers, but I\u2019m stuck at the final step: generating a valid x-recaptcha-token.</p> <p>The app uses reCAPTCHA v3 (no user challenge), and I do have the site key extracted from the app. In their flow, they first get a 410 (checks if your signature and their custom headers are valid), then fetch reCAPTCHA, add the token in a header (x-recaptcha-token), and finally get a 200 response.</p> <p>I\u2019m trying to figure out how to programmatically generate these tokens, ideally for free.</p> <p>The main problem is getting a valid enough token that the backend accepts (score-based in v3), and generating it each request, they only work one time.</p> <p>Has anyone here actually managed to pull this off? Any tips on what worked best (browser automation, mobile SDK hooking, or open-source bypass tools)?</p> <p>Would really appreciate any pointers to working methods, scripts, o",
        "id": 3125951,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lvsc6l/anyone_able_to_generate_xrecaptchatoken_v3_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone able to generate x-recaptcha-token v3 from site key?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/sneakerpoorguy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-09T18:05:37.962914+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-09T17:41:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I&#39;d like to know a little bit about the feasibility of this... I know it&#39;s possible to customize Amazon&#39;s API to show things like &quot;only products under $200&quot; and narrow down the search results in my website, but is it possible to also filter by &quot;Free Shipping to Chile&quot;? The thing is that I have a website and I want to include a search bar that shows Amazon&#39;s results. I don&#39;t want to provide filters for my visitors, just show products under $200 and with Free Shipping to Chile. Is this possible?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sneakerpoorguy\"> /u/sneakerpoorguy </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lvp4jn/amazon_spapi_doubt/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lvp4jn/amazon_spapi_doubt/\">[comments]</a></span>",
        "id": 3124884,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lvp4jn/amazon_spapi_doubt",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Amazon SP-API doubt",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/marres",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-09T09:25:37.116108+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-09T08:30:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><h1>Copperminer \u2013 A Gallery Ripper</h1> <p>Download Coppermine galleries the right way</p> <p>TL;DR:</p> <ul> <li>Point-and-click GUI ripper for Coppermine galleries</li> <li>Only original images, preserves album structure, skips all junk</li> <li>Handles caching, referers, custom themes, \u201cmimic human\u201d scraping, and more</li> <li>Built with ChatGPT/Codex in one night after <a href=\"http://farfarawaysite.com/\">farfarawaysite.com</a> died</li> <li>GitHub: <a href=\"https://github.com/xmarre/Copperminer\">github.com/xmarre/Copperminer</a></li> </ul> <p><strong>WHY I BUILT THIS</strong></p> <p>I\u2019ve relied on fan-run galleries for years for high-res stills, promo pics, and rare celebrity photos (Game of Thrones, House of the Dragon, Doctor Who, etc).<br/> When the \u201choly grail\u201d (farfarawaysite.com) vanished, it was a wake-up call. Copyright takedowns, neglect, server rot\u2014these resources can disappear at any time.<br/> I regretted not scraping it when I could, an",
        "id": 3120344,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lvdicu/tool_release_copperminer_recursive_ripper_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[Tool Release] Copperminer: Recursive Ripper for Coppermine Galleries",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GenuineJenius",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-07-09T01:50:15.542747+00:00",
        "date_dead_since": null,
        "date_published": "2025-07-09T01:28:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I&#39;m fairly new to web scraping and trying to pull event information from a few different websites. Right now, I&#39;m using BeautifulSoup with requests, but I&#39;m running into trouble with duplicate events and data are going into the wrong column.</p> <p>If anyone has tips on how to reliably scrape event listings\u2014or tools or methods that work well for these kinds of pages\u2014I\u2019d really appreciate it!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GenuineJenius\"> /u/GenuineJenius </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lv68ti/tips_for_scraping_event_websites/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lv68ti/tips_for_scraping_event_websites/\">[comments]</a></span>",
        "id": 3118334,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1lv68ti/tips_for_scraping_event_websites",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tips for Scraping Event Websites?",
        "vote": 0
    }
]