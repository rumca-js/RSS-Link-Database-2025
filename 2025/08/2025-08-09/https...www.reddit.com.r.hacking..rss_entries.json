[
    {
        "age": null,
        "album": "",
        "author": "/u/100xdakshcodes",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-09T21:58:11.972569+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-09T21:25:27+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/100xdakshcodes\"> /u/100xdakshcodes </a> <br/> <span><a href=\"/r/bugbounty/comments/1mm0nu7/ios_app_prevent_http_traffic_from_being/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/hacking/comments/1mm0qth/ios_app_prevent_http_traffic_from_being/\">[comments]</a></span>",
        "id": 3293003,
        "language": "en",
        "link": "https://www.reddit.com/r/hacking/comments/1mm0qth/ios_app_prevent_http_traffic_from_being",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 534,
        "source_url": "https://www.reddit.com/r/hacking/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "iOS app prevent http traffic from being intercepted through BurpSuite proxy, any workaround for this?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dvnci1452",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-09T14:22:58.329829+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-09T14:21:20+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/hacking/comments/1mlqman/took_me_a_full_5_minutes_to_bypass_5000_hours_of/\"> <img src=\"https://preview.redd.it/fm5mfb4660if1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c8e4b76ba247a57e76945791b2463537dfb5f972\" alt=\"Took me a full 5 minutes to bypass &quot;5,000 hours of red teaming GPT-5&quot;\" title=\"Took me a full 5 minutes to bypass &quot;5,000 hours of red teaming GPT-5&quot;\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I really hope this isn&#39;t the path to Artificial General Intelligence.</p> <p><a href=\"https://github.com/Trivulzianus/Data-Structure-Injection\">Here&#39;s</a> the full repo explaining the approach.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dvnci1452\"> /u/dvnci1452 </a> <br/> <span><a href=\"https://i.redd.it/fm5mfb4660if1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/hacking/comments/1mlqman/took_me_a_full_5_minutes_to_bypass_5000_",
        "id": 3290756,
        "language": "en",
        "link": "https://www.reddit.com/r/hacking/comments/1mlqman/took_me_a_full_5_minutes_to_bypass_5000_hours_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 534,
        "source_url": "https://www.reddit.com/r/hacking/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/fm5mfb4660if1.png?width=640&crop=smart&auto=webp&s=c8e4b76ba247a57e76945791b2463537dfb5f972",
        "title": "Took me a full 5 minutes to bypass \"5,000 hours of red teaming GPT-5\"",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dvnci1452",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-09T07:52:50.963839+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-09T06:58:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve experimented with implementing backdoors into locally-hosted LLMs and the validity to then upload them back to HF (which I didn&#39;t).</p> <p>I&#39;ve successfully done so, in three separate ways:</p> <ol> <li><p>Modify the forward and backward hooks to dissuade the model from providing &#39;safe&#39; answers based on a hidden trigger (e.g. &#39;per our last discussion).</p></li> <li><p>Implant a small neural network that will do the same.</p></li> <li><p>Fine-tune the model to do the same, with an approach that is virtually impossible to find.</p></li> </ol> <p>I&#39;ve then wondered whether any malicious actors have managed to do so! I decided to test this against the first approach, which is easiest to audit since one doesn&#39;t have to download the actual model, just some wrapper code.</p> <p>So, I&#39;ve downloaded the wrapper code for 10k HF models, and ran a search to find custom forward and backward hooks.</p> <p>Rest assured, (un)f",
        "id": 3289055,
        "language": "en",
        "link": "https://www.reddit.com/r/hacking/comments/1mlj1nr/scanned_top_10k_used_huggingface_models_to_detect",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 534,
        "source_url": "https://www.reddit.com/r/hacking/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scanned top 10k used HuggingFace models to detect runtime backdoors",
        "vote": 0
    }
]