[
    {
        "age": null,
        "album": "",
        "author": "/u/Boring-Baker-3716",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-09T19:03:07.808706+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-09T18:12:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone! Working on a project where I&#39;m scraping news articles and running into some issues. Would love some advice since it is my first time scraping</p> <p><strong>What I&#39;m doing:</strong> Building a chatbot that needs to process 10 years worth of articles from antiwar.com. The site links to tons of external news sources, so I&#39;m scraping those linked articles for the actual content.</p> <p><strong>My current setup:</strong></p> <ul> <li>Python scraper with newspaper3k for content extraction</li> <li>Have checkpoint recovery working fine</li> <li><a href=\"http://Archive.is\">Archive.is</a> as fallback when sites are down</li> </ul> <p><strong>The problem:</strong> newspaper3k works decent on recent articles (2023-2025) but really struggles with older stuff (2015-2020). I&#39;m losing big chunks of article content, especially as I go further back in time. Makes sense since website layouts have changed a lot over the years.</p> <p><stro",
        "id": 3292323,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mlw65l/need_help_with_content_extraction",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help with content extraction",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/donnyjepp85",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-09T19:03:07.979507+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-09T18:00:42+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1mlvvlr/auto_populate_or_prefilled_website_form/\"> <img src=\"https://preview.redd.it/ps09v9kn91if1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=135e5c6dab056032c4897da8a3610899b3d46c35\" alt=\"Auto populate or prefilled website form\" title=\"Auto populate or prefilled website form\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I want the form to autopopulated when user parse their website link</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/donnyjepp85\"> /u/donnyjepp85 </a> <br/> <span><a href=\"https://i.redd.it/ps09v9kn91if1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mlvvlr/auto_populate_or_prefilled_website_form/\">[comments]</a></span> </td></tr></table>",
        "id": 3292324,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mlvvlr/auto_populate_or_prefilled_website_form",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ps09v9kn91if1.png?width=640&crop=smart&auto=webp&s=135e5c6dab056032c4897da8a3610899b3d46c35",
        "title": "Auto populate or prefilled website form",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SprayAffectionate321",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-09T17:58:13.086251+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-09T17:26:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve attempted to scrape a website using Selenium for weeks with no success as the list keeps coming up empty. I believed that a wrong class attribute for the containers was the problem, but the issue keep coming up even after I make changes. There several threads about empty lists, but their solutions don&#39;t seem to be applicable to my case.</p> <pre><code>from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.chrome.service import Service as ChromeService from webdriver_manager.chrome import ChromeDriverManager import time service = ChromeService(ChromeDriverManager().install()) driver = webdriver.Chrome(service=service) try: driver.get(&quot;https://www.walmart.ca/en/cp/furniture/living-room-furniture/21098?icid=cp_l1_page_furniture_living_room_59945_1OSKV00B1T&quot;) # Replace with your target URL time.sleep(5) # Wait for the page to load dynamic content product_items = driver.find_elements(By.CLA",
        "id": 3291944,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mlv1jn/list_comes_up_empty_even_after_adjusting_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "List comes up empty even after adjusting the attributes",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Puzzle_Age555",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-09T17:58:12.859571+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-09T17:17:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a quick question.</p> <p>I\u2019ve been digging into Perplexity AI, and I\u2019m genuinely fascinated by its ability to pull real-time data to construct answers. I\u2019m also very impressed by how it brings up fresh web content.</p> <p>I\u2019ve read their docs about <strong>PerplexityBot</strong> and seen the recent news about their <strong>\u201cstealth\u201d</strong> crawling tactics that <strong>Cloudflare pointed out</strong>. So I know the basics of what they\u2019re doing, but I\u2019m much more interested in the &quot;<strong>How&quot;</strong>. I\u2019m hoping some of you with deeper expertise can help me theorise about what\u2019s happening under the hood.</p> <p>Beyond the public drama, what does their internal scraping and processing pipeline look like? Some questions on my mind</p> <ul> <li><strong>What kind of tech stack do they use?</strong> I understand they may use their stack now, but what did they use in the early days when Perplexity launched?</li> <li><strong>How do they ",
        "id": 3291943,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mlutrk/what_is_the_real_process_behind_perplexitys_web",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What is the real process behind Perplexity\u2019s web scraping?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/RefrigeratorSouthern",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-09T16:53:06.893572+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-09T15:57:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is there a way to get ahead on the online virtual waiting room ? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/RefrigeratorSouthern\"> /u/RefrigeratorSouthern </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mlsvcb/ticketmaster/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mlsvcb/ticketmaster/\">[comments]</a></span>",
        "id": 3291609,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mlsvcb/ticketmaster",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Ticketmaster",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Agile-Working4121",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-09T15:48:06.133633+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-09T14:38:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How do you scrape a site without triggering their bot detection when they block headless browsers?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Agile-Working4121\"> /u/Agile-Working4121 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mlqzwy/scrape_a_site_without_triggering_their_bot/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mlqzwy/scrape_a_site_without_triggering_their_bot/\">[comments]</a></span>",
        "id": 3291289,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mlqzwy/scrape_a_site_without_triggering_their_bot",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scrape a site without triggering their bot detection",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Coding-Doctor-Omar",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-09T14:43:08.093221+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-09T13:42:33+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1mlpr78/why_cant_i_see_this_internal_api_response/\"> <img src=\"https://preview.redd.it/disn8kslzzhf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb3fabb6c7cf2e62d08e4aedb9b6a2202f855f7c\" alt=\"Why can't I see this internal API response?\" title=\"Why can't I see this internal API response?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I am trying to scrape data from booking.com, but the API response here is hidden. How to get around that??</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Coding-Doctor-Omar\"> /u/Coding-Doctor-Omar </a> <br/> <span><a href=\"https://i.redd.it/disn8kslzzhf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mlpr78/why_cant_i_see_this_internal_api_response/\">[comments]</a></span> </td></tr></table>",
        "id": 3290934,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mlpr78/why_cant_i_see_this_internal_api_response",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/disn8kslzzhf1.jpeg?width=640&crop=smart&auto=webp&s=fb3fabb6c7cf2e62d08e4aedb9b6a2202f855f7c",
        "title": "Why can't I see this internal API response?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Leather-Cod2129",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-09T13:38:07.032229+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-09T12:52:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I\u2019m running into a frustrating issue with my scraper. On some sites, I get blocked <strong>instantly</strong>, even though I\u2019ve implemented a bunch of anti-detection measures.</p> <p>Here\u2019s what I\u2019m already doing:</p> <ol> <li><strong>Playwright stealth mode:</strong>This library is designed to make Playwright harder to detect by modifying many properties that contribute to the browser fingerprint.pythonCopierModifier from playwright_stealth import Stealth await Stealth.apply_stealth_async(context)<br/></li> <li><strong>Rotating User-Agents:</strong> I use a pool (<code>_UA_POOL</code>) of recent browser User-Agents (Chrome, Firefox, Safari, Edge) and pick one randomly for each session.</li> <li><strong>Realistic viewports:</strong> I randomize the screen resolution from a list of common sizes (<code>_VIEWPORTS</code>) to make the headless browser more believable.</li> <li><strong>HTTP/2 disabled</strong></li> <li><strong>Custom HTTP he",
        "id": 3290586,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mlooyp/scraper_blocked_instantly_on_some_sites_despite",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraper blocked instantly on some sites despite stealth. Help",
        "vote": 0
    }
]