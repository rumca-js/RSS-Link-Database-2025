[
    {
        "age": null,
        "album": "",
        "author": "/u/Moomainmin",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T23:20:37.630809+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T23:16:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This is coming from someone who\u2019s completely new to burning DVD\u2019s and has done research for way too long that my eyes hurt. I use DVDStyler to burn some episodes of Bojack Horseman, only able to fit about 4 episodes per disc, but the quality drops around the 3-4 episode of the disc and it\u2019s infuriating. I saw online that encoders might convert my MP4\u2019s to better quality so they don\u2019t look so pixelated on my screen (also the image sort of pulses sometimes on screen too? Like randomly the colors will glitch and shift) can anyone recommend a free or good program for that? And also what are the best settings on the program? I really want to keep physical media bc my internet is god awful and sometimes my streaming services just don\u2019t work. Also for context my video bitrate on dvdstyler is 5mbps, and audio bitrate is 800, Ty for reading this far, I hope I gave enough context </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com",
        "id": 3387835,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwqfls/question_about_burning_dvds",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Question about burning DVD\u2019s",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Natural-Penalty2492",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T22:14:07.355094+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T21:43:06+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwo76v/i_am_doing_my_part/\"> <img src=\"https://b.thumbs.redditmedia.com/sHrcVU1u5PqRUIKgHTrEcLeP6coR3j_scpYYXvEm61g.jpg\" alt=\"I am doing my part\" title=\"I am doing my part\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>22.5 TB of data sent in the last 5 months. I am doing my part.</p> <p>If you need any help, I have unlimited bandwidth, i can seed any data, if you need. </p> <p><a href=\"https://preview.redd.it/zcdnvha60gkf1.png?width=634&amp;format=png&amp;auto=webp&amp;s=a722667f016c766bc619fec16384806f0796cf98\">https://preview.redd.it/zcdnvha60gkf1.png?width=634&amp;format=png&amp;auto=webp&amp;s=a722667f016c766bc619fec16384806f0796cf98</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Natural-Penalty2492\"> /u/Natural-Penalty2492 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwo76v/i_am_doing_my_part/\">[link]</a></span> &#32; <span><a hre",
        "id": 3387412,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwo76v/i_am_doing_my_part",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/sHrcVU1u5PqRUIKgHTrEcLeP6coR3j_scpYYXvEm61g.jpg",
        "title": "I am doing my part",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MReus11R",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T20:00:01.227272+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T19:30:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>On iOS devices, there\u2019s a common issue where files stop downloading once you exit the app. How do people usually download large MEGA files? Do you have to keep the screen on and stay inside the app the whole time?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MReus11R\"> /u/MReus11R </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwkr06/issue_with_mega_downloads/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwkr06/issue_with_mega_downloads/\">[comments]</a></span>",
        "id": 3386515,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwkr06/issue_with_mega_downloads",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Issue with mega downloads",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Zoombatrox",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T18:54:14.776064+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T18:46:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, I find myself in the odd position of having two Gen 5 nvmes, but a motherboard with one pcie5 m2 slot and one pcie4 m2 slot.</p> <p>I would like to set these up in a RAID1 to minimize downtime if/when one drive dies. But, ideally I would like to not be constrained to pcie4 performance.</p> <p>I assume if I naively set up a diskmgmt raid1 (this is a windows machine), I am constrained by the pcie4 slot, at the very least for writes.</p> <p>Can I realistically set up a mirrored drive where the slower drive is just &quot;eventually consistent&quot;? Something like a --write-behind on mdadm equivalent or even just some sort of daily rsync, but that mirrors the whole drive identically (including boot partitions).</p> <p>An odd situation, I know. Worst case I could set up both drives on pcie4, but it&#39;s sad leaving performance on the table.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Zoombatrox\"> /u/Zoombatro",
        "id": 3386008,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwjkth/an_unconventional_nvme_raid1_on_windows",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "An unconventional NVMe RAID1 on Windows? Unbalanced drive speeds",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/kanzphan123",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T18:54:14.357551+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T18:41:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Don\u2019t be lazy and postpone your duty(hobby) as a data hoarder. All it takes is a simple ban from the platform, or when the creator sold their channel for money, for your favorite content to be gone forever. </p> <p>Happened to me twice(2 channels). Some of my content creator are from a third world country, they build their channel until they are not, and the end result is always to sell their channel for extra cash. Unlike first world country creators, they would rather nuke their whole channel before selling it. Still, it\u2019s content that will forever be gone.</p> <p>The pain of losing the content before you are able to archive is almost as bad as losing that content in a hard drive failure.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/kanzphan123\"> /u/kanzphan123 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwjfjc/archive_that_channel_now_nothing_on_the_internet/\">[link]</a></span> ",
        "id": 3386007,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwjfjc/archive_that_channel_now_nothing_on_the_internet",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Archive that channel NOW!!! Nothing on the internet stays there forever",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AlwaysBlaze_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T18:54:14.125844+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T18:32:47+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwj7h5/cant_pay_wont_pay_impoverished_streaming_services/\"> <img src=\"https://external-preview.redd.it/2UAkcqDsGCiY8BdATiIwhMiI8Ls_-f6WPBA-NkTQl1E.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=628eef39cd59ad9cac6ba70180b2a8eb259b3d5b\" alt=\"Can\u2019t pay, won\u2019t pay: impoverished streaming services are driving viewers back to piracy\" title=\"Can\u2019t pay, won\u2019t pay: impoverished streaming services are driving viewers back to piracy\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AlwaysBlaze_\"> /u/AlwaysBlaze_ </a> <br/> <span><a href=\"https://www.theguardian.com/film/2025/aug/14/cant-pay-wont-pay-impoverished-streaming-services-are-driving-viewers-back-to-piracy\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwj7h5/cant_pay_wont_pay_impoverished_streaming_services/\">[comments]</a></span> </td></tr></table>",
        "id": 3386006,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwj7h5/cant_pay_wont_pay_impoverished_streaming_services",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/2UAkcqDsGCiY8BdATiIwhMiI8Ls_-f6WPBA-NkTQl1E.jpeg?width=640&crop=smart&auto=webp&s=628eef39cd59ad9cac6ba70180b2a8eb259b3d5b",
        "title": "Can\u2019t pay, won\u2019t pay: impoverished streaming services are driving viewers back to piracy",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/fliberdygibits",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T18:54:15.085057+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T18:19:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m in need of lots of USB drives around 32gb for a project. I assume looking for a &quot;lot&quot; on ebay is the best option and I know there are concerns over scammy products which aren&#39;t what they advertise. I also know how to test for those at least once I have them in hand (which could be too late?).</p> <p>Beyond that I&#39;m a bit out of my wheelhouse and I wonder if anyone has any tips for locating 10-20 at a time drives with relative assurance they will be legit? Or is this just going to require a bit of a gamble on my part?</p> <p>P.S. - I know I could pursue a refund from ebay but that adds another level of hassle.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/fliberdygibits\"> /u/fliberdygibits </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwiutb/purchasing_bulk_usb_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/",
        "id": 3386009,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwiutb/purchasing_bulk_usb_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Purchasing bulk USB drives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CHIRAGGOWDA",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T16:44:27.195694+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T16:38:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was looking for a picture of a friend and I came across a service that lets you reverse-search a person&#39;s face from a photo. It&#39;s called faceseek. It&#39;s pretty wild. I was so intrigued that I started thinking about the data behind it. Has anyone ever tried to archive a facial recognition database? What would that even look like?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CHIRAGGOWDA\"> /u/CHIRAGGOWDA </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwg3pv/has_anyone_tried_to_archive_a_facial_recognition/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwg3pv/has_anyone_tried_to_archive_a_facial_recognition/\">[comments]</a></span>",
        "id": 3384851,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwg3pv/has_anyone_tried_to_archive_a_facial_recognition",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Has anyone tried to archive a facial recognition database?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BearyJi",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T16:44:27.365482+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T16:38:11+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwg3gh/this_is_the_ali_coupon_i_have_recently_collected/\"> <img src=\"https://b.thumbs.redditmedia.com/EMYlUvG-zxnH3Bv1OgRRTIpE23tjAwpC7_YASQ0V_aA.jpg\" alt=\"This is the ali coupon I have recently collected. \ud83d\udc47 If you need it, pick it up yourself. (21/8)\" title=\"This is the ali coupon I have recently collected. \ud83d\udc47 If you need it, pick it up yourself. (21/8)\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BearyJi\"> /u/BearyJi </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1mwg3gh\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwg3gh/this_is_the_ali_coupon_i_have_recently_collected/\">[comments]</a></span> </td></tr></table>",
        "id": 3384852,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwg3gh/this_is_the_ali_coupon_i_have_recently_collected",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/EMYlUvG-zxnH3Bv1OgRRTIpE23tjAwpC7_YASQ0V_aA.jpg",
        "title": "This is the ali coupon I have recently collected. \ud83d\udc47 If you need it, pick it up yourself. (21/8)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/drinkwaterandbehappy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T15:34:37.972198+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T14:41:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I signed up for a trading course on this platform called WHOP. They have an app and website and all. I have been paying the monthly dues for the last few months but haven&#39;t got the time to complete the course. I am not able to continue paying the monthly dues now. Its getting too expensive. They have recorded lectures about trading and I would like to download those so I can learn at my own pace later on. I tried using a video download extension on chrome but it did not allow me to download these videos.</p> <p>Can anyone please suggest how to download these videos. Thank you</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/drinkwaterandbehappy\"> /u/drinkwaterandbehappy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwcuts/need_to_download_videos_from_an_online_course/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwcuts/need_to_download_videos",
        "id": 3384142,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwcuts/need_to_download_videos_from_an_online_course",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need to download videos from an online course subscription platform called WHOP. I have paid access right now but can't continue paying the monthly dues to keep my access to those videos.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PeepTheExposure",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T14:24:59.655021+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T14:19:41+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I work in film production and photography and I want to get an ideal home storage setup. I used to have an OWC Thunderbay 4 that just randomly died and doesn&#39;t mount anymore -- denied warranty service too - thankfully I had a backup.</p> <p>I am now thinking of investing in another RAID or NAS setup. Part of me thinks doing 2 x 20TB Western Digital Drives + Backblaze could satisfy my needs for redundancy and speed. </p> <p>The other part of me thinks that having a network accessible drive with 4 x HDDs could also work, however, I don&#39;t have a clear or easy connection directly to my router. </p> <p>My Macbook Pro M1 MAX has 4TB of internal SSD storage for &quot;hot&quot; projects. My ideal is that I&#39;d be able to move all of my &quot;cold&quot; (completed) projects onto this external system. </p> <p>Can someone point me in the right direction? I&#39;ve heard tons of bad stories about every NAS company out there and not sure what my ideal set",
        "id": 3383484,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwc956/curious_about_optimal_setup_for_cold_hot_storage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Curious about optimal setup for cold / hot storage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Classic-Plan-7966",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T14:24:59.476451+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T13:41:13+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Classic-Plan-7966\"> /u/Classic-Plan-7966 </a> <br/> <span><a href=\"/r/sysadmin/comments/1mwb8zx/is_this_dell_poweredge_r750xs_worth_buying/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwb9fd/is_this_dell_poweredge_r750xs_worth_buying/\">[comments]</a></span>",
        "id": 3383483,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwb9fd/is_this_dell_poweredge_r750xs_worth_buying",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is this Dell PowerEdge R750xs worth buying",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheBadCarbon",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T14:24:59.827288+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T13:39:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Do any of you collect and store images of art that you like digitally? Could be actual art pieces or a funny meme drawing you found online.</p> <p>For a bit of context, I have been fascinated by the art of trading card games, but I don&#39;t have enough interest in actually playing them. Spending hundreds even thousands on them just to be put in a binder and not played with seems like a bit of a waste. But I would love to have a digital collection I could flip through from time to time. Maybe even print out a nice one for display every once in a while. And I know I can just search up most of these, but that takes the <del>hoarding</del> collecting fun out of it.</p> <p>Also things like movie posters. I love the art and history that goes into these, but I do not have the space to hang up as many as I would like. So, having a digital collection at least seems like a nice alternative.</p> <p>Just curious if anyone else had done something similar. I figur",
        "id": 3383485,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwb7vt/collecting_and_storing_art_digitally",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Collecting and Storing Art Digitally",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Existing_Exercise127",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T12:14:44.212331+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T11:11:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have been thinking about creating a site in which commodities commonly in markets whole over the world is represented. Currently I plan on adding commodities which are currently in production and circulation. And also additional details like their price, their short description(company and normal use and so on), and commentary by the user who added the product. Then it could be categorised into models, groceries and stationery or such. How do u think i should go about this? What to look for or take into consideration?</p> <p>(By commodities I don\u2019t mean only raw materials or primary agricultural products, I meant all products in the market, raw and finished, big and small, mass produced and rarer products)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Existing_Exercise127\"> /u/Existing_Exercise127 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mw7yb2/i_have_been_planning_to_create_a_",
        "id": 3382348,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mw7yb2/i_have_been_planning_to_create_a_compendium_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I have been planning to create a compendium of commodities(only goods) whole over the world",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Existing_Exercise127",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T09:45:13.408635+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T08:49:11+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Existing_Exercise127\"> /u/Existing_Exercise127 </a> <br/> <span><a href=\"/r/Annas_Archive/comments/1mw5j6y/i_have_been_planning_to_create_a_compendium_of/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mw5jsz/i_have_been_planning_to_create_a_compendium_of/\">[comments]</a></span>",
        "id": 3381479,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mw5jsz/i_have_been_planning_to_create_a_compendium_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I have been planning to create a compendium of commodities(only goods) whole over the world",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/FiddleSmol",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T08:38:07.959243+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T08:04:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just dropping this here in case anyone wants a handy way to grab videos with yt-dlp using aria2c for faster downloads.</p> <p>I use this on Android (Termux), but it should work fine on Linux/WSL too. Before running, make sure you have ffmpeg, aria2, and yt-dlp installed.</p> <p>Installing the tools: </p> <p>ffmpeg:</p> <p>Termux: pkg install ffmpeg</p> <p>Linux/WSL (Debian/Ubuntu): sudo apt update &amp;&amp; sudo apt install ffmpeg</p> <p>aria2:</p> <p>Termux: pkg install aria2</p> <p>Linux/WSL (Debian/Ubuntu): sudo apt update &amp;&amp; sudo apt install aria2</p> <p>yt-dlp:</p> <p>Termux: pip install -U yt-dlp (requires Python and pip)</p> <p>Linux/WSL: pip install -U yt-dlp or download the standalone binary from the official yt-dlp GitHub releases and place it in your PATH.</p> <p>Here\u2019s the command I use \u2014 replace the URL at the end with your desired video and the quality you want, in this case change the &quot;480&quot;:</p> <p>ytdlp &amp;&amp; yt",
        "id": 3381100,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mw4v0v/handy_ytdlp_aria2c_setup_for_fast_video_downloads",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Handy yt-dlp + aria2c Setup for Fast Video Downloads on Android/Linux For Video Archiving",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/vic8760",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T07:30:02.537966+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T07:26:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.theregister.com/2025/08/20/ietf_dnsop_3901bis_ipv4_ipv6/\">https://www.theregister.com/2025/08/20/ietf_dnsop_3901bis_ipv4_ipv6/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/vic8760\"> /u/vic8760 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mw49kx/serious_wont_this_kill_half_the_internet/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mw49kx/serious_wont_this_kill_half_the_internet/\">[comments]</a></span>",
        "id": 3380803,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mw49kx/serious_wont_this_kill_half_the_internet",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Serious, Won't this kill half the internet ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Alexcsm2",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T03:08:27.487027+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T02:22:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Sorry if this has been discussed previously, I\u2019m a little new to data storage and I\u2019m just looking for a simple solution to my use case. Basically, I just want to store 1-2 tb of data running continuously. I currently have the basic Sabrent lay flat enclosure with no cooling (<a href=\"https://a.co/d/1H7zW7U\">https://a.co/d/1H7zW7U</a>) and I\u2019m curious if this is ok for small storage sizes long term (mainly concerned about heat). Should I upgrade to something with cooling? For a little context, I\u2019m planning on hooking this up to a Linux computer that will act as a home and cloud server, so I want it to be running the hard drive 24/7. Any insight is appreciated, thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Alexcsm2\"> /u/Alexcsm2 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mvyqj4/basic_enclosures_for_12tb_storage/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.c",
        "id": 3379718,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mvyqj4/basic_enclosures_for_12tb_storage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Basic enclosures for 1-2tb storage?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Red_dawg64",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-21T00:58:59.344643+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-21T00:49:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://www.thestreet.com/deals/acasis-6-in-1-external-hard-drive-and-docking-station-amazon-sale\">https://www.thestreet.com/deals/acasis-6-in-1-external-hard-drive-and-docking-station-amazon-sale</a></p> <p>Saw this and it peaked my interest because of the 8TB hard drive. Does anyone know what brand model of hard drive is enclosed?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Red_dawg64\"> /u/Red_dawg64 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mvwpkk/acasis_8tb_hard_drive_hub_anyone_know_what_kind/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mvwpkk/acasis_8tb_hard_drive_hub_anyone_know_what_kind/\">[comments]</a></span>",
        "id": 3379258,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mvwpkk/acasis_8tb_hard_drive_hub_anyone_know_what_kind",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Acasis 8tb hard drive hub. Anyone know what kind of hard drive is in this?",
        "vote": 0
    }
]