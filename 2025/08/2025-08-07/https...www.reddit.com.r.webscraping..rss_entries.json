[
    {
        "age": null,
        "album": "",
        "author": "/u/katzapmap",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-07T20:28:05.844617+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-07T20:17:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Full disclosure, I do not currently have any coding skills. I&#39;m an urban planning student and employee.</p> <p>Is it possible to build a tool that would scrape info from each parcel on a specific street from this map and input the data on a spreadsheet?</p> <p>Link included</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/katzapmap\"> /u/katzapmap </a> <br/> <span><a href=\"https://gis.buffalony.gov/portal/apps/webappviewer/index.html?id=77c7711c9d3546f99bf2cd765822ee22\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mkasvp/is_web_scraping_possible_with_this_gis_map/\">[comments]</a></span>",
        "id": 3277931,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mkasvp/is_web_scraping_possible_with_this_gis_map",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is web scraping possible with this GIS map?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DepartureDiligent743",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-07T21:33:12.181849+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-07T15:19:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey fellow scrapers! I&#39;m trying to extract geographic data on fiber optic deployment locations in France and need some guidance. I&#39;ve experimented with Selenium, Puppeteer, and direct API calls but I&#39;m still pretty new to this and feel like I&#39;m missing better approaches.</p> <p>What makes this tricky is that I need to separate the data based on map legend categories - typically &quot;already fibered,&quot; &quot;recently fibered,&quot; and &quot;programmed to be fibered&quot; areas. For the planned deployments, I&#39;d love to capture any timestamp data showing when they&#39;re scheduled, ideally organizing everything into a spreadsheet with timeline info.</p> <p>The main challenge is that these French telecom sites load map data dynamically via JavaScript, making it tough to extract both the coordinates and their corresponding legend status. I&#39;m also hitting rate limits on some sites. It&#39;s one thing to scrape basic location da",
        "id": 3278380,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mk2wz4/help_scraping_fiber_deployment_maps_with_status",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[Help] Scraping Fiber Deployment Maps with Status Categories",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Automatic_Cherry_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-07T16:08:07.906741+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-07T15:16:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What resources do you recommend to gain a broader understanding of web scraping?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Automatic_Cherry_\"> /u/Automatic_Cherry_ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mk2tvj/learn_web_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mk2tvj/learn_web_scraping/\">[comments]</a></span>",
        "id": 3275901,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mk2tvj/learn_web_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Learn Web Scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Comfortable-Ship-753",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-07T21:33:12.423934+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-07T12:08:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Need advice: Building a table tennis player statistics scraper tool (without using official APIs)</p> <p>Background:</p> <p>I&#39;m working on a data collection tool for table tennis player statistics (rankings, match history, head-to-head records, recent form) from sport websites for sports analytics research. The goal is to build a comprehensive database for performance analysis and prediction modeling.</p> <p>Project info:<br/> Collect player stats: wins/losses, recent form, head-to-head records</p> <p>Track match results and tournament performance</p> <p>Export to Excel/CSV for statistical analysis</p> <p>Personal research project for sports data science</p> <p>Why not official APIs:</p> <p>Paid APIs are expensive for personal research</p> <p>Need more granular data than typical APIs provide</p> <p>Current Approach:</p> <p>Python web server (using FastAPI framework) running locally</p> <p>Chrome Extension to extract data from web pages</p> <p>Semi",
        "id": 3278381,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mjybro/building_a_table_tennis_player_statistics_scraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Building a table tennis player statistics scraper tool",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/sqfreire",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-07T10:43:10.003155+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-07T10:18:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi!</p> <p>I am a researcher trying to understand the history and industry of web scraping. I&#39;m particularly interested in the role web scraping has in the broader context of the development of generative AI technologies. </p> <p>I am currenty trying to assess web scraping as work, focusing on the human role played in the supervision of automated scraping as a necessary step for the production of datasets, subsequently used for the training of generative AI systems. </p> <p>Trying out this subreddit to see if anyone has any resources with information about this.</p> <p>I would also be interested in talking with anyone who works as a web scraper or who does web scraping as part of their profession. Feel free to DM me if you&#39;d be up for it!</p> <p>For a bit of context:<br/> <strong>Why am I doing this research?</strong></p> <p>Most research on web scraping has been centered on the technical side of software development. As the dataset marketplac",
        "id": 3273190,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mjw9zm/history_and_industry_of_web_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "History and industry of web scraping?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MymoneyDontjigggle",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-07T04:09:39.295967+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-07T04:01:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, Im trying to scrape product reviews from Amazon, but I keep hitting a wall with the tools I have used. They only let me scrape not more than 100 reviews, even though there are over 2500 for some products. If you have any tips or suggestions, I would really appreciate it! Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MymoneyDontjigggle\"> /u/MymoneyDontjigggle </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mjq2g1/need_help_in_scraping_amazon/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mjq2g1/need_help_in_scraping_amazon/\">[comments]</a></span>",
        "id": 3271385,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mjq2g1/need_help_in_scraping_amazon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help in Scraping Amazon",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Corvoxcx",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-07T01:59:40.554730+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-07T01:21:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey Folks,</p> <p>Looking for some input on this question.....</p> <p>Main Question:</p> <ul> <li>Are any of you doing programatic product niche research? <ul> <li>Possibly using services like Jungle Scout or Helium 10</li> </ul></li> </ul> <p>Details:</p> <ul> <li>What I want to: <ul> <li>Identify competitors on Amazon</li> <li>Identify which products they are listing have high sales</li> <li>Optional: Identify potential their Alibaba manufacturer or manufacturers selling similar products.</li> </ul></li> </ul> <p>Would love some feedback/thoughts</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Corvoxcx\"> /u/Corvoxcx </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mjmr8v/question_programatic_product_research_and_third/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mjmr8v/question_programatic_product_research_and_third/\">[comments]</a></span>",
        "id": 3270928,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mjmr8v/question_programatic_product_research_and_third",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Question: Programatic Product Research and third party integration",
        "vote": 0
    }
]