[
    {
        "age": null,
        "album": "",
        "author": "/u/SunOfSaturnnn",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-05T23:43:41.808588+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-05T22:46:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>To attempt making a long story short, I\u2019ve recently been introduced to and have been learning about a number of things\u2014quantitative analysis, Python, and web scraping to name a few. </p> <p>To develop a personal project that could later be used for a portfolio of sorts, I thought it would be cool if I could combine the aforementioned things with my current obsession, Marvel Rivals. </p> <p>Thus the idea to create a program that would take in player data and run calculations in order to determine how many games you would need to play in order to achieve a desired rank was born. I also would want it to tell you the amount of games it would take you to reach lord on your favorite characters based on current performance averages and have it show you how increases/decreases would alter the trajectory. </p> <p>Tracker (dot) gg was the first target in mind because it has data relevant to player performance like w/l rates, playtime, and other stats. It also h",
        "id": 3261469,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1minwb7/gaming_data_questions",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Gaming Data Questions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ahmd-ramadan",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-05T23:43:41.977481+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-05T22:19:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, I&#39;m interested in building a service/tool that can monitor multiple social media platforms (like X, Reddit, etc.) for specific keywords in real time or near real time.</p> <p>The idea is to track mentions of certain terms across platforms \u2014 is it possible to build something like this?</p> <p>If anyone knows of any tutorials, videos, or open-source projects that can help me get started, I\u2019d really appreciate it if you could share them or mention the creators. Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ahmd-ramadan\"> /u/ahmd-ramadan </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1min908/can_build_a_tool_to_monitor_social_media_by/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1min908/can_build_a_tool_to_monitor_social_media_by/\">[comments]</a></span>",
        "id": 3261470,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1min908/can_build_a_tool_to_monitor_social_media_by",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can Build a Tool to Monitor Social Media by Keywords, Any Tutorials ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Mindless-Problem-187",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-05T23:43:42.146217+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-05T21:51:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Fair Warning: I&#39;m a noob, and this is more of a concept (or fantasy lol) for a purely undetectable data extraction method</p> <p>I&#39;ve seen one or two posts floating around here and there about taking images of a site, and then using an OCR engine to extract data from the images, rather than making requests directly to a site&#39;s DOM.</p> <p>For my example, take an active GUI running a standard browser session with a site permanently open, a user logged in, and basic input automation imitating human behavior to navigate the site (typing, mouse movements, scrolling, tabbing in and out). Now, add a script that switches to a different window so the browser is not the active window, takes OS-level screenshots, and switches back to the browser to interact, scroll, etc., before running again.</p> <p>What I don&#39;t know is what this looks like from the browser (and website&#39;s) perspective. With my limited knowledge, this seems like a hard-to-de",
        "id": 3261471,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mimjbr/scraping_heavilyfortified_sites_using_oslevel",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping heavily-fortified sites using OS-level data capture",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ges_20",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-05T20:29:00.248884+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-05T19:47:43+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1mijbbi/automated_bulk_image_downloader_in_python/\"> <img src=\"https://b.thumbs.redditmedia.com/vnPdcRANtmc3keDv98UOHs_ArgAQnzIYhYnDsBiiH8Q.jpg\" alt=\"Automated bulk image downloader in python\" title=\"Automated bulk image downloader in python\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I wrote this Python script a while ago to automate downloading images from Bing for a specific task. It uses requests to fetch the page and BeautifulSoup to parse the results.</p> <p>Figured it might be useful to someone here, so I cleaned it up and put it on GitHub: <a href=\"https://www.google.com/url?sa=E&amp;q=https%3A%2F%2Fgithub.com%2Fges201%2FBulk-Image-Downloader\"><strong>https://github.com/ges201/Bulk-Image-Downloader</strong></a></p> <p>The READMEmd covers how it works and how to use it</p> <p>It&#39;s nothing complex, just a straightforward scraper, It also tends to work better for general search terms; highly spec",
        "id": 3260292,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mijbbi/automated_bulk_image_downloader_in_python",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/vnPdcRANtmc3keDv98UOHs_ArgAQnzIYhYnDsBiiH8Q.jpg",
        "title": "Automated bulk image downloader in python",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Left_Illustrator3769",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-05T19:23:30.134526+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-05T16:54:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>hii everyone i am new to web scraping and what are free resources that you use for webscraping tools in 2025 sites i am mostly focusing on free resources as a unemployed member of the society and as web scraping evolved overtime i don&#39;t know most of the concepts it would be helpful for the info thanks :-)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Left_Illustrator3769\"> /u/Left_Illustrator3769 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1miekfn/web_scrapingguide_2025/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1miekfn/web_scrapingguide_2025/\">[comments]</a></span>",
        "id": 3259817,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1miekfn/web_scrapingguide_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "web scraping-guide 2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Past_Election_5005",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-05T14:01:38.902737+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-05T13:30:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Unfortunately my usage would fall right in between their plans so I need to overpay to use them. Looking for alternatives that are just as accurate</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Past_Election_5005\"> /u/Past_Election_5005 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mi98wm/any_other_services_as_accurate_as_scrapfly/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mi98wm/any_other_services_as_accurate_as_scrapfly/\">[comments]</a></span>",
        "id": 3256753,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mi98wm/any_other_services_as_accurate_as_scrapfly",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any other services as accurate as Scrapfly?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-05T14:01:38.726961+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-05T13:01:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels\u2014whether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>If you&#39;re new to web scraping, make sure to check out the <a href=\"https://webscraping.fyi\">Beginners Guide</a> \ud83c\udf31</p> <p>Commercial products may be mentioned in replies. If you want to promote your own products and services, continue to use the <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">monthly thread</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 3256752,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mi8kv1/weekly_webscrapers_hiring_faqs_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weekly Webscrapers - Hiring, FAQs, etc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cargt3",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-05T11:48:49.494907+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-05T11:21:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, </p> <p>I&#39;m building a RAG application and I need to scrape some pages for Markdown content. I&#39;m having issues with the Adidas website. I\u2019ve tried multiple paid web scraping solutions, but none of them worked. I also tried using Crawl4AI, and while it sometimes works, it&#39;s not reliable.</p> <p>I&#39;m trying to understand the actual bot detection mechanism used by the Adidas website. Even when I set headless=false and manually open the page using Chromium, I still get hit with an anti-bot challenge.</p> <p><a href=\"https://www.adidas.dk/hjaelp/returnering-refundering/returpolitik\"><em>https://www.adidas.dk/hjaelp/returnering-refundering/returpolitik</em></a></p> <p>regards</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cargt3\"> /u/cargt3 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mi6h9s/how_to_scrape_from_adidas_page_how_they_detect/\">[link]</a></span> &#32; <span><a",
        "id": 3255750,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mi6h9s/how_to_scrape_from_adidas_page_how_they_detect",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape from adidas page, how they detect its scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Arthur5242",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-05T09:39:41.239852+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-05T07:30:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey folks! I\u2019m new to web scraping and GitHub Actions, so I built something simple but useful for myself:</p> <p>\ud83d\udd17 Daily Hacker News Headlines Email Automation</p> <p>It scrapes the top 10 headlines from The Hacker News and emails them to me every morning at 9am (because caffeine and cybersecurity go well together \u2615\ud83d\udcbb).</p> <p>No server, no cron jobs, no laptop left on overnight \u2014 just GitHub doing the magic.</p> <p>Would love feedback, ideas, or just a friendly upvote to keep me motivated \ud83d\ude04</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Arthur5242\"> /u/Arthur5242 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mi2ppb/my_first_github_actions_web_scraper_for_hacker/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mi2ppb/my_first_github_actions_web_scraper_for_hacker/\">[comments]</a></span>",
        "id": 3254911,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mi2ppb/my_first_github_actions_web_scraper_for_hacker",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "My First GitHub Actions Web Scraper for Hacker News Headlines",
        "vote": 0
    }
]