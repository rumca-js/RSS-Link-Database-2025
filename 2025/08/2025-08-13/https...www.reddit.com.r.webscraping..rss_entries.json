[
    {
        "age": null,
        "album": "",
        "author": "/u/should_not_register",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-13T21:38:58.551873+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-13T20:49:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been doing a daily scrape, using curl impersonate for over a year no issues, but now\u2019s it\u2019s getting cloud flare blocked.</p> <p>The site has always had cloudflare protection on it.</p> <p>It seems like something may have updated on the cloudflare detection logic?</p> <p>I\u2019m using residential proxies as well, and cannot seem to crack it.</p> <p>I also resorted to using patchright to load a browser instance but it\u2019s also getting flagged 100% of the time.</p> <p>Any suggestions?? Fairly mission critical data scrape for our app. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/should_not_register\"> /u/should_not_register </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mpg7ry/has_cloudflare_updated_or_changed_its_detection/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mpg7ry/has_cloudflare_updated_or_changed_its_detection/\">[comments]</a></span>",
        "id": 3324049,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mpg7ry/has_cloudflare_updated_or_changed_its_detection",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Has cloudflare updated or changed its detection?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/myronfr",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-13T22:43:54.259200+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-13T17:03:43+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1mpa4qn/2025_update_fingerprinting_tutorial_for_web/\"> <img src=\"https://external-preview.redd.it/zH9tJNJ5laWvjrZHEPxpmO3qErRUIAjQjTbch3Y4dm4.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b80e4d599ebba1ec3377abfbc05a40fb74191f91\" alt=\"[2025 Update] Fingerprinting Tutorial for Web Scraping\" title=\"[2025 Update] Fingerprinting Tutorial for Web Scraping\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Major 2025 update \u2014 full whitepaper + tutorial on how passive fingerprinting impacts web scraping. We break down: \u2022 TLS/QUIC handshake fingerprints (JA3/JA4 vectors, ALPN, ext order) \u2022 HTML5 APIs as entropy sources (Canvas, Audio, Fonts, Sensors) \u2022 WebGL GPU profiling via shader precision, driver quirks, texture formats \u2022 How anti-bot systems combine these to detect scrapers Educational only \u2014 for understanding, modeling, and measuring detection vectors before scraping.</p> </div><!-- SC_ON --> &#32; submitted by",
        "id": 3324460,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mpa4qn/2025_update_fingerprinting_tutorial_for_web",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/zH9tJNJ5laWvjrZHEPxpmO3qErRUIAjQjTbch3Y4dm4.png?width=640&crop=smart&auto=webp&s=b80e4d599ebba1ec3377abfbc05a40fb74191f91",
        "title": "[2025 Update] Fingerprinting Tutorial for Web Scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/RobertTeDiro",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-13T08:38:02.130451+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-13T07:57:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m using C#, HtmlAgilityPack package and selenium if I need, on upwork I saw clients mainly search scraping done via Python. Yesterday I tried to write scarping using python which I already do in C# and I think it is easier using c# and agility pack instead of using python and beautiful soup package.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/RobertTeDiro\"> /u/RobertTeDiro </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1moyc31/which_language_and_tools_are_you_use/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1moyc31/which_language_and_tools_are_you_use/\">[comments]</a></span>",
        "id": 3318032,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1moyc31/which_language_and_tools_are_you_use",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Which language and tools are you use?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/fdarklord",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-13T09:43:17.460954+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-13T06:52:21+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1moxbnr/fast_bulk_requests_in_python/\"> <img src=\"https://external-preview.redd.it/7NTGr8gxR9_miWth8HE-V5v3LRQF_BN_KeZZRxnaJ3A.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ffc69d37c67fc9b8eceb8f06dfdf26b0d61f062d\" alt=\"Fast Bulk Requests in Python\" title=\"Fast Bulk Requests in Python\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>What do you think about this method for making bulk requests? Can you share a faster method?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/fdarklord\"> /u/fdarklord </a> <br/> <span><a href=\"https://youtu.be/glJscIWoFyk\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1moxbnr/fast_bulk_requests_in_python/\">[comments]</a></span> </td></tr></table>",
        "id": 3318340,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1moxbnr/fast_bulk_requests_in_python",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/7NTGr8gxR9_miWth8HE-V5v3LRQF_BN_KeZZRxnaJ3A.jpeg?width=320&crop=smart&auto=webp&s=ffc69d37c67fc9b8eceb8f06dfdf26b0d61f062d",
        "title": "Fast Bulk Requests in Python",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Winter-Current4456",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-13T07:32:53.007024+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-13T06:29:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello fellas, Do you know of a workaround to install playwright on fedora 42? That isn&#39;t supported by it yet.Has anyone overcame this adversity? Thanks in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Winter-Current4456\"> /u/Winter-Current4456 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mowylh/playwright_on_fedora_42_is_it_possible/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mowylh/playwright_on_fedora_42_is_it_possible/\">[comments]</a></span>",
        "id": 3317730,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mowylh/playwright_on_fedora_42_is_it_possible",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Playwright on Fedora 42, is it possible?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ok_Feature9744",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-13T06:27:44.411036+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-13T06:03:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking for something or someone to help sift through the noise on our target sites (Redfin, realtor, Zillow)</p> <p>Not looking for property info. We want agent info like name, state, cell, email and brokerage domain</p> <p>In an idea world, being able to prompt in natural language my query request would be amazing. But beggars can not be choosers.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok_Feature9744\"> /u/Ok_Feature9744 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mowiqc/looking_for_scraper_tool_or_assistance/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mowiqc/looking_for_scraper_tool_or_assistance/\">[comments]</a></span>",
        "id": 3317466,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mowiqc/looking_for_scraper_tool_or_assistance",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for scraper tool or assistance",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Extra-Astronaut5862",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-13T09:43:17.789614+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-13T05:43:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m going to run a task weekly for scraping. I&#39;m currently experimenting with running 8 requests at a time to a single host and throttling for RPS (rate per sec) of 1.</p> <p>How many requests should I reasonably have in-flight towards 1 site, to avoid pissing them off? Also, at what rates will they start picking up on the scraping?</p> <p>I&#39;m using a browser proxy service so to my knowledge it&#39;s untraceable. Maybe I&#39;m wrong?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Extra-Astronaut5862\"> /u/Extra-Astronaut5862 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mow77u/respectable_webscraping_rates/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mow77u/respectable_webscraping_rates/\">[comments]</a></span>",
        "id": 3318341,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mow77u/respectable_webscraping_rates",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Respectable webscraping rates",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/No_Feeling4670",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-13T02:07:45.397154+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-13T02:00:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m a digital marketer and need a compliant, robust scraper that collects a dealership\u2019s vehicle listings and outputs a normalized feed my site can import. The solution must handle JS-rendered pages, pagination, and detail pages, then publish to JSON/CSV on a schedule (daily or hourly).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No_Feeling4670\"> /u/No_Feeling4670 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1morwgu/digital_marketer_looking_for_help/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1morwgu/digital_marketer_looking_for_help/\">[comments]</a></span>",
        "id": 3316528,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1morwgu/digital_marketer_looking_for_help",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Digital Marketer looking for Help",
        "vote": 0
    }
]