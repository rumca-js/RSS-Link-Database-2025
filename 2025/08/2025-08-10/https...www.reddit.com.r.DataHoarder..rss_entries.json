[
    {
        "age": null,
        "album": "",
        "author": "/u/alkafrazin",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T23:37:53.119303+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T23:10:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been periodically grazing old japanese webpages, art and media type stuff, mostly phps but some of the more charming commercialite stuff as well, wgetting anything that looks interesting enough. I&#39;ve come across a few pages that just don&#39;t wget anything useful, though, due to the use of scripts to handle page linking. I undoubtedly have many many incomplete backups that I&#39;m not aware of, and can think of a few of the top of my head as well.</p> <p>Is there a good alternative that can handle scripts well enough to scrape pages like colobockle.jp effectively?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/alkafrazin\"> /u/alkafrazin </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmx2a0/better_alternatives_to_wget_for_archlinux/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmx2a0/better_alternatives_to_wget_for_archlinux/\">[comm",
        "id": 3299024,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmx2a0/better_alternatives_to_wget_for_archlinux",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "better alternatives to wget for archlinux?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Dinobam100",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T22:32:52.224030+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T22:20:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m planning to download and seed all available non-fiction books from Anna\u2019s Archive, LibGen, or similar sources in the near future. I\u2019m trying to figure out the most efficient way to do this.</p> <p>From what I understand, LibGen provides lists of magnet or torrent files that can be downloaded, but I\u2019m wondering if Anna\u2019s Archive might offer a better or easier way to grab everything. Is there a method (for example, a script, a database dump, or a text file of all magnet links) that would allow me to bulk-download all non-fiction books from these sites?</p> <p>Also, I\u2019m particularly interested in Lebanese non-fiction books (Arabic, by Lebanese authors). If anyone knows a reliable source for those\u2014whether on these archives or elsewhere\u2014I\u2019d appreciate the recommendation.</p> <p>Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Dinobam100\"> /u/Dinobam100 </a> <br/> <span><a href=\"https://www.reddit",
        "id": 3298795,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmvxnh/wanting_to_torrent_all_nonfiction_books_whats_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Wanting to torrent all non-fiction books. What's the best way about it?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/kelemvor33",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T22:32:52.394522+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T21:34:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi.</p> <p>I recently picked up two 4TB USB drives to use for backing up files from my laptop. It is mostly picture files from photography but also just standard documents and things. My plan is to keep one USB drive at home and keep one offsite &quot;in case the house burns down&quot;. I&#39;ll swap them out every so often.</p> <p>I want to be able to plug in the external drive and kick off a backup that will compare the contents of the external drive with my local drive and copy over anything that&#39;s new or modified and remove anything that&#39;s no longer there. Removed files should go into a recycle bin type folder on the USB drive in case I&#39;d need to restore something. Many times I move moves files from folder to folder or rename them so if it can handle stuff like that, all the better.</p> <p>If I run a backup every few days, each one should go really fast. However, when I then go swap out the USB drive with the one I keep offsite, I woul",
        "id": 3298796,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmuuce/whats_the_best_free_software_for_backing_up_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What's the best free software for backing up files to an external drive, and swapping between two drives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PricePerGig",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T21:27:59.002372+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T21:16:48+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PricePerGig\"> /u/PricePerGig </a> <br/> <span><a href=\"https://pricepergig.com/ebay-au\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmuep6/i_updated_pricepergigcom_to_add_ebaycomau_as/\">[comments]</a></span>",
        "id": 3298520,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmuep6/i_updated_pricepergigcom_to_add_ebaycomau_as",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I Updated PricePerGig.com to add \ud83c\udde6\ud83c\uddfa eBay.com.au \ud83c\udde6\ud83c\uddfa as requested in this sub",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/optimism0007",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T21:27:58.611971+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T20:34:59+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmtcyw/optical_discs_eat_20_years_of_preservation_for/\"> <img src=\"https://preview.redd.it/dh6izebn49if1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=289377c61fb3938e33687bb853678ed8f7d12850\" alt=\"Optical discs eat 20 years of preservation for breakfast!\" title=\"Optical discs eat 20 years of preservation for breakfast!\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Going through old stuff under the bed, I was surprised it played media flawlessly, even the 700MB CD-R disc which is probably older. <strong>What&#39;s the argument against optical storage solutions like the M-disc other than storage capacity?</strong></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/optimism0007\"> /u/optimism0007 </a> <br/> <span><a href=\"https://i.redd.it/dh6izebn49if1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmtcyw/optical_discs_eat_2",
        "id": 3298519,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmtcyw/optical_discs_eat_20_years_of_preservation_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/dh6izebn49if1.jpeg?width=640&crop=smart&auto=webp&s=289377c61fb3938e33687bb853678ed8f7d12850",
        "title": "Optical discs eat 20 years of preservation for breakfast!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/andreas0069",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T20:23:01.622033+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T19:26:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey DataHoarders,<br/> A few days back I shared my disk price tracker that I built out of frustration with existing tools (managing 1PB+ will do that to you). The feedback here was incredibly helpful, so I wanted to circle back with an update.</p> <p>Based on your suggestions, I&#39;ve been refining the web tool and just launched an iOS app. The mobile experience felt necessary since I&#39;m often checking prices while out and about\u2014figured others might be in the same boat.</p> <p><strong>What&#39;s improved since last time:</strong></p> <ul> <li>Better deal detection algorithms</li> <li>A little better ui for web.</li> <li>Mobile-first design with the new iOS app</li> <li>iOS version has currency conversion ability</li> </ul> <p><strong>Still working on:</strong></p> <ul> <li>Android version (coming later this year - sorry)</li> <li>Adding more retailers beyond Amazon/eBay - This is a BIG wish for people.</li> <li>Better disk detection - don&#39;t wa",
        "id": 3298267,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmrm3m/my_1pb_storage_setup_drove_me_to_create_a_disk",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "My 1PB storage setup drove me to create a disk tracker\u2014just launched the mobile version",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/broadcloak",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T19:18:03.013085+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T19:16:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m moving to the US in a few weeks and I have a couple of external HDDs that I use for Plex, so they&#39;re full of movies and TV shows. Is it better to bring them in carry-on or main luggage, or maybe just post them over seperately? And are they likely to get checked? I know what the TSA site says, but I&#39;m just wondering if anything has changed in the current circumstances.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/broadcloak\"> /u/broadcloak </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmrbsg/bringing_external_hard_drives_to_america/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmrbsg/bringing_external_hard_drives_to_america/\">[comments]</a></span>",
        "id": 3297958,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmrbsg/bringing_external_hard_drives_to_america",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Bringing external hard drives to America",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Neural_Nerd_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T19:18:03.197551+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T19:11:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I&#39;m in the market for a reliable external SSD and I&#39;m getting a bit lost in all the options. I&#39;ll primarily be using it for:</p> <ul> <li>Transferring large video and project files from my laptop.</li> <li>Storing and editing my Lightroom/Photoshop library directly from the drive.</li> <li>As a primary backup for important documents and code.</li> </ul> <p>I&#39;m looking for something in the 1TB to 2TB range.</p> <p>My research so far, including many posts on Reddit, keeps pointing towards the Crucial X9 Pro. It seems to have a great reputation for being a solid all-rounder with a good price-to-performance ratio.</p> <p>For those of you who own or have used the Crucial X9 Pro, I&#39;d love to get your honest, long-term review:</p> <ul> <li>How is the real-world speed holding up, especially during large file transfers (e.g., a 100GB folder)? Does it throttle?</li> <li>Have you had any issues with reliability or connect",
        "id": 3297959,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmr7cd/external_ssd_buying_guide_needed_2025_is_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "External SSD Buying Guide Needed (2025) - Is the Crucial X9 Pro still the king?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/optimism0007",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T19:18:02.631945+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T18:33:30+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmq7hx/optical_discs_eat_20_years_of_preservation_for/\"> <img src=\"https://preview.redd.it/6bme66bwj8if1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=03a5ab7b4918220c540d4b9ed8547202ec784b17\" alt=\"Optical discs eat 20 years of preservation for breakfast!\" title=\"Optical discs eat 20 years of preservation for breakfast!\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/optimism0007\"> /u/optimism0007 </a> <br/> <span><a href=\"https://i.redd.it/6bme66bwj8if1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmq7hx/optical_discs_eat_20_years_of_preservation_for/\">[comments]</a></span> </td></tr></table>",
        "id": 3297957,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmq7hx/optical_discs_eat_20_years_of_preservation_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/6bme66bwj8if1.jpeg?width=640&crop=smart&auto=webp&s=03a5ab7b4918220c540d4b9ed8547202ec784b17",
        "title": "Optical discs eat 20 years of preservation for breakfast!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ageless3",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T18:12:56.200907+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T17:43:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I bought a ASUSTOR NAS a bit ago, with 2 10TB WD Red drives. First round everything started up fine and one of the WD Red drives was never recognized. Also, did some trouble shooting (switching them around) and noticed the faulty drive was really loud. Sent it back for a replacement. Now the ASUSTOR software says the second drive is faulty? How likely is it that this is just bad luck or is there more likely an issue with the NAS? I have been building computers for a while now and feel that I have almost never gotten a faulty drive. Twice in a row seems bizarre.</p> <p>Anyone have thoughts?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ageless3\"> /u/Ageless3 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmow5k/nas_drives_2_failed/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmow5k/nas_drives_2_failed/\">[comments]</a></span>",
        "id": 3297643,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmow5k/nas_drives_2_failed",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "NAS Drives - 2 failed?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/FranconianBiker",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T17:07:51.470228+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T17:01:54+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmntst/rate_my_backup_strat/\"> <img src=\"https://preview.redd.it/3dr1aky248if1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3ff87a44906c0d106d99ae69beb0d2b940a559cd\" alt=\"Rate my backup strat\" title=\"Rate my backup strat\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>This is my lockbox offsite backup just in case my server rack burns down. The two tapes at the back are the important ones. Sadly I cannot backup my entire 10TB server currently due to the tapes being too small and me not having enough LTO6 tapes for a triple rotation at 10TB. I do plan on getting a LTO8 drive in the future for full backups. Especially since I plan on upgrading my SSD server to 22TB.</p> <p>I&#39;m happy to hear any improvement ideas!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/FranconianBiker\"> /u/FranconianBiker </a> <br/> <span><a href=\"https://i.redd.it/3dr1aky248if1.jpeg\">[li",
        "id": 3297338,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmntst/rate_my_backup_strat",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/3dr1aky248if1.jpeg?width=640&crop=smart&auto=webp&s=3ff87a44906c0d106d99ae69beb0d2b940a559cd",
        "title": "Rate my backup strat",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Keksdosendieb",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T17:07:51.224310+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T16:23:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys,</p> <p>lets say I want to save this livestream here: <a href=\"https://live.theworldgames.org/m/nHjSM4cJ?r=YWCYAAkX\">https://live.theworldgames.org/m/nHjSM4cJ?r=YWCYAAkX</a> </p> <p>I tryed a couple things but I can not find a valid URL to download from. </p> <p>Of course I could screencaputure but that seems a little clunky. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Keksdosendieb\"> /u/Keksdosendieb </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmmuen/i_need_a_hint_to_get_stuff_from_wg_streams/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmmuen/i_need_a_hint_to_get_stuff_from_wg_streams/\">[comments]</a></span>",
        "id": 3297337,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmmuen/i_need_a_hint_to_get_stuff_from_wg_streams",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I need a hint to get stuff from WG Streams",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lilblu87",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T16:02:50.806818+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T15:17:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was backing up on my hard drive, a flash drive, free cloud storage, and DVD-R or CD-R. However, I know things have changed over the years and I guess DVD/CD and flash drives are not as common anymore. </p> <p>What should I be buying? I don&#39;t have a lot of money. I definitely like backing stuff up to different sources/media though. Should I be looking at SSDs? I didn&#39;t think they were any more reliable than flash drives. I&#39;m so confused now. </p> <p>I&#39;m also interested to know the feelings on microSD cards. I like filling one up with photos or audio recordings, then backing the files up to multiple sources, then retiring the microSD card. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lilblu87\"> /u/lilblu87 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mml64b/what_type_of_media_is_recommended_for_backing_up/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.c",
        "id": 3296961,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mml64b/what_type_of_media_is_recommended_for_backing_up",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What type of media is recommended for backing up photos, documents and other personal files?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BeLikeDead",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T16:02:51.093761+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T15:14:48+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mml3rb/need_help_in_backing_up_data/\"> <img src=\"https://preview.redd.it/uqgfr2vyk7if1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff589d019e29f164b645e6b5ea1e1d7ab85f44e7\" alt=\"Need help in backing up data\" title=\"Need help in backing up data\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>How can I convert these pages (there are lots of them) into Excel files? I need to store them... Share your ideas.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BeLikeDead\"> /u/BeLikeDead </a> <br/> <span><a href=\"https://i.redd.it/uqgfr2vyk7if1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mml3rb/need_help_in_backing_up_data/\">[comments]</a></span> </td></tr></table>",
        "id": 3296962,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mml3rb/need_help_in_backing_up_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/uqgfr2vyk7if1.jpeg?width=640&crop=smart&auto=webp&s=ff589d019e29f164b645e6b5ea1e1d7ab85f44e7",
        "title": "Need help in backing up data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BestSelf2015",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T14:57:57.487242+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T13:53:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>There is a website with 30-40 blog posts with high quality charts/pictures. What would be the best way to backup the pages and also be able to view on my ipad? Is there a certain file format that is best? I don&#39;t mind paying for an app up to $25. </p> <p>Thank You!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BestSelf2015\"> /u/BestSelf2015 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmj5o5/archive_a_website_with_high_res_charts/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmj5o5/archive_a_website_with_high_res_charts/\">[comments]</a></span>",
        "id": 3296602,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmj5o5/archive_a_website_with_high_res_charts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Archive a website with high res charts?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/astride_unbridulled",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T12:47:51.113673+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T11:43:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It always stutters on </p> <p><code>Downloading m3u8 manifest</code></p> <p>Am I missing something or is this not possible currently?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/astride_unbridulled\"> /u/astride_unbridulled </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmgfjb/can_ytdlp_get_stuff_from_dailymotion/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmgfjb/can_ytdlp_get_stuff_from_dailymotion/\">[comments]</a></span>",
        "id": 3295926,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmgfjb/can_ytdlp_get_stuff_from_dailymotion",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can yt-dlp get stuff from Dailymotion?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/bugs181",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T11:42:56.803366+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T11:15:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>TL;DR: Single ZFS mirror vdevs per pool with MergerFS and double parity vdevs with SnapRaid.</strong></p> <p>Well, after running the setup that I have for a while; I seem to be outgrowing my storage setup. Who would have thought that collecting ISOs could be so addicting? Especially as ISOs get larger and larger. Surprisingly my hot dog collection is growing more than anticipated too. Add in the fact that Steam games are also getting larger.</p> <p>I&#39;m currently running the 12U Startech open rack with a 12 bay DAS. My new upgrade plan is to buy a new 27U server cabinet, essentially doubling my space. Part of this upgrade will see a new 24 bay storage shelf, just for ISOs and such. Keeping the 12 bay with 3-wide ZFS mirrors for important data.</p> <p>I have been very very happy with my 3x3 ZFS mirrors. I just recently moved and during the move, several drives died. I didn&#39;t have a single issue resilvering, even though it was nerve wrack",
        "id": 3295639,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmfxde/call_me_crazy_i_want_this_setup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Call me crazy, I want this setup",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/RoughTechnology4741",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T09:32:55.028673+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T08:56:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Assuming you use the same PC how do you avoid viruses from all the porn downloading?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/RoughTechnology4741\"> /u/RoughTechnology4741 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmdo2a/do_you_have_a_separate_pc_for_data_hoarding_or_do/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmdo2a/do_you_have_a_separate_pc_for_data_hoarding_or_do/\">[comments]</a></span>",
        "id": 3295127,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmdo2a/do_you_have_a_separate_pc_for_data_hoarding_or_do",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Do you have a separate PC for data hoarding or do you use the same PC for everything?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Bertrum",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T08:27:52.943719+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T08:17:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I saw this video: <a href=\"https://www.youtube.com/watch?v=L5RJZmuRJKA\">https://www.youtube.com/watch?v=L5RJZmuRJKA</a> of a person creating their own backup of Wikipedia on a laptop using a Debian based OS called Zorin and Kiwix to download Wikipedia, but I wanted to know if you can do the same thing for any website you want or have a specific URL/domain you want to use that may be more obscure or lesser known. Because my goal is to get a mini pc and like a GM tek/Nuc box and run a local server off it on my network. So I can have my own backed up interactive version of my favorite sites that I can use in a browser and be able to interact with all the elements of the site like viewing images and navigating pages etc. Like I was actually browsing the real live site. Would this work? Or is there a more eloquent/easier way to do this? </p> <p>Apparently according to Kiwix you need to create a Zim file of the website and they have an online tool that allo",
        "id": 3294911,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmd2w2/i_want_to_create_a_local_network_backup_of_my",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I want to create a local network backup of my favorite sites using Kiwix/Debian based OS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/geetbatth",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T08:27:52.506889+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T07:33:57+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmceux/did_i_just_make_perfect_tool_for_you_guys/\"> <img src=\"https://preview.redd.it/d4uv3l6ra5if1.gif?width=640&amp;crop=smart&amp;s=c5e4b148b30441c96917bf91887cd740c7453f78\" alt=\"Did i just make perfect tool for you guys?\" title=\"Did i just make perfect tool for you guys?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I ll be honest i had no idea that this subreddit existed .last week i hacked together a powershell tool that you can run from context window of any folder which then organizes files and folders inside that folder into appropriate folders using a.i. so far i have tested it with 4000 file folder and it has performed really well .Groups together similar files and give a nice name to the folder. There is an option to undo changes if you dont like what it did .100% powershell so windows only for now . Sorry mac users :p Please check it out , its opensource and free. Feedback is very welcome. Jus",
        "id": 3294910,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmceux/did_i_just_make_perfect_tool_for_you_guys",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/d4uv3l6ra5if1.gif?width=640&crop=smart&s=c5e4b148b30441c96917bf91887cd740c7453f78",
        "title": "Did i just make perfect tool for you guys?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/spinnerspin1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T06:17:50.573443+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T06:09:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Should i go for Toshiba Enterprise MG for a plex media server or those seagate exos? if theres another brand you&#39;d like to recommend strictly for this usage case, let me know!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/spinnerspin1\"> /u/spinnerspin1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmb2th/thoughts_on_toshiba_enterprise_mg/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmb2th/thoughts_on_toshiba_enterprise_mg/\">[comments]</a></span>",
        "id": 3294532,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmb2th/thoughts_on_toshiba_enterprise_mg",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Thoughts on Toshiba Enterprise MG?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Straykiller",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T06:17:50.746047+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T05:55:23+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmauhi/jumped_on_the_26tb_external_deal_should_i_be/\"> <img src=\"https://preview.redd.it/34emf746t4if1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a178992d1754d374b2023e1412cf5f29e3a19df2\" alt=\"Jumped on the 26tb external deal, should I be worried?\" title=\"Jumped on the 26tb external deal, should I be worried?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey everyone I just picked up a pair of the 26tb seagate external hdd with plans to add them to my existing Unraid array. I started the pre clear before removing them from the hdd enclosures. One of the two drive is consistently slower and roughly 10c hotter, should I be concerned about this or is it normal? I have a fan blowing on both and would expect temps to be similar. My Current Unraid server only has one 10tb wd red so I don\u2019t have much experience as to whats normal when pre clearing a drive. Thanks </p> </div><!-- SC_ON --> &#32; submitted b",
        "id": 3294533,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmauhi/jumped_on_the_26tb_external_deal_should_i_be",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/34emf746t4if1.jpeg?width=640&crop=smart&auto=webp&s=a178992d1754d374b2023e1412cf5f29e3a19df2",
        "title": "Jumped on the 26tb external deal, should I be worried?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sixteen_Down",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T06:17:50.916861+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T05:38:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So how do you clean up your messiest directories? I&#39;ve got tons like <a href=\"https://postimg.cc/0zxhhRcW\">this</a> just from old libraries where things didn&#39;t get organized correctly from the beginning and now I&#39;m overwhelmed by how long it would take to manually sort them into Season folders. Ideally, a Docker solution would be great but so far all I&#39;ve found is Medusa and it&#39;s interface seems to suggest it&#39;s primarily meant to fill in gaps in libraries, like Huntarr. I&#39;m okay with a CLI solution, too.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sixteen_Down\"> /u/Sixteen_Down </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmakke/how_do_you_clean_up_your_messiest/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmakke/how_do_you_clean_up_your_messiest/\">[comments]</a></span>",
        "id": 3294534,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmakke/how_do_you_clean_up_your_messiest",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you clean up your messiest directories/libraries? Need an automated solution, esp. for TV series",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AlphaJuiceCo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T18:12:57.000985+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T05:21:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone!</p> <p>I just started my data hoarding journey today \u2014 focusing on anime collections.<br/> Since I\u2019m a student, I can\u2019t afford much in terms of hardware yet, so I\u2019m using 1 TB of cloud storage on FebBox for now.</p> <p>My first completed hoard is <em>Death Note</em>. I plan to keep expanding my library and will post updates on what I\u2019ve already archived and what I\u2019m planning to grab next.</p> <p>Excited to join the community and learn from all of you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AlphaJuiceCo\"> /u/AlphaJuiceCo </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmaag1/new_to_data_hoarding/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mmaag1/new_to_data_hoarding/\">[comments]</a></span>",
        "id": 3297644,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mmaag1/new_to_data_hoarding",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New to Data Hoarding",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/illbollocksyou",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T18:12:57.192929+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T03:31:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi. So, I want to preserve as many blu ray releases of Indian movies as possible, given that the blu rays themselves are no longer available and with the google drive storage limit a few years back, all the available torrents seem to have dies out. I&#39;m currently at a loss for sites as well. Ive tried all the usual sites but no luck. The only movies i got in full remux quality were Kaithi, Bahubali and Mankatha, if you know the names. These production houses do not care about preserving their movies and i would like to keep a copy of the movies as i have pretty fond childhood memories of them.</p> <p>A lot of these movies are not available in streaming services anymore and a lot of them are actually self -censored due to the growing censorship in the indian subcontinent and the original version is only present in the dvd or the blu ray releases. I know Japan has some blu ray releases but they will also dry out due to limited quantity production. So",
        "id": 3297645,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mm8ahj/blu_ray_remux_database_of_indian_movies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Blu Ray Remux database of Indian Movies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Nervous_Condition58",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T03:02:52.657727+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T02:56:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, just bought a new laptop and would like to have a image backup of the SSD before I set everything up. Any recommendations for a free software? Thank You</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Nervous_Condition58\"> /u/Nervous_Condition58 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mm7mpm/recommend_a_free_image_backup_tool/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mm7mpm/recommend_a_free_image_backup_tool/\">[comments]</a></span>",
        "id": 3294004,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mm7mpm/recommend_a_free_image_backup_tool",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Recommend a free image backup tool",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/grapejuice666",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T01:57:52.818792+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T01:50:38+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mm6blj/seagate_drive_connection_issues/\"> <img src=\"https://a.thumbs.redditmedia.com/ybprhkFUnUmGnQGVrq-6Pi1qRUdVnVPZ3YJAxpHOV78.jpg\" alt=\"Seagate drive connection issues\" title=\"Seagate drive connection issues\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hello! The port on my seagate external drive has recently given me trouble. The connection is difficult to make and my laptop rarely registers that it is plugged in. When the drive does connect the data is fine, I have no issues there\u2026 does anyone have troubleshooting ideas or an opinion on what I should do? I figure I will just need to extract the data and get a new drive, but in the meantime I\u2019d like to try to access some things\u2026.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/grapejuice666\"> /u/grapejuice666 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1mm6blj\">[link]</a></span> &#32; <span><a href=\"",
        "id": 3293831,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mm6blj/seagate_drive_connection_issues",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/ybprhkFUnUmGnQGVrq-6Pi1qRUdVnVPZ3YJAxpHOV78.jpg",
        "title": "Seagate drive connection issues",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Violinnoob",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T01:57:52.998299+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T01:20:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Word salad title because I don&#39;t really know how to describe this but I was trying to use this because I just learned the hard way you can only view your last 1000 saved posts, whenever I try to open the link <a href=\"https://eternity.portals.sh\">https://eternity.portals.sh</a> to get to the little menu thing shown in the demo video <a href=\"https://www.youtube.com/watch?v=4pxXM98ewIc\">https://www.youtube.com/watch?v=4pxXM98ewIc</a> I just get sent to the github repository, and I want to know if this means the link is dead or am if I&#39;m missing something</p> <p><a href=\"https://www.reddit.com/r/TheoryOfReddit/comments/rfo7bt/dealing_with_reddits_1000item_listing_limits_i/\">https://www.reddit.com/r/TheoryOfReddit/comments/rfo7bt/dealing_with_reddits_1000item_listing_limits_i/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Violinnoob\"> /u/Violinnoob </a> <br/> <span><a href=\"https://www.reddit.com/r/Dat",
        "id": 3293832,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mm5q1f/eternity_webapp_for_bypassing_reddit_1000_save",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "eternity webapp for bypassing reddit 1000 save limit server portal down?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Personal-Bet-3911",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T01:57:53.172558+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T00:40:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking to order 2-3 24 bay 4U rack mount cases. I have the following requirements and maybe someone has ordered something recently that works and meets my needs</p> <p>all my drives are SATA based. I have been upgrading my HBA cards slowly that accommodate the SFF-8643 connector. Who knows if I get some sas drives and from my understanding sata and sas can work together on the same back plane as long as the HBA can deal with both. </p> <p>Power supply, still on the fence if I want a single ATX PSU or redundancy. </p> <p>Rails, included, would be nice but also easy to come by if needed.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Personal-Bet-3911\"> /u/Personal-Bet-3911 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mm4x1v/multiple_case_alibaba_order_help/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mm4x1v/multiple_case_alibaba_order_help/\">",
        "id": 3293833,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mm4x1v/multiple_case_alibaba_order_help",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Multiple case Alibaba order help",
        "vote": 0
    }
]