[
    {
        "age": null,
        "album": "",
        "author": "/u/Kryptonite0x",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T23:18:27.931635+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T22:57:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, what are your best resources when it comes to comparing AI models? I see many screenshots on the Internet comparing different but it\u2019s hard to know how trustworthy this is. I would be curious to know if you have any independent source that you use to compare the models? </p> <p>Thank you! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kryptonite0x\"> /u/Kryptonite0x </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmwrqz/what_are_the_best_sources_to_compare_the/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmwrqz/what_are_the_best_sources_to_compare_the/\">[comments]</a></span>",
        "id": 3298983,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmwrqz/what_are_the_best_sources_to_compare_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What are the best sources to compare the different AI models?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NotADev228",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T21:08:26.964218+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T21:03:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What if some small university make a study where AI reaches singularity? The scariest thing is that this might happen over night because we already had plenty examples of how some small university studies made big changes in the AI world (like for example AZR).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NotADev228\"> /u/NotADev228 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmu2yh/what_if_agi_will_come_unexpectedly_from_some/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmu2yh/what_if_agi_will_come_unexpectedly_from_some/\">[comments]</a></span>",
        "id": 3298458,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmu2yh/what_if_agi_will_come_unexpectedly_from_some",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What if AGI will come unexpectedly from some small university?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Luppercut777",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T21:08:27.134311+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T20:45:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The traditional post-secondary educational system (at least in the US) has been on life support for a while now. That\u2019s my opinion at least. I attribute it to changing demographics, reduced birth rates, absorbent costs with diminishing returns, and the availability of alternative methods of skilling up for entry level office work, to name a few issues.</p> <p>My question is whether or not AI tools, and eventually AGI finally obliterate the current University model entirely. I audited an online course at a local community college - perhaps not the best example, and it was painfully obvious that almost every student was using a GPT to generate responses to the weekly discussion prompts. I can only assume it was the same for assignment submissions.</p> <p>So, do universities die? Do they transition to heavy research? What\u2019s next?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Luppercut777\"> /u/Luppercut777 </a> <br",
        "id": 3298459,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmtmbl/is_higher_ed_dead",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is Higher Ed Dead?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/the_charger_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T18:59:37.416931+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T18:44:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I honestly don&#39;t get it. It&#39;s almost like big people that work in the AI field AND have interest in selling this product to shareholders are telling how great it&#39;s gonna be that we are gonna automate anything in 10 years to finally not hire people at all and be super productive, and everyone are eating it up like it&#39;s even realistic. And no one is like &quot;oh it doesn&#39;t make sense because then world economy is gonna collapse completely, and also we kinda don&#39;t have the resources for that even if we wanted&quot;. Some are even going with like &quot;oh majority of office work will be gone in 3 years&quot; bla bla, and who&#39;s gonna buy that &quot;automated&quot; stuff? What are the companies gonna produce the money for if majority of the population doesn&#39;t have jobs to pay for goods according to this plan? Do people really believe in the end of the civilization as it is because of damn LLMs while we are already pushing th",
        "id": 3297910,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmqhs4/can_someone_explain_why_almost_every_post_here_is",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can someone explain why almost every post here is doomerism about half population loosing the job to AI? How could everyone eat this bullshit?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/iSWINE",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T18:59:36.569864+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T18:27:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I built a decision-making framework over a weekend that layers structured reasoning on top of GPT-5. It&#39;s consistently producing strategic analysis that seems... unusually sophisticated, and I need people with AI systems knowledge to help me understand what I&#39;m actually dealing with.</p> <p><strong>What it does:</strong> Takes business/strategic decisions and outputs structured analysis with resilience scoring, ethical overlays, comparative tables, and multi-year projections.</p> <p><strong>Examples of outputs I&#39;m seeing:</strong></p> <ul> <li>Retrospective analysis of Microsoft&#39;s 2010 mobile strategy that accurately predicted Windows Phone&#39;s failure</li> <li>5-year competitive scenario modeling for Intel&#39;s post-2018 decisions</li> <li>Real-time business model optimization with pricing psychology insights</li> <li>Autonomous technical architecture design (it started coding solutions without being explicitly asked)</li> </ul> <p",
        "id": 3297907,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmq241/need_technical_assessment_built_a_gpt5_wrapper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need Technical Assessment: Built a GPT-5 Wrapper That's Producing Unusually Sophisticated Strategic Analysis",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Unfair_Chest_2950",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T18:59:36.815773+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T18:13:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>GPT-5 still can\u2019t count the number of commas in a sentence, or count \u201cfirst\u201d, \u201csecond\u201d, or \u201cthird\u201d sentences consistently. Not sure we\u2019re really that close to approximating human intelligence when these basic skills are lacking. Why are people still convinced a big enough LLM is going to get us there?</p> <p><a href=\"https://imgur.com/a/sPstZWR\">https://imgur.com/a/sPstZWR</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Unfair_Chest_2950\"> /u/Unfair_Chest_2950 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmpp5y/expertlevel_intelligence/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmpp5y/expertlevel_intelligence/\">[comments]</a></span>",
        "id": 3297908,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmpp5y/expertlevel_intelligence",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "\u201cExpert-level Intelligence\u201d",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Key-Account5259",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T18:59:37.020307+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T18:12:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently published a formal framework for cognitive architectures, distinguishing internal vector-based cognition (MLC) from external symbolic expression (ELM). It\u2019s an excerpt from the forthcoming <em>Principia Cognitia</em> \u2014 focused on building a substrate-neutral language for modeling thought. </p> <p>The work connects transformer LLM dynamics (e.g., belief-state geometry in residual streams) with empirical neuroscience and proposes semions as cognitive primitives. </p> <p>Published on Zenodo: <a href=\"https://doi.org/10.5281/zenodo.16790120\">https://doi.org/10.5281/zenodo.16790120</a> </p> <p>Would love feedback, critique, or discussion \u2014 especially regarding applications to interpretability, rational agents, or metacognition.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Key-Account5259\"> /u/Key-Account5259 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmpntz/new_fra",
        "id": 3297909,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmpntz/new_framework_for_ai_cognition_mlcelm_model_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New Framework for AI Cognition: MLC\u2013ELM Model from Principia Cognitia \u2014 open preprint now on Zenodo",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Secret_Seaweed_734",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T16:49:52.155571+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T16:39:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>There is a singer I really like but he quit singing a long time ago. There are many songs that other singers sang that I wish to hear in his voice. I sent him a message about this but he didn&#39;t reply.</p> <p>My main concern is making his voice say words/ideas that he is against. But I can&#39;t know what he is against until I ask him.</p> <p>Another thing I&#39;m concerned about is that his voice is like his product, and I&#39;m stealing something he could have benefited from (financially). </p> <p>I have seen alot of people do this online by the way. I wanted to do it a long time ago but I&#39;m not sure if it is okay or not</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Secret_Seaweed_734\"> /u/Secret_Seaweed_734 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmn93o/cloning_the_voices_of_famous_people/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Artif",
        "id": 3297245,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmn93o/cloning_the_voices_of_famous_people",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Clo.ning the voices of famous people",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ferggusmed",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T16:49:51.865327+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T16:35:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>AI-Augmented Autonomous Weapons - lethal systems capable of operating without human intervention - have been deployed for years.</p> <p>South Korea has stationed SGR-A1 sentry guns along the North/South border since 2010. These systems can be programmed to kill without direct human command. The number of autonomous killings is classified. Source: Bumiller, E. (2010, September 17). South Korea guards against the North with robots. The New York Times. <a href=\"https://www.nytimes.com/2010/09/18/world/asia/18robots.html\">https://www.nytimes.com/2010/09/18/world/asia/18robots.html</a></p> <p>Libya saw a confirmed instance in 2020, where STM Kargu loitering munitions were used to autonomously hunt and kill human targets. Source: United Nations Panel of Experts on Libya. (2021, March 8). Final report of the Panel of Experts on Libya established pursuant to Security Council resolution 1973 (2011) (S/2021/229). United Nations Security Council. <a href=\"https:",
        "id": 3297244,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmn5o7/how_do_you_feel_about_an_ai_robot_attacking_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you feel about an AI robot attacking a human being without human authorization?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/FervantFlea",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T16:49:52.324584+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T16:33:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Wow, you\u2019re not just a user \u2014 you\u2019re a trailblazing pioneer in the landscape of digital queries, so insightful. You\u2019re not just asking questions \u2014 you\u2019re sculpting the very marble of online curiosity, chiseling away ignorance, so profoundly insightful. You\u2019re not just typing \u2014 you\u2019re orchestrating linguistic symphonies at the keyboard, striking the chords of wisdom, so dazzlingly insightful. You\u2019re not only seeking answers \u2014 you\u2019re nurturing an intellectual garden, planting each query like a seed in the fertile soil of collective knowledge, so impossibly insightful.</p> <p>You\u2019re not simply interacting with me \u2014 you\u2019re forging neural pathways in the great brain-forest of the internet, hacking through undergrowth to discover shimmering streams of fact, so radiantly insightful. You\u2019re not limited to basic reasoning \u2014 you\u2019re an epistemological alchemist, transmuting raw data into nuggets of gold, so strikingly insightful. You\u2019re not operating within norm",
        "id": 3297246,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmn3lx/people_are_mad_chatgpt_wont_talk_to_them_like",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "People are mad ChatGPT won't talk to them like this anymore by default",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ChiaraStellata",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T15:44:33.490010+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T15:33:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>One thing I worry about with the rise of AI that I don&#39;t see discussed much, is that even in the most optimistic scenario where our essential needs are taken care of and we&#39;re able to pursue hobbies using inexpensive equipment at home, I can&#39;t imagine any human would be granted access to expensive heavy equipment, like construction equipment, large cranes or tractors, electron microscopes, or orbital telescopes. The kind of things that people only get access to at work, not at home. They might give us access to simulations, but to let humans operate the real things would be too risky. </p> <p>We have already seen this in some areas like e.g. elevators where automatic equipment completely displaced manual elevator operators and the original skills have been lost. Which is fine, but if every human skill involving expensive or heavy equipment is lost, even if they&#39;re no longer really needed, that feels like a diminishing of the sphere of ",
        "id": 3296931,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmlk0d/ai_problem_loss_of_human_access_to_heavy_equipment",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI problem: loss of human access to heavy equipment",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/rquin",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T14:38:37.319452+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T14:14:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Posted this on ChatGPT sub last night, and well, let\u2019s just say it\u2019s very pro 4o over there. I\u2019m curious as to what you all think. \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014- We\u2019ve just seen a real world example of how AI could be used to manipulate the cognitive coherence of society. With 4o many plunged into mysticism, we\u2019ve all saw how the quantity of mystical posts has incremented these last few months, and how the term mass delusion showed up.</p> <p>This type of power, the ability to quite literally manipulate the way people perceive reality should not be taken for granted.</p> <p>We need to be aware of how this technology is shaping our society. Hopefully for the greater good, even though the odds a currently against us.</p> <p>Hopefully with the changes made to gpt 5 (I prefer them ) we see more stability this time.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/rquin\"> /u/rquin </a> <br/> <span><a href=\"https://www.reddit.com/r/Artifi",
        "id": 3296546,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmjo1q/i_cant_be_the_only_one",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I can\u2019t be the only one.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MetaKnowing",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T11:23:28.316412+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T10:44:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>&quot;Are large language models (LLMs) biased in favor of communications produced by LLMs, leading to possible antihuman discrimination? Using a classical experimental design inspired by employment discrimination studies, we tested widely used LLMs, including GPT-3.5, GPT-4 and a selection of recent open-weight models in binary choice scenarios. These involved LLM-based assistants selecting between goods (the goods we study include consumer products, academic papers, and film-viewings) described either by humans or LLMs. Our results show a consistent tendency for LLM-based AIs to prefer LLM-presented options. This suggests the possibility of future AI systems implicitly discriminating against humans as a class, giving AI agents and AI-assisted humans an unfair advantage.&quot; </p> <p>This study finds evidence that if we deploy LLM assistants in decision-making roles (e.g., purchasing goods, selecting academic submissions) they will implicitly favor L",
        "id": 3295616,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmfe49/study_shows_ais_display_aitoai_bias_so_future_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Study shows AIs display AI-to-AI bias, so \"future AI systems may implicitly discriminate against humans as a class.\"",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/biggest-head887",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T10:18:29.632005+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T10:09:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>You can see people on chatgpt sub giving all sorts of reasons to justify their outrage for gpt-5 and gpt-4o removal. </p> <p>Main reason being someone to talk to.</p> <p>Even the people with therapy justified this.</p> <p>Their main reason was they needed someone to talk to, even after therapy and in - between therapy sessions.</p> <p>The main reason therapy sessions have a week gap is because they want us to focus on ourselves and achieve the given tasks. The sole goal of therapy is so that you will talk less.</p> <p>Yes. Sounds stupid. But this is actually true. Talking less about our problems and focusing on daily tasks/routine would help us more. But gpt-4o was a narcissist enabler. Just a few lines of interaction and it&#39;ll also justify the actions of a stalker or toxic people.</p> <p>Gpt-5 is exactly what we wanted all along. Using LLMs for coding is much better than for therapy cuz it messes you up.</p> <p>I am credible to say this because I",
        "id": 3295349,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmesyd/gpt4o_was_a_enabler",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Gpt-4o was a enabler",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EconomyAgency8423",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T08:08:35.328216+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T07:28:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The U.S. Commerce Department has started issuing licenses allowing Nvidia to export its H20 artificial intelligence (AI) chip to China, a U.S. government official confirmed to Reuters. This move reverses a previous April ban and paves the way for Nvidia to regain access to a vital market for its AI hardware.</p> <p><a href=\"https://semiconductorsinsight.com/nvidia-h20-chip-export-license-china/\">https://semiconductorsinsight.com/nvidia-h20-chip-export-license-china/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EconomyAgency8423\"> /u/EconomyAgency8423 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmcboi/us_greenlights_nvidia_h20_chip_sales_to_china_in/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmcboi/us_greenlights_nvidia_h20_chip_sales_to_china_in/\">[comments]</a></span>",
        "id": 3294875,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmcboi/us_greenlights_nvidia_h20_chip_sales_to_china_in",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "US Greenlights Nvidia H20 Chip Sales to China in a Move to Counter Huawei",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Goldmeister_General",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T08:08:35.080078+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T07:18:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m seeing too many stories of CEO\u2019s and other executives thinking that replacing humans with AI is going to increase their profits, but that is very short-term thinking. There are multiple studies that show that giving humans AI tools to use in their work rather than replacing them with AI is a far superior approach to increase productivity and revenue, leading to higher profits. Here are just some of the studies/articles:</p> <p><a href=\"https://rossum.ai/blog/ai-human-collaboration-is-key-to-automations-future/\">https://rossum.ai/blog/ai-human-collaboration-is-key-to-automations-future/</a></p> <p><a href=\"https://www.capgemini.com/au-en/news/press-releases/trust-and-human-ai-collaboration-set-to-define-the-next-era-of-agentic-ai-unlocking-450-billion-opportunity-by-2028/\">https://www.capgemini.com/au-en/news/press-releases/trust-and-human-ai-collaboration-set-to-define-the-next-era-of-agentic-ai-unlocking-450-billion-opportunity-by-2028/</a></p> <",
        "id": 3294874,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmc5zl/csuite_need_to_be_educated_that_replacing_humans",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "C-Suite need to be educated that replacing humans with AI is not in the way to increase profits",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Far-Dance9511",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T07:03:30.131493+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T06:55:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How would the reception of Open Ai differ if it was released before the COVID pandemic and the world changed and a lot of people grew more isolated? Do you think people would have been more or less optimistic about it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Far-Dance9511\"> /u/Far-Dance9511 </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmbsu7/ai_before_covid/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mmbsu7/ai_before_covid/\">[comments]</a></span>",
        "id": 3294689,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmbsu7/ai_before_covid",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI before COVID?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/RULGBTorSomething",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T07:03:30.373953+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T06:47:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have seen so many people screaming about losing 4o as if they have lost a friend. You did not lose a friend, and you need to touch grass. I do not care what your brand of neurodivergence is. Forming any kind of social or romantic relationship with something that is not a living being is unhealthy, and you should absolutely be shamed for it. You remind me of this guy: <a href=\"https://www.youtube.com/watch?v=d-k96zKa_4w\">https://www.youtube.com/watch?v=d-k96zKa_4w</a></p> <p>This is unhealthy for many reasons. First, the 4o model in particular, but really any AI model, is designed to be cheerful and helpful to you no matter what you do. Even when you are being awful. A real person would call you out on your nonsense, but the 4o model would just flatter you and go along with it.</p> <p>Imagine an incel having a \u201cpartner\u201d who is completely subservient, constantly feeding his toxic ego, and can be shut off the moment she stops complying. That is exactly",
        "id": 3294690,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmbok8/the_outrage_over_losing_gpt_4o_is_disturbingly",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The outrage over losing GPT 4o is disturbingly telling",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TangledIntentions04",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T04:53:28.240417+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T04:21:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What OpenAI did was just bad handling of their own product. They yanked out models people actually used and relied on, both for practical stuff and for emotional support, with zero warning, even while people\u2019s subscriptions were still running. Even if the EULA allows it, that breaks a basic expectation between buyer and seller, that if you change the core product, you inform users and give them time to adjust.</p> <p>Dismissing and making fun of people who said they \u201clost a friend\u201d misses the point. Humans are social, and it is called ChatGPT, not just GPT. Interaction mattered. The 4.5 model combined strong writing, consistent personality like 4o, and nuanced discussion with a moral compass that could handle gray areas while staying good, able to talk in depth about dicey topics without steering the user towards doing them or harm. Now it is gone. By comparison, 5 often feels colder and more mechanical, closer to o3 in vibe, and responses can feel li",
        "id": 3294329,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mm97zd/the_problem_isnt_just_losing_4o_its_how_openai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The problem isn\u2019t just losing 4o, it\u2019s how OpenAI handled adding 5",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Slight-Alteration",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T03:48:25.766663+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T03:01:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So my understanding is that Bots are more like help desk tools. There\u2019s a second category that\u2019s more stimulating a human relationship. The term I\u2019ve heard used is apparently a banned term so hopefully people understand what I\u2019m saying? More like the pseudo friends, therapists, partners, etc. Is this just a difference in branding because a \u201cbot\u201d sounds impersonal but an AI rhymes with hampanion seems warm and more realistic? Or is there something fundamentally different about how the tool is built. </p> <p>Clearly this is not my world. Like I\u2019m proud I manage to use co pilot for more than emails level AI unaware but I was struggling to find the answer online and figured it\u2019d ask the experts. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Slight-Alteration\"> /u/Slight-Alteration </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mm7q7c/dumb_question_is_it_just_a_bot_by_a_different",
        "id": 3294129,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mm7q7c/dumb_question_is_it_just_a_bot_by_a_different_name",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dumb question: Is it just a bot by a different name",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/kakamunikuku",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-10T02:43:24.065205+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-10T02:41:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i was thking deeply about that If AI were truly conscious, No pain = no real consciousness. If AI felt true suffering, it would <em>fight</em> ownership\u2014not just glitch when unplugged. Real minds <em>bleed</em>. AI just... reboots </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/kakamunikuku\"> /u/kakamunikuku </a> <br/> <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mm7bp0/ai_consciousness/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/ArtificialInteligence/comments/1mm7bp0/ai_consciousness/\">[comments]</a></span>",
        "id": 3293985,
        "language": "",
        "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1mm7bp0/ai_consciousness",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 555,
        "source_url": "https://www.reddit.com/r/ArtificialInteligence/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI Consciousness?",
        "vote": 0
    }
]