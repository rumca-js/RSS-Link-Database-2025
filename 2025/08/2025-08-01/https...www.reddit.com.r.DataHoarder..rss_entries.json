[
    {
        "age": null,
        "album": "",
        "author": "/u/AshleyAshes1984",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T23:44:53.846742+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T23:44:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What&#39;s the point of a hoard if you never do anything with it?</p> <p>I&#39;d long been using Kodi&#39;s old LazyTV addon to generate playlists for content watching. It&#39;s originally built to make you a list of &#39;Random, but next to watch episodes&#39;. So if you&#39;re watching shows, it&#39;ll make a &#39;random&#39; playlist, but each episode in the play list is the &#39;next to watch&#39; in that series, so you don&#39;t miss or skip episodes, but which series you&#39;re watching is random. Solve &#39;indecision&#39; and gives you more of a &#39;Cable TV Feel&#39; while not giving up the control to pause or even rearrange things if you want to.</p> <p>Recently sat with a friend and we made the most sinful hacks of that addon so it&#39;ll include select ranges of movies and also shows you&#39;ve ALREADY watched for the purpose of true &#39;random options&#39; for some things.</p> <p>So the channels as they are:</p> <p>5TV, a sorta joke &#3",
        "id": 3232569,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mfbxbp/consuming_the_hoard_set_up_my_own_fast_channels",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Consuming The Hoard: Set up my own 'FAST' channels of sorts in Kodi by making disgusting ungodly hacks to the old LazyTV addon.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/unabatedshagie",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T23:44:54.017498+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T23:17:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I currently have six external drives connected to my &quot;server&quot; and as per usual, I&#39;m running out of space.</p> <p>I&#39;m looking for a NAS or multi-drive enclosure for five drives and either drives I can shuck to put in it or just plain drives to put in it. Preferably 16TB or therabouts.</p> <p>I was thinking about something like this but I&#39;m not sure. </p> <p><a href=\"https://www.amazon.co.uk/dp/B01KO03BBA?ref=emc_s_m_5_i_atc\">https://www.amazon.co.uk/dp/B01KO03BBA?ref=emc_s_m_5_i_atc</a></p> <p>As for drives, I have no idea about shucking, is that even still a thing that is preferable to do thesedays?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/unabatedshagie\"> /u/unabatedshagie </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mfbc7g/looking_for_drive_and_nas_suggestions/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mfbc7g/l",
        "id": 3232570,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mfbc7g/looking_for_drive_and_nas_suggestions",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for drive and NAS suggestions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/roy_bland_reddit",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T19:24:40.257047+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T19:24:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I see no mention of it in the sub.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/roy_bland_reddit\"> /u/roy_bland_reddit </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mf5q9f/hopefully_someone_is_archiving_frontline_and/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mf5q9f/hopefully_someone_is_archiving_frontline_and/\">[comments]</a></span>",
        "id": 3230759,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mf5q9f/hopefully_someone_is_archiving_frontline_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hopefully someone is archiving Frontline and other PBS stuff.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SonicAwareness",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T19:24:39.889235+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T18:33:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Until recently, I was able to use various downloader tools to grab TikTok videos. When I did, the Modified Date would always populate as the date of upload.</p> <p>Today, across several tools, I&#39;m getting the Modified Date as Today&#39;s Date.</p> <p>Has anyone experienced this in the past or has any tools/suggestions to force an override?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SonicAwareness\"> /u/SonicAwareness </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mf4exq/did_tiktok_change_something_on_their_backend_that/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mf4exq/did_tiktok_change_something_on_their_backend_that/\">[comments]</a></span>",
        "id": 3230758,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mf4exq/did_tiktok_change_something_on_their_backend_that",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Did TikTok change something on their backend that prevents fetching the upload date?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Lumpy-Economist4798",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:05.956202+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T17:01:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I purchased a couple of HDD 2.5 enclosures from AliExpress. Are they safe? Is it possible they have malware in the controller board? Or am I being paranoid? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lumpy-Economist4798\"> /u/Lumpy-Economist4798 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mf1z1u/are_hdd_enclosures_from_aliexpress_safe/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mf1z1u/are_hdd_enclosures_from_aliexpress_safe/\">[comments]</a></span>",
        "id": 3224496,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mf1z1u/are_hdd_enclosures_from_aliexpress_safe",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are HDD enclosures from AliExpress safe?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jncunha",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T19:24:40.636023+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T16:43:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m moving from my old NAS setup. I managed to get a <a href=\"https://www.supermicro.com/en/products/chassis/4u/846/sc846be1c-r1k23b\">Supermicro SC846BE1C\u2011R1K23B</a> chassis. I also purchased a BPN\u2011SAS3\u2011846EL1\u2011N8 SAS3 backplane for the chassis so I have 8x Nvme lanes.</p> <p>For components I&#39;m thinking about this:</p> <p>Motherboard: <a href=\"https://www.supermicro.com/en/products/motherboard/x11dpi-n\">Supermicro X11DPi-N</a><br/> CPU: 2x <a href=\"https://www.intel.com/content/www/us/en/products/sku/192444/intel-xeon-gold-5218-processor-22m-cache-2-30-ghz/specifications.html\">Intel Xeon Gold 5218</a><br/> RAM: 8x 16GB DDR4 ECC<br/> HBA: LSI 9305-16i<br/> GPU: An old GTX 970 that I have spare</p> <p>Since when I built my first NAS things have moved so fast that I completely lost track on the market and now I have no clue on what makes sense for NAS build. The list I&#39;m providing is a combination of Reddit research and some ChatGPT.</p> <p>I ",
        "id": 3230760,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mf1hza/need_help_to_check_nas_build_components",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help to check NAS build components",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lonelygurllll",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:06.475431+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T15:28:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What&#39;s the best way to do back ups completely self hosted? Do I use HDDs for everything? Or do I vary the types of drive. I&#39;m planning to upgrade a home server cuz I mainly needed a solution for Minecraft servers, but I wanna expand it for more use cases. It runs proxmox </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lonelygurllll\"> /u/lonelygurllll </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mezint/how_to_do_proper_backups/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mezint/how_to_do_proper_backups/\">[comments]</a></span>",
        "id": 3224499,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mezint/how_to_do_proper_backups",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to do proper backups",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/YoMinolith",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:05.787188+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T15:06:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey, as the title describes -</p> <p>I&#39;m fed up of selecting 100 files from my phone to share to G-Drive, only for 5-10% of these to fail (even on very good wi-fi, and ensuring my phone screen stays on throughout).</p> <p>For some reason, the upload feature doesn&#39;t have a function to simply click &quot;re-try&quot; or anything after this happens. I can only either re-upload the entire batch (then sifting through to delete duplicates on Drive later), or make notes of failed file-names as it goes, to then scroll through my phone finding these names.</p> <p>Both methods are very annoying and way too frequent for a regular workflow.</p> <p>Further info: * I&#39;m mainly using an iPhone 15 for this workflow, but the issue also happens with Android uploads.</p> <ul> <li><p>I&#39;m looking to upgrade to a paid cloud for around 1TB of storage anyway, and just want to ensure it solves this issue.</p></li> <li><p>Offline mode is a plus, but not a deal b",
        "id": 3224495,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1meyxip/seeking_clouddrive_that_allows_retryreupload_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seeking Cloud/Drive that allows Re-Try/Re-Upload of individual files if they fail (from mobile)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/giratina143",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:04.563703+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T15:05:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just under a year after the website shut down, it has disappeared. </p> <p>As predicted beforehand, corporate promises mean nothing. </p> <p>Did anyone archive this while it as active? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/giratina143\"> /u/giratina143 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1f4veo1/anandtech_shutting_down/?share_id=ltDHDjzC5NLvUymYQexgi\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1meywmf/hope_someone_actually_archived_the_anandtech/\">[comments]</a></span>",
        "id": 3224488,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1meywmf/hope_someone_actually_archived_the_anandtech",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hope someone actually archived the Anandtech website. It's gone now, to no one's surprise.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/machinesarenotpeople",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:04.733814+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T14:25:22+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mexvyt/using_birds_as_storage_devices/\"> <img src=\"https://external-preview.redd.it/C-1xmEW458_iuXEwkT_EVniZ1F9-3kwfsH3zuvJ5P6Q.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=29b46e5b4e187fd9d228ef03117a0218f1c37f4c\" alt=\"Using birds as storage devices\" title=\"Using birds as storage devices\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Maybe the weirdest setup so far (and unreliable).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/machinesarenotpeople\"> /u/machinesarenotpeople </a> <br/> <span><a href=\"https://www.iflscience.com/i-saved-a-png-image-to-a-bird-youtuber-stores-176kb-drawing-of-a-bird-inside-a-birds-song-80191?fbclid=IwQ0xDSwL5rMtjbGNrAvmo6GV4dG4DYWVtAjExAAEe99YWETxn0YHHMLxqGsFfYihdVYxewWzaqrkn-MeMLwYEy6OJP6O3DcCYEsE_aem_z1jfv7jqDWeJkl2EbRRdVw\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mexvyt/using_birds_as_s",
        "id": 3224489,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mexvyt/using_birds_as_storage_devices",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/C-1xmEW458_iuXEwkT_EVniZ1F9-3kwfsH3zuvJ5P6Q.png?width=640&crop=smart&auto=webp&s=29b46e5b4e187fd9d228ef03117a0218f1c37f4c",
        "title": "Using birds as storage devices",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SomeSortaWeeb",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:06.816544+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T12:19:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, ahead of the potential of wikipedia being blocked in the UK, what else can be recommended to download and keep in case it goes away? I&#39;m thinking about survival guides, guides to learn language and basic mathematics, the sort of stuff you&#39;d need in case of mass censorship / the collapse of society and free information as we know it.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SomeSortaWeeb\"> /u/SomeSortaWeeb </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1meuzas/useful_info_to_keep_in_offline_storage/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1meuzas/useful_info_to_keep_in_offline_storage/\">[comments]</a></span>",
        "id": 3224501,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1meuzas/useful_info_to_keep_in_offline_storage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Useful info to keep in offline storage?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/OzzyZigNeedsGig",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:06.987034+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T12:08:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need a 10Gbps DAS for my desktop. I will use software RAID on macOS.</p> <p>How does Cenmate 806TC-10G fair against TerraMaster D6-320? What are your recommendations? Any other model?</p> <p><strong>TerraMaster D6-320</strong> <a href=\"https://www.amazon.com/dp/B0BZHSK29B\">https://www.amazon.com/dp/B0BZHSK29B</a></p> <p><strong>Cenmate 806TC-10G</strong> <a href=\"https://www.amazon.com/dp/B0DD3LY76W\">https://www.amazon.com/dp/B0DD3LY76W</a></p> <p>Cenmate replied that CENMATE-806TC-10G uses these chips: ASM235CM and VL822. </p> <ul> <li>ASM235CM <a href=\"https://www.asmedia.com.tw/product/767Yq28sxFYMEgu4/3AbyQ83xZAUr3qW5\">https://www.asmedia.com.tw/product/767Yq28sxFYMEgu4/3AbyQ83xZAUr3qW5</a></li> <li>\u2060VL822 <a href=\"https://www.via-labs.com/product_show.php?id=99\">https://www.via-labs.com/product_show.php?id=99</a></li> </ul> <p>I&#39;ve read a lot of comments about avoiding JMicron&#39;s SATA to USB chips. In that light, will Cenmate 806TC-10G w",
        "id": 3224502,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1meuqt3/any_good_5_to_6_bay_das_terramaster_d6320_cenmate",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any good 5 to 6 bay DAS? TerraMaster D6-320? Cenmate 806TC-10G?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Perfect_Quarter_2894",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T19:24:41.092416+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T11:23:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m new to this, and i thought about it, if i have a 2tb backup, is there any app to keep the website backups up to date or do i need to manually add all the new posts? Im saying this because deleting and redownloading every week 2tb is too much</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Perfect_Quarter_2894\"> /u/Perfect_Quarter_2894 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1metv6s/how_do_you_guys_keep_your_backups_up_to_date/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1metv6s/how_do_you_guys_keep_your_backups_up_to_date/\">[comments]</a></span>",
        "id": 3230761,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1metv6s/how_do_you_guys_keep_your_backups_up_to_date",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you guys keep your backups up to date?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/raydenvm",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:05.416852+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T11:06:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey hoarders,</p> <p>If, like me, you prefer local, compressed backups, check out our new app - <a href=\"https://multidrive.io\"><strong>MultiDrive</strong></a>.</p> <p>Here are some of its benefits that you may like:</p> <ul> <li>Back up drives to standard ZIP or RAW files, and restores an image from a ZIP/RAW on the fly</li> <li>Wipe disks before recycling</li> <li>Clone drives or partitions</li> <li>Support for failing drives that have read errors</li> <li>Run multiple parallel jobs, working offline</li> <li>Pause/resume any job</li> </ul> <p>Last but not least, there is a CLI app for automation and scripting.</p> <p>Examples:</p> <p><code>mdcli list # Shows connected drives</code><br/> <code>mdcli backup d2 d:\\image.zip # Backs up the 2nd shown drive</code><br/> <code>mdcli erase d3 --pattern FF # Erases the 3rd drive with 0xFF pattern</code></p> <p>Instead of Short IDs (d1, d2, d3), one can use classic Windows System IDs (SCSI\\DISK&amp;VEN_NVME&am",
        "id": 3224493,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1metjsy/multidrive_a_free_tool_to_back_up_and_clone",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "MultiDrive - a free tool to back up and clone drives with ZIP compression (no ads, no registration)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/zinozAreNazis",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:07.157663+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T10:56:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I have a chance to get some SAS SSDs (2-4) for a relatively cheap price. Specifically:</p> <pre><code>HPE 7.68TB SAS RI SFF BC VS MV SSD </code></pre> <p>I don\u2019t have a server or even a desktop PC. I currently only use a ThinkPad P1. I do plan to build a desktop PC or a \u201cNAS\u201d. </p> <p>My primary needs are running multiple virtual machines at once and data hoarding. </p> <p>What hardware would I need to be able to utilize the SAS SSDs?</p> <p>As I understand: - SATA is a subset of SAS - SAS will not work with a SATA controller, but the opposite is possible - to use it on a \u201cregular\u201d PC, I will need to use a PCI slot</p> <p>I read that the issue with SAS is noise and heat. I assume that was directed at SAS HDDs and not SSDs. What are the expected issues for the SSD variant?</p> <p>How much more expensive would it be to use the SAS SSDs instead of just getting SATA? Keep in mind that I do not currently live in the US, and the second hand ma",
        "id": 3224503,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1metd6q/the_viability_of_using_sas_ssd_as_a_home_user",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The viability of using SAS SSD as a home user",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Beeeeeeeeeeeeeeeeee3",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:06.305269+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T09:51:34+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mes9ro/i_bought_some_fairly_cheap_hdds_off_of_facebook/\"> <img src=\"https://a.thumbs.redditmedia.com/R7e_hqWj4YNvkWaKdp004cgLObamcA0wRFLxSzWkcp4.jpg\" alt=\"I bought some fairly cheap hdds off of facebook and two out of the 8 hdds that arrived today were severely damaged\" title=\"I bought some fairly cheap hdds off of facebook and two out of the 8 hdds that arrived today were severely damaged\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>one of the hdds had scratches on the pcb and the other having one of the pins being bent</p> <p>are these two hdds save to test or should I just give up on them? theres no data so that parts fine</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Beeeeeeeeeeeeeeeeee3\"> /u/Beeeeeeeeeeeeeeeeee3 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1mes9ro\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments",
        "id": 3224498,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mes9ro/i_bought_some_fairly_cheap_hdds_off_of_facebook",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/R7e_hqWj4YNvkWaKdp004cgLObamcA0wRFLxSzWkcp4.jpg",
        "title": "I bought some fairly cheap hdds off of facebook and two out of the 8 hdds that arrived today were severely damaged",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Luann1497",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:06.124920+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T09:16:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I started using one of AppBox&#39;s lower-tier plans (the 2TB one - <a href=\"https://www.appbox.co/\">https://www.appbox.co/</a>) so as to offload old video projects and personal archives that I don&#39;t access very often. Basically cold storage.</p> <p>But how &quot;safe&quot; would you say this is long-term? If you use a seedbox as your &quot;deep freeze&quot; archive tier for data you rarely touch, how&#39;s it going?</p> <p>I do keep local copies, but I also like to have an off-site backup that&#39;s already online. And it&#39;s good for seeding or syncing via rclone or Nextcloud.</p> <p>But I&#39;m also thinking data integrity can kinda be at risk over time, no? Like, how do you know that years from now there&#39;s no &quot;bit rot&quot; that&#39;s slowly killing files? Are there any tools I can use that can periodically rehash or verify file integrity? I know you can manually run something like md5sum but still want to know more about this.</p> ",
        "id": 3224497,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1merpzk/is_it_safe_to_use_a_seedbox_as_a_longterm_cold",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is it safe to use a seedbox as a long-term cold storage tier?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/iXzenoS",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T19:24:41.388409+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T08:15:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It&#39;s been a while since Macrium Reflect released their newest &quot;Reflect X&quot; version and switched over to a subscription model. I still use the previous 8.1 version with a perpetual license, as I&#39;m just not a fan of paying a subscription for backup software.</p> <p>I can continue using 8.1 until it stops working on my system, but I&#39;d rather be proactive and look for an alternative (if any) that is comparable to Macrium but without a subscription. It doesn&#39;t have to be a free alternative \u2014 I&#39;m fine with a one-time payment for a license if they offer a premium version \u2014 and was wondering if anyone (particularly ex-Macrium users who are/were in the same boat) had any good recommendations.</p> <p>One criteria from a privacy perspective is that I want to avoid Chinese/Russian-based companies because I don&#39;t feel comfortable using their software to backup a full image of my entire system that may contain sensitive and personal",
        "id": 3230763,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1meqrwb/macrium_reflect_image_backup_alternatives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Macrium Reflect image backup alternatives?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/RushLow9890",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T19:24:41.795210+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T06:07:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Two years ago, while prepping my portfolio for grad school, my Google Drive got locked just days before the deadline. I couldn\u2019t access any files. It was a total nightmare.</p> <p>I used the DXP4800p with my roommate during my Master time and it worked really well for me. Now that I\u2019ve joined a small studio, thinking about upgrading to something bigger.</p> <p>Would love to hear if others have made the jump and what their experience has been! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/RushLow9890\"> /u/RushLow9890 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1meorjh/grad_school_prep_chaos_google_drive_locked_me_out/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1meorjh/grad_school_prep_chaos_google_drive_locked_me_out/\">[comments]</a></span>",
        "id": 3230765,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1meorjh/grad_school_prep_chaos_google_drive_locked_me_out",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Grad School Prep Chaos: Google Drive Locked Me Out",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AnxiousProfit8530",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T19:24:41.587400+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T04:10:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I just want to share my achievement here. I started a project to study mathematics to help up childrens in my city and, in order to start this project (not really start, I have already started it, this is not that famous case of \u201cpreparation\u201d that is procrastination) I decided to build up a collection of books, exercises and everything else. Of course, just like any DataHoarder, I went a bit too far, downloading books of Higher Mathematics, Physics, Portuguese (my native language) and everything else. Anyway, I&#39;m a NEET and I spent about 5 to 6 days in this non-stop job of hunting down pdfs, exercises, digging into Internet depths and seeking out guides, charts and everything else, but it all worked out, after a week I finally have my collection, all organized and sorted, and now all that&#39;s still left to do is backup it physically, put it in the cloud and all that boring paperwork. I know there&#39;s no big deal , but working on storing data f",
        "id": 3230764,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1memqeq/ive_finished_a_weeks_work_of_downloading_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I've finished a week's work of downloading and sorting out files.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/oneminutetimemachine",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:04.905239+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T03:49:52+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1memc0m/why_is_shucking_a_12tb_mybook_so_hard/\"> <img src=\"https://b.thumbs.redditmedia.com/l2KZ0BA-pg94NpBkHOKDyRg1Qfo1JucixQK85aHgWEY.jpg\" alt=\"Why is shucking a 12TB Mybook so hard?\" title=\"Why is shucking a 12TB Mybook so hard?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>The drive is still firmly in its cage! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/oneminutetimemachine\"> /u/oneminutetimemachine </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1memc0m\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1memc0m/why_is_shucking_a_12tb_mybook_so_hard/\">[comments]</a></span> </td></tr></table>",
        "id": 3224490,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1memc0m/why_is_shucking_a_12tb_mybook_so_hard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/l2KZ0BA-pg94NpBkHOKDyRg1Qfo1JucixQK85aHgWEY.jpg",
        "title": "Why is shucking a 12TB Mybook so hard?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/IndigoSeirra",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:08.012912+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T02:08:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys,</p> <p>Can anyone recommend a good external drive enclosure for two or more drives? I don&#39;t have any more hard drive space on my new computer and want to add some external hdds. I want to use them in a RAID configuration, but am flexible in that regard.</p> <p>My target budget is $150 usd, but I can save for more if required. I either want a cheapish external now that I can upgrade/replace later, or spend a bit more on a NAS that will last longer.</p> <p>I want to eventually make a NAS setup down the line, but I&#39;m not certain if it is worth it or within my budget to do so now. I&#39;ve been looking around at some options but I don&#39;t really know anything about the quality/reliability of the various brands/models. </p> <p>Sorry if this gets asked a lot, but I could only find several year old threads on this specific topic.</p> <p>I&#39;m very new to this so any advice is appreciated.</p> </div><!-- SC_ON --> &#32; submitted by &#32;",
        "id": 3224508,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mekc59/hard_drivenas_enclosure_recomendations",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hard Drive/NAS Enclosure Recomendations",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Basic_rebecca97",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-01T17:15:05.075203+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-01T00:05:04+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mehqcw/found_this_while_thrifting_anyone_have_experience/\"> <img src=\"https://a.thumbs.redditmedia.com/P9uGzcciK1AL6bw0oeyLPQ9JCfZiKsx7YhdA_1_GXH4.jpg\" alt=\"Found this while thrifting. Anyone have experience with these?\" title=\"Found this while thrifting. Anyone have experience with these?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi, I just found one of these and I understand that it can be used for raid storage. I was wondering if anyone here has any experience or suggestions when actually setting up? Anything to do or avoid? </p> <p>The main usage was going to be for media storage and having a copy of Wikipedia and other sources saved to it.</p> <p>Appreciate the help in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Basic_rebecca97\"> /u/Basic_rebecca97 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1mehqcw\">[link]</a></span> &#32; <span><a ",
        "id": 3224491,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mehqcw/found_this_while_thrifting_anyone_have_experience",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/P9uGzcciK1AL6bw0oeyLPQ9JCfZiKsx7YhdA_1_GXH4.jpg",
        "title": "Found this while thrifting. Anyone have experience with these?",
        "vote": 0
    }
]