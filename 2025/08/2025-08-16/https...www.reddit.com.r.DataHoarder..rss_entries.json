[
    {
        "age": null,
        "album": "",
        "author": "/u/CivicWithNitrous",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-17T00:01:14.591396+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T23:05:37+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1msat86/is_this_legit_what_am_i_missing_here/\"> <img src=\"https://preview.redd.it/xf4iqa3gqgjf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6138fd82d91a54dccee1ae8918777c920599aa01\" alt=\"Is this legit? What am I missing here?\" title=\"Is this legit? What am I missing here?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CivicWithNitrous\"> /u/CivicWithNitrous </a> <br/> <span><a href=\"https://i.redd.it/xf4iqa3gqgjf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1msat86/is_this_legit_what_am_i_missing_here/\">[comments]</a></span> </td></tr></table>",
        "id": 3346966,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1msat86/is_this_legit_what_am_i_missing_here",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/xf4iqa3gqgjf1.jpeg?width=640&crop=smart&auto=webp&s=6138fd82d91a54dccee1ae8918777c920599aa01",
        "title": "Is this legit? What am I missing here?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/gnexuser2424",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-17T00:01:12.608504+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T22:59:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Need to know the difference between the two and if they are equals...and which should I get. </p> <p>I hear they are quieter than the exos X and HC550s but I&#39;d like to confirm it. </p> <p>I need 2ndary storage in my music studio. Running outta SSD space as well as on my 2TB WD Black HDD.</p> <p>Prices are good on those two series so they both would fit. I&#39;m torn between the 2. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/gnexuser2424\"> /u/gnexuser2424 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1msanrp/seagate_exos_7e10_vs_wd_ultrastar_hc330/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1msanrp/seagate_exos_7e10_vs_wd_ultrastar_hc330/\">[comments]</a></span>",
        "id": 3346963,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1msanrp/seagate_exos_7e10_vs_wd_ultrastar_hc330",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "seagate exos 7e10 vs wd ultrastar hc330",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ZOODUDE100",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T22:56:08.129589+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T22:28:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Started using <a href=\"http://savethevideo.com\">savethevideo.com</a> for offline PBS viewing.<br/> Recently, I ran into a snag with one video. <a href=\"https://www.pbs.org/video/the-homeless-tempest-tossed-en-espanol-o4lj1d/\">https://www.pbs.org/video/the-homeless-tempest-tossed-en-espanol-o4lj1d/</a><br/> I start the conversion process and once it is finished, I hit download for the file and it makes a different file type, not a video. </p> <p>Have you had this problem and can work around this issue?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ZOODUDE100\"> /u/ZOODUDE100 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms9vxb/video_downloading_trouble/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms9vxb/video_downloading_trouble/\">[comments]</a></span>",
        "id": 3346771,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms9vxb/video_downloading_trouble",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Video Downloading Trouble",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Renrut23",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T22:56:08.313330+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T22:17:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking for a x8 board that holds 2 or more nvme drives and handles bifurcation. My bios does not support it. Looking to try and fit it in a ThinkCentre m90q. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Renrut23\"> /u/Renrut23 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms9lwc/pcie_to_nvme_board_recommendation/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms9lwc/pcie_to_nvme_board_recommendation/\">[comments]</a></span>",
        "id": 3346772,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms9lwc/pcie_to_nvme_board_recommendation",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "PCIE to NVME board recommendation",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/realAnirudhsharma",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-17T00:01:13.364351+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T22:06:22+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/realAnirudhsharma\"> /u/realAnirudhsharma </a> <br/> <span><a href=\"/r/synology/comments/1ms9b8d/first_time_synology_user_looking_for_tips_on_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms9bsj/first_time_synology_user_looking_for_tips_on_a/\">[comments]</a></span>",
        "id": 3346964,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms9bsj/first_time_synology_user_looking_for_tips_on_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "First time synology user, looking for tips on a couple of things.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BlackTadius",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T21:51:09.925331+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T21:40:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a Seagate Exos HDD and today I got a &quot;bitchslap&quot; by it going to park by itself.</p> <p>I&#39;ve read that I have to turn EPC off with &quot;SeaChest Utilities&quot; for the head to read non-stop while the PC runs but have my questions:<br/> -Does the procedure wipe my HDD?<br/> -Does 24/7 reading take from the HDD-s lifespan?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BlackTadius\"> /u/BlackTadius </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms8o2l/if_i_turn_off_epc_on_my_exos_after_loading_it/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms8o2l/if_i_turn_off_epc_on_my_exos_after_loading_it/\">[comments]</a></span>",
        "id": 3346529,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms8o2l/if_i_turn_off_epc_on_my_exos_after_loading_it",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "If I turn off EPC on my Exos AFTER loading it with stuff will I lose the files already stored on it?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Exodusllc",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T20:46:09.030428+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T20:08:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Id like to buy an expasion for my laptop for all my CAD Files and other backups. What external harddrive would you guys buy if it had to be as small as possible, 16tb+ space, reliable and max 270\u20ac. Seagate expantion 16tb maybe?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Exodusllc\"> /u/Exodusllc </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms6808/advice_on_best_pricequality_for_an_16tb_external/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms6808/advice_on_best_pricequality_for_an_16tb_external/\">[comments]</a></span>",
        "id": 3346247,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms6808/advice_on_best_pricequality_for_an_16tb_external",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Advice on best price/quality for an 16tb+ external harddrive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Flubrotizolam",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T20:46:08.787415+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T19:54:31+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms5twr/wd_my_cloud_ridiculous_network_usage/\"> <img src=\"https://preview.redd.it/v14el129sfjf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab5b1beb836fed1150f1d94c7751ce2cca735107\" alt=\"WD My Cloud - ridiculous network usage\" title=\"WD My Cloud - ridiculous network usage\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I have a WD My cloud home, and its network usage is very high when I leave it plugged in. If I look in my task manager it seems to be &quot;system&quot; which is using up bandwidth, specifically ntoskrnl in the system32 folder. The real culprit is WD\u2019s background services (sync, indexing?). I once left it plugged in and it used up 18 TB of bandwidth in less than a month. How can I make it stop eating my bandwidth? What&#39;s causing this? Anyone have any experience with this? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Flubrotizolam\"> /u/Flubroti",
        "id": 3346246,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms5twr/wd_my_cloud_ridiculous_network_usage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/v14el129sfjf1.png?width=320&crop=smart&auto=webp&s=ab5b1beb836fed1150f1d94c7751ce2cca735107",
        "title": "WD My Cloud - ridiculous network usage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Drumsequivalent",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-17T00:01:13.862517+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T19:51:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently decided to get into datahording, mostly due to the current state of the world and an increasing fear of all my favorite things disappearing due to censorship, and I was wondering if you guys had any info you could share with a newbie? I am currently browsing the wiki and google to learn how to properly do this but I wanted to see if anyone had anything that they wish they knew before they got started/experience that could help me avoid some beginner mistakes? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Drumsequivalent\"> /u/Drumsequivalent </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms5r5v/any_good_tips_or_hints_you_wish_you_knew_before/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms5r5v/any_good_tips_or_hints_you_wish_you_knew_before/\">[comments]</a></span>",
        "id": 3346965,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms5r5v/any_good_tips_or_hints_you_wish_you_knew_before",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any good tips or hints you wish you knew before you started?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/2qup21",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T19:41:21.276238+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T19:25:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>im trying to build an archive using old box hard drive but im worried about viruses is there anyway to safely wipe a hard drive that could be potentially dangerous.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/2qup21\"> /u/2qup21 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms51pd/question_about_safely_wiping_hard_drive_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms51pd/question_about_safely_wiping_hard_drive_for/\">[comments]</a></span>",
        "id": 3346006,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms51pd/question_about_safely_wiping_hard_drive_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "question about safely wiping hard drive for storage",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Old_Mushroom8813",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T19:41:21.898677+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T19:06:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>loooking for free cloud storage solution, as an alternative to MEGA</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Old_Mushroom8813\"> /u/Old_Mushroom8813 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms4ip1/i_used_to_exploit_the_storage_bug_on_mega_android/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms4ip1/i_used_to_exploit_the_storage_bug_on_mega_android/\">[comments]</a></span>",
        "id": 3346007,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms4ip1/i_used_to_exploit_the_storage_bug_on_mega_android",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I used to exploit the storage bug on MEGA android app to go over the 20gb free limit, but now its patched. Could you please suggest a free cloud storage solution that supports media sharing, with minimum 1TB of space?!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/prototype073",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:07.388015+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T17:54:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I&#39;m planning on creating a backup server for all of my data that I&#39;ll put in my parents house, but I have a few questions.</p> <ol> <li><p>Should a backup server copy the main one hardware-wise? Main server has a HW firewall. Should my backup have one, too?</p></li> <li><p>I&#39;d like both to have raw storage on both, as I don&#39;t need high availability, and my only worry is data corruption. As I&#39;ve learned from another post I made, it&#39;s not viable to fully automate checksumming and replacing corrupted files from a remote server (<a href=\"https://www.reddit.com/r/homelab/comments/1iek3n7/setting_up_bitrot_protection_between_two_servers/\">https://www.reddit.com/r/homelab/comments/1iek3n7/setting_up_bitrot_protection_between_two_servers/</a>). Would it be more viable to individually checksum on both servers and manually replace corrupted files, as bitrot could only affect a couple of files from time to time.</p></li> <li><p>What el",
        "id": 3345687,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms2iki/im_setting_up_a_backup_data_server_and_have_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I'm setting up a backup data server and have a couple questions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SubjectVisible",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:07.585036+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T17:52:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So far im thinking about the Samsung T9 or T7 shield. Leaning towards the T9. Any suggestions?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SubjectVisible\"> /u/SubjectVisible </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms2ggr/looking_for_a_rugged_external_ssd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms2ggr/looking_for_a_rugged_external_ssd/\">[comments]</a></span>",
        "id": 3345688,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms2ggr/looking_for_a_rugged_external_ssd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a rugged external SSD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/matthias_lehner",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:07.765435+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T17:31:52+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms1vwh/am_i_able_to_move_this_external_hdd_to_a_docking/\"> <img src=\"https://b.thumbs.redditmedia.com/RI02YFSNZSwk8PIPLpK59hZJvvhOj75vCYvVdLQ71Sk.jpg\" alt=\"Am I able to move this external HDD to a docking station?\" title=\"Am I able to move this external HDD to a docking station?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Man.. one of my WD Elements 2TB(this model: <a href=\"https://www.westerndigital.com/en-ca/products/portable-drives/wd-elements-portable-usb-3-0-hdd?sku=WDBU6Y0020BBK-WESN\">https://www.westerndigital.com/en-ca/products/portable-drives/wd-elements-portable-usb-3-0-hdd?sku=WDBU6Y0020BBK-WESN</a>) died 2 days ago and I tried different cables of working hard disks but nothing worked. </p> <p>I&#39;ve been trying to get a docking station and see if I can set the external HDD there, is that possible? I don&#39;t even know if this guy opens up or not without me damaging it :(</p> </div><!-- SC_",
        "id": 3345689,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms1vwh/am_i_able_to_move_this_external_hdd_to_a_docking",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/RI02YFSNZSwk8PIPLpK59hZJvvhOj75vCYvVdLQ71Sk.jpg",
        "title": "Am I able to move this external HDD to a docking station?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Myfirstreddit124",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T17:31:14.442949+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T17:04:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How would you move 20 TB of files from one hard drive to another?</p> <p>These are both consumer USB drives.</p> <p>I want to preserve all file and folder attributes.</p> <p>I have a MacBook Air. It copies at a rate of several hours per TB.</p> <p>I want to leave the computer unattended and ignore errors. Various read/write, file not found, and unknown errors tend to occur during long copy operations. Ideally these errors would be logged but not stop the operation.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Myfirstreddit124\"> /u/Myfirstreddit124 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms14z5/how_would_you_move_20tb_of_files/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms14z5/how_would_you_move_20tb_of_files/\">[comments]</a></span>",
        "id": 3345370,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms14z5/how_would_you_move_20tb_of_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How would you move 20TB of files?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ready_Top496",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:08.143429+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T16:59:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m trying to download every image from a tag, nearly 18k images. I got to 5k and then gallery-dl stopped since pixiv only allows the first 5k results to be viewed. From searches I don\u2019t think there\u2019s an actual solution, but is there a workaround? For example, download the 5001st to 10,000th images and so on?</p> <p>Also, is there a way to specify to download from oldest to newest? I\u2019d like to prioritize older artworks first</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ready_Top496\"> /u/Ready_Top496 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms0zcp/about_gallerydl_with_pixiv/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1ms0zcp/about_gallerydl_with_pixiv/\">[comments]</a></span>",
        "id": 3345691,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms0zcp/about_gallerydl_with_pixiv",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "About gallery-dl with pixiv",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/bahargaon",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:08.316100+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T16:55:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello people,</p> <p>I&#39;ve learnt all about data management from this community.<br/> I&#39;m up against a challenge.</p> <p>I am going to be dividing (not equally) my time between two countries for some years. I own very little data\u2014about 12 TB\u2014and it&#39;s in my country of origin. I need to access it in the new country I&#39;m in. I tried accessing it via TailScale, but it doesn&#39;t seem practical because of how slow it is.</p> <p>Ideally, I would want to access data from both countries, without having to fly with harddisks each time. I am not very technical, but am looking up &#39;setting up wire guard&#39; in my country of origin on one of my next trips.</p> <p>What do you think is a good long-term solution for my situation? </p> <p>All advise/ideas appreciated. TIA!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/bahargaon\"> /u/bahargaon </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/com",
        "id": 3345692,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1ms0v6t/managing_and_accessing_data_between_two_countries",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Managing and accessing data between two countries",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/surele",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:08.525807+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T16:06:01+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrzi5n/bought_a_new_4tb_drivewanna_know_if_its_not_a/\"> <img src=\"https://b.thumbs.redditmedia.com/bWBpKDch0VYrCzOYYXoFVq_b5WdKf5dQmx0oiK6NvdY.jpg\" alt=\"bought a new 4tb drive(wanna know if its not a faulty one)\" title=\"bought a new 4tb drive(wanna know if its not a faulty one)\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/0t79k98nmejf1.png?width=734&amp;format=png&amp;auto=webp&amp;s=318617b71d7bec7e62b384a617bef402b5290ade\">https://preview.redd.it/0t79k98nmejf1.png?width=734&amp;format=png&amp;auto=webp&amp;s=318617b71d7bec7e62b384a617bef402b5290ade</a></p> <p>i installed a self hosted app to monitor my drives it returned this so i got scared and ran the smart long test </p> <p><a href=\"https://privatebin.net/?35e8270e56452913#DU2AxkuGs3EuauVyQaHKg5egFoYCGygHBLPY32KJH2UQ\">S.M.A.R.T test and scan results</a></p> <p>not sure if this is the best sub to post this but i dont k",
        "id": 3345693,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrzi5n/bought_a_new_4tb_drivewanna_know_if_its_not_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/bWBpKDch0VYrCzOYYXoFVq_b5WdKf5dQmx0oiK6NvdY.jpg",
        "title": "bought a new 4tb drive(wanna know if its not a faulty one)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Different_Ad_5345",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T14:17:06.707920+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T14:16:26+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrwhz7/genuine/\"> <img src=\"https://b.thumbs.redditmedia.com/8rDPF0T1F8z2Aqe6LGgG6JZ-gchivuJALJDj-MeeCnA.jpg\" alt=\"Genuine?\" title=\"Genuine?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Need help on if these are genuine drives or are they altered with(reset)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Different_Ad_5345\"> /u/Different_Ad_5345 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1mrwhz7\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrwhz7/genuine/\">[comments]</a></span> </td></tr></table>",
        "id": 3344393,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrwhz7/genuine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/8rDPF0T1F8z2Aqe6LGgG6JZ-gchivuJALJDj-MeeCnA.jpg",
        "title": "Genuine?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/sko2sko",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:08.733415+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T12:09:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all,</p> <p>I\u2019m looking for a (macOS) app to clean up photo metadata (timestamps + locations) more efficiently than Apple Photos.</p> <p>Ideal features:</p> <ul> <li>Batch editing of metadata.</li> <li>AI/ML clustering (grouping photos from the same scene/time).</li> <li>Suggestions for filling in missing metadata by comparing with nearby photos.</li> <li>Bonus: ability to use LLMs (ChatGPT, Claude, etc.) to recommend likely locations or times based on image content.</li> </ul> <p>So far I\u2019ve seen HoudahGeo, MetaImage, ExifTool, but they\u2019re quite manual. Is there anything more modern/AI-driven out there?</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sko2sko\"> /u/sko2sko </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrtf9x/app_for_smart_photo_metadata_editing_ai/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrtf9x/app_for_sma",
        "id": 3345694,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrtf9x/app_for_smart_photo_metadata_editing_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "App for smart photo metadata editing (AI clustering + LLM recommendations)?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Correct_Quantity_314",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T12:06:13.378381+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T11:49:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Partner and I are exiting the US and will be traveling for the foreseeable future with no consistent base. I\u2019ve been sailing the seas for a while now after a long hiatus and have amassed quite a collection of things (nothing nowhere near impressive as some users here, maybe a few TB\u2019s at most), and am mostly concerned about security and access while abroad. </p> <p>This may be too vague a summary and with too many variables for a quick answer so my apologies if so, but, could someone provide a general direction or summary of a workable approach at managing this sort of thing while on the move? Being able to access media at least in some marginally convenient way, as securely and privately as possible, while having the space to continue growth? Having something like a physical NAS at a stable location isn\u2019t possible atm, but that\u2019s my long term goal once we settle.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/C",
        "id": 3343757,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrszq0/how_to_effectively_hoard_data_while_constantly",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to effectively hoard data while constantly traveling abroad?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/wsrvnar",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:07.936648+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T11:16:15+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrsbfs/seagate_spins_up_a_raid_on_a_counterfeit_hard/\"> <img src=\"https://external-preview.redd.it/nVn47kF-SQ2Vv3wBSbkRv3vHJVRc58PhDfmCzgEEd8w.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ea8481807aebedf8ae3d3fdc1cf8d0f0b6c6a225\" alt=\"Seagate spins up a raid on a counterfeit hard drive workshop \u2014 authorities read criminals' writes while they spill the beans\" title=\"Seagate spins up a raid on a counterfeit hard drive workshop \u2014 authorities read criminals' writes while they spill the beans\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Bust finds nearly 700 Seagate hard drives, along with some from Kioxia and Western Digital.</p> <p>According to German news outlet Heise, notable progress has been made regarding the counterfeit Seagate hard drive case. Just like something out of an action movie, security teams from Seagate&#39;s Singapore and Malaysian offices, in conjunction with local Malaysian authorit",
        "id": 3345690,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrsbfs/seagate_spins_up_a_raid_on_a_counterfeit_hard",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/nVn47kF-SQ2Vv3wBSbkRv3vHJVRc58PhDfmCzgEEd8w.jpeg?width=640&crop=smart&auto=webp&s=ea8481807aebedf8ae3d3fdc1cf8d0f0b6c6a225",
        "title": "Seagate spins up a raid on a counterfeit hard drive workshop \u2014 authorities read criminals' writes while they spill the beans",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TechnicianHorror6142",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:08.962825+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T10:44:21+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrrojg/28_tb_seagate_expansion_is_now_330_usd_in_seagate/\"> <img src=\"https://preview.redd.it/dg9yrquy1djf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d371b018bb7ba6f3453fbb8514cd7a3db3f7cce4\" alt=\"28 TB Seagate expansion is now 330 usd in Seagate website\" title=\"28 TB Seagate expansion is now 330 usd in Seagate website\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TechnicianHorror6142\"> /u/TechnicianHorror6142 </a> <br/> <span><a href=\"https://i.redd.it/dg9yrquy1djf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrrojg/28_tb_seagate_expansion_is_now_330_usd_in_seagate/\">[comments]</a></span> </td></tr></table>",
        "id": 3345695,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrrojg/28_tb_seagate_expansion_is_now_330_usd_in_seagate",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/dg9yrquy1djf1.jpeg?width=640&crop=smart&auto=webp&s=d371b018bb7ba6f3453fbb8514cd7a3db3f7cce4",
        "title": "28 TB Seagate expansion is now 330 usd in Seagate website",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Flashy_Register_6730",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:09.165026+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T09:50:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I currently have the following situation:<br/> I have about 200 gigabytes of images on my google photos, auto-synced from my phone out of sheer laziness. i actually have about 6tb of storage in my apartment.<br/> At the top level, they are about 70% wildflower images, and 30% other photos such as selfies/people, documents, and memes.<br/> I like that google photos has some sort of search feature that allows me to just search for &quot;plants&quot;. However its wonky and google photos is generally giving me a tough time in terms of organizing my pictures. </p> <p>Now heres what i would really like to do:<br/> At the most basic I would like to at least automatically sort out all plant pictures from the rest of the photos, into two separate folders. i have this software here that allows me to sort images by color values but that one doesnt lend itself to organizing tens of thousands of photos. </p> <p>ideally id have a program that can scan my entire PC ",
        "id": 3345696,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrqnwy/giant_heap_of_images_to_sort_general_advice_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Giant heap of images to sort. general advice and discussion",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/roadrussian",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T09:56:04.865543+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T09:29:41+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrqap8/jmicron_jms578_512_to_4096_sector_size/\"> <img src=\"https://preview.redd.it/x2efih1iocjf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a68732c9e02da172e094cf3b14abb62e99f6614e\" alt=\"Jmicron JMS578 512 to 4096 Sector Size Translation problem in external enclosures: DIY solution\" title=\"Jmicron JMS578 512 to 4096 Sector Size Translation problem in external enclosures: DIY solution\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/roadrussian\"> /u/roadrussian </a> <br/> <span><a href=\"https://i.redd.it/x2efih1iocjf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrqap8/jmicron_jms578_512_to_4096_sector_size/\">[comments]</a></span> </td></tr></table>",
        "id": 3343151,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrqap8/jmicron_jms578_512_to_4096_sector_size",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/x2efih1iocjf1.jpeg?width=320&crop=smart&auto=webp&s=a68732c9e02da172e094cf3b14abb62e99f6614e",
        "title": "Jmicron JMS578 512 to 4096 Sector Size Translation problem in external enclosures: DIY solution",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Past-Major1850",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T09:56:05.551387+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T08:59:50+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrprlp/if_the_internet_was_going_offline_in_1_week_what/\"> <img src=\"https://preview.redd.it/jkmez91jjcjf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=757d7748669d5ba5ab28298b6f73ee53b78090da\" alt=\"If the internet was going offline in 1 week, what would you hoard first?\" title=\"If the internet was going offline in 1 week, what would you hoard first?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hypothetical scenario: let\u2019s say we all get a warning that the entire internet will go down permanently in 7 days. No cloud, no streaming, no downloads, nothing accessible once it\u2019s gone.</p> <p>If that really happened, what would be the first things you\u2019d start hoarding?</p> <p>I\u2019m curious what the priority list of a true data hoarder would look like in such a doomsday internet scenario.</p> <p>And maybe it would give me some idea about what i should hoard.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a",
        "id": 3343152,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrprlp/if_the_internet_was_going_offline_in_1_week_what",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/jkmez91jjcjf1.jpeg?width=640&crop=smart&auto=webp&s=757d7748669d5ba5ab28298b6f73ee53b78090da",
        "title": "If the internet was going offline in 1 week, what would you hoard first?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Docom_s13",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:09.427848+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T08:27:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey there,</p> <p>I&#39;m looking for a new system drive for my PC, preferably in M.2 NVMe 2280 format. I can buy either a top-notch consumer-grade 1 TB SSD, or an enterprise-grade 480 GB SSD; the latter is less than half the size and about 20% more expensive, but has the benefit of power loss protection (PLP). How important is it in 2025 for a desktop SSD - in particular one used as a system drive - to have PLP?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Docom_s13\"> /u/Docom_s13 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrp6v3/ssd_with_plp_for_desktop_in_2025/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrp6v3/ssd_with_plp_for_desktop_in_2025/\">[comments]</a></span>",
        "id": 3345697,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrp6v3/ssd_with_plp_for_desktop_in_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SSD with PLP for desktop in 2025?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Beginning-Guitar988",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T18:36:09.597121+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T07:18:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey!</p> <p>I&#39;m looking to download manga from Manga Plaza that I&#39;ve already purchased. You can read your purchases from their manga reader/viewer widget, but can download them. I tried BID, and no luck.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Beginning-Guitar988\"> /u/Beginning-Guitar988 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrny70/pulling_purchased_manga_from_manga_plaza/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrny70/pulling_purchased_manga_from_manga_plaza/\">[comments]</a></span>",
        "id": 3345698,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrny70/pulling_purchased_manga_from_manga_plaza",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Pulling purchased manga from Manga Plaza",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/serpent666999666",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T05:33:32.089305+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T03:01:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I have a system currently in a Meshify 2 XL. In this system I have a Threadripper Pro 3975WX, 256GB RAM, 2x Asus Turbo RTX 3090s and a 2000 Watt PSU.</p> <p> </p> <p>I&#39;m looking at building a new 9950X3D System and want to turn my current system into a Render Node plus NAS.I have two PCIE slots left with which I will install a LSI 16i HBA and a ASUS Hyper M.2 Card which came with the motherboard. Then as the Meshify 2 XL can hold up to 18 HDDs I was going to install 2x 4TB Samsung 870 EVO and 16x 3.5&quot; HDDs either 24TB/28TB Seagate Exos/WD Ultrastar; depending on which manufacturer I decide on (happy to receive advice).I was also going to install 8 new Fans (4x Noctua NF-A14 industrialPPC-3000 and 4x Noctua NF-A14 chromax.black).</p> <p> </p> <p>My question is do you think it will be safe to do that? Will there be enough cooling to keep everything happy? Or should I buy an 8e HBA + SAS Expander and build a JBOD to then attach to the server",
        "id": 3342224,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrivfg/too_much_in_a_meshify_2_xl",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Too Much in a Meshify 2 XL",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jordan_w98",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T03:23:30.449278+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T01:54:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://reddit.com/link/1mrhe48/video/opnw0ecicajf1/player\">https://reddit.com/link/1mrhe48/video/opnw0ecicajf1/player</a></p> <p>This project started a couple of weeks ago because I wanted to build my own personal \u201cNetflix\u201d for myself and my family. My goal was to make it as simple yet advanced as possible \u2014 so if someone I know wants a movie added, I can log in and have it ready within minutes.</p> <p>What you see here is a demo of me searching for a movie, browsing available torrents, and configuring settings to ingest it into my storage server. It\u2019s a bit slow right now since nothing has been fully optimized yet, but I\u2019m looking for suggestions to help make this future app better in any way.</p> <p>For example, features like automatically handling TV show torrents that contain full-season episode packs, or auto-applying subtitles, would be really helpful.</p> <p>My current goals are: </p> <ol> <li><p>Have all content transcoded into multi",
        "id": 3341866,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrhe48/looking_for_suggestions_for_an_application_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for suggestions for an application to torrent and manage content more efficiently",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Deschutes_Overdrive",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T03:23:30.618049+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T01:31:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am currently using external HDD using <strong>XFS</strong> filesystem as a cold storage backup medium.</p> <p>Should I migrate to <strong>Btrfs</strong> for its checksum functionality?</p> <p>There are any recommended practices that should I be aware of?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Deschutes_Overdrive\"> /u/Deschutes_Overdrive </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrgw1e/filesystem_recommendations_for_cold_storage_on_hdd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrgw1e/filesystem_recommendations_for_cold_storage_on_hdd/\">[comments]</a></span>",
        "id": 3341867,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrgw1e/filesystem_recommendations_for_cold_storage_on_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Filesystem recommendations for Cold Storage on HDD.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Maverick_Walker",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T01:13:07.578872+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T00:56:27+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrg3vj/hows_this_to_start/\"> <img src=\"https://preview.redd.it/t47qkc1b5ajf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9a549260086133499bc24ef650687bf0113b40d1\" alt=\"How\u2019s this to start?\" title=\"How\u2019s this to start?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Found a 48tb Orico on marketplace for 450, dropped to 400 because the 8th drive would limit the other 10tb helium filled hard drives.</p> <p>Where do I start with this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Maverick_Walker\"> /u/Maverick_Walker </a> <br/> <span><a href=\"https://i.redd.it/t47qkc1b5ajf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrg3vj/hows_this_to_start/\">[comments]</a></span> </td></tr></table>",
        "id": 3341481,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrg3vj/hows_this_to_start",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/t47qkc1b5ajf1.jpeg?width=640&crop=smart&auto=webp&s=9a549260086133499bc24ef650687bf0113b40d1",
        "title": "How\u2019s this to start?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Playingvideogames1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T01:13:07.750964+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T00:34:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I bought a pc lately to serve as a backup, I bought three 3.5&quot; HDD and im trying to figure out how I can connect all three to one cable. What Sata power cable do I need to buy?. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Playingvideogames1\"> /u/Playingvideogames1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrfm72/im_not_sure_what_sata_power_cable_i_should_buy/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrfm72/im_not_sure_what_sata_power_cable_i_should_buy/\">[comments]</a></span>",
        "id": 3341482,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrfm72/im_not_sure_what_sata_power_cable_i_should_buy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Im not sure what Sata power cable i should buy for my ThinkStation P520?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/nice__username",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T00:09:39.105688+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T00:05:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Ordered 4 x 16 TB Seagate Exos April 4th, 2025</p> <p>Dead disk August 15, 2025</p> <p>No potential to RMA just out ~$300 and there&#39;s fuck all anyone will do</p> <p>It&#39;s much better worth it to just spend the extra money and get warrantied, original disks from a manufacturer. I&#39;m extremely disappointed. My old 4 x 4TB Red Pro&#39;s never had any issues ever and I was able to sell them easily. Those ran fine for four years.</p> <p>What a stupid mistake I&#39;ve made. Heed my warning and never, ever purchase from this company. I fell for the bait.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nice__username\"> /u/nice__username </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrey1q/do_not_purchase_from_goharddrive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrey1q/do_not_purchase_from_goharddrive/\">[comments]</a></span>",
        "id": 3341206,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrey1q/do_not_purchase_from_goharddrive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Do not purchase from GoHardDrive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/vilos5099",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-16T00:09:39.607343+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-16T00:03:03+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrevva/copyparty_cloudflare_tunnel_docker_image/\"> <img src=\"https://external-preview.redd.it/x6wj8M1AC1sV9Rfus1A_1nzZbXsQz7E9W8cxKH_K7PQ.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9e7d6478e9e6cab17c97a9db0161df8e3b76d958\" alt=\"copyparty + Cloudflare Tunnel Docker Image\" title=\"copyparty + Cloudflare Tunnel Docker Image\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;ve created a Docker image that bundles <a href=\"https://github.com/9001/copyparty\">copyparty</a> with a Cloudflare Tunnel, providing a simple and secure way to expose your file-sharing instance to the internet.</p> <p>This approach offers several benefits:</p> <ul> <li><strong>Ease of Use</strong>: Get up and running quickly. All you need is your <code>copyparty</code> configuration file and a Cloudflare Tunnel token. No need to manually install or manage <code>cloudflared</code>.</li> <li><strong>Portability</strong>: The containeri",
        "id": 3341207,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrevva/copyparty_cloudflare_tunnel_docker_image",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/x6wj8M1AC1sV9Rfus1A_1nzZbXsQz7E9W8cxKH_K7PQ.png?width=640&crop=smart&auto=webp&s=9e7d6478e9e6cab17c97a9db0161df8e3b76d958",
        "title": "copyparty + Cloudflare Tunnel Docker Image",
        "vote": 0
    }
]