[
    {
        "age": null,
        "album": "",
        "author": "/u/Vegetable_Pass_9597",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T19:25:35.168124+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T18:46:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>ESP32 Inkjet Cartridge Controller Project - Hardware Debugging Help Needed</strong></p> <p>I&#39;m reproducing Jeroen Domburg&#39;s HP63 cartridge controller project (Magic Printer Cartridge Paintbrush) and have encountered several hardware failures. Looking for advice on debugging strategy and potential design issues.</p> <p><strong>Project Status:</strong> Successfully achieved some ink output (cyan, occasional yellow) before hardware failures occurred. Using Jeroen&#39;s original KiCad files and exact component specifications.</p> <p><strong>Hardware Architecture:</strong></p> <ul> <li>3-board system: PSU board (3.3V/9V/16V rails), ESP32 board, cartridge control board</li> <li>MC14504B level converters for 3.3V to 9V/16V translation</li> <li>Custom power protection circuit for nozzle drive (10\u00b5s pulse limiting)</li> <li>ESP32-S3 as programmer, GPIO22 substituted for GPIO12 (to avoid using bootstrapping pin)</li> </ul> <p><strong>Current Iss",
        "id": 3395251,
        "language": "",
        "link": "https://www.reddit.com/r/ReverseEngineering/comments/1mxeuo5/sprites_mods_magic_printer_cartridge_paintbrush",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 476,
        "source_url": "https://www.reddit.com/r/ReverseEngineering/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Sprites mods - Magic Printer Cartridge Paintbrush",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/zeltrax77",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T17:13:43.817686+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T16:29:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Been messing around with the idea of reverse-engineering Al stuff, and came across this tool called FaceSeek. Basically, you upload a pic and it finds similar faces online.</p> <p>Got me thinking... could tools like this be used to test how strong face embeddings really are? Most papers talk about attacks where you can rebuild or guess embeddings, sometimes even reconstruct faces, but that&#39;s all heavy lab work. FaceSeek feels like a real-world testbed where you deal with messy stuff like bad lighting, weird angles, compression... the things that break models outside clean datasets.</p> <p>Curious if anyone here has ever used something like this to see where embeddings fail or drift? Thinking about uploading slightly changed pics to see if matches hold or if it starts pulling random faces. Would be cool to know if anyone&#39;s tried experiments like this or has ideas.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com",
        "id": 3394252,
        "language": "",
        "link": "https://www.reddit.com/r/ReverseEngineering/comments/1mxb8o7/anyone_ever_tried_reversing_facematching_systems",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 476,
        "source_url": "https://www.reddit.com/r/ReverseEngineering/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone ever tried reversing face-matching systems?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Afolun",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T03:32:30.940271+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T02:43:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I put together a tiny, observe\u2011only LD_PRELOAD template aimed at RE workflows. It interposes a function in a self\u2011owned <code>.so</code>, logs args/ret/latency to CSV, and auto\u2011plots a histogram in GitHub Actions. Useful as a lightweight dynamic probe before pulling out heavier tooling.</p> <ul> <li>What you get <ul> <li><a href=\"http://libhook.so\"><code>libhook.so</code></a> that forwards via <code>dlsym(RTLD_NEXT, ...)</code></li> <li>Demo target <a href=\"http://libdemo.so\"><code>libdemo.so</code></a> and a small driver</li> <li><code>hook.csv</code> + <code>latency.png</code> (generated locally or in CI artifacts)</li> <li>Clean Makefile and a CI pipeline: build \u2192 run with <code>LD_PRELOAD</code> \u2192 plot \u2192 upload</li> </ul></li> <li>Quick start</li> <li>git clone <a href=\"https://github.com/adilungo39/libdemo-instrumentation\">https://github.com/adilungo39/libdemo-instrumentation</a> cd libdemo-instrumentation make &amp;&amp; make run &amp;&amp; make",
        "id": 3388982,
        "language": "",
        "link": "https://www.reddit.com/r/ReverseEngineering/comments/1mwuwj3/releaseshowcase_minimal_ld_preload_observeonly",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 476,
        "source_url": "https://www.reddit.com/r/ReverseEngineering/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[Release/Showcase] Minimal LD_PRELOAD \u201cobserve\u2011only\u201d interposer for your own .so \u2014 hook, log, plot (with CI)",
        "vote": 0
    }
]