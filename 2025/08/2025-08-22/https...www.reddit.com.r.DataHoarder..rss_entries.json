[
    {
        "age": null,
        "album": "",
        "author": "/u/jdoerrerstl1977",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T23:57:49.089360+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T23:24:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I am looking for studs for the rack kit. I got a qnap ts-859u-rp. but it dos not have the studs for the j clips. Any help would be great where I can a quire them thanks!</p> <p>This studs/screws are missing I am trying to find something so i can use the rails. </p> <p><a href=\"https://ibb.co/VcBZr6j4\">https://ibb.co/VcBZr6j4</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jdoerrerstl1977\"> /u/jdoerrerstl1977 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxlt7a/qnap_rack_mount_studs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxlt7a/qnap_rack_mount_studs/\">[comments]</a></span>",
        "id": 3396900,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxlt7a/qnap_rack_mount_studs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "QNAP Rack Mount STUDS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Archivist_Goals",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T23:57:48.563867+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T23:21:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This post is not meant to be entirely alarmist. The professionals are currently hard at work ensuring that the data sets that the Smithsonian currently has it has are backed up appropriately. But I thought I would share this here in case anyone wants to help contribute, and back up copies of that data. LOCKSS.</p> <p><a href=\"http://sciop.net/datasets/\">http://sciop.net/datasets/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Archivist_Goals\"> /u/Archivist_Goals </a> <br/> <span><a href=\"http://sciop.net/datasets/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxlr92/backing_up_the_smithsonian_institutions_data_sets/\">[comments]</a></span>",
        "id": 3396898,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxlr92/backing_up_the_smithsonian_institutions_data_sets",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Backing up the Smithsonian Institutions Data Sets",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Hellboymeep",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T23:57:49.258957+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T23:20:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a huge 46gb tsv file i wanna open and look at, however nothing can open it for me. Either the file is too big or whatever program will simply just crash in the end, anyone that can help?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hellboymeep\"> /u/Hellboymeep </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxlpsy/opening_large_tsv_files/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxlpsy/opening_large_tsv_files/\">[comments]</a></span>",
        "id": 3396901,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxlpsy/opening_large_tsv_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Opening large tsv files",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/-jake28-",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T23:57:48.808043+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T23:05:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Howdy,</p> <p>I\u2019ve been looking at some verbatim 50gb blu ray discs for archiving some important data. However the vast majority of the listings I found online seem to lack the MABL branding on them, versus the 25gb discs which do. Now the research I did on m disc vs MABL suggests very little reason to get the m discs, especially for the price. However, the 50gb discs don\u2019t even seem to have the MABL branding, which makes me very suspicious of their quality.</p> <p>For reference, here\u2019s one of the listings I\u2019m talking about: <a href=\"https://www.amazon.com/Verbatim-BD-R-Blu-ray-Recordable-Media/dp/B00LPM2CU8\">https://www.amazon.com/Verbatim-BD-R-Blu-ray-Recordable-Media/dp/B00LPM2CU8</a></p> <p>If you select the 25gb option in that listing it still shows the MABL branding.</p> <p>Pretty much what I\u2019m trying to get at is any quality difference between MABL and non-MABL discs. If anyone with more knowledge or experience than I could help out, I would be",
        "id": 3396899,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxld5e/verbatim_mabl_blu_ray_discs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Verbatim MABL Blu ray discs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jagdip",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T22:52:42.783537+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T22:28:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have old synology i bought decade ago or more and it is slow and shut down by itself. i have 4 4 tb nas drives and 4 2tb nas drives ( red drives from western digital i think ) and some 1tb nas drives. i also have a beelink s12 pro mini pc. is there a way i can use all these and build a NAS system? i am reading that i can buy a JBOD enclosure and do it that way. if yes, which JBOD enclosure will work for me. i need some data protection. i was using raid 10 in my synology but i can live with raid 5 or 6. i also have these old dell tower servers which i purchased 12 years ago to build home lab and those have dual zeon processors. can i use those? they consume lot of power and i have those turned off because of that but i am open to ideas</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jagdip\"> /u/jagdip </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxkh6g/suggestions_for_nas/\">[link]</a>",
        "id": 3396622,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxkh6g/suggestions_for_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "suggestions for NAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/pizzaatmywedding",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T21:47:49.852424+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T21:41:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need a lot of storage for media. I am likely going to just bite the bullet, and build a NAS with a 10+ HDD bay case I have. But I already have a decent server, and the cost effectiveness of a 4-6 bay enclosure to plug into it instead is tempting. My question for those who have experience: Is there a good enclosure that is designed for **continuous** use? I&#39;ve looked and looked, and answers are all over the place. </p> <p>fyi I don&#39;t care about read/write speed, USB 3.0 speeds are literally more than enough for me so this isn&#39;t a concern. I understand USB isn&#39;t as safe. I just want to know, is there an enclosure that will keep my drives as cool as a real case with fans, basically. This is *exclusively* for media/plex data.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/pizzaatmywedding\"> /u/pizzaatmywedding </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxjc4l/good_encl",
        "id": 3396202,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxjc4l/good_enclosure_dock_for_247_operation",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Good Enclosure Dock For 24/7 Operation",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Listen2urSilentCry",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T21:47:50.097022+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T20:47:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello! I inherited a data clean up project from a Historical Data Dump that has 60,000 folders. I have been tasked with either finding an app to scan the files, figure out what is inside, and then rename to match what the contents are inside- or manually go through 60,000 folders. Is there such a solution? Thank you in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Listen2urSilentCry\"> /u/Listen2urSilentCry </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxhzbx/method_to_scan_identify_and_rename_60000_folders/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxhzbx/method_to_scan_identify_and_rename_60000_folders/\">[comments]</a></span>",
        "id": 3396203,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxhzbx/method_to_scan_identify_and_rename_60000_folders",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Method to scan, identify, and rename 60,000 folders of a historical data dump on a Shared drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Probabilicious",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T20:42:17.789955+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T19:51:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Right now my \u201cbackup system\u201d is pretty basic: I occasionally copy important files to an external drive. It works in the short term, but I know it\u2019s not really reliable or future-proof. Before something goes wrong and I lose data, I want to set up a proper backup strategy. This way of doing back ups feels really oldskool and outdate, so i am looking for a new way to set up my back up system. So it is done based on the 2025 standard of doing back ups. </p> <p>I\u2019m working with a Windows laptop. I&#39;ve got about 500 GB of data. So lets assume i am looking of a back up system that can holds its own until 1 TB. That seems reasonable for the next years.</p> <p>What I\u2019m looking for:</p> <ul> <li>I just want a proper system of doing back ups so i cant accidently lose my stuff. I dont really need something to fancy. If it works, then it is fine. </li> <li>Up to now I\u2019ve only thought about backups in terms of restoring files, not my whole system. Not really su",
        "id": 3395774,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxgjla/back_up_system",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Back up system",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Toomanyhobbies1983",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T21:47:50.377750+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T19:49:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>A while ago, I found a media management software that let you have organizational control of photo and video assets. Meta tagging, previewing files in one location. Access to the file folder structure, batch renaming. It could do this for a large amount of files </p> <p>Anything like that on the market currently?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Toomanyhobbies1983\"> /u/Toomanyhobbies1983 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxghkq/media_management_software/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxghkq/media_management_software/\">[comments]</a></span>",
        "id": 3396204,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxghkq/media_management_software",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Media Management Software",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Top_fishermans",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T19:37:58.562542+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T19:05:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxfcl3/bought_26tb_seagate_drive_from_amazon_external/\"> <img src=\"https://preview.redd.it/boqeq620dmkf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=25221e5d820ac437c03c5c63761002397e3770c7\" alt=\"Bought 26tb Seagate drive from Amazon external one for $419 CAD\" title=\"Bought 26tb Seagate drive from Amazon external one for $419 CAD\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Is this a good price? It comes to $16 per tb </p> <p>Can\u2019t seem to find a better price than this Might shuck it not sure yet </p> <p>My old drives from Wd are like 8 years old I fear they will fail anytime already super laggy and issues copying stuff</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Top_fishermans\"> /u/Top_fishermans </a> <br/> <span><a href=\"https://i.redd.it/boqeq620dmkf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxfcl3/bough",
        "id": 3395316,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxfcl3/bought_26tb_seagate_drive_from_amazon_external",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/boqeq620dmkf1.jpeg?width=640&crop=smart&auto=webp&s=25221e5d820ac437c03c5c63761002397e3770c7",
        "title": "Bought 26tb Seagate drive from Amazon external one for $419 CAD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ThermoElectricMan",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T19:37:59.125006+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T18:44:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>TLDR: Synology Active Backup for Business on my Windows 11 laptop keeps failing with <em>\u201cUnable to take a snapshot for SystemVolume3 (C:)\u201d</em> (VSS error 0x80042308). Tried increasing shadow storage, clearing stale shadows, rebooting, etc., but still get partial backups. Anyone fixed this without ditching <em>Entire Device</em> backups?</p> <p>Here are more details:</p> <p>I\u2019m running <strong>Active Backup for Business</strong> on my Windows 11 laptop (Lenovo Legion 9i) and keep getting <em>\u201cPartially complete\u201d</em> backups. The log shows:</p> <pre><code>Error 80042308: Unable to take a snapshot for SystemVolume3, C:\\ </code></pre> <p>Event Viewer logs this at the same time:</p> <pre><code>VSS error 12305: Volume/disk not connected or not found DeviceIoControl(\\\\?\\Volume{GUID}\u2026) </code></pre> <p>Things I\u2019ve tried so far:</p> <ul> <li>Increased shadow copy storage size on C:\\ to 30GB.</li> <li>Verified all VSS Writers are Stable with no errors (<code",
        "id": 3395318,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxesql/vss_snapshot_errors_breaking_abb_backups_on_my",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "VSS snapshot errors breaking ABB backups on my Windows 11 laptop",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Description_Capable",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T19:37:58.843707+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T18:40:07+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxep4b/m2_ssd_thermal_management_analysis_impact_on/\"> <img src=\"https://a.thumbs.redditmedia.com/JMcy6u2ew0SHbbK4WKWHXZhDZyVfhtLiF5pgM_Q5O40.jpg\" alt=\"M.2 SSD Thermal Management Analysis - Impact on Drive Longevity (Samsung 980 Pro Study)\" title=\"M.2 SSD Thermal Management Analysis - Impact on Drive Longevity (Samsung 980 Pro Study)\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><strong>TL;DR:</strong> Quantified thermal impact of passive cooling on Samsung 980 Pro. Peak temps reduced from 76\u00b0C to 54\u00b0C. Critical implications for drive longevity in storage arrays.</p> <p>As data hoarders, we often focus on capacity and redundancy while overlooking thermal management. I decided to quantify the thermal impact of basic M.2 cooling on a Samsung 980 Pro using controlled testing.</p> <p><strong>Background:</strong> NAND flash has well-documented temperature sensitivity. Higher operating temperatures accelerate we",
        "id": 3395317,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxep4b/m2_ssd_thermal_management_analysis_impact_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/JMcy6u2ew0SHbbK4WKWHXZhDZyVfhtLiF5pgM_Q5O40.jpg",
        "title": "M.2 SSD Thermal Management Analysis - Impact on Drive Longevity (Samsung 980 Pro Study)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheBigC9933",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T18:34:11.570747+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T18:29:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking at starting a nas for my home, mainly for photo back up. Trying to do it on a budget, thinking about using a spare Intel nuc with an enclosure. I found a used probox HFR7-SU31CH for $60. Is this with picking up to use?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheBigC9933\"> /u/TheBigC9933 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxef95/beginner_nas_probox/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxef95/beginner_nas_probox/\">[comments]</a></span>",
        "id": 3394839,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxef95/beginner_nas_probox",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Beginner NAS Probox",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PotentialInvite6351",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T18:34:11.743673+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T18:12:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a 465gb NVME and have win 11 installed on 224gb (only 113gbs are used) sata ssd now I wanna shift windows to my NVME using disk genius software so can I just create a 150gb partiiton in nvme and use it to shift windows in it as a whole drive?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PotentialInvite6351\"> /u/PotentialInvite6351 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxdyqo/i_need_help_with_migrating_windows_11_to_new/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxdyqo/i_need_help_with_migrating_windows_11_to_new/\">[comments]</a></span>",
        "id": 3394840,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxdyqo/i_need_help_with_migrating_windows_11_to_new",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I need help with migrating windows 11 to new drive using Disk genius",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/FriskyCthulhu",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T19:37:59.354355+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T16:51:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been in the process of digitizing all my family&#39;s photos. Made it through thousands of negatives with my little workhorse Epson V600, but I want something a little faster for photo prints.</p> <p>I&#39;m torn between the Epson FastFoto FF-680W which seems to be the gold standard for home photo scanning, but I&#39;m also eyeing up the Ricoh ScanSnap iX2500 which recently came out. I family history documents I&#39;d like to scan too, so I&#39;m leaning a bit towards the ScanSnap (I know the FastFoto can scan documents too), but I can&#39;t find opinions on the quality of the ScanSnap photo scans. Also, I&#39;m a little worried about reports of the Epson&#39;s poor quality control of the FastFoto&#39;s rollers which are reported to sometimes be rough enough to scratch photos; I know that&#39;s a risk with any auto feeder. </p> <p>Looking for first-hand experience (or reviews if you know of any) about the photo quality, especially if you have",
        "id": 3395319,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxbto4/anyone_have_experience_with_the_new_ricoh",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone have experience with the new Ricoh ScanSnap iX2500?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/haterofslimes",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T17:28:03.529888+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T16:40:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi fellas,</p> <p>I&#39;m looking to see if anyone here has experience with vendors for a bulk SD card purchase. Looking at around 500 256gb Sandisk SD cards. I know there&#39;s a lot of fakes floating around so hoping to find a vendor that&#39;s trustworthy.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/haterofslimes\"> /u/haterofslimes </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxbj3s/recommendations_for_bulk_sd_card_purchase/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxbj3s/recommendations_for_bulk_sd_card_purchase/\">[comments]</a></span>",
        "id": 3394300,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxbj3s/recommendations_for_bulk_sd_card_purchase",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Recommendations for bulk SD card purchase?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/0SwifTBuddY0",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T17:28:03.352491+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T16:28:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello! I was wondering what are the best solutions for virus scanning especially if I dont have to get on the web to use it. I am thinking about how I never really scan my files and there is an increasing amount of bad actors out and about and i would hate to leave myself vulnerable. I do some torrenting as well so a good portion of my backup is personal entertainment apps and videos gotten from who knows where mirrored.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/0SwifTBuddY0\"> /u/0SwifTBuddY0 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxb7mg/how_do_you_guys_audit_yalls_storage_for_viruses/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxb7mg/how_do_you_guys_audit_yalls_storage_for_viruses/\">[comments]</a></span>",
        "id": 3394299,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxb7mg/how_do_you_guys_audit_yalls_storage_for_viruses",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do you guys audit yalls storage for viruses?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PricePerGig",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T16:23:51.106119+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T16:08:57+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PricePerGig\"> /u/PricePerGig </a> <br/> <span><a href=\"https://pricepergig.com/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mxaohg/ebay_and_amazon_disk_price_comparison_aggregator/\">[comments]</a></span>",
        "id": 3393759,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxaohg/ebay_and_amazon_disk_price_comparison_aggregator",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "eBay and Amazon Disk Price Comparison / Aggregator now at PricePerGig.com - eBay really is cheaper for used stuff! (and thank you all for the support)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GreyNeighbor",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T16:23:51.444670+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T15:52:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi!</p> <p>We have A LOT of (disorganized) photos we have been adding to a 2015 2TB SiliconPower ($125 total in 2015) portable hard drive. Feels like we just bought it, but when I looked at my shopping history saw we got it in 2015.</p> <p>When do you start worrying about age of a portable hard drive and what do you do (physical media) aside from cloud services? --MEANING do you tend to buy newer drives and copy what you have on old ones and keep adding from there?</p> <p>Also, any suggestions for a NEW reliable known/decent brand (SIMPLE to use) that is a decent value these days? It seems SiliconPower isn&#39;t make portable hard drives anymore. Need a current tech backup to the backup&#39;s backup ;)</p> <p>Thanks so much, this is so stressful trying to not lose old photos.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GreyNeighbor\"> /u/GreyNeighbor </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoard",
        "id": 3393761,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mxa8tm/portable_hard_drive_for_a_lot_of_photos_what_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Portable Hard Drive for A LOT of Photos / + What to do when a portable hard drive is 10+ years old / Replies for someone with BASIC understanding please",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Dat_Cool_Guy33",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T16:23:51.275543+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T15:28:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Okay so I\u2019ll back up a bit. Over the years working in IT and working on computers for friends and family, I\u2019ve acquired a large number of various drives (mostly SATA, some SAS drives, and some various SSDs [like 2.5inch and NVME\u2019s]) </p> <p>That said, I\u2019d love to use these drives for network storage and combine as many of them together as I can. I have some SAS drives are about 3TB, a couple HDD\u2019s that range from 80gb, 500gb, and 2TB.</p> <p>They also have been in use for different periods of time so im not sure how worn through some drives are so I want to have Raid set up incase some of the drives die on me</p> <p>I\u2019ve heard about JBOD enclosures but idk if there\u2019s a sort of JBOD that combines different connector types, cooling, etc.</p> <p>So my question to you lovely hoarders, what would you do with a collection of various sized drives with different connections?</p> <p>P.s. long time lurker, first time poster :)</p> </div><!-- SC_ON --> &#32; sub",
        "id": 3393760,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mx9lzc/i_have_a_bunch_of_drives_that_im_not_sure_how_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I have a bunch of drives that I\u2019m not sure how to use\u2026that I want to use lol",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Raenoke",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T15:18:21.910314+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T15:14:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just mounted 12 3.5&quot; SATA HDDs in my Fractal Design Define 7XL, and I intend to mount 4 more SSDs, with them linked together via a 16x SAS HBA card. Now my challenge is actually powering these things.</p> <p>Despite Fractal giving us the ability to mount so many drives, there doesn&#39;t seem to be a lot of information about actually powering them besides quite literally building your own Molex to SATA daisy chains with 18g wire, or at least I&#39;m having trouble finding information.</p> <p>I don&#39;t want to buy cheap daisy chains off Amazon and burn down my house. Anyone have any advice?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Raenoke\"> /u/Raenoke </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx98j1/how_to_power_16_sata_drives_in_a_define_7xl/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx98j1/how_to_power_16_sata_drives_in_a_d",
        "id": 3393138,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mx98j1/how_to_power_16_sata_drives_in_a_define_7xl",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to power 16 SATA drives in a Define 7XL?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mtomas7",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T15:18:21.737840+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T15:07:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have 3 drives SSD1, SSD2 and HDD1. When I copy a large (19GB) file from the the outside drive, for some reason hash on SSD1 and HDD1 always the same, but SSD2 most of the times (~5 to 1) fails. I reformatted the drive in NTFS with full long formatting, and the problem remains.</p> <p>Interesting, when I copy smaller files (8GB) to SSD2, hash would validate also on SSD2.</p> <p>Could it be the case that I formatted with 16K block size vs default 4K block? But why the difference in 19GB file size not validating vs 8gb validating?</p> <p>Thank you for you insight!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mtomas7\"> /u/mtomas7 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx91ji/cannot_resolve_failed_hash_validation_conundrum/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx91ji/cannot_resolve_failed_hash_validation_conundrum/\">[comments]</a>",
        "id": 3393137,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mx91ji/cannot_resolve_failed_hash_validation_conundrum",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cannot resolve failed hash validation conundrum",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Hopeful_Ingenuity_18",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T15:18:22.081657+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T14:21:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone. I found a few HP .pbf files from the SD Card that was in my old IPAQ. I have no clue how to go about extracting the data. Specifically the pictures :/</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hopeful_Ingenuity_18\"> /u/Hopeful_Ingenuity_18 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx7v3g/opening_pbf_file_from_hp_ipaq_pocket_pc_2003/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx7v3g/opening_pbf_file_from_hp_ipaq_pocket_pc_2003/\">[comments]</a></span>",
        "id": 3393139,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mx7v3g/opening_pbf_file_from_hp_ipaq_pocket_pc_2003",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Opening PBF file from HP IPAQ Pocket PC 2003",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/First_Musician6260",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T15:18:22.253093+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T14:15:05+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx7p6c/fun_fact_2_tb_7200_rpm_cmr_wd_blues_do_actually/\"> <img src=\"https://a.thumbs.redditmedia.com/yMh1J-CRi2TGLxWvOS6KZhiKkmNelqDN4oync5bslk4.jpg\" alt=\"Fun fact: 2 TB 7,200 RPM CMR WD Blues do actually exist. But they're rare.\" title=\"Fun fact: 2 TB 7,200 RPM CMR WD Blues do actually exist. But they're rare.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/First_Musician6260\"> /u/First_Musician6260 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1mx7p6c\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx7p6c/fun_fact_2_tb_7200_rpm_cmr_wd_blues_do_actually/\">[comments]</a></span> </td></tr></table>",
        "id": 3393140,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mx7p6c/fun_fact_2_tb_7200_rpm_cmr_wd_blues_do_actually",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/yMh1J-CRi2TGLxWvOS6KZhiKkmNelqDN4oync5bslk4.jpg",
        "title": "Fun fact: 2 TB 7,200 RPM CMR WD Blues do actually exist. But they're rare.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BarelyBrony",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T14:11:31.461527+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T13:43:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Recently got scammed by a Chinese seller of alleged 4tb external SSDs before realising they delete most of what I copy onto them.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BarelyBrony\"> /u/BarelyBrony </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx6w8z/looking_for_reliable_external_drives_for_bulk/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx6w8z/looking_for_reliable_external_drives_for_bulk/\">[comments]</a></span>",
        "id": 3392381,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mx6w8z/looking_for_reliable_external_drives_for_bulk",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for reliable external drives for bulk purchase",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Traditional_Leg_4244",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T19:37:59.932696+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T11:58:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone, i am after the updated firmware for the NetApp variant of the ATTO 6500N. The current config is as per the info cli below:</p> <p>Device Status = Good<br/> Device = &quot;FibreBridge 6500N&quot;<br/> Serial Number = FB6500N126229<br/> Device Version = 1.62<br/> Build Number = 071A<br/> Build Date = &quot;Feb 29 2016&quot; 09:37:32<br/> Flash Revision = 2<br/> CLI Revision = 1.75<br/> Base version = 51.01<br/> Version Number = 1.62<br/> User-defined name = &quot;Fibre Channel - SAS Bridge&quot;<br/> World Wide Name = 20 00 00 10 86 64 09 E0<br/> FC1 Node Name = 20 00 00 10 86 64 09 E0<br/> FC1 Port Name = 21 00 00 10 86 64 09 E0<br/> FC1 Data Rate = N/A<br/> FC1 Connection Mode = N/A<br/> FC2 Node Name = 20 00 00 10 86 64 09 E0<br/> FC2 Port Name = 22 00 00 10 86 64 09 E0<br/> FC2 Data Rate = 8Gb<br/> FC2 Connection Mode = ptp<br/> MP1 MAC Address = 00 10 86 64 09 E0<br/> MP1 IP Address = <a href=\"http://192.168.0.112/\">192.168.0.112</a",
        "id": 3395320,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mx4i6a/atto_6500n_the_netapp_variant_and_i_am_looking",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "ATTO 6500N, the NetApp variant and i am looking for an updated firmware",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Buggs_y",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T13:05:35.940638+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T11:35:00+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx40y5/this_resonated_for_me/\"> <img src=\"https://external-preview.redd.it/dWhnczJxcG80a2tmMfVko5hdEp2Y-fnj8yXcJGeaOshfLNH5K9FwTRpi4gnd.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=383e043c97de168761a3fcad7144635dd9c6a198\" alt=\"This resonated for me.\" title=\"This resonated for me.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Buggs_y\"> /u/Buggs_y </a> <br/> <span><a href=\"https://v.redd.it/4411zkzo4kkf1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mx40y5/this_resonated_for_me/\">[comments]</a></span> </td></tr></table>",
        "id": 3391604,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mx40y5/this_resonated_for_me",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/dWhnczJxcG80a2tmMfVko5hdEp2Y-fnj8yXcJGeaOshfLNH5K9FwTRpi4gnd.png?width=640&crop=smart&auto=webp&s=383e043c97de168761a3fcad7144635dd9c6a198",
        "title": "This resonated for me.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Hopeful-Staff3887",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T07:00:47.774667+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T06:50:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to encrypt my 1TB drive, but I am choosing between them. I only read it on Linux, so which is better?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hopeful-Staff3887\"> /u/Hopeful-Staff3887 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwzdre/luks_or_veracrypt/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwzdre/luks_or_veracrypt/\">[comments]</a></span>",
        "id": 3389866,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwzdre/luks_or_veracrypt",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "LUKS or VeraCrypt",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BuonaparteII",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T07:00:47.540199+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T06:36:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>If you&#39;re trying to download recursively from the Wayback Machine you generally don&#39;t get everything you want or you get too much. For me personally, I want a copy of all the sites files as close to a specific time-frame as possible--similar to what I would get if using <code>wget --recursive --no-parent</code> on the site at the time.</p> <p>The main thing that prevents that is the darn-tootin&#39; <em>TIMESTAMP</em> in the URL. If you &quot;manage&quot; that information you can pretty easily run wget on the Wayback Machine.</p> <p>I wrote a python script to do this here:</p> <p><a href=\"https://github.com/chapmanjacobd/computer/blob/main/bin/wayback_dl.py\">https://github.com/chapmanjacobd/computer/blob/main/bin/wayback_dl.py</a></p> <p>It&#39;s a pretty simple script. You could likely write something similar yourself. The main thing that it needs to do is track when wget gives up on a URL because it traverses the parent but this could just b",
        "id": 3389865,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwz5pz/its_not_that_difficult_to_download_recursively",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "It's not that difficult to download recursively from the Wayback Machine",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/hustlercoolie",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T07:00:47.331500+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T06:25:03+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwyyuk/got_my_second_nas_for_offsite_backup/\"> <img src=\"https://preview.redd.it/fnu6bd34likf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4140f63b6570143751aa565d6ba7ca3bbdbf5e57\" alt=\"Got my second NAS for offsite backup\" title=\"Got my second NAS for offsite backup\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Finally chosen this DH4300Plus model and have been waiting for this box to arrive for a while, and it finally came today. Got it set up with a few drives and even an old WD I had lying around for backups. Power usage looks reasonable so far, and it feels quieter than I expected. Docker\u2019s available too, which I\u2019ll probably play around with later. </p> <p>This is actually my second NAS, planning to leave it at my parents\u2019 place and use it as an offsite backup. For now just glad it\u2019s up and running at last.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hus",
        "id": 3389864,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwyyuk/got_my_second_nas_for_offsite_backup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/fnu6bd34likf1.png?width=640&crop=smart&auto=webp&s=4140f63b6570143751aa565d6ba7ca3bbdbf5e57",
        "title": "Got my second NAS for offsite backup",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TheMisterPants",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T03:44:17.186329+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T03:42:56+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheMisterPants\"> /u/TheMisterPants </a> <br/> <span><a href=\"/r/homelab/comments/1mww3f0/taking_suggestions_on_moving_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mww3ql/taking_suggestions_on_moving_data/\">[comments]</a></span>",
        "id": 3389043,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mww3ql/taking_suggestions_on_moving_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Taking suggestions on moving data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Such-Bench-3199",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T03:44:16.939490+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T03:09:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Recently turned 40, and unfortunately my (1000 hours) was spent doing something illegal. There is very rarely a time when I am not archiving/downloading something. During the day I bookmark videos on X and download when I get home, same for YouTube videos, and don&#39;t get me started if it is world events because someone has to record both the apocalypse/daily dumpster fire and when the revolution finally begins.</p> <p>But looking over my hoard, I could justify some things while others are becoming more and more difficult. </p> <p>Example </p> <p>Podcasts, I was initially ecstatic to being with when I nailed how to, but now I struggle with a almost full 10TB drive, culling what I no longer am interested in to make space, offloading (sometimes deleting) or what has finished/been cancelled. I can justify some like Rogan or WTF, one for showing the downfall of civilisation and documenting where it began, or WTF when it eventually finishes this year. </",
        "id": 3389042,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwvfht/what_is_something_you_hoard_that_you_used_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What is something you hoard that you used to justify now you can't?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EL_DJ",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T02:38:55.449398+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T02:36:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Been running this NAS for over 10 years with a couple WD Red 3TB HDDs, mirrored (RAID1), but only have 10% capacity remaining. So, I ordered and just received a couple Toshiba N300 14TB HDWG51EXZSTA 512MB cash HDDs. Although not on Synology&#39;s compatibility list for my NAS, I&#39;m pretty sure they will work. The HDWG21EXZSTA is on the list, its 212MB cache being the difference, but it&#39;s hard to find.</p> <p>I&#39;ve been using 3TB HDDs in enclosures for offsite backup of the NAS. So, now with 14TB capacity I need at least two 14TB backup drives. My Seagate 3TB HDDs I bought at Costco some 10 years ago have worked for that. A couple TOSHIBA 3TB Canvio Basics Portable HDDs USB 3.0 also have worked fine for backup purposes. Any of those fit in my safe deposit box, but the Seagates barely.</p> <p>What backup 14TB storage would work for me adequately in this capacity?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com",
        "id": 3388788,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwura5/in_expanding_synology_ds214play_nas_to_two_14tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "In expanding Synology DS214play NAS to two 14TB RAID1, need a couple 14TB drives for offsite backup purposes",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/tater1337",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T02:38:55.617247+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T02:26:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>every post I see is 4 years old or older.</p> <p>I have a bunch of old PCs and loose hard drives that have stuff on them and I&#39;d like to just make ISO or other mountable options so that I can sort thru them later on my NAS. I also have a stack of audio and data CDs and some movie DVDs that I&#39;d like to rip for backup purposes</p> <p>Clonezilla doesnt make images that can be mounted easily<br/> the Macrium Reflect FREE Edition 8.0.7783 mirror site looks so sketchy that I not only want to run antivirus, I wanna to take a bleach shower</p> <p>4 year old posts for DVD ISOs list multiple ways and methods but don&#39;t give a lot of good answers of which to pick </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tater1337\"> /u/tater1337 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwujol/recent_suggestions_for_backing_up_hard_drives_and/\">[link]</a></span> &#32; <span><a href=\"https://w",
        "id": 3388789,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwujol/recent_suggestions_for_backing_up_hard_drives_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "recent suggestions for backing up Hard drives and CD's and DVDs?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/MullingMulianto",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T02:38:55.810713+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T02:18:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Am looking for SSDs. (last I checked was 2022 or some unearthly number of years ago (it was Black Friday Preparation))</p> <p>I recall at the time the popular picks were Sandisk wd BLACK 850x, Samsung 980 pro, Hynix P41.</p> <p>I have stayed sparsely updated and from what I know. P41s are no longer recommended (in fact they are actively advised against due to <a href=\"https://forum.level1techs.com/t/all-sk-hynix-p41-ssds-suffer-from-write-performance-loss/225118\">common hardware defects</a>)</p> <p>The recommended min. size for SSD has also changed, AFAIK? It used to be &gt;= 2TB, but now I see recommendations for much bigger sizes.</p> <p>What are the SSD &#39;meta&#39; options and size recommendations for 2025? What has changed from the last time I checked?</p> <p>Would prefer something durable for long-term recycling (eg to different machines).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MullingMulianto\"> ",
        "id": 3388790,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwueac/new_ssd_options_in_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "New SSD options in 2025",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ZOODUDE100",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T02:38:55.244949+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T02:00:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It&#39;s been a couple years since I worked on this and need someone to walk me through the process</p> <p><a href=\"https://www.stolaf.edu/singforjoy/listen/2024-01-07\">https://www.stolaf.edu/singforjoy/listen/2024-01-07</a> </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ZOODUDE100\"> /u/ZOODUDE100 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwu09p/can_anyone_help_me_grab_this_audio_file/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwu09p/can_anyone_help_me_grab_this_audio_file/\">[comments]</a></span>",
        "id": 3388787,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwu09p/can_anyone_help_me_grab_this_audio_file",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can anyone help me grab this audio file?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/musthaveleft1hago",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-22T00:24:49.172358+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-22T00:24:13+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/musthaveleft1hago\"> /u/musthaveleft1hago </a> <br/> <span><a href=\"/r/truenas/comments/1mwrx4i/which_version_of_truenas_for_a_set_and_forget/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mwrxw1/which_version_of_truenas_for_a_set_and_forget/\">[comments]</a></span>",
        "id": 3388118,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mwrxw1/which_version_of_truenas_for_a_set_and_forget",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Which version of truenas for a set and forget configuration?",
        "vote": 0
    }
]