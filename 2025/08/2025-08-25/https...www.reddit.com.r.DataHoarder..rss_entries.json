[
    {
        "age": null,
        "album": "",
        "author": "/u/swordfish1211",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T21:43:30.833891+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T21:16:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have 30+ dvds full of family pictures, all of them have been in the wardrobe and untouched since maybe 2013 or so. I did try to upload one of them which was lightly scratched and almost all of the pictures were corrupted. I was wondering if there was a way to make sure that didn&#39;t happen to the rest of the DVDs.</p> <p>I&#39;m not very knowledgeable about any of this so please explain simply if possible.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/swordfish1211\"> /u/swordfish1211 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n02yie/dvd_to_digital/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n02yie/dvd_to_digital/\">[comments]</a></span>",
        "id": 3416541,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n02yie/dvd_to_digital",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "DVD to digital",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/wingzntingz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T21:43:30.529439+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T20:58:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Might be silly question Is it ok if I put WD my book horizontally instead of vertically ? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/wingzntingz\"> /u/wingzntingz </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n02hmu/is_a_it_ok_to_put_wd_my_book_on_its_side/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n02hmu/is_a_it_ok_to_put_wd_my_book_on_its_side/\">[comments]</a></span>",
        "id": 3416540,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n02hmu/is_a_it_ok_to_put_wd_my_book_on_its_side",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is a it ok to put WD My book on its side ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/RedeemableQuality",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T21:43:31.051253+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T20:44:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"http://www.makeupalley.com\">www.makeupalley.com</a> is the website</p> <p>It&#39;s loved by millions of people around the world since 1999 and an incredible source about vintage beauty. It&#39;s shutting down and it will be a huge loss to the beauty world and early internet lovers if all the information were to be forever lost.</p> <p>If you can help, please let us know!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/RedeemableQuality\"> /u/RedeemableQuality </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n02432/visitor_here_and_admirer_of_your_skills_a_beloved/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n02432/visitor_here_and_admirer_of_your_skills_a_beloved/\">[comments]</a></span>",
        "id": 3416542,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n02432/visitor_here_and_admirer_of_your_skills_a_beloved",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Visitor here and admirer of your skills! A beloved website called makeupalley.com is shutting down. Is there anyone who can help archive all the data and glory?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mwomrbash",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T20:39:21.234204+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T20:38:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I am looking for some advice on an external SAS controller for my PowerEdge R640. I just got a PowerVault TL2000 and need a SAS controller to operate it. Does anyone have any recommendations on some inexpensive ones?</p> <p>I have a LTO5 drive in the TL2000.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mwomrbash\"> /u/mwomrbash </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n01yne/dell_r640_which_sas_controller_for_tl2000/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n01yne/dell_r640_which_sas_controller_for_tl2000/\">[comments]</a></span>",
        "id": 3416077,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n01yne/dell_r640_which_sas_controller_for_tl2000",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dell R640 which SAS controller for TL2000?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Maddy186",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T20:39:21.386969+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T20:24:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a webpage which has many videos on it. Video only opens when i click Play. It opens in a popup .</p> <p>I tried looking for any video format while its being streamed but none of these (<code>.m3u8</code>, <code>.mpd</code>, <code>.ts</code>, <code>.mp4</code> ). When video loads a few .jpg come in Network stream but thats it. All small files, none pointing to the actual video.</p> <p>I tried using FetchV, Yt-DLP but they cant get the video . </p> <p>How should i proceed </p> <p>Link </p> <p><a href=\"https://play.ddpanda.org/?ch=2&amp;id=mp33&amp;s=bc8810fc7506553878265fdebb5943503d691dad12de9a80d2aa7c530f56036f\">https://play.ddpanda.org/?ch=2&amp;id=mp33&amp;s=bc8810fc7506553878265fdebb5943503d691dad12de9a80d2aa7c530f56036f</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Maddy186\"> /u/Maddy186 </a> <br/> <span><a href=\"https://play.ddpanda.org/?ch=2&amp;id=mp33&amp;s=bc8810fc7506553878265fdebb5943503d6",
        "id": 3416078,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n01ld9/cant_seem_to_download_multiple_videos_need_help",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cant seem to download multiple videos, need help",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/retrac1324",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T20:39:20.975258+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T20:07:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1n014ef/youtube_secretly_used_ai_to_edit_peoples_videos/\"> <img src=\"https://external-preview.redd.it/zLo5zDemuUulUz7sT0eaadotBOOd3U4UT6Qcjndpnfg.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b1b881b96f08551a0b734ec156a08879213fd096\" alt=\"YouTube secretly used AI to edit people's videos\" title=\"YouTube secretly used AI to edit people's videos\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/retrac1324\"> /u/retrac1324 </a> <br/> <span><a href=\"https://www.bbc.com/future/article/20250822-youtube-is-using-ai-to-edit-videos-without-permission\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n014ef/youtube_secretly_used_ai_to_edit_peoples_videos/\">[comments]</a></span> </td></tr></table>",
        "id": 3416076,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n014ef/youtube_secretly_used_ai_to_edit_peoples_videos",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/zLo5zDemuUulUz7sT0eaadotBOOd3U4UT6Qcjndpnfg.jpeg?width=320&crop=smart&auto=webp&s=b1b881b96f08551a0b734ec156a08879213fd096",
        "title": "YouTube secretly used AI to edit people's videos",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Walterwhite_2503",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T19:32:46.775838+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T18:58:54+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzzbuv/can_some_one_help_me_out/\"> <img src=\"https://preview.redd.it/lpcfybckq7lf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d9e0fc253c3d7c2d807dcedf7f2f035818fe7209\" alt=\"Can some one help me out\" title=\"Can some one help me out\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Walterwhite_2503\"> /u/Walterwhite_2503 </a> <br/> <span><a href=\"https://i.redd.it/lpcfybckq7lf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzzbuv/can_some_one_help_me_out/\">[comments]</a></span> </td></tr></table>",
        "id": 3415683,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzzbuv/can_some_one_help_me_out",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/lpcfybckq7lf1.jpeg?width=640&crop=smart&auto=webp&s=d9e0fc253c3d7c2d807dcedf7f2f035818fe7209",
        "title": "Can some one help me out",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Sanzpa",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T19:32:46.247693+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T18:43:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi!</p> <p>I bought the HGST Ultrastar DC HC520 and came with an adapter but it is not working anymore (faulty contact on the adapter that came with the drive) and I do not know what cable I need to bypass the power disable. <a href=\"https://www.ebay.es/itm/156046813385\">https://www.ebay.es/itm/156046813385</a></p> <p>Can someone help me find it? I read about molex and so on but I do not know... The motherboard is an Asrock A620M (<a href=\"https://www.asrock.com/MB/AMD/A620M%20Pro%20RS/index.la.asp\">https://www.asrock.com/MB/AMD/A620M%20Pro%20RS/index.la.asp</a>)</p> <p>I read I am based in Spain so anything off Amazon ESP or US would help immensely. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sanzpa\"> /u/Sanzpa </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzywsx/noob_powerdisable_adapter_solution_hc520/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/",
        "id": 3415681,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzywsx/noob_powerdisable_adapter_solution_hc520",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[noob] PowerDisable adapter / solution HC520",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/greenerd6",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T19:32:46.400549+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T18:42:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>is there a easy program to bulk compare files? mostly pdfs and ziped stl files ? i got like 10 tbs to go through and ik theres at least like 100 gbs i can shave of in duplicates </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/greenerd6\"> /u/greenerd6 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzywe1/is_there_a_easy_program_to_bulk_compare_files/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzywe1/is_there_a_easy_program_to_bulk_compare_files/\">[comments]</a></span>",
        "id": 3415682,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzywe1/is_there_a_easy_program_to_bulk_compare_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "is there a easy program to bulk compare files? mostly pdfs and ziped stl files",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Acrobatic_Dinner6129",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T18:26:48.724794+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T18:21:06+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzybx3/is_my_drive_cooked/\"> <img src=\"https://a.thumbs.redditmedia.com/Rd_lzsO9OHMnSK8eTacwJ5LJqiz7-6rnNG5Kdh5xnM8.jpg\" alt=\"Is my drive cooked?\" title=\"Is my drive cooked?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi So I just got this new 14tb drive in, and it&#39;s giving me a cyclic redundancy error when I try to initialize it, I can feel it spinning and no weird noises or anything. I tried running it through Victoria, but it does not look right. I still am in the return window, so I&#39;m guessing I just need to return it and order another but wanted to see if there was anything else worth trying before I send it back. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Acrobatic_Dinner6129\"> /u/Acrobatic_Dinner6129 </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1mzybx3\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comme",
        "id": 3415173,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzybx3/is_my_drive_cooked",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/Rd_lzsO9OHMnSK8eTacwJ5LJqiz7-6rnNG5Kdh5xnM8.jpg",
        "title": "Is my drive cooked?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/KrixKalimo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T18:26:48.878047+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T18:17:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It has been very difficult to get information and specs. He runs a small business making animated web series and seems to need at least 20Tb (for lukewarm or cold storage, I don\u2019t think he wants to edit off of it day to day) and I personally think he\u2019ll need room to double that in years to come.</p> <p>I don\u2019t know what\u2019s available on his mobo or whether he has an old PC to set up a NAS. I was thinking if there wasn\u2019t a good simple solution for an internal or external drive, he should just get a 4-bay NAS and start with two 22Tb WD Red Pros (going off of price per Gb atm). But I haven\u2019t done much storage stuff yet and am also not up on the storage market, so we could use some advice. I can probably convince him to do any sort of set up for him but simple solutions are also welcome.</p> <p>Here is a post I wrote for him so that he could post it on forums and Reddit, but I don\u2019t think he ever did:</p> <p>CPU: i7 4770 Mobo: ASUS 287-c RAM: 24 Gb GPU: 306",
        "id": 3415174,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzy8i0/video_producer_friend_seeks_a_20tb_solution",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Video Producer Friend seeks a 20Tb+ Solution",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/covered1028",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T18:26:48.570323+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T17:49:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was gonna set it up after seeing some people here with over 100k+ videos. Got ready to set it up but now I saw that the file names can&#39;t be edited?</p> <p>I remember they were the most recommended. What are you guys using now if not tube archivist?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/covered1028\"> /u/covered1028 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzxgm3/who_still_uses_tube_archivist_after_they_made/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzxgm3/who_still_uses_tube_archivist_after_they_made/\">[comments]</a></span>",
        "id": 3415172,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzxgm3/who_still_uses_tube_archivist_after_they_made",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Who still uses Tube Archivist after they made file names non human readable?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ctrolaltdelete",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T16:17:35.691538+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T16:13:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello. I recently stumbled into this subreddit looking for a solution for my laptop that won&#39;t fully boot up and is stuck on automatic repair loop. I assume it was my attempt at downloading DaVinci resolve 15 (all other versions didn&#39;t work i kept going backwards). It&#39;s giving me very limited prompts and rejects my password for prompts. Idk how to fix that but I assume by getting an external hard drive? it&#39;s an old HP laptop bought refurbished. The problem is I am a complete noob at what i&#39;m reading on here. 1) if anyone knows how to fix the automatic repair loop that does or doesn&#39;t include using and external hard drive please please please help.2) I&#39;ve been trying to read on here about saving and transfering data and i haven&#39;t got a clue where to begin or end. I plan on getting a transcend 1tb. Where I inquired it was between transcend and seagate and it seams transcend is the better one of the two. I have observed th",
        "id": 3414166,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzuugz/explain_like_i_am_5",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Explain like I am 5",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Walterwhite_2503",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T16:17:35.402704+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T15:51:07+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzu81h/can_some_one_help_me_out/\"> <img src=\"https://preview.redd.it/vz93stf4t6lf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=793bb7bde01e6cd8790cc2cd439553e1c88bb4f4\" alt=\"Can some one help me out\" title=\"Can some one help me out\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi I want to download lectures because they are about to expire and i literally don&#39;t know what to do I&#39;m not a coder or techie guy.Some one told me to do inspect thing but I don&#39;t know this code appeared I searched for mp4 file but couldn&#39;t find earlier I used to download from 1dm on mobile but now it doesn&#39;t work and my friend tried but it download only 10mb video.I don&#39;t have much time to record so much.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Walterwhite_2503\"> /u/Walterwhite_2503 </a> <br/> <span><a href=\"https://i.redd.it/vz93stf4t6lf1.jpeg\">[link]</a>",
        "id": 3414165,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzu81h/can_some_one_help_me_out",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/vz93stf4t6lf1.jpeg?width=640&crop=smart&auto=webp&s=793bb7bde01e6cd8790cc2cd439553e1c88bb4f4",
        "title": "Can some one help me out",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/WhatNot303",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T15:12:43.345588+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T14:53:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The College Board sneakily took down all but latest few backups of the Free Response Questions of their AP Calculus exams. Prior this (for decades) they had a huge range of past exams, along with solutions and grading rubrics hosted for students and teachers to use: <a href=\"https://apcentral.collegeboard.org/courses/ap-calculus-ab/exam/past-exam-questions\">https://apcentral.collegeboard.org/courses/ap-calculus-ab/exam/past-exam-questions</a></p> <p>Does anyone have access to a backup of this data? As a calculus teacher, I&#39;m very frustrated at their lack of transparency and blatant obfuscation.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/WhatNot303\"> /u/WhatNot303 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzsn7z/request_for_ap_calculus_frqs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzsn7z/request_for_ap_calculus_frqs/\">[comments]",
        "id": 3413564,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzsn7z/request_for_ap_calculus_frqs",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Request for AP Calculus FRQs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cercyyyy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T14:06:56.683792+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T13:15:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzq6qe/hdd_suddenly_went_from_100_to_1_health/\"> <img src=\"https://a.thumbs.redditmedia.com/po-XYbO-syTnbObemnqMoxYJxUug2is4GK0yC-SSPp4.jpg\" alt=\"Hdd suddenly went from 100% to 1% health\" title=\"Hdd suddenly went from 100% to 1% health\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>As per title i noticed this when my hdd rack started beeping and upon checking it in hdd sentinel i get the following errors. Should i try chkdsk /f /r, use another software or is it just transfer the data to another hdd and send it to reclying? TIA </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cercyyyy\"> /u/cercyyyy </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1mzq6qe\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzq6qe/hdd_suddenly_went_from_100_to_1_health/\">[comments]</a></span> </td></tr></table>",
        "id": 3413020,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzq6qe/hdd_suddenly_went_from_100_to_1_health",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://a.thumbs.redditmedia.com/po-XYbO-syTnbObemnqMoxYJxUug2is4GK0yC-SSPp4.jpg",
        "title": "Hdd suddenly went from 100% to 1% health",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cercyyyy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T14:06:56.875282+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T13:14:52+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzq6i6/hdd_suddenly_went_from_100_to_1_health/\"> <img src=\"https://b.thumbs.redditmedia.com/uPAsIXX0uu5hXN6T6VfkqAIBzXUJQrq4imu65eEKB4Y.jpg\" alt=\"Hdd suddenly went from 100% to 1% health\" title=\"Hdd suddenly went from 100% to 1% health\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>As persoane title i noticed this when my hdd rack started beeping and upon checking it in hdd sentinel i get the following errors. Should i try chkdsk /f /r, use another software or is it just transfer the data to another hdd and send it to reclying? TIA </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cercyyyy\"> /u/cercyyyy </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1mzq6i6\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzq6i6/hdd_suddenly_went_from_100_to_1_health/\">[comments]</a></span> </td></tr></table>",
        "id": 3413021,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzq6i6/hdd_suddenly_went_from_100_to_1_health",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/uPAsIXX0uu5hXN6T6VfkqAIBzXUJQrq4imu65eEKB4Y.jpg",
        "title": "Hdd suddenly went from 100% to 1% health",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/IntentionChoice7007",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T13:02:32.224507+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T12:48:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>im not the best financially so what are some good cheap HDDs (maybe even SSDs)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/IntentionChoice7007\"> /u/IntentionChoice7007 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzpk48/data_hoarding_on_a_budget/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzpk48/data_hoarding_on_a_budget/\">[comments]</a></span>",
        "id": 3412561,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzpk48/data_hoarding_on_a_budget",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Data hoarding on a budget?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Arrtwo-deetwo",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T11:55:27.245705+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T11:26:25+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mznv39/new_seagate_10tb_should_it_sound_like_this/\"> <img src=\"https://external-preview.redd.it/YjQzbHNtandoNWxmMWB9pKCId5rJRJraycpFB7rz0iqHeyF-2jn9e-BeQ-ds.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=299ea36d696b599c6e04e5fa00bcb97a16db5887\" alt=\"New Seagate 10TB, should it sound like this?\" title=\"New Seagate 10TB, should it sound like this?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Fresh out of the box, this is how it sounds when I&#39;m transferring data onto it. Should I be concerned? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Arrtwo-deetwo\"> /u/Arrtwo-deetwo </a> <br/> <span><a href=\"https://v.redd.it/9kp1ntewh5lf1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mznv39/new_seagate_10tb_should_it_sound_like_this/\">[comments]</a></span> </td></tr></table>",
        "id": 3412092,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mznv39/new_seagate_10tb_should_it_sound_like_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/YjQzbHNtandoNWxmMWB9pKCId5rJRJraycpFB7rz0iqHeyF-2jn9e-BeQ-ds.png?width=640&crop=smart&auto=webp&s=299ea36d696b599c6e04e5fa00bcb97a16db5887",
        "title": "New Seagate 10TB, should it sound like this?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HeroVax",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T11:55:26.892327+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T11:13:13+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mznm7e/is_this_authentic_seagate_ironwolf_pro_hdd/\"> <img src=\"https://b.thumbs.redditmedia.com/CGipaNqf3pDHzi-o1-v7cZorgM2yYTi7RuGlRy68LIk.jpg\" alt=\"Is this authentic Seagate Ironwolf Pro HDD?\" title=\"Is this authentic Seagate Ironwolf Pro HDD?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I bought it for $260 USD for a &quot;brand new&quot; drive. I suspect it&#39;s not because the price is cheap anyway. And as I suspected it&#39;s actually a used HDD with Power On Hours 15,577 (approx. 1.77 years). </p> <p>I checked the HDD itself for any marks or visible scratches but I found none. Even the gold pins was clean. Is this a renewed/recertified HDD or fake Ironwolf Pro based on the images I provided?</p> <p>FARM logs: <a href=\"https://pastebin.com/gxzizBPM\">https://pastebin.com/gxzizBPM</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HeroVax\"> /u/HeroVax </a> <br/",
        "id": 3412091,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mznm7e/is_this_authentic_seagate_ironwolf_pro_hdd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/CGipaNqf3pDHzi-o1-v7cZorgM2yYTi7RuGlRy68LIk.jpg",
        "title": "Is this authentic Seagate Ironwolf Pro HDD?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/skylerdj",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T09:45:35.093566+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T09:13:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone, I&#39;m a bit new to all this server stuff and want to basically go all in on having my own plex server with tons of TBs of storage. Currently, i have a few 1TB drives laying around with movies and tv shows on them so I connected them to my gaming PC to host them on plex and that works pretty fine, except when i want to use things like handbrake or play games, which i can&#39;t do at the same time and i&#39;m already out of storage.</p> <p>I&#39;ve been reading this and other subs and there are a tons of recommendations of just buy a NAS, or buy a small windows box or mac mini and connect it to a DAS. I quite like the mac mini option so far as I use a mac for work and there&#39;s currently a discount for both mac mini M2 and M4 at my local shop. There&#39;s also the option to buy an entire new gaming PC and use my old one as the server but that&#39;s overkill. Some of these are confusing to me. I know Synology is a NAS, but there&#39;s s",
        "id": 3411246,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzlldv/need_help_setting_up_a_server_ndas_for_plex_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help setting up a server + N/DAS for plex and multipurpose use",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ExcitingNight-1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T08:39:29.867172+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T08:27:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am trying to deploy and install Syncovery silently on AWS env.</p> <p>Goal is that everytime an instance is recreated, we can use the silent installation to deploy Syncovery and use it without any manual setup.</p> <p>Did anyone use a similar setup?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ExcitingNight-1\"> /u/ExcitingNight-1 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzkw1t/syncovery_silent_installation/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzkw1t/syncovery_silent_installation/\">[comments]</a></span>",
        "id": 3410937,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzkw1t/syncovery_silent_installation",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Syncovery silent installation",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/abbrechen93",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T07:33:43.552184+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T06:51:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>DriveThruRPG has free RPG books. I discovered this website just today while buying stuff from HumbleBundle.com, so I don&#39;t know if the set of free books is rotating from time to time or if they&#39;re permanently the same.</p> <p><a href=\"https://www.drivethrurpg.com/en/browse?priceMin=0&amp;priceMax=0\">https://www.drivethrurpg.com/en/browse?priceMin=0&amp;priceMax=0</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/abbrechen93\"> /u/abbrechen93 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzjeue/free_rpg_books/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzjeue/free_rpg_books/\">[comments]</a></span>",
        "id": 3410645,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzjeue/free_rpg_books",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Free RPG books",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/1petabytefloppydisk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T07:33:43.286858+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T06:36:03+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzj61s/annas_archive_torrents_the_rdatahoarder_effect/\"> <img src=\"https://preview.redd.it/fjovcyt414lf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b736c45ed7ed50165768b812257efc55aa6115b\" alt=\"Anna's Archive torrents: the r/DataHoarder effect\" title=\"Anna's Archive torrents: the r/DataHoarder effect\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>There were two recent posts on <a href=\"/r/DataHoarder\">r/DataHoarder</a> about seeding Anna&#39;s Archive torrents. One <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqqu9m/why_is_annas_archive_so_poorly_seeded/\">here</a> (posted by me) on August 15 and another <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mspswq/annas_archive_tool_enter_how_many_tbs_you_can/\">here</a> (posted by <a href=\"/u/Spirited-Pause\">u/Spirited-Pause</a>) posted on August 17.</p> <p>I&#39;m guessing this sharp uptick, which doesn&#39;t look like anything else goi",
        "id": 3410644,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzj61s/annas_archive_torrents_the_rdatahoarder_effect",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/fjovcyt414lf1.jpeg?width=640&crop=smart&auto=webp&s=9b736c45ed7ed50165768b812257efc55aa6115b",
        "title": "Anna's Archive torrents: the r/DataHoarder effect",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dictatort0tsfeeb",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T05:25:02.471060+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T04:40:32+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzh96e/anyone_have_nordic_netherens_winter_opus_ep/\"> <img src=\"https://preview.redd.it/t5mgfu4te3lf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b74a5636f18c630de69e550e0da92dda40c0086a\" alt=\"Anyone have Nordic Netheren's 'Winter Opus' EP?\" title=\"Anyone have Nordic Netheren's 'Winter Opus' EP?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dictatort0tsfeeb\"> /u/dictatort0tsfeeb </a> <br/> <span><a href=\"https://i.redd.it/t5mgfu4te3lf1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzh96e/anyone_have_nordic_netherens_winter_opus_ep/\">[comments]</a></span> </td></tr></table>",
        "id": 3410129,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzh96e/anyone_have_nordic_netherens_winter_opus_ep",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/t5mgfu4te3lf1.png?width=640&crop=smart&auto=webp&s=b74a5636f18c630de69e550e0da92dda40c0086a",
        "title": "Anyone have Nordic Netheren's 'Winter Opus' EP?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Kaspbooty",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T02:07:52.610004+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T02:03:43+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I used &#39;wget -m -p -E -k -np <a href=\"https://domain.com\">https://domain.com</a>&#39;</p> <p>but then found:</p> <p>&#39;wget --mirror --convert-links --adjust-extension --wait=2 --random-wait --no-check-certificate -P ./wiki_mirror -e robots=off <a href=\"http://example.com/wiki/\">http://example.com/wiki/</a>&#39;</p> <p>Should I trash my first scrape, and then re-do it with the second command, or keep the first one, or should I do both?</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kaspbooty\"> /u/Kaspbooty </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mze998/best_practice_scraping_a_wiki/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mze998/best_practice_scraping_a_wiki/\">[comments]</a></span>",
        "id": 3409532,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mze998/best_practice_scraping_a_wiki",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best practice scraping a wiki",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/jazilli",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T02:07:53.319117+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T01:29:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Specifically, I want to archive MLB games from mlb.tv</p> <p>I have the paid service, which gives me access to all of the games from the past few seasons. </p> <p>I&#39;ve tried video download extensions, but for whatever reason, they don&#39;t work on that site. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jazilli\"> /u/jazilli </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzdj59/is_there_a_way_to_download_videos_from_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzdj59/is_there_a_way_to_download_videos_from_a/\">[comments]</a></span>",
        "id": 3409533,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzdj59/is_there_a_way_to_download_videos_from_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a way to download videos from a subscription site?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/No-Alternative3524",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T02:07:52.308335+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T01:23:43+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzdf38/got_my_first_large_drive/\"> <img src=\"https://b.thumbs.redditmedia.com/n00VH4Ys5VQnOSZnieC0IvT1WlUozmVr1ax3baByYMg.jpg\" alt=\"Got my first large drive!\" title=\"Got my first large drive!\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/94xa8dqwh2lf1.png?width=602&amp;format=png&amp;auto=webp&amp;s=7b9fcba65c028532346fc259dec627b18c8452a9\">https://preview.redd.it/94xa8dqwh2lf1.png?width=602&amp;format=png&amp;auto=webp&amp;s=7b9fcba65c028532346fc259dec627b18c8452a9</a></p> <p>Got this baby after saving for a bit of time (I&#39;m a student) Started filling it with random data from the internet, datasets and ml models. I have a problem but the problem is my hobby.</p> <p>Its connected to a windows machine but mounted and formatted with ext4 on WSL2. Not ideal but I only have one desktop haha.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/u",
        "id": 3409531,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzdf38/got_my_first_large_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/n00VH4Ys5VQnOSZnieC0IvT1WlUozmVr1ax3baByYMg.jpg",
        "title": "Got my first large drive!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/nefariousgc",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T06:28:50.454648+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T01:18:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking to build a NAS, mainly to store all my phone photos and raw photos from my other cameras.</p> <p>Currently in my cart are:</p> <p>UGreen DXP2800 - supports (2) M.2 NVME + (2) drive bays</p> <p>(2) 1TB Kingston NV3 OR (2) 500GB WD SN700 - Kingston costs less, with a few Reddit users recommending this for value and caching - WD was made for a 24/7 NAS</p> <p>(2) 4TB WD Red Plus</p> <p>I am a complete amateur when it comes to this. I only have a general idea of which RAID array to use, but I still have several questions.</p> <p>1) I keep seeing people mentioning using the M.2 drives for caching. How does this relate to storing on the other drives, and can you explain this to me like I\u2019m 10?</p> <p>2) I have read in several forums that RAID5 is the way to go with 4+ drives. In this case, are the (2) M.2 drives included in the four, or just used for caching? </p> <p>3) If the M.2 drives are mainly for caching, is it worth spending extra for less ca",
        "id": 3410362,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzdbdl/cloud_storage_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cloud Storage NAS?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Deep_Corgi6149",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T02:07:52.114712+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T01:12:40+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzd6qc/we_all_gotta_start_somewhere_well_find_this_guy/\"> <img src=\"https://external-preview.redd.it/nIBz5SjL60HYj7Ywt-X2jQldyK_Rlz_EG9NI5IRnouw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f97d11a2683844e837d9149f60f42d29d736a09\" alt=\"We all gotta start somewhere. We'll find this guy in 2 years with a 2 x 24-bay 4U rackmounts.\" title=\"We all gotta start somewhere. We'll find this guy in 2 years with a 2 x 24-bay 4U rackmounts.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Deep_Corgi6149\"> /u/Deep_Corgi6149 </a> <br/> <span><a href=\"https://v.redd.it/gc3omt1s18kf1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzd6qc/we_all_gotta_start_somewhere_well_find_this_guy/\">[comments]</a></span> </td></tr></table>",
        "id": 3409530,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzd6qc/we_all_gotta_start_somewhere_well_find_this_guy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/nIBz5SjL60HYj7Ywt-X2jQldyK_Rlz_EG9NI5IRnouw.png?width=640&crop=smart&auto=webp&s=2f97d11a2683844e837d9149f60f42d29d736a09",
        "title": "We all gotta start somewhere. We'll find this guy in 2 years with a 2 x 24-bay 4U rackmounts.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lumberfart",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-25T01:02:40.557803+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-25T00:19:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have about 1000 mediafire links that I need to download. Is there any way for me to add the links to a program, and then slowly download them over the next few days with minimal babysitting? Ideally, something that can survive a system reboot without interruption.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lumberfart\"> /u/lumberfart </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzc2nh/is_there_a_qbittorent_equivalent_for_mediafire/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mzc2nh/is_there_a_qbittorent_equivalent_for_mediafire/\">[comments]</a></span>",
        "id": 3409316,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mzc2nh/is_there_a_qbittorent_equivalent_for_mediafire",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a Qbittorent equivalent for Mediafire links?",
        "vote": 0
    }
]