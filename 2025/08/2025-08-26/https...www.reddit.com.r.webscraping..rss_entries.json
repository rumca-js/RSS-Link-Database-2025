[
    {
        "age": null,
        "album": "",
        "author": "/u/strokeright",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T23:28:45.246475+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T23:12:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;d like to scrape these sites for both listed and off-market properties It&#39;s my understanding that they are constantly changing their structure. So, my worry is that constantly changing parsing scripts over time will be cumbersome. Does anyone do this successfully without using web scraping API plans? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/strokeright\"> /u/strokeright </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n10zim/how_to_scrape_zillow_redfin_trulia_etc/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n10zim/how_to_scrape_zillow_redfin_trulia_etc/\">[comments]</a></span>",
        "id": 3426332,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n10zim/how_to_scrape_zillow_redfin_trulia_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape Zillow, Redfin, Trulia, etc...",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Tajertaby",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T19:01:36.058533+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T18:53:37+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1n0ufn3/error_403_on_wwwpcpartpickercom/\"> <img src=\"https://preview.redd.it/7vleu0dluelf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=56857be5834d2e5cd0b0717c5e2a6e20e9dd7760\" alt=\"Error 403 on www.pcpartpicker.com\" title=\"Error 403 on www.pcpartpicker.com\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>How to fix?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tajertaby\"> /u/Tajertaby </a> <br/> <span><a href=\"https://i.redd.it/7vleu0dluelf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n0ufn3/error_403_on_wwwpcpartpickercom/\">[comments]</a></span> </td></tr></table>",
        "id": 3424399,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n0ufn3/error_403_on_wwwpcpartpickercom",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/7vleu0dluelf1.jpeg?width=640&crop=smart&auto=webp&s=56857be5834d2e5cd0b0717c5e2a6e20e9dd7760",
        "title": "Error 403 on www.pcpartpicker.com",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/KingBeven",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T17:58:10.958684+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T17:57:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I come to ask for advice. Can anyone explain to me where or how to scrape WhatsApp Business Account number?</p> <p>Thanks in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/KingBeven\"> /u/KingBeven </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n0syk5/whatsapp_phone_numbers/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n0syk5/whatsapp_phone_numbers/\">[comments]</a></span>",
        "id": 3423911,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n0syk5/whatsapp_phone_numbers",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WhatsApp Phone Numbers",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/trivialstudies",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T17:58:11.122902+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T17:33:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need some help pulling listings from eBay now that they\u2019ve deprecated the Browse API.</p> <p>For years I used the Browse API to pull auctions from a specific seller in a given category that were ending before a certain time. It worked perfectly\u2014until the API was retired.</p> <p>eBay\u2019s docs suggested switching to the Finding API, but its filters are very limited. The best I could do was pull all items in a category and then filter locally. I also experimented with the Feeds API, but it has similar limitations. I&#39;m targeting categories with tens of thousands of listings, so I&#39;d prefer not to download everything (with current bid prices) on a daily basis.</p> <p>As a workaround, I switched my scripts to scraping the HTML pages using URLs like this: <a href=\"https://www.ebay.com/sch/\">https://www.ebay.com/sch/</a>&lt;category&gt;/i.html?_nkw=&lt;seller&gt;&amp;_armrs=1&amp;_ipg=240&amp;_from=&amp;LH_Complete=0&amp;LH_Sold=0&amp;_sop=1&amp;LH_Auc",
        "id": 3423912,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n0sasz/ebay_browse_api_deprecated_whats_the_best_way_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "eBay Browse API deprecated \u2013 what\u2019s the best way to filter listings?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cesio132",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T14:43:02.249751+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T14:36:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I\u2019m new to scraping and honestly not good with coding, so setting up scrapers has been really hard for me. I\u2019ve been trying to scrape hiring.cafe because there\u2019s some data I need, but the problem is that the links I want are hidden behind some dynamic script. When I use simple scrapers (like browser extensions), they only grab the static HTML and completely miss the links. The links only show up when I hover or click on certain buttons, and then they disappear again. I tried using Chrome DevTools to look at the network tab and elements, but I still can\u2019t figure out how to consistently extract the real URLs.</p> <p>I know that tools like Playwright, Puppeteer, or Selenium might be the way to go, but setting them up feels overwhelming for me since I don\u2019t have much coding background.</p> <p>Thanks in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cesio132\"> /u/cesio132 </a> <br/> <span",
        "id": 3422094,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n0nk2u/scraping_hiringcafe",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Hiring.cafe",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AutoModerator",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T13:38:04.280473+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T13:01:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels\u2014whether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>If you&#39;re new to web scraping, make sure to check out the <a href=\"https://webscraping.fyi\">Beginners Guide</a> \ud83c\udf31</p> <p>Commercial products may be mentioned in replies. If you want to promote your own products and services, continue to use the <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">monthly thread</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 3421464,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n0l7ou/weekly_webscrapers_hiring_faqs_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weekly Webscrapers - Hiring, FAQs, etc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BeautifulSimilar6991",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T11:27:00.714431+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T11:14:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys, lately I&#39;m thinking of building a SaaS around my business contacts database and I&#39;m a little confused. Do you think it&#39;s worth a try or just sell it old school? Appreciate your thoughts guys \ud83d\ude4f</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BeautifulSimilar6991\"> /u/BeautifulSimilar6991 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n0iywf/is_it_worth_the_build/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n0iywf/is_it_worth_the_build/\">[comments]</a></span>",
        "id": 3420545,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n0iywf/is_it_worth_the_build",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is it worth the build?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Double_Effective_137",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T08:13:05.490795+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T07:38:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I\u2019m trying to scrape product data from site <a href=\"https://4print.com/\">4print.com</a>. Each product page has multiple selectable parameters (size, quantity, paper type, etc.), and the final price updates dynamically based on the selected combination.</p> <p>What I want to achieve is:</p> <ul> <li>Extract all possible parameter combinations for each product</li> <li>Capture the dynamically updated price for each combination</li> <li>Automate this process so it runs efficiently</li> </ul> <p>How can I approach this kind of scraping? Especially handling dynamic option selection and detecting when the price changes for each combination.</p> <p>Any tips, example approaches, or best practices would be really helpful. Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Double_Effective_137\"> /u/Double_Effective_137 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n0fidy",
        "id": 3419364,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n0fidy/how_to_scrape_dynamic_prices_with_multiple",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape dynamic prices with multiple product options?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Motor-Glad",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T07:07:00.951500+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T06:21:13+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1n0ebzv/for_the_best_of_the_best/\"> <img src=\"https://preview.redd.it/7zgiv72d4blf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7f03164d4c43955d44060deebae437d6615cd07c\" alt=\"For the best of the best\" title=\"For the best of the best\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I think I can scrape almost any site. But 1 is not working headless. </p> <p>Just want to know if it is possible. </p> <p>Anybody managed to visit any soccer page on 365 in headless mode in the last month and get the content loading up? Tried everything. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Motor-Glad\"> /u/Motor-Glad </a> <br/> <span><a href=\"https://i.redd.it/7zgiv72d4blf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n0ebzv/for_the_best_of_the_best/\">[comments]</a></span> </td></tr></table>",
        "id": 3419064,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n0ebzv/for_the_best_of_the_best",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/7zgiv72d4blf1.jpeg?width=640&crop=smart&auto=webp&s=7f03164d4c43955d44060deebae437d6615cd07c",
        "title": "For the best of the best",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/KurtL10",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T03:51:48.076988+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T02:31:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone, I&#39;ve dabbled in scraping over the years and tried to do this on my own, but this particular need is way over my head. I need to call in the big guns (you).</p> <p>I&#39;m working on a new platform/app that is a community of sports card collectors. But I need the data on said sports cards. I have some websites handy that have data on every set of cards released over the years; details on every specific card, variations from the base cards, etc. etc. I&#39;d love to have someone to work with that can scrape this effectively for me.</p> <p>Here&#39;s an example page that needs scraping: <a href=\"https://baseballcardpedia.com/index.php/2024_Bowman\">https://baseballcardpedia.com/index.php/2024_Bowman</a></p> <ul> <li>Parsing out the year and set name</li> <li>The whole base card sets, card #s, player names, if it&#39;s a rookie card or not</li> <li>The insert cards like Prospects, Scouts 100, etc.</li> <li>Parallel cards to the base cards",
        "id": 3418263,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n0a7ho/looking_for_dependable_scraper_for_an_ambitious",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for dependable scraper for an ambitious sports card project",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Tough-Joke1881",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T02:46:53.089289+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T02:27:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m looking to scrape the YT shorts feed by simulating an auto scroller and grabbing metadata. Any advice on proxies to use and preferred methods?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tough-Joke1881\"> /u/Tough-Joke1881 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n0a435/scraping_youtube_shorts/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n0a435/scraping_youtube_shorts/\">[comments]</a></span>",
        "id": 3418018,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n0a435/scraping_youtube_shorts",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping YouTube Shorts",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SynergizeAI",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-26T01:44:09.509230+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-26T01:16:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Low code/first time scraper but I\u2019ve done research to find GQL and SGQLC as efficient libraries for scraping publicly accessible endpoints. But at scale, rate limiting, error handling, and other considerations come into play. </p> <p>Any libraries/dependencies or open source tools you\u2019d recommend? Camoufox on GitHub looks useful for anti-detection</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SynergizeAI\"> /u/SynergizeAI </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n08l1f/scraping_direct_hidden_api_at_scale/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1n08l1f/scraping_direct_hidden_api_at_scale/\">[comments]</a></span>",
        "id": 3417712,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1n08l1f/scraping_direct_hidden_api_at_scale",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping direct Hidden API at scale",
        "vote": 0
    }
]