[
    {
        "age": null,
        "album": "",
        "author": "/u/gnexuser2424",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T23:50:21.119694+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T23:28:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Dell precision t3600 and seagate exos x16 16tb sata drives do you need the pin 3 mod???</p> <p>Do you need to cover pin 3 w kapton tape or take the pin out the power cable for these drives with the dell precision t3600 power supply or do the precision t3600 power supply handle 3.3v on pin 3 differently?? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/gnexuser2424\"> /u/gnexuser2424 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n59ca6/dell_precision_t3600_and_seagate_exos_x16_16tb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n59ca6/dell_precision_t3600_and_seagate_exos_x16_16tb/\">[comments]</a></span>",
        "id": 3465061,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n59ca6/dell_precision_t3600_and_seagate_exos_x16_16tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dell precision t3600 and seagate exos x16 16tb sata drives do you need the pin 3 mod???",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/KahvaltidaBorYedim",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T23:50:20.884177+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T23:05:53+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1n58uj7/im_not_joking_please/\"> <img src=\"https://preview.redd.it/y6h4q5c5sfmf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6ec132a915f9f19aa93c994c9ad10059fd7d95c6\" alt=\"I'm not joking please!\" title=\"I'm not joking please!\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Is this fine long term? i don&#39;t have any space left.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/KahvaltidaBorYedim\"> /u/KahvaltidaBorYedim </a> <br/> <span><a href=\"https://i.redd.it/y6h4q5c5sfmf1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n58uj7/im_not_joking_please/\">[comments]</a></span> </td></tr></table>",
        "id": 3465060,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n58uj7/im_not_joking_please",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/y6h4q5c5sfmf1.jpeg?width=640&crop=smart&auto=webp&s=6ec132a915f9f19aa93c994c9ad10059fd7d95c6",
        "title": "I'm not joking please!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HastyOpossum100",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T23:50:21.274929+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T22:47:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I know I can download Wikipedia, and schedule it too: <a href=\"https://github.com/ternera/auto-wikipedia-download?tab=readme-ov-file#\">https://github.com/ternera/auto-wikipedia-download?tab=readme-ov-file#</a> . But is there a service I can self host to view those files as if they were Wikipedia? By using an ip adddres. I have Proxmox, with Windows and Linux VMs, and TrueNAS?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HastyOpossum100\"> /u/HastyOpossum100 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n58fgv/selfhosted_wikipedia/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n58fgv/selfhosted_wikipedia/\">[comments]</a></span>",
        "id": 3465062,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n58fgv/selfhosted_wikipedia",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Selfhosted Wikipedia",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/IlliterateFeline",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T22:45:25.188004+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T21:56:02+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Wikipedia is currently being threatened by the US administration, and it&#39;s fall would be akin to the burning of Alexandria. For the people who have it hoarded (If you don&#39;t, get it! Its 60gb without images, 160gb with), any plans on helping put it up again for the general public if it does fall?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/IlliterateFeline\"> /u/IlliterateFeline </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n57a7h/is_anyone_here_planning_on_putting_wikipedia_up/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n57a7h/is_anyone_here_planning_on_putting_wikipedia_up/\">[comments]</a></span>",
        "id": 3464750,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n57a7h/is_anyone_here_planning_on_putting_wikipedia_up",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is anyone here planning on putting Wikipedia up again with alternative hosts if the main site gets taken down?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/spinnerspin1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T22:45:25.328571+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T20:54:25+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1n55th2/46_hdd_bay_enclosure_with_a_very_solid_fan/\"> <img src=\"https://b.thumbs.redditmedia.com/GjTJZniy5QOzODKYDdAEIdSNejL2k0iqVm5DWb2LnWE.jpg\" alt=\"4-6 HDD Bay enclosure with a very solid fan?\" title=\"4-6 HDD Bay enclosure with a very solid fan?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hello, im currently using an Orico 5 HDD bay and was hoping to get better temps than these.. this is with an external USB fan blowing behind it , otherwise the Toshiba MG drives would be 50c~. Could you guys recommend me a 4-6 HDD bay with an actual good airflow and temps? im looking to have it hover around low 40&#39;s (40-44~) . Any insight or suggestions would be greatly appreciated!</p> <p><a href=\"https://preview.redd.it/5razx3i55fmf1.png?width=807&amp;format=png&amp;auto=webp&amp;s=98e14377f6da1376cc3027c0b7127f4f22e9556f\">https://preview.redd.it/5razx3i55fmf1.png?width=807&amp;format=png&amp;auto=webp&amp;s=98e",
        "id": 3464751,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n55th2/46_hdd_bay_enclosure_with_a_very_solid_fan",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/GjTJZniy5QOzODKYDdAEIdSNejL2k0iqVm5DWb2LnWE.jpg",
        "title": "4-6 HDD Bay enclosure with a very solid fan?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PublicQ",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T22:45:25.048446+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T19:47:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am currently downloading a library of what looks to be about 20m .epub files. I want to store them on my SSD and full text search and read them on my iPhone. How do I go about doing this?</p> <p>(I don&#39;t know how to code but I can do basic command line work)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PublicQ\"> /u/PublicQ </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n545qf/how_do_i_view_20_million_ebooks/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n545qf/how_do_i_view_20_million_ebooks/\">[comments]</a></span>",
        "id": 3464749,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n545qf/how_do_i_view_20_million_ebooks",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do I view ~20 million ebooks?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TraditionalMight2951",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T19:17:13.601961+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T18:58:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am in the process of building my first nas, so storage requirements aren\u2019t too high, I have purchased 2x Seagate NAS ST4000VN000 4TBs to go alongside the 2TB that is coming with my hp elitedesk 800 g3 sff. Is there anything I should be careful about, I purchased the drives for \u00a335 each from cex here in the uk. Planning on setting up truenas scale and play around with containers. Any advice for setting these up, thinking mirroring the 4TBs and having the 2TB standalone?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TraditionalMight2951\"> /u/TraditionalMight2951 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n52wnz/seagate_nas_st4000vn000/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n52wnz/seagate_nas_st4000vn000/\">[comments]</a></span>",
        "id": 3463785,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n52wnz/seagate_nas_st4000vn000",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seagate NAS ST4000VN000",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/1214",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T19:17:13.362426+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T18:26:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been using iDrive for backups for a couple of years and really like it. I have it set to run at night, so every morning I see a desktop notification showing how many files were uploaded or skipped. What it doesn\u2019t show is how much storage I\u2019ve used and how much I have left. I\u2019m almost certain that when I first signed up, the daily notification included those numbers. I liked having that quick snapshot without logging into the app.</p> <p>Does anyone know if there\u2019s a way to get storage usage back into the daily notification?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/1214\"> /u/1214 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n523zs/did_idrive_remove_storage_info_from_daily_backup/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n523zs/did_idrive_remove_storage_info_from_daily_backup/\">[comments]</a></span>",
        "id": 3463784,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n523zs/did_idrive_remove_storage_info_from_daily_backup",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Did iDrive remove storage info from daily backup notifications?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mwomrbash",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T18:10:37.253822+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T17:56:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I recently bought a bunch of used 6TB IBM SAS drives. They are reporting the wrong size. I read that this may be an issue with the block size. Does anyone have any suggestions on how I can possibly fix this? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mwomrbash\"> /u/mwomrbash </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n51d64/sas_hdd_reporting_wrong_size_on_perc_h730/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n51d64/sas_hdd_reporting_wrong_size_on_perc_h730/\">[comments]</a></span>",
        "id": 3463492,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n51d64/sas_hdd_reporting_wrong_size_on_perc_h730",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "SAS HDD reporting wrong size on perc H730",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/woodandscrews",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T18:10:37.381660+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T17:44:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m digitizing old fotos. Many show multiple people and I want to save their names too. Do I put it in the file name, eg. from left to right: aunt_frida_uncle_bob_grandma.jpg? What if I only know one person? unknown_unknown_grandpa_unknown.jpg?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/woodandscrews\"> /u/woodandscrews </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n5123j/when_archiving_old_photos_that_show_multiple/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n5123j/when_archiving_old_photos_that_show_multiple/\">[comments]</a></span>",
        "id": 3463493,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n5123j/when_archiving_old_photos_that_show_multiple",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "When archiving old photos that show multiple people, what is the best practice for recording who is who in the picture?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Yonutz33",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T17:05:32.311736+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T16:58:19+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4zw25/psa_avoid_buying_hbas_from_serverschmiede/\"> <img src=\"https://b.thumbs.redditmedia.com/RkWg0BMxJTOCQuzFcAapri1hEbntEJXfpguA5j0_YLg.jpg\" alt=\"PSA, avoid buying HBA's from serverschmiede\" title=\"PSA, avoid buying HBA's from serverschmiede\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>After searching for a very long time for a place to buy an LSI 9400 8i/16i in Europe (not as common or cheap as in the US). I hope i posted with the correct flair and that these kind of posts are allowed.</p> <p>I ended up buying one from serverschmiede.com: total price (incl taxes, shipping and bracket) 130\u20ac. Didn&#39;t get it from ebay because it was about 20\u20ac more expensive.</p> <p>At this price i hoped it was an original, found lots of positive reviews (on ebay they have 100% somehow) on them so i thought i chose correcty. When it arrived i noticed some things off:</p> <p>-no Broadcom/Avago/LSI written on the card (m",
        "id": 3463133,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4zw25/psa_avoid_buying_hbas_from_serverschmiede",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/RkWg0BMxJTOCQuzFcAapri1hEbntEJXfpguA5j0_YLg.jpg",
        "title": "PSA, avoid buying HBA's from serverschmiede",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DiaryofaFairy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T17:05:31.949444+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T16:25:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Ideally I want all the videos of this channel but this is just a random one I chose for example that I cant play.</p> <p>Its important/interesting for my studies.</p> <p><a href=\"https://web.archive.org/web/20140326002223/https://www.youtube.com/watch?v=bYqeeQXdI0s\">https://web.archive.org/web/20140326002223/https://www.youtube.com/watch?v=bYqeeQXdI0s</a> or <a href=\"https://www.youtube.com/watch?v=bYqeeQXdI0s\">https://www.youtube.com/watch?v=bYqeeQXdI0s</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DiaryofaFairy\"> /u/DiaryofaFairy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4z2yb/i_found_archived_the_youtube_channel_and_title_of/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4z2yb/i_found_archived_the_youtube_channel_and_title_of/\">[comments]</a></span>",
        "id": 3463131,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4z2yb/i_found_archived_the_youtube_channel_and_title_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I found archived the youtube channel and title of video but not the video itself is there to play what step next I should take?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Train-Wreck-60",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T17:05:32.074407+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T16:21:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I&#39;ve managed to find the URL that I&#39;m trying to download that I mentioned earlier in a recent post but I&#39;m having some trouble so I&#39;ll definitely need some help with this </p> <p>Link: <a href=\"https://youtu.be/EwcLi-HHm8I\">https://youtu.be/EwcLi-HHm8I</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Train-Wreck-60\"> /u/Train-Wreck-60 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4yyq9/the_video_im_trying_to_download/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4yyq9/the_video_im_trying_to_download/\">[comments]</a></span>",
        "id": 3463132,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4yyq9/the_video_im_trying_to_download",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The Video I'm Trying To Download",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/HumongusFridge",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T14:55:40.604762+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T14:13:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I am thinking of ditching my Dell T330 and getting a 10&quot; mini rack with 2 mini PCs to be quieter and more portable.</p> <p>I have found some 3D printed designs for hot swap bays for my 8x8Tb hdds. Currently they are 7x SAS and 1x SATA all attached to the T330&#39;s backplane and then to a Supermicro AOC-S3008L-L8i HBA with 2x SFF-8463 ports. The 3D model has &quot;bring your own&quot; backplane solution that is technically SATA female-to-male connections to facilitate the hot swap functionality.</p> <p>I found some SFF-8482 to sata adapters but I cannot verify that they will work since it is a fact that SAS drives are not compatible with SATA.</p> <p>My plan is to use those, and then get 2 SFF-8643 breakout cables and power the drives separately with a flex atx psu.</p> <p>Is it possible to do so? Or are SAS breakout cables only compatible with SATA drives? I&#39;ve seen some backplanes that offer SAS connectors for the drives but only exp",
        "id": 3462328,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4vrj2/how_do_sff8482_to_sata_adapters_work",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do SFF-8482 to SATA adapters work?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/wii_enjoyer",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T16:00:36.701782+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T14:03:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i know this is a question said many times, but i seem to never find an easy solution. i have about 35k photos/videos on my camera roll and i want a manual backup to my pc. i have it icloud backedup, but in case of an emergency, i want a physcial backup. </p> <p>ive heard people talk about using a usb cable which is super slow, or exporting to windows photos but thats also super buggy, or google photos but id rather not sync all that storage to cloud again but if i have to ill do it. maybe im wrong or these issues got fixed but idk rn.</p> <p>im seeing a microsoft store app called apple devices, but wanted to see other peoples opinions on this, what is the easiest/non-buggy/no errors/crashing way to backup 250gb from iphone to windows?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/wii_enjoyer\"> /u/wii_enjoyer </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4vjbu/backing_up_entire_iphone",
        "id": 3462688,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4vjbu/backing_up_entire_iphone_camera_roll_to_pc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "backing up entire iphone camera roll to pc?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/bjmarmy0003",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T14:55:41.225606+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T13:54:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Can anyone tell some good ways to store maximum data while spending minimum amount of money ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/bjmarmy0003\"> /u/bjmarmy0003 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4vbma/where_to_store_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4vbma/where_to_store_data/\">[comments]</a></span>",
        "id": 3462330,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4vbma/where_to_store_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Where to store data ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Train-Wreck-60",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T14:55:40.729484+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T13:51:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I remember seeing a video ages ago which I don&#39;t have the URL for of The King&#39;s Academy Show of Oliver Twist and one of the videos I absolutely loved was when they did Pick A Pocket Or Two and for months I&#39;ve been trying to find that particular video but it doesn&#39;t seem to be anywhere </p> <p>Is there any help that you could give me into finding this video as I used to love watching that video which I&#39;m struggling to find and also can&#39;t find the URL for it anywhere so if anyone is willing it help I would be extremely grateful </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Train-Wreck-60\"> /u/Train-Wreck-60 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4v96c/any_way_to_watch_a_private_youtube_video/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4v96c/any_way_to_watch_a_private_youtube_video/\">[comments]</a></span>",
        "id": 3462329,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4v96c/any_way_to_watch_a_private_youtube_video",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any way to watch a private YouTube video",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ok-Interaction-7812",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T13:50:29.556375+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T13:44:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>If hoarding is a digital disease, how do you protect from Stored files - transmitted diseases?</p> <p>And how do I check if there is any malware in my pdfs, epubs, mobis, cbrs, cbzs, mp4s, etc.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok-Interaction-7812\"> /u/Ok-Interaction-7812 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4v35e/did_i_catch_an_std_storagetransmitted_disease/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4v35e/did_i_catch_an_std_storagetransmitted_disease/\">[comments]</a></span>",
        "id": 3461920,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4v35e/did_i_catch_an_std_storagetransmitted_disease",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "did I catch an STD? (Storage-transmitted disease)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/RevolutionaryBath710",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T13:50:29.743656+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T13:08:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys I\u2019ve been reading through old posts and can\u2019t find a good answer. I don\u2019t have a solid place of residence so NAS is out of the picture for me at the moment but I am looking for 4-8tb of storage I can dump old footage into and have limited worries. I\u2019ve been reading that hdd\u2019s are best would the \u201cLaCie 5TB Rugged USB 3.1 Gen 1 Type-C External Portable Hard Drive\u201d be a good choice? I know it\u2019s just sea gate but I haven\u2019t found any which are good. It will just be part of my storage solution and I\u2019ll use some fast ssd\u2019s for editing and short term stuff. Thanks I appreciate all advice </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/RevolutionaryBath710\"> /u/RevolutionaryBath710 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4u9oh/looking_for_a_good_portable_long_term_storage/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4u9oh/looking_for_a_",
        "id": 3461921,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4u9oh/looking_for_a_good_portable_long_term_storage",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a good portable long term storage option",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lixxus_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T13:50:29.391221+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T12:51:20+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lixxus_\"> /u/lixxus_ </a> <br/> <span><a href=\"https://www.reddit.com/gallery/1n4aeng\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4tw0l/3d_print_rtl9220dp_nvme_enclosure_had_zero/\">[comments]</a></span>",
        "id": 3461919,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4tw0l/3d_print_rtl9220dp_nvme_enclosure_had_zero",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "{3d Print} RTL9220DP NVMe enclosure had zero ventilation, so I 3D printed a fix for my Proxmox/Xpenology RAID setup",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NuclearPower",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T12:45:27.439883+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T12:01:59+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4sw64/huawei_shows_off_their_24576_tb_ai_ssd/\"> <img src=\"https://external-preview.redd.it/xTIpX-NERDUfxRi96o4Xedkgt6zNP8pXjtTWuln1J-k.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8bcbb1a224993d1607825563d8f2958da01fd896\" alt=\"Huawei shows off their 245.76 TB &quot;AI SSD&quot;\" title=\"Huawei shows off their 245.76 TB &quot;AI SSD&quot;\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NuclearPower\"> /u/NuclearPower </a> <br/> <span><a href=\"https://www.youtube.com/watch?v=DbzWqL9_GH4\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4sw64/huawei_shows_off_their_24576_tb_ai_ssd/\">[comments]</a></span> </td></tr></table>",
        "id": 3460686,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4sw64/huawei_shows_off_their_24576_tb_ai_ssd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/xTIpX-NERDUfxRi96o4Xedkgt6zNP8pXjtTWuln1J-k.jpeg?width=320&crop=smart&auto=webp&s=8bcbb1a224993d1607825563d8f2958da01fd896",
        "title": "Huawei shows off their 245.76 TB \"AI SSD\"",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/18th_Nitrox",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T13:50:29.869474+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T11:51:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Got myseld a used Synology DS 720+ and would like to run 2x 12TB WD Red Plus drives in it. I got the first drive (WD120EFBX) a couple of months ago and would like to purchase a second drive for a RAID 1 setup. </p> <p>While the WD120EFBX is still available, the WD120EFGX now became the cheaper drive at local dealers. The only difference seems to be the larger cache size (512MB instead of 256MB).</p> <p>Ist it recommendable to mix the drives or should I spend more \u20ac to get the &quot;inferior&quot; WD120EFBX as a second drive, so I run the same model?</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/18th_Nitrox\"> /u/18th_Nitrox </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4sp7m/mixing_wd_red_plus_wd120efbx_and_wd120efgx/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4sp7m/mixing_wd_red_plus_wd120efbx_and_wd120efgx/\">[comments]</a><",
        "id": 3461922,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4sp7m/mixing_wd_red_plus_wd120efbx_and_wd120efgx",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Mixing WD Red Plus WD120EFBX and WD120EFGX?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/waitingforcracks",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T12:45:27.726632+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T09:24:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>There is a channel/page/user on VK that uploads some videos. Given that it&#39;s VK, there is a high chance that it gets blocked or deleted or removed for some or the other reason. I want to download and archive all the videos from that channel/page/user. How can I do it?</p> <p>Jdownloader is able to grab each video off if the URL is given but it&#39;s Link Grabber is not able to collect all the link. I need to find a way to get the URL of each video. Please help :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/waitingforcracks\"> /u/waitingforcracks </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4qazb/vk_download_all_videos_from_a_channel/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4qazb/vk_download_all_videos_from_a_channel/\">[comments]</a></span>",
        "id": 3460688,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4qazb/vk_download_all_videos_from_a_channel",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "VK: Download all videos from a channel",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Myfirstreddit124",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T12:45:27.315743+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T09:14:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I copied a 10TB folder with 20k files. The destination has two fewer items and is about 20GB smaller. How can I find which files are missing?</p> <p>The copy completed with no errors.</p> <p>FreeFileSync tells me that the two folders are identical.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Myfirstreddit124\"> /u/Myfirstreddit124 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4q5l2/how_can_i_compare_the_contents_of_two_folders/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4q5l2/how_can_i_compare_the_contents_of_two_folders/\">[comments]</a></span>",
        "id": 3460685,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4q5l2/how_can_i_compare_the_contents_of_two_folders",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can I compare the contents of two folders?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Tall_Emergency3823",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T13:50:30.031206+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T09:13:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Tried to tinker with Buzzheavier requests and found ...</p> <pre><code>import re, os, requests, hashlib from urllib.parse import urlparse UA = {&quot;User-Agent&quot;: &quot;Mozilla/5.0&quot;} def get_file_info(buzz_url): # Fetch page to extract filename r = requests.get(buzz_url, headers=UA) r.raise_for_status() name = re.search(r&#39;&lt;span class=&quot;text-2xl&quot;&gt;([^&lt;]+)&lt;/span&gt;&#39;, r.text) filename = name.group(1) if name else os.path.basename(urlparse(buzz_url).path) # Get flashbang URL dl_url = buzz_url.rstrip(&quot;/&quot;) + &quot;/download&quot; h = {&quot;HX-Request&quot;: &quot;true&quot;, &quot;Referer&quot;: buzz_url, **UA} r2 = requests.get(dl_url, headers=h) r2.raise_for_status() link = r2.headers.get(&quot;hx-redirect&quot;) return filename, link def download_and_sha256(url, filename): sha256 = hashlib.sha256() with requests.get(url, headers=UA, stream=True) as r: r.raise_for_status() with open(filename, &quot;wb&quot",
        "id": 3461923,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4q54e/buzzheavier_bypass",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Buzzheavier Bypass",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/andru5wi55",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T12:45:28.011553+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T07:57:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m interested in downloading all the articles on this website because it contains a compilation of several external links that are very valuable. However, the site is no longer maintained, and I don&#39;t know when it will suddenly disappear. </p> <p>The site is The Plain Text Project, and it&#39;s mainly a text-based site. <a href=\"https://plaintextproject.online/articles.html\">https://plaintextproject.online/articles.html</a> </p> <p>How could I download all the article pages in macOS without having to download them one by one manually?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/andru5wi55\"> /u/andru5wi55 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4oyd0/how_could_i_efficiently_download_this_website/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4oyd0/how_could_i_efficiently_download_this_website/\">[comments]</a></span>",
        "id": 3460690,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4oyd0/how_could_i_efficiently_download_this_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How could I efficiently download this website?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Assaro_Delamar",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T12:45:27.601604+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T07:12:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am looking for a vendor that sells large (8TB or more) refurbished SSDs for a low price and ships to Germany. I don&#39;t really care if it is Sata, M.2 or sth else.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Assaro_Delamar\"> /u/Assaro_Delamar </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4o9w5/looking_for_a_large_refurbished_ssd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4o9w5/looking_for_a_large_refurbished_ssd/\">[comments]</a></span>",
        "id": 3460687,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4o9w5/looking_for_a_large_refurbished_ssd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a large refurbished SSD",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ArgonWilde",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T12:45:28.209860+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T04:55:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>As per the title, I run hyper-v, and have been struggling to find a reliable means of running periodic backups. </p> <p>In my professional life, I&#39;ve used Veeam, but that&#39;s clearly not viable at home due to licensing etc. </p> <p>What should I do? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ArgonWilde\"> /u/ArgonWilde </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4m0wr/how_would_you_handle_backups_with_hyperv/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4m0wr/how_would_you_handle_backups_with_hyperv/\">[comments]</a></span>",
        "id": 3460691,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4m0wr/how_would_you_handle_backups_with_hyperv",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How would you handle backups with hyper-v?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/wickedplayer494",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T12:45:28.879951+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T03:01:58+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4jz37/wd_ultrastar_vs_red_pro_18tb_which_should_you_buy/\"> <img src=\"https://external-preview.redd.it/nigIsmtosI0GETczV42_6rpmuyFEQXDHhPiTtsJ2akQ.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4313af8b17f43f197fce06c1917002ed918cd05c\" alt=\"WD Ultrastar vs Red Pro 18TB - Which should you buy?\" title=\"WD Ultrastar vs Red Pro 18TB - Which should you buy?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/wickedplayer494\"> /u/wickedplayer494 </a> <br/> <span><a href=\"https://www.youtube.com/watch?v=EatJHRP6LmI\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4jz37/wd_ultrastar_vs_red_pro_18tb_which_should_you_buy/\">[comments]</a></span> </td></tr></table>",
        "id": 3460694,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4jz37/wd_ultrastar_vs_red_pro_18tb_which_should_you_buy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/nigIsmtosI0GETczV42_6rpmuyFEQXDHhPiTtsJ2akQ.jpeg?width=320&crop=smart&auto=webp&s=4313af8b17f43f197fce06c1917002ed918cd05c",
        "title": "WD Ultrastar vs Red Pro 18TB - Which should you buy?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/IMOguy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T12:45:27.850446+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T01:24:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently recorded an mkv file and when I removed the parts of the video I didn&#39;t want using MKVToolnix, the file became smaller. It should be smaller, because the output is a smaller file, but in total I only removed about 10-15 seconds of video and the file went from the original size of around 34GB to 20.3GB. Before anyone asks I did turn off compression under preferences. There are also stutters in the video that are not horrible in the source file, but are even worse overall in the output file. Is there some compression setting I&#39;m missing?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/IMOguy\"> /u/IMOguy </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4i3b6/why_is_mkvtoolnix_decreasing_file_size/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4i3b6/why_is_mkvtoolnix_decreasing_file_size/\">[comments]</a></span>",
        "id": 3460689,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4i3b6/why_is_mkvtoolnix_decreasing_file_size",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Why is MKVToolnix decreasing file size substantially?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Gierrah",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T12:45:28.444846+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T00:58:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve recently upgrading my storage capabilities, and hit a milestone of over 100tb of Raw Storage. I&#39;ve acquired 4x 24tb hard drives from a best buy $249 sale (ST24000DM001). I ordered the cheap Cenmate 4 bay enclosure off amazon, though I&#39;m sure it won&#39;t be fast, It was cheapest and looked best for my desk.<br/> I&#39;ve also got an old M93p tiny, which I plan on using for control. And a USB Bluray reader for dumping games and my Bluray collection.</p> <p>The advice I&#39;m looking for is mainly software related. I&#39;ve been getting used to arch, debating whether I use that or windows for this thing. I&#39;m thinking I&#39;ll run the drives mirrored for 48tb total. I&#39;ll also be using it for more than just videos. I&#39;ve got a lot of games I want to store the installers for, I plan on seeding the Smithsonian image collections. Not entirely certain what softwares to use to access these files from other devices, as before I&#39;v",
        "id": 3460692,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4hkbq/advice_on_softwareorganization_for_a_budget_home",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Advice on software/organization for a budget home NAS/DAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AJBOJACK",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-31T12:45:28.569890+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-31T00:51:28+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AJBOJACK\"> /u/AJBOJACK </a> <br/> <span><a href=\"/r/homelab/comments/1n4hex5/help_with_server_rails_on_case_r4424_24bay_4u_case/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1n4hffi/help_with_server_rails_on_case_r4424_24bay_4u_case/\">[comments]</a></span>",
        "id": 3460693,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1n4hffi/help_with_server_rails_on_case_r4424_24bay_4u_case",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help with server rails on case R4424 24bay 4u case",
        "vote": 0
    }
]