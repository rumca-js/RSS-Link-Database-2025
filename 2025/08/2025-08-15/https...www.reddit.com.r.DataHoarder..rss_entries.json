[
    {
        "age": null,
        "album": "",
        "author": "/u/LoafLegend",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T23:02:57.132493+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T22:16:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anyone had experience using a TerraMaster 5-bay NAS (Linux mdadm) set to RAID 5, then years later migrated the same drives to a PC runing Linux? </p> <p>Also the same question , but migrating to a newer TerraMaster also using Linux mdadm TOS? </p> <p>I understand the drives must be in the same 1-5 order. I wanted to hear any issues or advice about the upgrade path i suggested above. Thank you </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LoafLegend\"> /u/LoafLegend </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrc8ak/raid_5_encounter_upgrade/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrc8ak/raid_5_encounter_upgrade/\">[comments]</a></span>",
        "id": 3340951,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrc8ak/raid_5_encounter_upgrade",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Raid 5 Encounter Upgrade?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Charcookiecumbs",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T21:58:00.739308+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T21:40:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I tried to use it but can\u2019t understand what I\u2019m supposed to do and didn\u2019t exactly understand ,it gave me an error and downloaded nothing </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Charcookiecumbs\"> /u/Charcookiecumbs </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrbay6/can_someone_give_me_an_step_by_step_explanation/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrbay6/can_someone_give_me_an_step_by_step_explanation/\">[comments]</a></span>",
        "id": 3340599,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrbay6/can_someone_give_me_an_step_by_step_explanation",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can someone give me an step by step explanation on using scrawler to download all my twitter likes?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SwingDingeling",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T21:58:01.054904+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T21:10:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So far SnapTik seems to be the best but maybe there are better ones. And hopefully without the watermark (for videos they dont have a watermark)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SwingDingeling\"> /u/SwingDingeling </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrahjx/what_site_allows_you_to_download_tiktok_picture/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mrahjx/what_site_allows_you_to_download_tiktok_picture/\">[comments]</a></span>",
        "id": 3340600,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mrahjx/what_site_allows_you_to_download_tiktok_picture",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What site allows you to download TikTok picture posts in the best quality?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Southern-Jicama-3073",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T19:48:03.357878+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T19:19:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Just got a thunderbolt 4 external ssd for my windows laptop that comes with tb4 port. The drive doesn\u2019t show up in file explorer but can be ejected. No error message or pop up upon plugin. It\u2019s listed in disk management as Disk # partition # instead of the product name, and the format option is not available. I\u2019ve talked to ssd and laptop support and they are clueless as well. Any help appreciated. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Southern-Jicama-3073\"> /u/Southern-Jicama-3073 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mr7hyb/why_ssd_ejectable_but_not_in_file_explorer/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mr7hyb/why_ssd_ejectable_but_not_in_file_explorer/\">[comments]</a></span>",
        "id": 3339930,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mr7hyb/why_ssd_ejectable_but_not_in_file_explorer",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Why SSD ejectable but not in file explorer",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Deschutes_Overdrive",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T19:48:03.526634+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T19:06:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone!</p> <p>I am planning to run two ownCloud Infinite Scale (OCIS) instances on a N150 + 12GB RAM miniPC (GMKtec G9 Plus Mini PC NAS with 4x NVMe 1TB SSDs).</p> <p>Usage will be light, not many users, and I am not expecting more than two concurrent users at a time.</p> <p>My domains are going to be DDNS because I do not have a static IP from my ISP (it is very expensive) and I am planning to use reverse DNS to redirect traffic between the two OCIS instances.</p> <p>My first thought is using Fedora Server and running everything under Podman containers.</p> <p>But, there is any better option than what I am planning?</p> <p>Thanks in advance for all comments on this.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Deschutes_Overdrive\"> /u/Deschutes_Overdrive </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mr75uv/os_recommendation_for_a_single_minipc_n150_12gb/\">[link]</a></span> ",
        "id": 3339931,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mr75uv/os_recommendation_for_a_single_minipc_n150_12gb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "OS recommendation for a single miniPC (N150 + 12GB RAM) hosting multiple OCIS (light use) server?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/theoldgaming",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T19:48:03.708645+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T19:05:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Alright so apparently there was a change and the <a href=\"https://www.verbatim.com/en/external-optical-drives/products/43888-ultra-hd-4k-blu-ray-writer-usb-c\">Verbatim 43888</a> is sold with a <em>LG BU40N</em> inside and not a Pioneer burner.</p> <p>So my question is:<br/> How much does this change impact the reliability of the burner itsself?<br/> And, to those who use or used it, is the Verbatim 43888 generally worth the price in general? </p> <p>I&#39;ve checked on this subreddit and on <a href=\"/r/makemkv\">r/makemkv</a> but couldn&#39;t find much direct info or the reviews/opinions were mixed (although the general consensus is that Pioneer is faster, reads more disks and is more reliable)<br/> Im asking because i want to burn my old CDs and DVDs over to Blu-Ray disks and i need something that will be able to read them 20 to 30 years from now.</p> <p><strong>Thanks for any and all input!!</strong></p> </div><!-- SC_ON --> &#32; submitted by &#32; ",
        "id": 3339932,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mr74ht/is_the_verbatim_43888_a_reliable_bluray_burner",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is the Verbatim 43888 a Reliable Blu-Ray burner?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/mlcarson",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T18:42:57.324110+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T18:23:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This might be better asked in the Linux forum but I&#39;m giving it a shot here.</p> <p>I&#39;ve got a 68TB JBOD LVM volume for backups. It&#39;s composed of 2 10TB drives and 6 8TB drives. The physical drives are configured as LVM2. The logical volume is vol_backups and the volume group is BackupVol. The logical volume is formatted as EXT4.</p> <p>It&#39;s mounted as:</p> <p>/dev/BackupVol/vol_backups /storage/media ext4 defaults, 0 1 </p> <p>The issue is that KDE Partition Manager is seeing this as an unknown partition type. </p> <p>Parted -l shows the 8TB physical disks as having a ZFS file system and partition table as loop. The 10TB physical disks show as having unknown partition table and no file system. It shows the LV as a 68TB EXT4 volume. An fsck -f check shows no issues on the 68TB LV. </p> <p>The 8TB drives were originally part of a ZFS array. KDE Partition Manager shows all of the partitions as LVM2 and no ZFS present. ZFS is not configur",
        "id": 3339494,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mr5zja/lvm_volume_issue",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "LVM volume issue",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GullibleDevice2414",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T18:42:57.497336+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T18:04:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all, anyone know what kind of hard drive is inside a WD Elements 12TB Hard Drive?</p> <p>Or know where I can find out please?</p> <p>I&#39;ve seen the 12tb recertified for a good price and was considering if I could shuck it and use it in a NAS at all</p> <p>Model WDBWLG0120HBK-EESN</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GullibleDevice2414\"> /u/GullibleDevice2414 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mr5gey/wd_elements_12_tb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mr5gey/wd_elements_12_tb/\">[comments]</a></span>",
        "id": 3339495,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mr5gey/wd_elements_12_tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WD Elements 12 TB",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/COREYTROOPER12",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T16:33:01.213155+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T16:31:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>im tryna download mp4s of db, dbz and gt from the internet archive but when i try to download all the mp4s it pops up with this. is there a way to download them?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/COREYTROOPER12\"> /u/COREYTROOPER12 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mr2v3d/is_there_a_way_to_download_the_files_without_this/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mr2v3d/is_there_a_way_to_download_the_files_without_this/\">[comments]</a></span>",
        "id": 3338501,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mr2v3d/is_there_a_way_to_download_the_files_without_this",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "is there a way to download the files without this popping up?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Modevs",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T15:28:01.040951+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T15:13:40+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mr0pfk/all_talk_huh/\"> <img src=\"https://preview.redd.it/khnf0b8997jf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=07b2096861acbbd391731b96f9ac97a34a2c1ce3\" alt=\"All talk huh?\" title=\"All talk huh?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Modevs\"> /u/Modevs </a> <br/> <span><a href=\"https://i.redd.it/khnf0b8997jf1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mr0pfk/all_talk_huh/\">[comments]</a></span> </td></tr></table>",
        "id": 3337975,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mr0pfk/all_talk_huh",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/khnf0b8997jf1.png?width=320&crop=smart&auto=webp&s=07b2096861acbbd391731b96f9ac97a34a2c1ce3",
        "title": "All talk huh?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/PricePerGig",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T15:28:01.424743+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T15:09:48+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PricePerGig\"> /u/PricePerGig </a> <br/> <span><a href=\"https://pricepergig.com/ebay-uk\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mr0lgr/i_updated_pricepergigcom_to_add_ebaycouk_ukgb_as/\">[comments]</a></span>",
        "id": 3337976,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mr0lgr/i_updated_pricepergigcom_to_add_ebaycouk_ukgb_as",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I Updated PricePerGig.com to add \ud83c\uddec\ud83c\udde7 eBay.co.uk UK/GB \ud83c\uddec\ud83c\udde7 as requested in this sub - and removed 100's of 'faulty' listings",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/gemini-cricket",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T16:33:00.878734+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T13:59:16+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqynjq/would_you_return_a_new_exos_x24_if_it_came_with/\"> <img src=\"https://preview.redd.it/9z9m4ceuv6jf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c737d9a7e8d1cc78123f14090372c6b4f2afed7\" alt=\"Would you return a new Exos X24 if it came with these dents?\" title=\"Would you return a new Exos X24 if it came with these dents?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Bought new Exos X24 24TB drive from Newegg and it arrived with these dents. Should I return it, or are they minor enough not to worry about (assuming it tests ok)?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/gemini-cricket\"> /u/gemini-cricket </a> <br/> <span><a href=\"https://i.redd.it/9z9m4ceuv6jf1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqynjq/would_you_return_a_new_exos_x24_if_it_came_with/\">[comments]</a></span> </td></tr></table>",
        "id": 3338499,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqynjq/would_you_return_a_new_exos_x24_if_it_came_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/9z9m4ceuv6jf1.png?width=640&crop=smart&auto=webp&s=2c737d9a7e8d1cc78123f14090372c6b4f2afed7",
        "title": "Would you return a new Exos X24 if it came with these dents?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NotBashB",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T14:24:47.773411+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T13:51:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Where to buy music legitimately and actually own the file? My Apple Music subscription ran out so wanted to host my own music on plex amp but before getting them from lest then legitimate sources I wanted to support artist I listen to frequently. </p> <p>Specifically Drake and rap music in general. </p> <p>Thanks for the help</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NotBashB\"> /u/NotBashB </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqygpi/how_to_buy_music_legitimately_and_keep_the_files/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqygpi/how_to_buy_music_legitimately_and_keep_the_files/\">[comments]</a></span>",
        "id": 3337458,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqygpi/how_to_buy_music_legitimately_and_keep_the_files",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to buy music legitimately and keep the files without DRM",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Grouchy-Emotion3485",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T16:33:01.418503+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T13:47:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a 20 TB Lacie 2 Big RAID that is failing and I need to make an image of it. Should I go with the 20TB/24TB/26TB Seagate Expansion, 22TB WD elements desktop, or get a barracuda internal HDD and docking station? What is going to be my most reliable option. Only looking to spend $350 so if I do internal hdd it would be $300 for the drive and another $50 for an enclosure. Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Grouchy-Emotion3485\"> /u/Grouchy-Emotion3485 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqycsh/need_help_choosing_a_20_26_tb_drive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqycsh/need_help_choosing_a_20_26_tb_drive/\">[comments]</a></span>",
        "id": 3338502,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqycsh/need_help_choosing_a_20_26_tb_drive",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help choosing a 20 - 26 TB Drive",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Few_Razzmatazz5493",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T14:24:48.051253+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T13:43:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So if you HAD TO buy either a BRAND NEW Toshiba N300 8TB NAS 3.5-Inch Internal Hard Drive or a BRAND NEW Seagate IronWolf Pro, 8 TB, Enterprise NAS Internal HDD; which would it be ? It&#39;s for my 4-bay NAS.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Few_Razzmatazz5493\"> /u/Few_Razzmatazz5493 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqy8l9/which_model_between_the_2/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqy8l9/which_model_between_the_2/\">[comments]</a></span>",
        "id": 3337459,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqy8l9/which_model_between_the_2",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Which Model Between The 2 ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/J-Cake",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T13:19:47.711496+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T12:59:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello. I have come to the somewhat depressing conclusion that there aren&#39;t really any off-the-shelf solutions that fit all of my needs. I&#39;m hoping for some advice on what my options are.</p> <h2>Requirements</h2> <ul> <li>Carry 8xSATA III 3.5&quot; HDDs</li> <li>Interface via PCIe3x4 OCuLink SFF port (the bandwidth is fine, I did the math)</li> <li>External power supply</li> <li>If you somehow know of any entirely passive solutions (no firmware or controllers in the middle etc) then PCIe signal integrity becomes a concern. The m.2 =&gt; OCuLink adapter I&#39;ve purchased is already 10cm long, so the cable-length allowance is tight</li> </ul> <p>I&#39;m seriously considering custom fabrication because I would also like to achieve a 10&quot; rack-mountable form factor, but my personal skills are not there yet to be able to tackle a project like this.</p> <p>Oh and if any of this is somehow achievable, it&#39;d be nice if I could keep both of my ",
        "id": 3336932,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqx4sw/what_options_do_i_have_for_an_8xsata_iii_over_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What options do I have for an 8xSATA III over a single PCIe 3x4 OCuLink port?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Alphabethur",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T10:03:00.686232+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T09:48:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi!</p> <p>Bought 2 4tb hdd here: <a href=\"https://www.ebay.de/itm/403661605662\">https://www.ebay.de/itm/403661605662</a></p> <p>Plugged them in, turned on, works, but smart ctl says they have 60k hours on its back each. On ebaythese drives are lsited as new. Did I get scammed?</p> <p>This is very weird. It&#39;s a large shop with lots of positive reviews.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Alphabethur\"> /u/Alphabethur </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqt4ni/new_drive_has_60k_hours_on_its_back/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqt4ni/new_drive_has_60k_hours_on_its_back/\">[comments]</a></span>",
        "id": 3335698,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqt4ni/new_drive_has_60k_hours_on_its_back",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "\"New\" drive has 60k hours on its back",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Signal_Ad_9000",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T08:58:29.531373+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T08:23:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, </p> <p>I&#39;m setting up my first NAS and wanting to build it as cheaply as possible, ideally with very few new parts. I&#39;ve got an old 1L thinkcenter pc and I need some way to attach 4 drives to it. From what I can see I need an external drive bay to plug into it. I ideally want a bare board I can plug my drives into, I dont want anything with a fancy case or addons. This leads me to the question:</p> <p>Does anyone know of any open source hardware that fullfills the purpose of a drive bay? </p> <p>Or alternatively, am I able to build an equivalent out of just cables? e.g. 4 sata to usb (using uasp) into a usb hub</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Signal_Ad_9000\"> /u/Signal_Ad_9000 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqrnij/diyopen_source_multiple_drive_bay/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqrni",
        "id": 3335354,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqrnij/diyopen_source_multiple_drive_bay",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "DIY/Open Source Multiple Drive Bay",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/1petabytefloppydisk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T07:51:35.608603+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T07:36:48+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqqu9m/why_is_annas_archive_so_poorly_seeded/\"> <img src=\"https://preview.redd.it/31szr5k4w4jf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3990c0edf471ecb4088b5cdba69af5ce9d7807eb\" alt=\"Why is Anna's Archive so poorly seeded?\" title=\"Why is Anna's Archive so poorly seeded?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://en.wikipedia.org/wiki/Anna%27s_Archive\">Anna&#39;s Archive</a>&#39;s full dataset of 52.9 million (from LibGen, Z-Library, and elsewhere) and 98.6 million papers (from Sci-Hub) along with all the metadata is available as a set of torrents. The breakdown is as follows:</p> <table><thead> <tr> <th align=\"left\"># of seeders</th> <th align=\"left\">10+ seeders</th> <th align=\"left\">4 to 10 seeders</th> <th align=\"left\">Fewer than 4 seeders</th> </tr> </thead><tbody> <tr> <td align=\"left\">Size seeded</td> <td align=\"left\">5.8 TB / 1.1 PB</td> <td align=\"left\">495 TB / 1.1 PB</",
        "id": 3335082,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqqu9m/why_is_annas_archive_so_poorly_seeded",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/31szr5k4w4jf1.png?width=640&crop=smart&auto=webp&s=3990c0edf471ecb4088b5cdba69af5ce9d7807eb",
        "title": "Why is Anna's Archive so poorly seeded?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Soft-Discount-9335",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T06:46:41.467161+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T06:28:07+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqpn0l/fansly_devtool_download_issue/\"> <img src=\"https://preview.redd.it/i22vb18kn4jf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=895980e8e6d237bdf84f053eb9f9e5c2fe0d6de4\" alt=\"Fansly devtool download issue\" title=\"Fansly devtool download issue\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi, unsure if this is the right sub to be in or if anyone would be able to help. I was able to download a small clip off Fansly by devtooling it with F12. The video downloaded but no audio, I also found the audio underneath it but no video showing. Is there a way to find both the video and audio together to download or any suggestions? Fairly inexperienced and new at all this. A photo also to get a better understanding of what I&#39;m looking at.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Soft-Discount-9335\"> /u/Soft-Discount-9335 </a> <br/> <span><a href=\"https://i.red",
        "id": 3334850,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqpn0l/fansly_devtool_download_issue",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/i22vb18kn4jf1.jpeg?width=640&crop=smart&auto=webp&s=895980e8e6d237bdf84f053eb9f9e5c2fe0d6de4",
        "title": "Fansly devtool download issue",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/wholovesmangos",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T05:43:04.329801+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T04:42:54+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqnqgs/mystery_solved/\"> <img src=\"https://external-preview.redd.it/NzJnbXdtbWc0NGpmMdDliQJEHdw7n9FpXc_MRO2_Ux2vQ5D4XeEX4vDlGsC4.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=905e079e0dd11e2ba699c785572d2bc8b2182487\" alt=\"mystery solved.\" title=\"mystery solved.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Cathartic, to say the least. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/wholovesmangos\"> /u/wholovesmangos </a> <br/> <span><a href=\"https://v.redd.it/y0qpymmg44jf1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqnqgs/mystery_solved/\">[comments]</a></span> </td></tr></table>",
        "id": 3334635,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqnqgs/mystery_solved",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/NzJnbXdtbWc0NGpmMdDliQJEHdw7n9FpXc_MRO2_Ux2vQ5D4XeEX4vDlGsC4.png?width=640&crop=smart&auto=webp&s=905e079e0dd11e2ba699c785572d2bc8b2182487",
        "title": "mystery solved.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/kelemvor33",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T05:43:03.547567+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T04:23:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>I put a 4TB drive in my laptop for storing documents and pictures. I&#39;m only using 1.5TB so far. I also picked up two 4TB external hard drives for backups. I want to run some sort of backup program that can do a full backup to start and then differential backups after that. I don&#39;t really need to back up the entire drive. I just need to be able to backup the documents, pictures, etc folder. If it does backup the entire drive, I guess that&#39;s fine. Just not needed.</p> <p>I tried searching via Google and looking on Youtube, but most of the info I found was years old so I don&#39;t know how accurate they are. I also looked in the WIki but those all looked like Linux programs or things based on scripts. I&#39;m looking for an actual program, made for Windows, that can do the backups.</p> <p>I&#39;d probably take one every few days since the files don&#39;t change all that often. Then every month I&#39;d swap between the two external ",
        "id": 3334633,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqncv8/is_there_a_good_and_free_backup_program_made_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a good and Free backup program, made for Windows, that does differential/incremental backups to a USB drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/r_Madlad",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T05:43:03.768956+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T03:01:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>For context, I am trying to archive some pages from Google Sites, but it looks like google embeds a lot of scripts and styles deep into their HTML files, that&#39;s very difficult to remove without damaging the actual content.</p> <p>I&#39;ve managed to just delete some of the scripts and styles using BeautifulSoup, but I couldn&#39;t remove the rest without deleting content. This is where I passed the partially-cleaned HTML file to a Large Language Model to handle the rest, but this burned through API credits like crazy every time it was run.</p> <p>I was hoping if anyone here has any suggestions on a better way to parse the GSites HTML, anything helps :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/r_Madlad\"> /u/r_Madlad </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqlp6l/how_can_i_download_clean_html_from_google_sites/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.co",
        "id": 3334634,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqlp6l/how_can_i_download_clean_html_from_google_sites",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can I download clean HTML from Google Sites?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DocsMax",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T01:21:22.233715+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T01:09:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking for something hotswappable - ever heard of them?</p> <p><a href=\"https://www.bhphotovideo.com/c/product/1688681-REG/rocstor_g37125_01_rocpro_d91_4tb_ssd.html\">https://www.bhphotovideo.com/c/product/1688681-REG/rocstor_g37125_01_rocpro_d91_4tb_ssd.html</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DocsMax\"> /u/DocsMax </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqj96f/rocstor_rocpro/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1mqj96f/rocstor_rocpro/\">[comments]</a></span>",
        "id": 3333770,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqj96f/rocstor_rocpro",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Rocstor Rocpro?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/EdgyFilipino42069",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-15T01:21:22.402885+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-15T00:42:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, I&#39;m thinking of getting a surveillance hard drive (either seagate skyhawk or WD purple) as one of my 3-2-1 backup drives because they&#39;re quite a bit cheaper than NAS or server drives and are CMR unlike desktop hard drives of the same size. I&#39;ve seen people say that surveillance hard drives might be bad for typical data hoarder use though because supposedly they have less error correction in their firmware because thats not so critical in surveillance applications (a few frames lost doesn&#39;t matter or whatever). Is this really true? Or is this just heresay? Could anyone point me to any real sources saying or testing whether or not this is true? I wanna make sure if all my other backups fail and I have only one left I can still restore everything from it.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/EdgyFilipino42069\"> /u/EdgyFilipino42069 </a> <br/> <span><a href=\"https://www.reddit.com/r",
        "id": 3333771,
        "language": "en",
        "link": "https://www.reddit.com/r/DataHoarder/comments/1mqin8r/surveillance_hard_drives_for_critical_backups",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Surveillance Hard Drives for critical backups",
        "vote": 0
    }
]