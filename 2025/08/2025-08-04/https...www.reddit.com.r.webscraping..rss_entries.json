[
    {
        "age": null,
        "album": "",
        "author": "/u/OkYesterday2198",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-04T22:49:39.491401+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-04T22:40:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to grab product images from stores. For example, I want to take a product&#39;s url from amazon and grab the image from it. Would it be better to make my own scraper use a pre-made service?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/OkYesterday2198\"> /u/OkYesterday2198 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mhs69n/should_i_build_my_own_web_scraper_or_purchase_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mhs69n/should_i_build_my_own_web_scraper_or_purchase_a/\">[comments]</a></span>",
        "id": 3252286,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mhs69n/should_i_build_my_own_web_scraper_or_purchase_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Should I build my own web scraper or purchase a service?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/NoUnderstanding7620",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-04T16:19:40.983569+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-04T15:50:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is it doable to scrape Airbnb to find my listing SEO ranking to track my progression ? </p> <p>(Airbnb only shows 15 pages results for each search which complicates things)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NoUnderstanding7620\"> /u/NoUnderstanding7620 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mhh5gu/airbnb_listings_seo_monitoring/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mhh5gu/airbnb_listings_seo_monitoring/\">[comments]</a></span>",
        "id": 3249527,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mhh5gu/airbnb_listings_seo_monitoring",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Airbnb listing's SEO monitoring",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/qaf23",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-04T16:19:41.177703+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-04T15:30:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a client that needs to search with google. It&#39;s not actually scraping as the client makes only 1 or 2 requests per minute. Can I get the search result html normally like a normal user on Chrome? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/qaf23\"> /u/qaf23 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mhgm0m/google_search_with_axios/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mhgm0m/google_search_with_axios/\">[comments]</a></span>",
        "id": 3249528,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mhgm0m/google_search_with_axios",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Google search with axios",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Fragrant-Progress668",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-04T08:44:40.141145+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-04T07:56:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey there</p> <p>I wanted to have a little Python script (with Django because i wanted it to be easily accessible from internet, user friendly) that goes into pages, and sums it up. </p> <p>Basically I&#39;m mostly scraping from archive.ph and it seems that it has heavy anti scraping protections. </p> <p>When I do it with rccpi on my own laptop it works well, but I repeatedly have a 429 error when I tried on my server. </p> <p>I tried also with scraping website API, but it doesn&#39;t work well with archive.ph, and proxies are inefficient. </p> <p>How would you tackle this problem ? </p> <p>Let&#39;s be clear, I&#39;m talking about 5-10 articles a day, no more. Thanks !</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Fragrant-Progress668\"> /u/Fragrant-Progress668 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mh7elx/scraping_from_a_mutualized_server/\">[link]</a></span> &#32; <span><a hre",
        "id": 3246234,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mh7elx/scraping_from_a_mutualized_server",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping from a mutualized server ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/AuthorOk8761",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-04T07:38:48.249056+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-04T05:55:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been experimenting with Python (mainly <code>requests</code> + <code>BeautifulSoup</code>, sometimes <code>Selenium</code>) for some personal data collection projects \u2014 things like tracking price changes or collecting structured data from public directories.</p> <p>Recently, I\u2019ve run into sites with more aggressive anti-bot measures:</p> <p>-Cloudflare challenges</p> <p>-Frequent captcha prompts</p> <p>-Rate limiting after just a few requests</p> <p>I\u2019m curious \u2014 how do you usually approach this without crossing any legal or ethical lines? Not looking for anything shady \u2014 just general strategies or \u201cbest practices\u201d that help keep things efficient and respectful to the site.</p> <p>Would love to hear about the tools, libraries, or workflows that have worked for you. Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AuthorOk8761\"> /u/AuthorOk8761 </a> <br/> <span><a href=\"https://www.reddit.co",
        "id": 3245935,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mh5hw9/any_goto_approach_for_scraping_sites_with_heavy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Any go-to approach for scraping sites with heavy anti-bot measures?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/badass_pitcher",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-04T06:34:52.063073+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-04T05:39:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is there any open source tool for bulk sending api requests to notebook lm.</p> <p>Like we want to send some info to notebook lm and then do q&amp;a to that.</p> <p>Thanks in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/badass_pitcher\"> /u/badass_pitcher </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mh58n5/api_for_notebook_lm/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mh58n5/api_for_notebook_lm/\">[comments]</a></span>",
        "id": 3245676,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mh58n5/api_for_notebook_lm",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Api for Notebook lm?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/xkingjosephx",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-04T06:34:51.852124+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-04T05:38:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been looking for a good way to paginate Amazon reviews since it requires a login after a change earlier this year. I&#39;m curious if anyone has figured out something that works well or knows of a tool that works well. So far coming up short trying several different tools. There are some that want me to pass in my session token, but I&#39;d prefer not to do that for a 3rd party, although I realize that may be unavoidable at this point. Any suggestions?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/xkingjosephx\"> /u/xkingjosephx </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mh57qu/how_to_paginate_amazon_reviews/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mh57qu/how_to_paginate_amazon_reviews/\">[comments]</a></span>",
        "id": 3245675,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mh57qu/how_to_paginate_amazon_reviews",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to paginate Amazon reviews?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/xkiiann",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-08-04T02:13:34.185090+00:00",
        "date_dead_since": null,
        "date_published": "2025-08-04T01:45:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I updated my awswaf solver to now also solve type &quot;image&quot; using gemini. In my oppinion this was too easy, because the image recognition is like 30 lines and they added basically no real security to it. I didn&#39;t have to look into the js file, i just took some educated guesses by soley looking at the requests</p> <p><a href=\"https://github.com/xKiian/awswaf\">https://github.com/xKiian/awswaf</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/xkiiann\"> /u/xkiiann </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mh0s51/aws_waf_solver_with_image_detection/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1mh0s51/aws_waf_solver_with_image_detection/\">[comments]</a></span>",
        "id": 3244817,
        "language": "en",
        "link": "https://www.reddit.com/r/webscraping/comments/1mh0s51/aws_waf_solver_with_image_detection",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AWS WAF Solver with Image detection",
        "vote": 0
    }
]