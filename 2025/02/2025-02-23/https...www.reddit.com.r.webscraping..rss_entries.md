# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## ISP vs residential proxies
 - [https://www.reddit.com/r/webscraping/comments/1iwlikz/isp_vs_residential_proxies](https://www.reddit.com/r/webscraping/comments/1iwlikz/isp_vs_residential_proxies)
 - RSS feed: $source
 - date published: 2025-02-23T21:47:30+00:00

<!-- SC_OFF --><div class="md"><p>Hello all,</p> <p>I plan on scraping around 15 sites all with around 20 seconds update times using api requests. Each site requires around 10-50 requests per update. </p> <p>I have been scraping for a week with 2 minute updates for each site with all 200 requests status, no blocks.</p> <p>In terms of proxies what is my best option?</p> <p>Residential proxies charge per gb , which will cost thousands with the amount of data I’m getting per request. </p> <p>Is it better to buy dedicated ISP proxies for a fraction of the price and rotate around 10 of these per website?</p> <p>Considering 2 minute updates are fine with 1 ip I have running now will this be ok to split the dedicated ISP’s for each update cycle? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/barryhall1337"> /u/barryhall1337 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1iwlikz/isp_vs_residential_proxies/">[link]</a></span> &

## Advice on Walmart Data Scraping & VA Vetting for E-Commerce
 - [https://www.reddit.com/r/webscraping/comments/1iwgak1/advice_on_walmart_data_scraping_va_vetting_for](https://www.reddit.com/r/webscraping/comments/1iwgak1/advice_on_walmart_data_scraping_va_vetting_for)
 - RSS feed: $source
 - date published: 2025-02-23T18:07:04+00:00

<!-- SC_OFF --><div class="md"><p>I realize this might be a basic query for this subreddit, but I’m not entirely sure where else to turn. I own an e-commerce company that is transitioning from being primarily Amazon-focused to also targeting Walmart. The challenge is that Walmart’s available data is alarmingly poor compared to Amazon’s, and I’m looking to scrape Walmart data—specifically reviews, stock data, and pricing—on an hourly basis.</p> <p>I’ve considered hiring virtual assistants and attempting this myself, but my technical skills are limited. I’m seeking a consultant (I’m happy to pay) who can help me:</p> <ol> <li>Understand the limits of what is technologically possible.</li> <li>Evaluate what’s feasible from a cost perspective.</li> <li>Identify which virtual assistants possess the necessary skills.</li> </ol> <p>Any tips, advice, or recommendations would be greatly appreciated. Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/u

## Looking for people who successfully done large Google related scrapes
 - [https://www.reddit.com/r/webscraping/comments/1iw803z/looking_for_people_who_successfully_done_large](https://www.reddit.com/r/webscraping/comments/1iw803z/looking_for_people_who_successfully_done_large)
 - RSS feed: $source
 - date published: 2025-02-23T11:19:55+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;d like to put together a team to shared their insight and potentially brain storm. Or who would at least be willing to share their insights so we may learn them and build from each other success.</p> <p>We all feel her lure, but Google is a fickle mistress. Perhaps together... we can tame the beast :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ArtisticCommittee183"> /u/ArtisticCommittee183 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1iw803z/looking_for_people_who_successfully_done_large/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1iw803z/looking_for_people_who_successfully_done_large/">[comments]</a></span>

## Any tool to scrape an app.?
 - [https://www.reddit.com/r/webscraping/comments/1iw3xn5/any_tool_to_scrape_an_app](https://www.reddit.com/r/webscraping/comments/1iw3xn5/any_tool_to_scrape_an_app)
 - RSS feed: $source
 - date published: 2025-02-23T06:33:55+00:00

<!-- SC_OFF --><div class="md"><p>I’m looking for a tool that can help scrape an app. Is this even possible ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Slow_Yesterday_6407"> /u/Slow_Yesterday_6407 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1iw3xn5/any_tool_to_scrape_an_app/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1iw3xn5/any_tool_to_scrape_an_app/">[comments]</a></span>

## Need Advice on a Project - Scraping For Real Estate Data
 - [https://www.reddit.com/r/webscraping/comments/1iw3f92/need_advice_on_a_project_scraping_for_real_estate](https://www.reddit.com/r/webscraping/comments/1iw3f92/need_advice_on_a_project_scraping_for_real_estate)
 - RSS feed: $source
 - date published: 2025-02-23T06:00:07+00:00

<!-- SC_OFF --><div class="md"><p>I am trying to build my first scraper(s) that will extract property data from city and county government websites. I&#39;m targeting notices of default, probate fillings, divorce fillings, notices of foreclosure, and code violations. The trouble I am running into is the complexity and layers of drop-down menus and text inputs that prevent me from getting to the information easily. Has anyone attempted this before, and do they have any advice? Am I talking the correct approach? Any information that will help me achieve this goal would be much appreciated. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/MeechDaStudent"> /u/MeechDaStudent </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1iw3f92/need_advice_on_a_project_scraping_for_real_estate/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1iw3f92/need_advice_on_a_project_scraping_for_real_estate/">[co

