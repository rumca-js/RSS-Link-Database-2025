# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Web Scraping many different websites
 - [https://www.reddit.com/r/webscraping/comments/1j0l00v/web_scraping_many_different_websites](https://www.reddit.com/r/webscraping/comments/1j0l00v/web_scraping_many_different_websites)
 - RSS feed: $source
 - date published: 2025-02-28T23:05:10+00:00

<!-- SC_OFF --><div class="md"><p>Hi I’ve recently undertaken a project that involves scraping data from restaurant websites. I have been able to compile lists of restaurants and get their home pages relatively easily, however I’m at a loss for how to come up with a general solution that works for each small problem.<br/> I’ve been trying to use a combination of scrapy splash and sometimes selenium. After building a few spiders in my project, I’m just realizing 1) the infinite amount of differences that I’ll encounter in navigating and scraping 2) the fact that any slight change will totally break each of these spiders.<br/> I’ve got a kind of crazy idea to incorporate a ML model that is trained on finding menu pages from the home page, and then locating menu item, price description etc. I feel like I could use the first part for designing the scrapy request(s) and the latter for scraping info. I know this would require an almost impossible amount of annotation and labeling of exampl

## Crawl4ai - Horizontal scaling - Tasks in the memory
 - [https://www.reddit.com/r/webscraping/comments/1j0jxbq/crawl4ai_horizontal_scaling_tasks_in_the_memory](https://www.reddit.com/r/webscraping/comments/1j0jxbq/crawl4ai_horizontal_scaling_tasks_in_the_memory)
 - RSS feed: $source
 - date published: 2025-02-28T22:17:10+00:00

<!-- SC_OFF --><div class="md"><p>It looks like it&#39;s memory-oriented for creating new tasks, so how do you make it run in multiple servers horizontally scaling? Because of the way it is now, it will cause inconsistency in querying for the task ID to retrieve the results if the request goes to a server where it was not created the task.</p> <p>Also when creating tasks via <code>/crawl</code> endpoint, including multiple URLs (about 10 URLs), it consumes a good amount of memory, I was able to see peaks of 99%.</p> <p>Does anyone already have this kind of problem?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Lanky_Report4899"> /u/Lanky_Report4899 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1j0jxbq/crawl4ai_horizontal_scaling_tasks_in_the_memory/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1j0jxbq/crawl4ai_horizontal_scaling_tasks_in_the_memory/">[comments]</a></span>

## Need help with Google Searching
 - [https://www.reddit.com/r/webscraping/comments/1j09xfn/need_help_with_google_searching](https://www.reddit.com/r/webscraping/comments/1j09xfn/need_help_with_google_searching)
 - RSS feed: $source
 - date published: 2025-02-28T15:13:51+00:00

<!-- SC_OFF --><div class="md"><p>Hello, I am new to web scraping and have a task at my work that I need to automate. </p> <p>My task is as follows List of patches &gt; google the string &gt; find the link to the website that details the patch&#39;s description &gt; scrape the web page </p> <p>My issue is that I wanted to use Python&#39;s BeautifulSoup to perform the web search from the list of items; however, it seems that Google won&#39;t allow me to automate searches. </p> <p>I tried to find my solution through Google but what it seems is that I would need to purchase an API key. Is this correct or is there a way to perform the websearch and get an HTML response back so I can get the link to the website I am looking for? </p> <p>Thank you</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/pmmethecarfax"> /u/pmmethecarfax </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1j09xfn/need_help_with_google_searching/">[link]</a></

## Influencer discovery demographics tools
 - [https://www.reddit.com/r/webscraping/comments/1j05cdv/influencer_discovery_demographics_tools](https://www.reddit.com/r/webscraping/comments/1j05cdv/influencer_discovery_demographics_tools)
 - RSS feed: $source
 - date published: 2025-02-28T11:14:49+00:00

<!-- SC_OFF --><div class="md"><p>How to do many influencer marketing tools build the influencer demographics of users. They are soo detailed like the top countries there audience is from , gender etc.</p> <p>There are the only things I’ve thought of:</p> <ol> <li>Scraping - scraping social media profiles in-depth and using machine learning to identify genders etc through posts. Running mutplie social accounts and not linking is hard. Also many of these tools offers api like how??</li> <li>Buying large dataset (again this can be challenging in having to regularly update)</li> <li>Official api (very very limited like Instagram you could do 200 pull per hour and very generic metrics like followers countries)</li> </ol> <p>What the best way scraping and machine learning not only would take along time but also can be very very expensive (hence these tools are also extremely expensive)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Jathushan2024"> /

## Help with scrapping from web to google sheet
 - [https://www.reddit.com/r/webscraping/comments/1j04wpp/help_with_scrapping_from_web_to_google_sheet](https://www.reddit.com/r/webscraping/comments/1j04wpp/help_with_scrapping_from_web_to_google_sheet)
 - RSS feed: $source
 - date published: 2025-02-28T10:45:13+00:00

<!-- SC_OFF --><div class="md"><p>Hello,</p> <p>I am trying to carp xchange rates from bank website through formulas “importhtml” and “importxml” to my google sheet.</p> <p><a href="https://www.mbank.cz/osobni/karty/debetni-karty/mkarta-svet/">https://www.mbank.cz/osobni/karty/debetni-karty/mkarta-svet/</a> EUR and USD and other down on the website.</p> <p>Any recommendations?</p> <p>Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Ambitious-Tip6649"> /u/Ambitious-Tip6649 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1j04wpp/help_with_scrapping_from_web_to_google_sheet/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1j04wpp/help_with_scrapping_from_web_to_google_sheet/">[comments]</a></span>

