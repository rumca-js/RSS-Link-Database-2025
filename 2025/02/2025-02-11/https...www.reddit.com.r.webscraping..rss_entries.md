# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Need help in web scraping
 - [https://www.reddit.com/r/webscraping/comments/1in8txx/need_help_in_web_scraping](https://www.reddit.com/r/webscraping/comments/1in8txx/need_help_in_web_scraping)
 - RSS feed: $source
 - date published: 2025-02-11T20:42:07+00:00

<!-- SC_OFF --><div class="md"><p><a href="https://seekingalpha.com/author/sa-transcripts/analysis">https://seekingalpha.com/author/sa-transcripts/analysis</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Ok_Listen_6389"> /u/Ok_Listen_6389 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1in8txx/need_help_in_web_scraping/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1in8txx/need_help_in_web_scraping/">[comments]</a></span>

## waiting for the data to flow in
 - [https://www.reddit.com/r/webscraping/comments/1in7rxb/waiting_for_the_data_to_flow_in](https://www.reddit.com/r/webscraping/comments/1in7rxb/waiting_for_the_data_to_flow_in)
 - RSS feed: $source
 - date published: 2025-02-11T19:59:02+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1in7rxb/waiting_for_the_data_to_flow_in/"> <img src="https://preview.redd.it/7uzai2e08xq61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1075705394c78313a4f5626c0968236b23907b21" alt="waiting for the data to flow in" title="waiting for the data to flow in" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/nickenlunctured"> /u/nickenlunctured </a> <br/> <span><a href="https://i.redd.it/7uzai2e08xq61.png">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1in7rxb/waiting_for_the_data_to_flow_in/">[comments]</a></span> </td></tr></table>

## Can I scrape PDFs that I can‚Äôt download from a website?
 - [https://www.reddit.com/r/webscraping/comments/1in74ts/can_i_scrape_pdfs_that_i_cant_download_from_a](https://www.reddit.com/r/webscraping/comments/1in74ts/can_i_scrape_pdfs_that_i_cant_download_from_a)
 - RSS feed: $source
 - date published: 2025-02-11T19:32:35+00:00

<!-- SC_OFF --><div class="md"><p>Long story short, but I have a list of thousands of PDFs I can view in browser but I can‚Äôt download without a cost.</p> <p>Is there anyway I can automate scraping some of the data from each of these PDFs and exporting to CSV? </p> <p>Can I set something up, like a macro to go to the next PDF as well?</p> <p>Apologies I can‚Äôt go into loads of detail, but that‚Äôs top level, I‚Äôm hoping this is the right place? As I understand PDFs and webpage scraping are 2 different things.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/baconhammock69"> /u/baconhammock69 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1in74ts/can_i_scrape_pdfs_that_i_cant_download_from_a/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1in74ts/can_i_scrape_pdfs_that_i_cant_download_from_a/">[comments]</a></span>

## Any workarounds to change proxy per page with playwright (python)?
 - [https://www.reddit.com/r/webscraping/comments/1imzrye/any_workarounds_to_change_proxy_per_page_with](https://www.reddit.com/r/webscraping/comments/1imzrye/any_workarounds_to_change_proxy_per_page_with)
 - RSS feed: $source
 - date published: 2025-02-11T14:27:47+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone! I have a proxy service that provides a new IP on every request, but it only kicks in after I restart my browser or launch a new browser context. I‚Äôm wondering if anyone knows a trick or solution to force the proxy to rotate IPs on each page load (or each request) without having to restart the browser every time.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/OrchidKido"> /u/OrchidKido </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1imzrye/any_workarounds_to_change_proxy_per_page_with/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1imzrye/any_workarounds_to_change_proxy_per_page_with/">[comments]</a></span>

## I want the name of every youtube video
 - [https://www.reddit.com/r/webscraping/comments/1imz6pz/i_want_the_name_of_every_youtube_video](https://www.reddit.com/r/webscraping/comments/1imz6pz/i_want_the_name_of_every_youtube_video)
 - RSS feed: $source
 - date published: 2025-02-11T14:00:05+00:00

<!-- SC_OFF --><div class="md"><p>Any ideas? I want them all so I can search them by word. As is, I could copy and paste the exact title of a youtube video and still fail to find it, so I&#39;m not even sure this is worth it. But, there has to be a better way. Prefferably the names and URLs but names are a solid start.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/GoldPlusWater"> /u/GoldPlusWater </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1imz6pz/i_want_the_name_of_every_youtube_video/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1imz6pz/i_want_the_name_of_every_youtube_video/">[comments]</a></span>

## Remove Links Crawl4AI for LLM Extraction Strategy?
 - [https://www.reddit.com/r/webscraping/comments/1imz1l4/remove_links_crawl4ai_for_llm_extraction_strategy](https://www.reddit.com/r/webscraping/comments/1imz1l4/remove_links_crawl4ai_for_llm_extraction_strategy)
 - RSS feed: $source
 - date published: 2025-02-11T13:52:55+00:00

<!-- SC_OFF --><div class="md"><p>Hi, </p> <p>I&#39;m using Crawl4AI. Nice it works.<br/> But one thing I would like is before it feeds the markdown result to an LLM Extraction Strategy, is it possible to remove the links on the input? </p> <p>The links really add up to the token limit. And I have no need for the links, I just need the body content. </p> <p>Is this possible?</p> <p>P.S. I tried searching for the documentation but i can&#39;t find any. Maybe I&#39;m wrong.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/bentraje"> /u/bentraje </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1imz1l4/remove_links_crawl4ai_for_llm_extraction_strategy/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1imz1l4/remove_links_crawl4ai_for_llm_extraction_strategy/">[comments]</a></span>

## Weekly Webscrapers - Hiring, FAQs, etc
 - [https://www.reddit.com/r/webscraping/comments/1imy1fd/weekly_webscrapers_hiring_faqs_etc](https://www.reddit.com/r/webscraping/comments/1imy1fd/weekly_webscrapers_hiring_faqs_etc)
 - RSS feed: $source
 - date published: 2025-02-11T13:01:31+00:00

<!-- SC_OFF --><div class="md"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels‚Äîwhether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>As with our <a href="https://reddit.com/r/webscraping/about/sticky?num=1">monthly thread</a>, self-promotions and paid products are welcome here ü§ù</p> <p>If you&#39;re new to web scraping, make sure to check out the <a href="https://webscraping.fyi">Beginners Guide</a> üå±</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/AutoModerator"> /u/AutoModerator </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1imy1fd/weekly_webscrapers_hiring_faqs_etc/">[l

## Help: Webscraping with VBA - Can't Find Search Bar
 - [https://www.reddit.com/r/webscraping/comments/1imwn4w/help_webscraping_with_vba_cant_find_search_bar](https://www.reddit.com/r/webscraping/comments/1imwn4w/help_webscraping_with_vba_cant_find_search_bar)
 - RSS feed: $source
 - date published: 2025-02-11T11:40:06+00:00

<!-- SC_OFF --><div class="md"><p>Hey guys,</p> <p>i&#39;m having trouble findung a searchbar in VBA via Selenium.</p> <p>That is the HTML Code:</p> <p>&lt;input placeholder=&quot;Nummern&quot; size=&quot;1&quot; type=&quot;text&quot; id=&quot;input-4&quot; aria-describedby=&quot;input-4-messages&quot; class=&quot;v-field\_\_input&quot; value=&quot;&quot;&gt;</p> <p>My VBA Code:</p> <p>Sub ScrapeGestisDatabase()</p> <p>Set ch = New Selenium.ChromeDriver</p> <p>ch.Start baseUrl:=&quot;<a href="https://gestis.dguv.de/search">https://gestis.dguv.de/search</a>&quot;</p> <p>ch.Get &quot;/&quot; &#39; Returns Gestis Search Site</p> <p>ch.FindElementById(&quot;input-4&quot;).SendKeys &quot;74-82-8&quot;</p> <p>End Sub</p> <p>So essentially what i&#39;m trying to do is finding the search bar &quot;Numbers&quot;on the gestis database (<a href="https://gestis.dguv.de/search">https://gestis.dguv.de/search</a>). But my Code doesn&#39;t find it. Also when i type the FindElementsByClass VBA still 

## Scraping Nutritional Information from Woolworths/Coles
 - [https://www.reddit.com/r/webscraping/comments/1imt6rd/scraping_nutritional_information_from](https://www.reddit.com/r/webscraping/comments/1imt6rd/scraping_nutritional_information_from)
 - RSS feed: $source
 - date published: 2025-02-11T07:25:10+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m working on my own calorie tracker in Google Sheets because I don&#39;t like the interface of Calorie tracking apps.</p> <p>I want to have an inbuilt database in the calorie tracker which draws data from Woolworths/Coles, however I have no clue about Web Scraping. I&#39;ve tried using ChatGPT to come up with code. So far it has not been successful. Partly because I don&#39;t have any background knowledge on coding, and partly (I assume) because I don&#39;t have any APIs to access the data. Again, new to coding so forgive me if my terminology is off.</p> <p>I have a macbook air, so I have to use Terminal, and I have Python3. Is there anyone who can point me in the direction of some existing resources, or help me create some script which will successfully scrape data?</p> <p>I found this<a href="https://github.com/wulfftech/Australia_GroceriesScraper"> GitHub</a> page, but unsure how to proceed with it.</p> </div><!-- SC_ON --> &#32; submitted b

## Need suggestions on airbnb scraping
 - [https://www.reddit.com/r/webscraping/comments/1imsqzu/need_suggestions_on_airbnb_scraping](https://www.reddit.com/r/webscraping/comments/1imsqzu/need_suggestions_on_airbnb_scraping)
 - RSS feed: $source
 - date published: 2025-02-11T06:54:32+00:00

<!-- SC_OFF --><div class="md"><p>everyone,</p> <p>I‚Äôm looking for advice on scraping Airbnb listings with a focus on specific booking days (Tuesday to Thursday of any month). I need to extract both property and host details, and I‚Äôm aware that Airbnb employs strong anti-scraping measures.</p> <p>What I‚Äôm Trying to Extract:</p> <p>Property Details: ‚Ä¢ Property ID (always collect) ‚Ä¢ Property name ‚Ä¢ Price per night ‚Ä¢ Coordinates (latitude and longitude) ‚Ä¢ Amenities ‚Ä¢ Property rating</p> <p>Host Details: ‚Ä¢ Host ID (always collect) ‚Ä¢ Host name ‚Ä¢ Host profile description (page content) ‚Ä¢ Total number of listings the host has ‚Ä¢ Host rating</p> <p>I have experience with TypeScript, Axios, Cheerio, and Puppeteer, but I‚Äôm open to any suggestions on how to tackle this problem effectively.</p> <p>My Main Questions: 1. What‚Äôs the best approach to extract this data? Should I lean towards using Puppeteer/Playwright, or is there a way to leverage any Airbnb API endpoints? 2. How can I handle or bypa

