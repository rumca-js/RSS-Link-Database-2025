[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-27T19:09:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, guys I recently finished making a Windows app as a pastime project for web scraping. I haven&#39;t packaged it yet but as for now it can only scrape and download said scraped data to a CSV file I&#39;ve never web scraped ever so it can&#39;t do what most of you would want it to do but I&#39;m willing to make the necessary addition to make web scraping easier and more efficient for you guys .</p> <p>Oh and btw does anyone know how I can upload the packed file to GitHub I made it with Electron and it is too large for a single commit.</p> <p>I hope I made sense </p> <p>my GitHub is <a href=\"https://github.com/Kylo-bytebit\">https://github.com/Kylo-bytebit</a><br/> link to project <a href=\"https://github.com/Kylo-bytebit/The-Scrapeenator\">https://github.com/Kylo-bytebit/The-Scrapeenator</a> </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Prestigious-Swim-819\"> /u/Prestigious-Swim-819 </a> <br/> <span><a href=\"ht",
        "id": 2211085,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iznqaz/open_source_web_scraping_software",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Open source Web scraping software",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-27T17:19:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Target will at times, hide products from being able to search on the website.</p> <p>Sometimes you u can locate the product by searching the sku directly, sometimes you cannot. If you know the direct link to the product, you can navigate to the webpage.</p> <p>I am scraping a category search and im always missing these products that are \u201chidden\u201d.</p> <p>Any idea how to locate these hidden products so i can scrape these, along with all the other products from the search?</p> <p>I have tried checking the network tab in developer tools for any search api, but there doesn\u2019t appear to be any (from what i can see).</p> <p>Btw is is for the australian target store (i assume it would be similar for US possibly).</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hlgherhopes\"> /u/hlgherhopes </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1izl24c/target_scrape_missing_products_from_sea",
        "id": 2210084,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1izl24c/target_scrape_missing_products_from_search",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Target scrape missing products from search",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-27T02:14:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, puppeteer-extra-plugin-stealth hasn&#39;t been updated in nearly 2 years so is there a reliable replacement of it for Nodejs and Puppeteer?</p> <p>I&#39;ve heard from ulixee hero. Has anyone used it enough to share their thoughts on it?</p> <p>Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AshNil\"> /u/AshNil </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iz500e/puppeteerextrapluginstealth_alternative/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iz500e/puppeteerextrapluginstealth_alternative/\">[comments]</a></span>",
        "id": 2205373,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iz500e/puppeteerextrapluginstealth_alternative",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "puppeteer-extra-plugin-stealth alternative?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-27T00:48:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I have been developing a scraping system consisting of 4 - 5 mini PCs networked together with a nice web dashboard, load balancing, backups to Google Drive, central database. </p> <p>Basically, it is a ready-to-go solution where you can drop in a scraping logic that needs to follow pretty simple design guidelines to work and upload a number of input csvs or any supported database and it will spit out results at a speed of around 1 million websites per month when tested on Google search results. </p> <p>it is primarily aimed at hard-to-scrape targets such as Google and that 1 million websites per month was achieved after the recent Google crackdown with a full headless browser </p> <p>of course, it can work even with simpler solutions for easier-to-scrape websites </p> <p>The cost of the hardware would be around 3000 - 5000 USD and the monthly cost would be with proxies around 400 USD a month. </p> <p>It is still in development and I am not trying",
        "id": 2205372,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iz3a96/is_there_a_market_for_standalone_scraping_device",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a market for standalone scraping device?",
        "vote": 0
    }
]