# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Open source Web scraping software
 - [https://www.reddit.com/r/webscraping/comments/1iznqaz/open_source_web_scraping_software](https://www.reddit.com/r/webscraping/comments/1iznqaz/open_source_web_scraping_software)
 - RSS feed: $source
 - date published: 2025-02-27T19:09:06+00:00

<!-- SC_OFF --><div class="md"><p>Hi, guys I recently finished making a Windows app as a pastime project for web scraping. I haven&#39;t packaged it yet but as for now it can only scrape and download said scraped data to a CSV file I&#39;ve never web scraped ever so it can&#39;t do what most of you would want it to do but I&#39;m willing to make the necessary addition to make web scraping easier and more efficient for you guys .</p> <p>Oh and btw does anyone know how I can upload the packed file to GitHub I made it with Electron and it is too large for a single commit.</p> <p>I hope I made sense </p> <p>my GitHub is <a href="https://github.com/Kylo-bytebit">https://github.com/Kylo-bytebit</a><br/> link to project <a href="https://github.com/Kylo-bytebit/The-Scrapeenator">https://github.com/Kylo-bytebit/The-Scrapeenator</a> </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Prestigious-Swim-819"> /u/Prestigious-Swim-819 </a> <br/> <span><a href="ht

## Target scrape missing products from search
 - [https://www.reddit.com/r/webscraping/comments/1izl24c/target_scrape_missing_products_from_search](https://www.reddit.com/r/webscraping/comments/1izl24c/target_scrape_missing_products_from_search)
 - RSS feed: $source
 - date published: 2025-02-27T17:19:48+00:00

<!-- SC_OFF --><div class="md"><p>Target will at times, hide products from being able to search on the website.</p> <p>Sometimes you u can locate the product by searching the sku directly, sometimes you cannot. If you know the direct link to the product, you can navigate to the webpage.</p> <p>I am scraping a category search and im always missing these products that are “hidden”.</p> <p>Any idea how to locate these hidden products so i can scrape these, along with all the other products from the search?</p> <p>I have tried checking the network tab in developer tools for any search api, but there doesn’t appear to be any (from what i can see).</p> <p>Btw is is for the australian target store (i assume it would be similar for US possibly).</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/hlgherhopes"> /u/hlgherhopes </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1izl24c/target_scrape_missing_products_from_sea

## puppeteer-extra-plugin-stealth alternative?
 - [https://www.reddit.com/r/webscraping/comments/1iz500e/puppeteerextrapluginstealth_alternative](https://www.reddit.com/r/webscraping/comments/1iz500e/puppeteerextrapluginstealth_alternative)
 - RSS feed: $source
 - date published: 2025-02-27T02:14:33+00:00

<!-- SC_OFF --><div class="md"><p>Hi, puppeteer-extra-plugin-stealth hasn&#39;t been updated in nearly 2 years so is there a reliable replacement of it for Nodejs and Puppeteer?</p> <p>I&#39;ve heard from ulixee hero. Has anyone used it enough to share their thoughts on it?</p> <p>Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/AshNil"> /u/AshNil </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1iz500e/puppeteerextrapluginstealth_alternative/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1iz500e/puppeteerextrapluginstealth_alternative/">[comments]</a></span>

## Is there a market for standalone scraping device?
 - [https://www.reddit.com/r/webscraping/comments/1iz3a96/is_there_a_market_for_standalone_scraping_device](https://www.reddit.com/r/webscraping/comments/1iz3a96/is_there_a_market_for_standalone_scraping_device)
 - RSS feed: $source
 - date published: 2025-02-27T00:48:55+00:00

<!-- SC_OFF --><div class="md"><p>Hi, I have been developing a scraping system consisting of 4 - 5 mini PCs networked together with a nice web dashboard, load balancing, backups to Google Drive, central database. </p> <p>Basically, it is a ready-to-go solution where you can drop in a scraping logic that needs to follow pretty simple design guidelines to work and upload a number of input csvs or any supported database and it will spit out results at a speed of around 1 million websites per month when tested on Google search results. </p> <p>it is primarily aimed at hard-to-scrape targets such as Google and that 1 million websites per month was achieved after the recent Google crackdown with a full headless browser </p> <p>of course, it can work even with simpler solutions for easier-to-scrape websites </p> <p>The cost of the hardware would be around 3000 - 5000 USD and the monthly cost would be with proxies around 400 USD a month. </p> <p>It is still in development and I am not trying

