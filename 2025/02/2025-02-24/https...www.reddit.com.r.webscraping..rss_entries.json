[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-24T21:06:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The main issue is that the XPath for popups (specifically the &quot;Not now&quot; buttons) keeps changing every time the page reloads. I initially targeted the button using the <code>aria-label</code> attribute, but even that doesn&#39;t always work because the XPath or the structure of the button dynamically changes</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/teabagpb\"> /u/teabagpb </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ixd0ac/selenium_issue_dynamic_popups_with_changing_xpath/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ixd0ac/selenium_issue_dynamic_popups_with_changing_xpath/\">[comments]</a></span>",
        "id": 2187825,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ixd0ac/selenium_issue_dynamic_popups_with_changing_xpath",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Selenium Issue: Dynamic Popups with Changing XPath",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-24T20:47:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Pretty much the title, I\u2019m just trying to see if there are cases where someone has build a product using scraped data, one example I could find is an web app with house listings collected from 30 different agencies. Which seems to be a win win for everyone given that when a user decided which house they like the link takes them back to the original listing. I\u2019ve thinking to do something similar and was wondering if anyone else had made a product that way. Thanks :) </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Emergency-Agreeable\"> /u/Emergency-Agreeable </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ixcjhd/has_any_build_a_product_using_scraped_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ixcjhd/has_any_build_a_product_using_scraped_data/\">[comments]</a></span>",
        "id": 2187343,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ixcjhd/has_any_build_a_product_using_scraped_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Has any build a product using scraped data?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-24T20:17:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to take cookies created in NoDriver and reuse them in Requests to make subsequent calls. However, this results in a 403 so I&#39;m assuming bot protection is flagging the request. I&#39;m also mimicking the headers in an identical manner. </p> <p>Does anyone have any experience making this work? I feel like I might be missing something simple </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/barrycarey\"> /u/barrycarey </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ixbs4x/cloudflare_bot_management_cookie_from_nodriver/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ixbs4x/cloudflare_bot_management_cookie_from_nodriver/\">[comments]</a></span>",
        "id": 2187342,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ixbs4x/cloudflare_bot_management_cookie_from_nodriver",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cloudflare Bot Management Cookie From NoDriver",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-24T10:00:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I was getting overwhelmed with so many APIs, tools and libraries out there. Then, I stumbled upon anti-detect browsers. Most of them let you create your own RPAs. You can also run them on a schedule with rotating proxies. Sometimes you&#39;ll need add a bit of Javascript code to make it work, but overall I think this is a great place to start learning how to use xpath and so on.</p> <p>You can also test your xpath in chrome dev tool console by using javascript. E.g. $x(&quot;//div//span[contains(@name, &#39;product-name&#39;)]&quot;)</p> <p>Once you have your RPA fully functioning and tested export it and throw it into some AI coding platform to help you turn it into python, node.js or whatever.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/polarmass\"> /u/polarmass </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iwylko/scraping_advice_for_beginners/\">[link]</a></span> &#32; <span><a hr",
        "id": 2181944,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iwylko/scraping_advice_for_beginners",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping advice for beginners",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-24T04:20:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>How does SingleFile extension finds all the images protected by javascript and can i replicate this in pupeteer to download all images ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NoUnderstanding7620\"> /u/NoUnderstanding7620 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iwtiyh/scraping_all_images_in_a_webpage_that_are_hidden/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iwtiyh/scraping_all_images_in_a_webpage_that_are_hidden/\">[comments]</a></span>",
        "id": 2181945,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iwtiyh/scraping_all_images_in_a_webpage_that_are_hidden",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping all images in a webpage that are hidden by jvascript",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-24T04:05:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have been using a Google Maps scraper to scrape business data too gather business info for marketing </p> <p>It only lets me use Google maps to pull the data and I have to be hovering over that specific search area to pull the data within it. </p> <p>Is there some sort of other scraper out there where I can pull google my business page data, such as the phone number for the business, website etc without the need for using google maps? </p> <p>or any data aggregator sites that can provide you google my business page data with phone # etc?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/getmybankroll\"> /u/getmybankroll </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iwt98x/google_my_business_page_scraper/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iwt98x/google_my_business_page_scraper/\">[comments]</a></span>",
        "id": 2181946,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iwt98x/google_my_business_page_scraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Google my business page scraper",
        "vote": 0
    }
]