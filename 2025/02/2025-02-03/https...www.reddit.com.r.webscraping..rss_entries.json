[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-03T16:54:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I&#39;m building an API for getting all the possible data on Discogs. Do you have any suggestions on what data you should be able to get using the API? I&#39;m trying to create a really complete API that lets you do anything you want. If you have any ideas, suggestion or you&#39;re interested in the project contact me or leave a comment to let me know.<br/> Thank you all!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/yonis1\"> /u/yonis1 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igtpbt/discogs_api_suggestions/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igtpbt/discogs_api_suggestions/\">[comments]</a></span>",
        "id": 2031530,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1igtpbt/discogs_api_suggestions",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Discogs API suggestions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-03T16:29:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I am developing something like a news aggregator for a specific niche. What is the best approach?</p> <p>1.Scraping all the news sites, that are relevant? Does someone have any tips for it, maybe some new cool free AI Stuff?</p> <ol> <li>Is there a way to scrape google news for free?</li> </ol> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Basti291\"> /u/Basti291 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igt3qi/scraping_of_news/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igt3qi/scraping_of_news/\">[comments]</a></span>",
        "id": 2031529,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1igt3qi/scraping_of_news",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping of news",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-03T15:44:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anyone found a master list of sources to scrape if I want to gather every single employee from a company?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/youngkilog\"> /u/youngkilog </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igs03n/how_to_scrape_every_single_employee_at_a_company/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igs03n/how_to_scrape_every_single_employee_at_a_company/\">[comments]</a></span>",
        "id": 2031532,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1igs03n/how_to_scrape_every_single_employee_at_a_company",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape every single employee at a company",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-03T15:26:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I am working on an application by which I input my (active) credentials for a target site, log into the site and navigate around. I am currently unable to do so because I do not know how to create/use the Cross Site Request Forgery token. </p> <p>[success bounty included]: I am looking for a web security engineer to help us reverse engineer how a CRSF token is generated on the client. This token is used to authenticate requests made to an end sites api and is generated by browsers, iOS, and android apps. We want to understand how the token is generated and if it\u2019s possible to create the token from a server to use in order to get data from the end sites apis. Any specialists have insight here?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/holedigger5\"> /u/holedigger5 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igrl66/seeking_help_cross_site_request_forgery_token/\">[link]</a></sp",
        "id": 2031531,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1igrl66/seeking_help_cross_site_request_forgery_token",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seeking help: Cross Site Request Forgery token creation/recreation",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-03T10:33:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m planning/building data extraction SaaS but with deepresearch and all the agents making it easier for more complex scraping tasks without coding, I wonder what would be a next-generation of scraping business that is niche enough I can get a decent demand for use?</p> <p>Since new API&#39;s that can do scraping is rapidly coming out, will it be smart to create a &#39;API wrapper&#39; service similar to OpenRouter way of optimizing and routing all/any scraping tasks in a simple to use API business? Do you think it has some demand that I should start?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sonozaki7\"> /u/sonozaki7 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igm75y/agentic_scraping_in_2025/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igm75y/agentic_scraping_in_2025/\">[comments]</a></span>",
        "id": 2029760,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1igm75y/agentic_scraping_in_2025",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Agentic scraping in 2025?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-03T08:40:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello all,</p> <p>I&#39;m trying to make nodriver grant or deny geolocation permission because the website I&#39;m trying to scrape does not show any information before granting or denying geolocation permissions. I tried grant_all_permissions function but it didn&#39;t worked. Is it possible to do it on Nodriver?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Crucify12\"> /u/Crucify12 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igkp4x/geolocation_permission_on_nodriver/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igkp4x/geolocation_permission_on_nodriver/\">[comments]</a></span>",
        "id": 2029016,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1igkp4x/geolocation_permission_on_nodriver",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Geolocation permission on Nodriver",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-03T08:13:58+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/yevbar\"> /u/yevbar </a> <br/> <span><a href=\"https://news.ycombinator.com/item?id=42916034\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igkcg5/gave_claude_lsd_sql_and_you_can_prompt_it_for/\">[comments]</a></span>",
        "id": 2028772,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1igkcg5/gave_claude_lsd_sql_and_you_can_prompt_it_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Gave Claude LSD SQL and you can prompt it for scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-03T08:09:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>On Sunday, OpenAI announced <a href=\"https://openai.com/index/introducing-deep-research/\">Deep Research</a>, an agent that can navigate the web, read sites in real time, and conduct complex research.</p> <p><strong>How will this affect web scraping? More specifically, what are Deep Research&#39;s limitations around web scraping? What won&#39;t it do?</strong></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AwareSeaworthiness52\"> /u/AwareSeaworthiness52 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igkaa7/what_does_openais_deep_research_agent_mean_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1igkaa7/what_does_openais_deep_research_agent_mean_for/\">[comments]</a></span>",
        "id": 2029017,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1igkaa7/what_does_openais_deep_research_agent_mean_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What does OpenAI's Deep Research agent mean for web scraping?",
        "vote": 0
    }
]