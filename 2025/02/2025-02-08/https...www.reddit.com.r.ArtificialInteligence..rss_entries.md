# Source:Artificial Intelligence Gateway, URL:https://www.reddit.com/r/ArtificialInteligence/.rss, language:

## AI subscriptions are getting expensive—how do you manage costs?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1il112d/ai_subscriptions_are_getting_expensivehow_do_you](https://www.reddit.com/r/ArtificialInteligence/comments/1il112d/ai_subscriptions_are_getting_expensivehow_do_you)
 - RSS feed: $source
 - date published: 2025-02-08T23:36:28+00:00

<!-- SC_OFF --><div class="md"><p>AI has been super useful, but as an individual, I’m struggling to afford all the niche services I need. Models like ChatGPT and Claude have API-based platforms bundling access, but for more specialized ones—like BuzzAbout, GummySearch, Browse AI, and Descript—there aren’t many flexible options.</p> <p>Some people subscribe individually, some use company plans, and I’ve even seen pay-per-use models. But for niche services, it feels like there aren’t great alternatives to paying full price. How do you manage costs? Would you prefer something like on-demand access instead of full subscriptions?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/YakFit9188"> /u/YakFit9188 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1il112d/ai_subscriptions_are_getting_expensivehow_do_you/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1il112d/ai_subs

## Do you think that what we have now is artificial intelligence?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikz9ex/do_you_think_that_what_we_have_now_is_artificial](https://www.reddit.com/r/ArtificialInteligence/comments/1ikz9ex/do_you_think_that_what_we_have_now_is_artificial)
 - RSS feed: $source
 - date published: 2025-02-08T22:16:41+00:00

<!-- SC_OFF --><div class="md"><p>My take: it is not.</p> <p>Argument 1: it is the most known one - LLMs output is based on statistics not understanding.</p> <p>Argument 2: LLMs are static. It is the most important point. Once model is trained it does not evolve. It can not learn on it&#39;s own.</p> <p>Argument 3: LLMs are not self-aware and therefore lack any critical thinking. LLM does not have any introspection (consequence of argument 1 and 2).</p> <p>Argument 4: (consequence of argument 3) it&#39;s the most overlooked one - all the seemingly human-like stuff done by &quot;ai&quot; are in fact pretty big software systems buit on top of LLMs. The whole wow-effect would be way smaller if regular people got a chance to interact with LLMs directly.</p> <p>Summary: undeniably modern LLMs are extremely cool technology. Products built on top of them are even cooler. Is it the AI ? I don&#39;t think so.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/us

## What would be the reason to use Meta AI?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikw2v5/what_would_be_the_reason_to_use_meta_ai](https://www.reddit.com/r/ArtificialInteligence/comments/1ikw2v5/what_would_be_the_reason_to_use_meta_ai)
 - RSS feed: $source
 - date published: 2025-02-08T19:57:22+00:00

<!-- SC_OFF --><div class="md"><p>Is there any clear advantage to using Meta AI? Seems more awkward to get to, being embedded in other apps, and I don’t think it’s as good as even the free ChatGPT today? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/PWHerman89"> /u/PWHerman89 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikw2v5/what_would_be_the_reason_to_use_meta_ai/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikw2v5/what_would_be_the_reason_to_use_meta_ai/">[comments]</a></span>

## Supervised Learning - Ground Truth
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikufdb/supervised_learning_ground_truth](https://www.reddit.com/r/ArtificialInteligence/comments/1ikufdb/supervised_learning_ground_truth)
 - RSS feed: $source
 - date published: 2025-02-08T18:47:23+00:00

<!-- SC_OFF --><div class="md"><p>I have recently started looking into machine learning and have a question. In supervised learning, there are features (X) and labels (Y). As I understand it, features are the inputs and labels are the expected output. Recently I was confronted with the term “ground truth” and I wanted to ask if ground truth is the same as a label (Y) ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/psy_com"> /u/psy_com </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikufdb/supervised_learning_ground_truth/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikufdb/supervised_learning_ground_truth/">[comments]</a></span>

## Am I susceptible to plagiarism if I tell my ideas to chatGPT?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikskjp/am_i_susceptible_to_plagiarism_if_i_tell_my_ideas](https://www.reddit.com/r/ArtificialInteligence/comments/1ikskjp/am_i_susceptible_to_plagiarism_if_i_tell_my_ideas)
 - RSS feed: $source
 - date published: 2025-02-08T17:29:47+00:00

<!-- SC_OFF --><div class="md"><p>For context, I like world building and I am making a medieval fantasy world for role-playing. I saw someone in social media saying they could play RPG with chat gpt and I wanted to do the same with my own world, tho I am afraid of plagiarism. </p> <p>In a technical way, could chat GPT store my ideas and suggest to other people if they asked for these kind of ideas? If so, how risky is it? Am I reasonable for being concerned or no?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/di_abolus"> /u/di_abolus </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikskjp/am_i_susceptible_to_plagiarism_if_i_tell_my_ideas/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikskjp/am_i_susceptible_to_plagiarism_if_i_tell_my_ideas/">[comments]</a></span>

## Social media logical fallacy AI feature
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikr26w/social_media_logical_fallacy_ai_feature](https://www.reddit.com/r/ArtificialInteligence/comments/1ikr26w/social_media_logical_fallacy_ai_feature)
 - RSS feed: $source
 - date published: 2025-02-08T16:26:14+00:00

<!-- SC_OFF --><div class="md"><p>Wouldn&#39;t it be great if Meta, TikTok, and X ran conversations through AI that analyzed the probability a post used a logical fallacy and made a little note that the post might be, say, an ad-hominem attack and present an explanation of the fallacy? It just seems like that might move the world into a so much more productive direction.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Lower_Chipmunk_3685"> /u/Lower_Chipmunk_3685 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikr26w/social_media_logical_fallacy_ai_feature/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikr26w/social_media_logical_fallacy_ai_feature/">[comments]</a></span>

## Does anyone have data comparing AI-based creators or channels to human creators on social media platforms like Instagram, YouTube, or X? Also, what’s the future outlook for this trend?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikpuvr/does_anyone_have_data_comparing_aibased_creators](https://www.reddit.com/r/ArtificialInteligence/comments/1ikpuvr/does_anyone_have_data_comparing_aibased_creators)
 - RSS feed: $source
 - date published: 2025-02-08T15:33:35+00:00

<!-- SC_OFF --><div class="md"><p>Looking for insights on how AI-based creators are performing compared to human creators on social media platforms like Instagram, YouTube, and X. Curious about trends and the future of this space. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Curious_Suchit"> /u/Curious_Suchit </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikpuvr/does_anyone_have_data_comparing_aibased_creators/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikpuvr/does_anyone_have_data_comparing_aibased_creators/">[comments]</a></span>

## It happened today. Coworker went into full panic
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikoseb/it_happened_today_coworker_went_into_full_panic](https://www.reddit.com/r/ArtificialInteligence/comments/1ikoseb/it_happened_today_coworker_went_into_full_panic)
 - RSS feed: $source
 - date published: 2025-02-08T14:45:44+00:00

<!-- SC_OFF --><div class="md"><p>Actually yesterday now.</p> <p>I am part of a small MSP and stretched thin but I along with the owner continue to evaluate AI products to see what is the right fit for us.</p> <p>We had a normal scheduled meeting just to go over where everything is at and then discussed some AI options we are considering.</p> <p>Among 10 or so people, my coworker decided to say “does anyone have a negative experience with AI? Anything negative to say?”</p> <p>Everyone was silent. The owner and I have been discussing in detail about any concerns on my end or thoughts I have about the trajectory of AI in our business, but I didn’t feel it was important to bring up because everything is in a dynamic floating position right now essentially.</p> <p>Then he went on “ok I guess I’m the only one. Eventually we have AI summarizing everything for us and our reading comprehension is going to go down the drain and then our way we communicate with our customers going to suffer an

## Understanding Image Generation Diffusion Model Training Parameters: A research analysis on confusing ML training terms and how they effect image outputs.
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iknn8m/understanding_image_generation_diffusion_model](https://www.reddit.com/r/ArtificialInteligence/comments/1iknn8m/understanding_image_generation_diffusion_model)
 - RSS feed: $source
 - date published: 2025-02-08T13:48:43+00:00

<!-- SC_OFF --><div class="md"><p>This research is conducted to help myself and the open-source community define &amp; visualize the effects the following parameters have on image outputs when training LoRAs for image generation: <em>Unet Learning Rate, Clip Skip, Network Dimension, Learning Rate Scheduler , Min SNR Gamma, Noise Offset,</em> <em>Optimizer, Network Alpha , Learning Rate Scheduler Number Cycle</em> </p> <p><a href="https://civitai.com/articles/11394/understanding-lora-training-parameters">https://civitai.com/articles/11394/understanding-lora-training-parameters</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Cold-Dragonfly-144"> /u/Cold-Dragonfly-144 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iknn8m/understanding_image_generation_diffusion_model/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iknn8m/understanding_image_generation_diffusio

## Does the meaning of AGI and the development of AI need to enter another phase now? Everyone's talking about the AGI, but they don't seem to realize that the real AGI is not that close (at least we're not so close - for now).
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikkjhq/does_the_meaning_of_agi_and_the_development_of_ai](https://www.reddit.com/r/ArtificialInteligence/comments/1ikkjhq/does_the_meaning_of_agi_and_the_development_of_ai)
 - RSS feed: $source
 - date published: 2025-02-08T10:36:29+00:00

<!-- SC_OFF --><div class="md"><p>We haven&#39;t even reached AGI. If we wanna build ASI, need to build AGI and *real AGI (not the marketing campaign) will help us developed the technologies needed to build ASI. </p> <p>In my opinion, we need to seriously change the way we test models, benchmark tests, etc. The current benchmark tests are too primitive. We need to take the application place, form, and type of problems to a higher level at this stage. </p> <p>Benchmarks shouldn&#39;t be only <strong><em>theoretical</em></strong>. In fact, yes, they aren&#39;t exactly theoretical, but something is missing. Let&#39;s think of a system that&#39;s very good in some subjects, but when it comes to another subjects, especially the <strong><em>real world</em></strong>, it doesn&#39;t give such good results. Next-generation benchmarks should shift from the purely theoretical level to something closer to real-world conditions.</p> <p>Therefore, in my opinion, we need to perform all these tests 

## What happened to self-driving cars?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikii53/what_happened_to_selfdriving_cars](https://www.reddit.com/r/ArtificialInteligence/comments/1ikii53/what_happened_to_selfdriving_cars)
 - RSS feed: $source
 - date published: 2025-02-08T08:11:17+00:00

<!-- SC_OFF --><div class="md"><p>Sometime in mid to late 2010s, I was convinced that by 2025 self-driving cars would be commonplace.</p> <p>Google trends also reflect that. Seems like around 2018, we had the peak of the hype.</p> <p>Nowadays, hardly anyone mentions them, and they are still far from being widely adopted.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/hn-mc"> /u/hn-mc </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikii53/what_happened_to_selfdriving_cars/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikii53/what_happened_to_selfdriving_cars/">[comments]</a></span>

## UltraIF: Decomposing Complex Instructions for Better LLM Alignment
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikhlei/ultraif_decomposing_complex_instructions_for](https://www.reddit.com/r/ArtificialInteligence/comments/1ikhlei/ultraif_decomposing_complex_instructions_for)
 - RSS feed: $source
 - date published: 2025-02-08T07:06:55+00:00

<!-- SC_OFF --><div class="md"><p>An interesting new approach for improving instruction-following in language models without requiring benchmark training data. The core idea is decomposing complex instructions into simpler components using a systematic framework called UltraIF.</p> <p>Key technical points: - Uses a decomposition-composition framework to break down instructions into atomic queries and constraints - Generates specific evaluation criteria for each constraint - Same model serves as both generator and evaluator, improving efficiency - Incorporates a feedback loop for iterative improvement - Works on both base models and already instruction-tuned models</p> <p>Results: - 8B parameter models achieved competitive performance with larger specialized instruction models - Showed improvements across 5 different evaluation benchmarks - Demonstrated effectiveness on LLaMA-3.1-8B model family - Required no benchmark training data - Improved performance even on previously instructio

## One-Minute Daily AI News 2/7/2025
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikdnr6/oneminute_daily_ai_news_272025](https://www.reddit.com/r/ArtificialInteligence/comments/1ikdnr6/oneminute_daily_ai_news_272025)
 - RSS feed: $source
 - date published: 2025-02-08T03:15:51+00:00

<!-- SC_OFF --><div class="md"><ol> <li><strong>GitHub</strong> Copilot brings mockups to life by generating code from images.[1]</li> <li><strong>Oscars</strong> Consider Requiring Films to Disclose AI Use After ‘The Brutalist’ and ‘Emilia Pérez’ Controversies.[2]</li> <li>Chinese tech giant quietly unveils advanced AI model amid battle over <strong>TikTok</strong>.[3]</li> <li>This Pixar-style dancing lamp hints at <strong>Apple’s</strong> future home robot.[4]</li> </ol> <p>Sources included at: <a href="https://bushaicave.com/2025/02/07/2-7-2025/">https://bushaicave.com/2025/02/07/2-7-2025/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Excellent-Target-847"> /u/Excellent-Target-847 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikdnr6/oneminute_daily_ai_news_272025/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikdnr6/oneminute_daily_ai_news_272025/">

## Help with Code
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikdj52/help_with_code](https://www.reddit.com/r/ArtificialInteligence/comments/1ikdj52/help_with_code)
 - RSS feed: $source
 - date published: 2025-02-08T03:09:05+00:00

<!-- SC_OFF --><div class="md"><pre><code>Hello! I was talking to an IA, if necessary, to bypass the admins I could send a coded message to a user, and it seemed like an error because they wrote an empty text, but when I quoted it, this appeared: “​window.\_\_oai\_logHTML?window.\_\_oai\_logHTML():window.\_\_oai\_SSR\_HTML=window.\_\_oai\_SSR\_HTML||Date.now();requestAnimationFrame((function(){window.\_\_oai\_logTTI?window.\_\_oai\_logTTI():window.\_\_oai\_SSR\_TTI=window.\_\_oai\_SSR\_TTI||Date.now()}))” Does anyone know what it could be, if it could be an error or something significant? </code></pre> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Cosas_Sueltas"> /u/Cosas_Sueltas </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikdj52/help_with_code/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikdj52/help_with_code/">[comments]</a></span>

## How has AI made things worse in your industry?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikcukd/how_has_ai_made_things_worse_in_your_industry](https://www.reddit.com/r/ArtificialInteligence/comments/1ikcukd/how_has_ai_made_things_worse_in_your_industry)
 - RSS feed: $source
 - date published: 2025-02-08T02:33:58+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;ll start: I work in the film industry. Besides garbage generated videos filling up my feed... so many writers and directors use AI to write film treatments and pitch decks. I feel like a word-salad thrown in my face, which they may not even have read. The standards getting lower and lower.</p> <p>I&#39;m curious about other industry.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/jimppqq"> /u/jimppqq </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikcukd/how_has_ai_made_things_worse_in_your_industry/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ikcukd/how_has_ai_made_things_worse_in_your_industry/">[comments]</a></span>

## why ansi is probably a more intelligent and faster route to asi than first moving through agi
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikch1h/why_ansi_is_probably_a_more_intelligent_and](https://www.reddit.com/r/ArtificialInteligence/comments/1ikch1h/why_ansi_is_probably_a_more_intelligent_and)
 - RSS feed: $source
 - date published: 2025-02-08T02:14:40+00:00

<!-- SC_OFF --><div class="md"><p>the common meme is that first we get to agi, and that allows us to quickly thereafter get to asi. what people miss is that ansi, (artificial narrow superintelligence) is probably a much more intelligent, cost-effective and faster way to get there. </p> <p>here&#39;s why. with agi you expect an ai to be as good as humans on pretty much everything. but that&#39;s serious overkill. for example, an agi doesn&#39;t need to be able to perform the tasks of a surgeon to help us create an asi.</p> <p>so the idea is to have ais be trained as agentic ais that are essentially ansis. what i mean is that you want ais to be superintelligent in various very specific engineering and programming tasks like pre-training, fine-tuning, project management and other specific tasks required to get to asi. its much easier and more doable to have an ai achieve this superior performance in those more narrow domains than to be able to ace them all.</p> <p>while it would be grea

## Ai systems with unacceptable risk now banned in the eu
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ikc0gp/ai_systems_with_unacceptable_risk_now_banned_in](https://www.reddit.com/r/ArtificialInteligence/comments/1ikc0gp/ai_systems_with_unacceptable_risk_now_banned_in)
 - RSS feed: $source
 - date published: 2025-02-08T01:51:50+00:00

<!-- SC_OFF --><div class="md"><p><a href="https://futurology.today/post/3568288">https://futurology.today/post/3568288</a></p> <p>Direct link to article:</p> <p><a href="https://techcrunch.com/2025/02/02/ai-systems-with-unacceptable-risk-are-now-banned-in-the-eu/">https://techcrunch.com/2025/02/02/ai-systems-with-unacceptable-risk-are-now-banned-in-the-eu/</a>?</p> <p>Some of the unacceptable activities include:</p> <p>AI used for social scoring (e.g., building risk profiles based on a person’s behavior).</p> <p>AI that manipulates a person’s decisions subliminally or deceptively.</p> <p>AI that exploits vulnerabilities like age, disability, or socioeconomic status.</p> <p>AI that attempts to predict people committing crimes based on their appearance.</p> <p>AI that uses biometrics to infer a person’s characteristics, like their sexual orientation.</p> <p>AI that collects “real time” biometric data in public places for the purposes of law enforcement.</p> <p>AI that tries to infer p

## I'm not happy with the human body, what?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ika6uo/im_not_happy_with_the_human_body_what](https://www.reddit.com/r/ArtificialInteligence/comments/1ika6uo/im_not_happy_with_the_human_body_what)
 - RSS feed: $source
 - date published: 2025-02-08T00:22:50+00:00

<!-- SC_OFF --><div class="md"><p>Today, feeling unwell, I was thinking: why do we have to feel all of this? Why do we have to get tired, hungry, sleepy, in pain, stressed, anxious? Why do we have to be human? Of course, our bodies have many positive aspects, like discovering, falling in love, or feeling happiness, but when I really think about it, I&#39;m not satisfied with the human body.</p> <p>This might sound strange or as if I don’t appreciate life, but—is life really a gift? Is it a gift for everyone? What about people who are born with degenerative diseases from the very beginning of their lives? Would they consider life a gift?</p> <p>These are things I think about when I’m bored. But I was also thinking, hopefully, in the future, we’ll be able to significantly improve our own bodies. And no, I’m not saying we should be eternal—far from it. But life would be considerably better if it weren’t a constant struggle until the end. I’m still young, but I hope to live in a time whe

