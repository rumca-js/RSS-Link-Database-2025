[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-04T19:34:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Help needed! I tried to download the time series of Heritage Foundation Economic Freedom Index. But its website seems to only allow me to download 2024 data, even the web-based query shows the time series. I would appreciate any help on this. The URL is: <a href=\"https://www.heritage.org/index/pages/all-country-scores\">https://www.heritage.org/index/pages/all-country-scores</a></p> <p>I saw a previous post about using the Chrome Developer tool, but I could not find any CSV file under the Network. </p> <p>#webdatascrapper</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Commercial_Share_744\"> /u/Commercial_Share_744 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ihq8w8/scraping_heritage_foundation_economic_freedom/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ihq8w8/scraping_heritage_foundation_economic_freedom/\">[comments]</a></span>",
        "id": 2042483,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ihq8w8/scraping_heritage_foundation_economic_freedom",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Heritage Foundation Economic Freedom Index",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-04T15:26:01+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1ihk5t9/i_created_an_agent_that_browses_the_web_using_a/\"> <img src=\"https://preview.redd.it/m5wxsnih45he1.gif?width=640&amp;crop=smart&amp;s=6a010e13c98d6eaeb603a3196cefb6866e126af5\" alt=\"I created an agent that browses the web using a vision language model\" title=\"I created an agent that browses the web using a vision language model\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/spacespacespapce\"> /u/spacespacespapce </a> <br/> <span><a href=\"https://i.redd.it/m5wxsnih45he1.gif\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ihk5t9/i_created_an_agent_that_browses_the_web_using_a/\">[comments]</a></span> </td></tr></table>",
        "id": 2039383,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ihk5t9/i_created_an_agent_that_browses_the_web_using_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/m5wxsnih45he1.gif?width=640&crop=smart&s=6a010e13c98d6eaeb603a3196cefb6866e126af5",
        "title": "I created an agent that browses the web using a vision language model",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-04T15:25:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m working on the demo of my product and since the beginning, for the scraping part I use my own scripts based on beautiful soup, lxml and requests. I also use VPNs and proxies or selenium when needed.</p> <p>I have tested different API providers at the very beginning of the project but I have some restrictions so I can&#39;t deal with just anyone. One thing that immediately annoyed me is they sell their API/platform as if it could scrape EVERYTHING natively while ... just no. And while testing their API, mostly I received parts of the web pages or social networks I never asked for. Moreover one request on two I sent was never processed. That&#39;s why I chose to build my own crawling and scraping infrastructure.</p> <p>I recently realized more and more scraping tools are based on AI. It made me remember one of the defective API providers I have tested was working on AI-based scraping methods when I called him.</p> <p>I&#39;d like to know what i",
        "id": 2039384,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ihk52q/are_you_using_your_own_script_api_or_ai_tools_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are you using your own script, API or AI tools to scrape ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-04T13:01:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels\u2014whether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>As with our <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">monthly thread</a>, self-promotions and paid products are welcome here \ud83e\udd1d</p> <p>If you&#39;re new to web scraping, make sure to check out the <a href=\"https://webscraping.fyi\">Beginners Guide</a> \ud83c\udf31</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ihh437/weekly_webscrapers_hiring_faqs_etc/\">[l",
        "id": 2038315,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ihh437/weekly_webscrapers_hiring_faqs_etc",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weekly Webscrapers - Hiring, FAQs, etc",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-04T08:41:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been working on a project that I think many of you might find useful, especially if you\u2019re dealing with Chrome automation or batch downloading web pages.</p> <p><a href=\"https://github.com/musaspacecadet/aws_lambda_chrome_starter\">https://github.com/musaspacecadet/aws_lambda_chrome_starter</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/musaspacecadet\"> /u/musaspacecadet </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ihdbgs/aws_lambda_chrome_gui_mode_starter/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ihdbgs/aws_lambda_chrome_gui_mode_starter/\">[comments]</a></span>",
        "id": 2036847,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ihdbgs/aws_lambda_chrome_gui_mode_starter",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AWS lambda chrome GUI mode starter",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-04T07:59:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Its the most basic version (/cdn-cgi/challenge-platform/h/b/jsd), but it\u2018s something\ud83e\udd37\u200d\u2642\ufe0f</p> <p><a href=\"https://github.com/xkiian/cloudflare-jsd\">https://github.com/xkiian/cloudflare-jsd</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/xkiiann\"> /u/xkiiann </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ihcrqr/i_reverse_engineered_the_cloudflare_jsd_challenge/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ihcrqr/i_reverse_engineered_the_cloudflare_jsd_challenge/\">[comments]</a></span>",
        "id": 2036846,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ihcrqr/i_reverse_engineered_the_cloudflare_jsd_challenge",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I reverse engineered the cloudflare jsd challenge",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-04T04:05:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"http://stake.com\">stake.com</a> is a betting site, I want to have this &quot;mother&quot; account, where every action (every placed bet) is replicated in other account. </p> <p>I believe every time a user places a bet, a request is sent to stake servers, with api keys, and bet info, if this is the case then to replicate this behavior I should just change the api key?</p> <p>Still, I&#39;ve no clue how to check this. I can do the coding, but idk the endpoints...</p> <p>help pls :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Chuti0800\"> /u/Chuti0800 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ih94ra/want_to_automate_this_behavior_in_stakecom/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ih94ra/want_to_automate_this_behavior_in_stakecom/\">[comments]</a></span>",
        "id": 2035895,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ih94ra/want_to_automate_this_behavior_in_stakecom",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Want to automate this behavior in stake.com",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-04T02:30:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have built a bunch of webscrapers in VS Code using python. I manually start them everyday. What kind of tools I can use to automatically run them locally on a schedule and save them in a database? Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NerfEveryoneElse\"> /u/NerfEveryoneElse </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ih7bbs/tools_to_automate_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ih7bbs/tools_to_automate_scraping/\">[comments]</a></span>",
        "id": 2035472,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ih7bbs/tools_to_automate_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tools to automate scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-04T01:47:08+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1ih6f77/does_anyone_recognize_this_format_i_misplaced_the/\"> <img src=\"https://b.thumbs.redditmedia.com/7xJYDCeWXeUzQctmZLasN3KOJPwmWzjtncT4R1x34IE.jpg\" alt=\"Does anyone recognize this format? I misplaced the folder I was using to archive some stories and can't remember the scraper I used. All I've got is this rules list and this failed download log. Both were in .csv format, and Skip Reason includes &quot;External&quot;, &quot;Failed&quot; and &quot;Distance Too Large&quot;\" title=\"Does anyone recognize this format? I misplaced the folder I was using to archive some stories and can't remember the scraper I used. All I've got is this rules list and this failed download log. Both were in .csv format, and Skip Reason includes &quot;External&quot;, &quot;Failed&quot; and &quot;Distance Too Large&quot;\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LandscapeOk972\"> /u/LandscapeOk972 ",
        "id": 2035663,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ih6f77/does_anyone_recognize_this_format_i_misplaced_the",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/7xJYDCeWXeUzQctmZLasN3KOJPwmWzjtncT4R1x34IE.jpg",
        "title": "Does anyone recognize this format? I misplaced the folder I was using to archive some stories and can't remember the scraper I used. All I've got is this rules list and this failed download log. Both were in .csv format, and Skip Reason includes \"External\", \"Failed\" and \"Distance Too Large\"",
        "vote": 0
    }
]