# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## I give up scraping this apidog doc website
 - [https://www.reddit.com/r/webscraping/comments/1irpbcl/i_give_up_scraping_this_apidog_doc_website](https://www.reddit.com/r/webscraping/comments/1irpbcl/i_give_up_scraping_this_apidog_doc_website)
 - RSS feed: $source
 - date published: 2025-02-17T17:28:06+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1irpbcl/i_give_up_scraping_this_apidog_doc_website/"> <img src="https://a.thumbs.redditmedia.com/DCYaM5jl1F3f0JTCkaTv5p8SaVvTGBVk3LfG5moexh8.jpg" alt="I give up scraping this apidog doc website" title="I give up scraping this apidog doc website" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p><a href="https://docs.zid.sa/">https://docs.zid.sa/</a> uses APIdog and they on purpose ignore the pathing so it&#39;s hard to extract, any help would be extremely appreciated.</p> <p>also they locked cloning, what is wrong with people forcing devs to go to the website.</p> <p><a href="https://preview.redd.it/0tksnsvwhqje1.png?width=1551&amp;format=png&amp;auto=webp&amp;s=faf0a831525dd74d30333dbd19de4825f3673d3a">URL slug and every parameter that make pathing easy is missing</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/xYousef"> /u/xYousef </a> <br/> <span><a href="https://ww

## Trying to extract some verbs from Wikipedia; which tool?
 - [https://www.reddit.com/r/webscraping/comments/1irk4xu/trying_to_extract_some_verbs_from_wikipedia_which](https://www.reddit.com/r/webscraping/comments/1irk4xu/trying_to_extract_some_verbs_from_wikipedia_which)
 - RSS feed: $source
 - date published: 2025-02-17T13:44:11+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1irk4xu/trying_to_extract_some_verbs_from_wikipedia_which/"> <img src="https://b.thumbs.redditmedia.com/xJ8-6E3QlbjXRq9ps35Psf7sL6cUczkrqeRIYOQJ4IE.jpg" alt="Trying to extract some verbs from Wikipedia; which tool?" title="Trying to extract some verbs from Wikipedia; which tool?" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>This list of transitive verbs on Wikipedia - what tool would you use to get the verbs themselves as a single list, navigable in a .txt file or similar?</p> <p><a href="https://preview.redd.it/an6g5jtbdpje1.png?width=1226&amp;format=png&amp;auto=webp&amp;s=0a208bbe69c96028103e0468395d6b91153ee81a">21,287 verbs, broken into pages of 200 each. </a></p> <p><a href="https://preview.redd.it/8isk6b0jdpje1.png?width=1862&amp;format=png&amp;auto=webp&amp;s=21c791153370815630dd767e8bc877ff826a9059">https://preview.redd.it/8isk6b0jdpje1.png?width=1862&amp;format=png&amp;auto=webp&amp;s=21c79115337

## A Web Scraper in C++
 - [https://www.reddit.com/r/webscraping/comments/1irh1pz/a_web_scraper_in_c](https://www.reddit.com/r/webscraping/comments/1irh1pz/a_web_scraper_in_c)
 - RSS feed: $source
 - date published: 2025-02-17T10:38:50+00:00

<!-- SC_OFF --><div class="md"><p>So I&#39;ve been researching how to build a web scraper in C++ for some time now but due to the lack of libraries that exist, such as the ones for Python that do, I decided to build my own running on top of the Chromium Embedded Framework. This gets after two of the core issues I was having with generic HTML scraper/parsers and CLI tools: dealing with heavy JavaScript sites and various bot detection methods. </p> <p>Just wanted to post this here to let anyone else thinking about it to know that it is possible to get something working :) and I hadn&#39;t seen this kind of use with CEF before. Github below. Lemme know any thoughts / improvements if you want below! Cheers.</p> <p><a href="https://github.com/CovertRob/web_scraper">https://github.com/CovertRob/web_scraper</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/CovertRob"> /u/CovertRob </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comment

## How can I clone a website using a web scraper?
 - [https://www.reddit.com/r/webscraping/comments/1irfsyx/how_can_i_clone_a_website_using_a_web_scraper](https://www.reddit.com/r/webscraping/comments/1irfsyx/how_can_i_clone_a_website_using_a_web_scraper)
 - RSS feed: $source
 - date published: 2025-02-17T09:08:47+00:00

<!-- SC_OFF --><div class="md"><p>I am working on a project where I have to make a python program that clones a website upto depth 1 and downloads all its html, css and js files. I tried httrack but when I used it on the CNET.com website it doesn&#39;t return all the css and js of the page. </p> <p>I am now thinking of using D4VINCI&#39;S Scrapling to clone a website upto depth 1? How is it possible? And are there any other tools that I can use to achieve this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Aggressive_Limit_657"> /u/Aggressive_Limit_657 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1irfsyx/how_can_i_clone_a_website_using_a_web_scraper/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1irfsyx/how_can_i_clone_a_website_using_a_web_scraper/">[comments]</a></span>

## Scraping my own public FB posts: gauging the time and effort...
 - [https://www.reddit.com/r/webscraping/comments/1irb2ld/scraping_my_own_public_fb_posts_gauging_the_time](https://www.reddit.com/r/webscraping/comments/1irb2ld/scraping_my_own_public_fb_posts_gauging_the_time)
 - RSS feed: $source
 - date published: 2025-02-17T04:00:21+00:00

<!-- SC_OFF --><div class="md"><p>as a novice. Apologies for redundance. </p> <p>Is this achievable from my phone, or easy with S+BS, I am trying to move them into a publishable format. </p> <p>Thanks! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ywkwpwnw"> /u/ywkwpwnw </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1irb2ld/scraping_my_own_public_fb_posts_gauging_the_time/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1irb2ld/scraping_my_own_public_fb_posts_gauging_the_time/">[comments]</a></span>

## Scraping/commenting bot
 - [https://www.reddit.com/r/webscraping/comments/1ir9tm8/scrapingcommenting_bot](https://www.reddit.com/r/webscraping/comments/1ir9tm8/scrapingcommenting_bot)
 - RSS feed: $source
 - date published: 2025-02-17T02:51:20+00:00

<!-- SC_OFF --><div class="md"><p>I am working on a selenium based scraper that crawls through posts on next door, articulates them with chatgpt, and formulated a response in the comments. This is in an attempt to automate some responses on my business profile. I cannot for the life of me get selenium to identify the comment box for me to click and start typing into. </p> <p>def post_comment_by_enter(driver, comment_text): &quot;&quot;&quot; Locates the comment form, scrolls if necessary, forces activation of the text area, types the comment naturally, and submits it while avoiding bot detection. &quot;&quot;&quot;</p> <pre><code>try: logging.info(&quot;ðŸ”Ž Step 1: Searching for the comment form...&quot;) max_scroll_attempts = 5 # Limit scrolling attempts scroll_attempt = 0 comment_form = None while scroll_attempt &lt; max_scroll_attempts: try: # Locate the comment form comment_form = WebDriverWait(driver, 5).until( EC.presence_of_element_located((By.CSS_SELECTOR, &quot;form.comment-bo

## Scraping odds checker
 - [https://www.reddit.com/r/webscraping/comments/1ir6lss/scraping_odds_checker](https://www.reddit.com/r/webscraping/comments/1ir6lss/scraping_odds_checker)
 - RSS feed: $source
 - date published: 2025-02-17T00:06:52+00:00

<!-- SC_OFF --><div class="md"><p>Im trying to scrape oddschecker.com, on specific player lines for certain games. When you click on a players bet ie â€˜Ronaldo to score 2+ goalsâ€™ it gets an API and shows a couple of bookies odds at the price. But if I want to pull every players odds, Iâ€™d have to press the button for the 20+ players and get it that way, which seems tedious. Would there be a faster way to automate this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/bananarama2318"> /u/bananarama2318 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1ir6lss/scraping_odds_checker/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ir6lss/scraping_odds_checker/">[comments]</a></span>

