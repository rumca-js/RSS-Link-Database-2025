[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-07T21:49:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Need help in scraping the data using all possible options present <a href=\"https://scmpbd.org/scip/lmis/form2_view.php\">https://scmpbd.org/scip/lmis/form2_view.php</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok_Listen_6389\"> /u/Ok_Listen_6389 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ik6qi1/need_help_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ik6qi1/need_help_scraping/\">[comments]</a></span>",
        "id": 2068193,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ik6qi1/need_help_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-07T19:03:46+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1ik2t2j/web_scraping_project/\"> <img src=\"https://b.thumbs.redditmedia.com/w1AIiuGADytbzDlX43yUk1E3LlQoGoXJxi4TRA3-Shc.jpg\" alt=\"Web scraping project\" title=\"Web scraping project\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;d like to build a <strong>GitHub</strong> repository to begin a new project for pulling data from the website <a href=\"https://t.co/jVGnhY6oBY\">http://trademap.org</a>. Who wants to join?</p> <p><a href=\"https://preview.redd.it/wflhwrs2mrhe1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=e9d029090e5a879ed21c0888f3fc2e93259ca835\">https://preview.redd.it/wflhwrs2mrhe1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=e9d029090e5a879ed21c0888f3fc2e93259ca835</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Slight_Intention_817\"> /u/Slight_Intention_817 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ik2t2j/web_scr",
        "id": 2067431,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ik2t2j/web_scraping_project",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/w1AIiuGADytbzDlX43yUk1E3LlQoGoXJxi4TRA3-Shc.jpg",
        "title": "Web scraping project",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-07T17:19:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am a Masters Student currently doing my thesis. </p> <p>I am doing a discourse analysis of political messaging made by US politicians. </p> <p>I need to somehow find all the tweets from approx 15 users (Politician&#39;s accounts) containing phrases such as &quot;healthcare&quot; &quot;ACA&quot; &quot;Obamacare&quot; etc. from the time period of at least 2016-2020 if not more.</p> <p>I have almost no programming experience, (I did one semester of Python programming, in my Bachelor but I was so bad at it). </p> <p>Does any have recommendations on what web scraping programs to use or know if there is a way I can achieve this myself by learning to code just specifically for this project (unlikely I know).</p> <p>All suggestions are appreciated and thank you for your patience in advance</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/iwanobitch\"> /u/iwanobitch </a> <br/> <span><a href=\"https://www.reddit.com/r/webs",
        "id": 2067432,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ik099o/scrapping_x_for_masters_thesis",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scrapping X for Masters Thesis",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-07T13:12:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, total beginner here. For a project, i&#39;m trying to attain the src URL for product listings generated by a search URL. Here are the sites: </p> <p>- Depop</p> <p>- Redbubble</p> <p>- Shein </p> <p>For Depop and Redbubble, i attempted to do so and for the sites with a response other than a 403 error, my HTTP response returned garbled binary -- encoding/response type is marked as html/text UTF-8. I understand that not too long ago, it was possible to scrape Depop. I remember seeing a tutorial over it, and also seeing another project from a few years ago on Github, but neither of them work now (requests are blocked by a 403 for the tutorial, and the Github project&#39;s HTML response is [None])</p> <p>For Shein, my response returns the general HTML layout for the site, but none of the product listings. After doing a little digging, it looks like the site first returns the HTML layout and then makes several requests for the image URLs required to f",
        "id": 2063898,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ijunut/looking_to_scrape_images_from_shopping_sites",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "looking to scrape images from shopping sites",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-07T11:03:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Can you please suggest a service where we can buy (rent) US resident proxies with regular (daily) rotation of ip-addresses with minimum payment for traffic? Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/maxim-kulgin\"> /u/maxim-kulgin </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ijsj4y/optimal_proxy_provider_for_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ijsj4y/optimal_proxy_provider_for_scraping/\">[comments]</a></span>",
        "id": 2063064,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ijsj4y/optimal_proxy_provider_for_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Optimal proxy provider for scraping?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-07T08:46:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I am running quite a big scraping operation (about 700M monthly requests, ideally 1000+ threads) And I am curious about the type of proxies/pricing you guys get. My target even allows datacenter proxies, but its obviously not guaranteed. Ive been looking on the internet and only ever found bad deals where you pay 800 USD for 1000 IPs and that be called \u201crotating\u201d.</p> <p>So to summarize, I am looking for rotating datacenter proxies with BIG pool, BIG concurrency and of course on the cheaper side, but I\u2019m happy to look into anything </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/guardsman000071\"> /u/guardsman000071 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ijqltp/looking_for_large_scale_scraping_proxies/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ijqltp/looking_for_large_scale_scraping_proxies/\">[comments]</a></span>",
        "id": 2062420,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ijqltp/looking_for_large_scale_scraping_proxies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for Large Scale Scraping Proxies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-07T05:48:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m curious about how everyone handles various types of crawlers, schedules tasks, monitors link status, visualizes statistics, etc ?</p> <p>It is easy to handle few crawler scripts, but when there are more crawl tasks, managing many crawlers may become difficult. And larger data requires more robust system and higher efficiency.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/zen_in_box\"> /u/zen_in_box </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ijo45b/in_2025_what_web_crawler_management_systems_are/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ijo45b/in_2025_what_web_crawler_management_systems_are/\">[comments]</a></span>",
        "id": 2061909,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ijo45b/in_2025_what_web_crawler_management_systems_are",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "In 2025, what web crawler management systems are you using?",
        "vote": 0
    }
]