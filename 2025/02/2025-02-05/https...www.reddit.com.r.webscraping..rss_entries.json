[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-05T20:55:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I am looking to scrape a list of all of the partners for an accounting software company. </p> <p>Is is a one off job but there are lots of different pages to get information from per partner.</p> <p>Any advice? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/willandthemsome\"> /u/willandthemsome </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iikl95/scraping_a_partner_directory/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iikl95/scraping_a_partner_directory/\">[comments]</a></span>",
        "id": 2050362,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iikl95/scraping_a_partner_directory",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping a partner directory",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-05T20:23:30+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello Guys i have a question i saw this github post <a href=\"https://github.com/Probabilities/Metrix-Reverse\">https://github.com/Probabilities/Metrix-Reverse</a></p> <p>and how do you people learn this like how do you reverse the site so deep? (i just wanna learn)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Fit_Chocolate771\"> /u/Fit_Chocolate771 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iijtt9/website_reverse/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iijtt9/website_reverse/\">[comments]</a></span>",
        "id": 2050819,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iijtt9/website_reverse",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Website Reverse",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-05T18:17:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>My cofounder and I have been developing a tool that scrapes law firm directories and then tracks any movement to and from the directory in order to follow the movements of lawyers.</p> <p>The idea is to then sell this data (lawyers name, contact number on directory, email address, and position) to a specific industry that would find this kind of data valuable.</p> <p>Is this legal to do? Are there any parameters here, and is there anything that we need to be careful of?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/3leavclova\"> /u/3leavclova </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iigp3b/scraping_law_firms_legality/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iigp3b/scraping_law_firms_legality/\">[comments]</a></span>",
        "id": 2049441,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iigp3b/scraping_law_firms_legality",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Law Firms Legality",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-05T16:00:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone, I hope you&#39;re all doing well.</p> <p>I want to start my post off by saying I know a little bit about web-scraping, and how it works; but nothing too much. A friend of mine asked me to try and help him with scraping some images off a website that is protected by what I assume to be sessions keys/cookies from a website called Pixiv Fanbox. </p> <p>The website is <a href=\"https://hagureoekaki.wp.xdomain.jp/wp-content/uploads/2025/01/87fe9d15a214195683094fceae79df1d.png\">https://hagureoekaki.wp.xdomain.jp/wp-content/uploads/2025/01/87fe9d15a214195683094fceae79df1d.png</a> (however what I provided is one of the many images on this website)</p> <p>I assume the website grabs your cookie/session ID from the creator&#39;s pixiv fanbox, matches it, then allows you to see the image. HOWEVER, I was able to pull these images before with </p> <p>curl -o image.png <a href=\"https://hagureoekaki.wp.xdomain.jp/wp-content/uploads/2025/01/87fe9d15a21",
        "id": 2048851,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iidb3k/need_help_with_scraping_this_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need Help With Scraping This Website!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-05T13:18:57+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1ii9qhv/how_to_debug_cloudflares_403/\"> <img src=\"https://b.thumbs.redditmedia.com/R-dc2NgsRZ1cJ5vgrZjP_3FKIlQEaRpYr2SL5oOwXtI.jpg\" alt=\"How to debug Cloudflare's 403\" title=\"How to debug Cloudflare's 403\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/sr212t42mbhe1.png?width=1730&amp;format=png&amp;auto=webp&amp;s=0ab5829c2746bc4667154991da54670da6b3c785\">https://preview.redd.it/sr212t42mbhe1.png?width=1730&amp;format=png&amp;auto=webp&amp;s=0ab5829c2746bc4667154991da54670da6b3c785</a></p> <p><a href=\"https://preview.redd.it/hntfygr4mbhe1.png?width=2016&amp;format=png&amp;auto=webp&amp;s=fa084f9d1cc7b0e99749261774313dd2d2c407eb\">https://preview.redd.it/hntfygr4mbhe1.png?width=2016&amp;format=png&amp;auto=webp&amp;s=fa084f9d1cc7b0e99749261774313dd2d2c407eb</a></p> <p>Hello, trying to learn web scraping and stuck on the Cloudflare Challenge on Scraping Course. Trying to debug ",
        "id": 2050820,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ii9qhv/how_to_debug_cloudflares_403",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/R-dc2NgsRZ1cJ5vgrZjP_3FKIlQEaRpYr2SL5oOwXtI.jpg",
        "title": "How to debug Cloudflare's 403",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-05T06:26:15+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want User name, title, rating, review content, and date of the review published.</p> <p>And yes, no money to spend. I have ASIN codes.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Appropriate-Jello308\"> /u/Appropriate-Jello308 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ii3v1f/1000_latest_amazon_reviews/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ii3v1f/1000_latest_amazon_reviews/\">[comments]</a></span>",
        "id": 2044824,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ii3v1f/1000_latest_amazon_reviews",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "1000 latest Amazon Reviews.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-05T04:40:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I want to see if AI and web scraping could help me with a task I am currently doing manually. Basically, I go to this website (<a href=\"https://www.languagecourse(dot)net/schools--ireland/junior\">https://www.languagecourse(dot)net/schools--ireland/junior</a>) and search for school names on Google to find their URLs. I then visit the URLs to locate their email(s). I compile all this information into an Excel list with the school name, website, and email.</p> <p>Is it possible to automate or simplify this process with web scraping and AI? Which service can do this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ronconpasas\"> /u/ronconpasas </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ii25kh/is_this_possible_with_webscraping_and_ai/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ii25kh/is_this_possible_with_webscraping_and_ai/\">[comments]</a><",
        "id": 2044575,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ii25kh/is_this_possible_with_webscraping_and_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is this possible with WebScraping and AI?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-05T04:40:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Let\u2019s say I want to I want to archive an entire website with around 10,000 pages. A website with mostly text and HTML/CSS, like an old web forum. And then to get the result in WARC files or something similar. </p> <p>Are there paid services that offer deep web crawling and export to an open format like WARC for a reasonable price? </p> <p>(I apologize if I&#39;m asking I question that&#39;s been asked and answered many times. I checked the wiki, I checked the guide, I searched for posts, and I did some Google searches before asking here.)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/didyousayboop\"> /u/didyousayboop </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ii258m/what_is_a_cheap_paid_service_to_archive_an_entire/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ii258m/what_is_a_cheap_paid_service_to_archive_an_entire/\">[comments]</a></span>",
        "id": 2044358,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ii258m/what_is_a_cheap_paid_service_to_archive_an_entire",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What is a cheap paid service to archive an entire large website?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-02-05T00:06:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Does anyone know of a tool to run a search for press releases/public company articles?</p> <p>I have a huge list of companies and I want to run a search for any time any of these companies has mentioned a set of keywords, which means they might be interested in my product.</p> <p>I\u2019ve tried using ChatGPT with no luck, so wondered if anyone here knows of a tool that could pull this off?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kj160\"> /u/Kj160 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ihwp4v/tool_to_search_for_press_releases/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ihwp4v/tool_to_search_for_press_releases/\">[comments]</a></span>",
        "id": 2043266,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ihwp4v/tool_to_search_for_press_releases",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tool to search for press releases",
        "vote": 0
    }
]