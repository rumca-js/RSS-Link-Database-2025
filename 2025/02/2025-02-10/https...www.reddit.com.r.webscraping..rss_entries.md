# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Hidden Link Scavenger Hunt
 - [https://www.reddit.com/r/webscraping/comments/1imji0p/hidden_link_scavenger_hunt](https://www.reddit.com/r/webscraping/comments/1imji0p/hidden_link_scavenger_hunt)
 - RSS feed: $source
 - date published: 2025-02-10T22:45:58+00:00

<!-- SC_OFF --><div class="md"><p>Hey guys, my school hid a link to enter a priority housing raffle in their website. Any way you guys could help me look for it. Here is the email: Can&#39;t participate tomorrow? We are also holding an online Golden Ticket Raffle! There is a hidden link to a Reapplication Quiz on our Residence Life website. Find the quiz by 5pm on 2/14, get all three answers right, and be entered in a raffle to win a priority lottery number. Winners will be announced on Monday, February 17. Link to website: <a href="https://www.luc.edu/reslife/">https://www.luc.edu/reslife/</a> Thank you so much!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/EvanJPim14"> /u/EvanJPim14 </a> <br/> <span><a href="https://www.luc.edu/reslife/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1imji0p/hidden_link_scavenger_hunt/">[comments]</a></span>

## X scrapping via nitter in 2025 still valid?
 - [https://www.reddit.com/r/webscraping/comments/1imfytk/x_scrapping_via_nitter_in_2025_still_valid](https://www.reddit.com/r/webscraping/comments/1imfytk/x_scrapping_via_nitter_in_2025_still_valid)
 - RSS feed: $source
 - date published: 2025-02-10T20:20:10+00:00

<!-- SC_OFF --><div class="md"><p>Hello. I&#39;m really new to scrapping but I&#39;ve been doing some reading and researching. X has really gone to shit, but I use it primarily to look at merchandise. I discovered nitter this morning and I&#39;m trying to see if it&#39;s a valid way of getting info from? I&#39;ve read X can ban your IP if you scrape from their website. Is nitter a valid way of doing this to avoid an IP ban? Are there things I should take into consideration, like poll rate, etc?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/FuaT10"> /u/FuaT10 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1imfytk/x_scrapping_via_nitter_in_2025_still_valid/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1imfytk/x_scrapping_via_nitter_in_2025_still_valid/">[comments]</a></span>

## Using Zendriver to grab current URL after redirect
 - [https://www.reddit.com/r/webscraping/comments/1ime887/using_zendriver_to_grab_current_url_after_redirect](https://www.reddit.com/r/webscraping/comments/1ime887/using_zendriver_to_grab_current_url_after_redirect)
 - RSS feed: $source
 - date published: 2025-02-10T19:11:06+00:00

<!-- SC_OFF --><div class="md"><p>So I have a login process I&#39;m trying to automate for Oauth. I get logged in and all the buttons pressed without issue then I get redirected to my localhost callback url. This is the url I need to pull from the browser. The page doesn&#39;t load since its not an actual website but the url contains my auth code to generate a new token. </p> <p>Since the page doesn&#39;t load tab.url is giving me this &quot;chrome-error://chromewebdata/&quot; </p> <p>Tried &quot;window.location.href&quot; as well but that also gives me the chrome error. </p> <p>Anyone got ideas on what I could do to grab the callback url?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/NewKindaSpecial"> /u/NewKindaSpecial </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1ime887/using_zendriver_to_grab_current_url_after_redirect/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ime887/

## Is this possible? — Custom calendar from set of urls
 - [https://www.reddit.com/r/webscraping/comments/1im9uza/is_this_possible_custom_calendar_from_set_of_urls](https://www.reddit.com/r/webscraping/comments/1im9uza/is_this_possible_custom_calendar_from_set_of_urls)
 - RSS feed: $source
 - date published: 2025-02-10T16:17:08+00:00

<!-- SC_OFF --><div class="md"><p>I have a list of venue websites that I reference regularly to see what events are coming up in my area. I would like to create a calendar that is populated by the events that those venues post on their own websites/pages. The event data will not be consistently formatted across the different websites I&#39;d like to pull from.</p> <p>I have no back end code skills and minimal CSS experience. Is it possible to aggregate this data in a no-code way? Maybe with the help of a web scraper? Bonus question: Is there a low-code way to take this aggregated data and make is show up in a calendar format?</p> <p>Example websites to pull data from: <a href="https://theveraproject.org/events/">https://theveraproject.org/events/</a> <a href="https://www.waywardmusic.org/">https://www.waywardmusic.org/</a></p> <p>Thanks so much for any leads/suggestions.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/avereee"> /u/avereee </a> <

## Extracting links with crawl4ai on a JavaScript website
 - [https://www.reddit.com/r/webscraping/comments/1im3zk4/extracting_links_with_crawl4ai_on_a_javascript](https://www.reddit.com/r/webscraping/comments/1im3zk4/extracting_links_with_crawl4ai_on_a_javascript)
 - RSS feed: $source
 - date published: 2025-02-10T11:28:31+00:00

<!-- SC_OFF --><div class="md"><p>I recently discovered crawl4ai and read through the entire documentation.</p> <p>Now I wanted to start what I thought was a simple project as a test and failed. Maybe someone here can help me or give me a tip.</p> <p>I would like to extract the links to the job listings on a website.<br/> Here is the code I use:</p> <pre><code>import asyncio import asyncpg from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode async def main(): # BrowserConfig – Dictates how the browser is launched and behaves browser_cfg = BrowserConfig( # headless=False, # Headless means no visible UI. False is handy for debugging. # text_mode=True # If True, tries to disable images/other heavy content for speed. ) load_js = &quot;&quot;&quot; await new Promise(resolve =&gt; setTimeout(resolve, 5000)); window.scrollTo(0, document.body.scrollHeight); &quot;&quot;&quot; # CrawlerRunConfig – Dictates how each crawl operates crawler_cfg = CrawlerRunConfig( sca

## Anyone know how this site has access to 10,000 news articles daily
 - [https://www.reddit.com/r/webscraping/comments/1im3r6h/anyone_know_how_this_site_has_access_to_10000](https://www.reddit.com/r/webscraping/comments/1im3r6h/anyone_know_how_this_site_has_access_to_10000)
 - RSS feed: $source
 - date published: 2025-02-10T11:13:29+00:00

<!-- SC_OFF --><div class="md"><p>I would like to a real time feed of around 200 news articles daily for my site to track Global news that happends in real time. I&#39;ve been struggling to scrape different sites and using APIs that offer small amount of free credits</p> <p>I was wondering how do you guys think a site like <a href="https://www.newsminimalist.com/about">https://www.newsminimalist.com/about</a> scrapes 10,000+ news daily. Im guessing they pay for an api like <a href="http://newsdata.io">newsdata.io</a> or or some other form of news API. </p> <p>My question is, is there a way to scrape real time news daily, from various different sources like newsminimalist do but without paying something like $300 a month. Again, I&#39;ve tried to use scrapers and it becomes painful when you want to access loads of different sources, I&#39;ve manually built a scraper that scrapes 4-5 news sources like BBC, Al Jazeera, Yahoo news etc but I&#39;d like a greater variety.</p> <p>Anyone kno

## How to fetch accurate Google Place ID from an address?
 - [https://www.reddit.com/r/webscraping/comments/1im2lri/how_to_fetch_accurate_google_place_id_from_an](https://www.reddit.com/r/webscraping/comments/1im2lri/how_to_fetch_accurate_google_place_id_from_an)
 - RSS feed: $source
 - date published: 2025-02-10T09:53:51+00:00

<!-- SC_OFF --><div class="md"><p>In my Python script, I am trying to fetch the Google Place ID using <code>googleapis</code> passing the address along with the latitude and longitude. However, the returned place ID differs from the actual place ID. Is there any way to achieve an accurate place ID?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Level_River_468"> /u/Level_River_468 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1im2lri/how_to_fetch_accurate_google_place_id_from_an/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1im2lri/how_to_fetch_accurate_google_place_id_from_an/">[comments]</a></span>

## Google vs. Scrapers: The Double Standard in Image Use
 - [https://www.reddit.com/r/webscraping/comments/1ilz0fu/google_vs_scrapers_the_double_standard_in_image](https://www.reddit.com/r/webscraping/comments/1ilz0fu/google_vs_scrapers_the_double_standard_in_image)
 - RSS feed: $source
 - date published: 2025-02-10T05:36:57+00:00

<!-- SC_OFF --><div class="md"><p>Google routinely displays images sourced from other websites within its search results, a practice that appears similar to web scraping. However, scraping by others is often viewed negatively, and can even lead to penalties. Why is Google&#39;s use of images considered an acceptable practice, while similar activities by other parties are often frowned upon or actively discouraged? Is there a justifiable difference, or does this represent a double standard in how web content is utilized?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ayushsuri"> /u/ayushsuri </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1ilz0fu/google_vs_scrapers_the_double_standard_in_image/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ilz0fu/google_vs_scrapers_the_double_standard_in_image/">[comments]</a></span>

## Any tools to help scrape app instead of site ?
 - [https://www.reddit.com/r/webscraping/comments/1ilu0tq/any_tools_to_help_scrape_app_instead_of_site](https://www.reddit.com/r/webscraping/comments/1ilu0tq/any_tools_to_help_scrape_app_instead_of_site)
 - RSS feed: $source
 - date published: 2025-02-10T00:51:38+00:00

<!-- SC_OFF --><div class="md"><p>I need a good tool to help scrape off an app ? Anybody know off one ? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Slow_Yesterday_6407"> /u/Slow_Yesterday_6407 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1ilu0tq/any_tools_to_help_scrape_app_instead_of_site/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ilu0tq/any_tools_to_help_scrape_app_instead_of_site/">[comments]</a></span>

