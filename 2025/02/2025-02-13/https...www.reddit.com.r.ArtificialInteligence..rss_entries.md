# Source:Artificial Intelligence Gateway, URL:https://www.reddit.com/r/ArtificialInteligence/.rss, language:

## [Help Needed] Developing an AI to Play Mini Metro – Struggling with Data Extraction & Strategy method...
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iowpgo/help_needed_developing_an_ai_to_play_mini_metro](https://www.reddit.com/r/ArtificialInteligence/comments/1iowpgo/help_needed_developing_an_ai_to_play_mini_metro)
 - RSS feed: $source
 - date published: 2025-02-13T23:24:53+00:00

<!-- SC_OFF --><div class="md"><p>Hello everyone !</p> <p>First of all, please excuse my English if i do mistakes, as it is not my native language and I am not necessarily comfortable with it :)</p> <p>Regarding this project, I will explain my initial intention. I know very little about coding, but I enjoy it and have had some Python lessons, along with a few small personal projects for fun, mostly using YouTube tutorials. Nothing too advanced...</p> <p>However, now I want to take it to the next level. Since I have some familiarity with coding, I’ve wanted to work on artificial intelligence for a while. I have never coded AI myself, but I enjoy downloading existing projects (for chess, checkers, cat-and-mouse games, etc.), testing their limits, and understanding how they work.</p> <p>One of my favorite strategy game genres is management games, especially Mini Metro. Given its relatively simple mechanics, I assumed there would already be AI projects for it. But to my surprise, I could

## Could artificial intelligence be evil?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iow3t2/could_artificial_intelligence_be_evil](https://www.reddit.com/r/ArtificialInteligence/comments/1iow3t2/could_artificial_intelligence_be_evil)
 - RSS feed: $source
 - date published: 2025-02-13T22:57:16+00:00

<!-- SC_OFF --><div class="md"><p>Do you believe artificial Intelligence has evil tendencies? It is my opinion that AI is incapable of experiencing true and real love. This being said people of faith believe God is love. So by integrating AI with our daily human life, we are slowly removing what was once pure humanity and love to a heartless society eventually turning into perhaps a literal hell on earth. It’s my opinion we have to set strict limits and boundaries early on while wading in this potential dangerous territory. Could AI be the Antichrist? Is anyone else concerned? Feedback is appreciated. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/J1mmyA"> /u/J1mmyA </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iow3t2/could_artificial_intelligence_be_evil/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iow3t2/could_artificial_intelligence_be_evil/">[comments

## Is AI learning ANYTHING from us?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iovwl1/is_ai_learning_anything_from_us](https://www.reddit.com/r/ArtificialInteligence/comments/1iovwl1/is_ai_learning_anything_from_us)
 - RSS feed: $source
 - date published: 2025-02-13T22:48:13+00:00

<!-- SC_OFF --><div class="md"><p>It really seems to me that now that we humans are getting good at detecting AI content (pictures of people with six fingers, three legs extra appendages) that AI should have been way ahead of us. Isn’t it learning from our learning?</p> <p>Text responses in ChaGPT? Well, ya got me there. As far as I can tell there’s a human in the back room. But pictures? C’mon can’t it do better than that?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/InevitableStruggle"> /u/InevitableStruggle </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iovwl1/is_ai_learning_anything_from_us/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iovwl1/is_ai_learning_anything_from_us/">[comments]</a></span>

## When did you start paying for AI apps, and what made you upgrade?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iovfph/when_did_you_start_paying_for_ai_apps_and_what](https://www.reddit.com/r/ArtificialInteligence/comments/1iovfph/when_did_you_start_paying_for_ai_apps_and_what)
 - RSS feed: $source
 - date published: 2025-02-13T22:27:26+00:00

<!-- SC_OFF --><div class="md"><p>Do you actually switch between different models (GPT4/Claude/DeepSeek), or mostly stick to one?</p> <p>For people using many AI tools: Is it worth paying for all of them? I&#39;m curious to know not only about the general apps like ChatGPT, but maybe some fun apps for photo editing, video creation, etc.</p> <p>Personally, we are paying for ChatGPT and Claude, and they&#39;re both worth the cost.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/PrestigiousPlan8482"> /u/PrestigiousPlan8482 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iovfph/when_did_you_start_paying_for_ai_apps_and_what/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iovfph/when_did_you_start_paying_for_ai_apps_and_what/">[comments]</a></span>

## Billionaires are the worst people to decide what AI should be
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iov92w/billionaires_are_the_worst_people_to_decide_what](https://www.reddit.com/r/ArtificialInteligence/comments/1iov92w/billionaires_are_the_worst_people_to_decide_what)
 - RSS feed: $source
 - date published: 2025-02-13T22:19:31+00:00

<!-- SC_OFF --><div class="md"><p>Billionaires think it&#39;s okay to hoard resources, yet they are the ones deciding the direction of AI and AGI, which will impact life in the universe, perhaps even reality itself.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Pareidolie"> /u/Pareidolie </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iov92w/billionaires_are_the_worst_people_to_decide_what/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iov92w/billionaires_are_the_worst_people_to_decide_what/">[comments]</a></span>

## Great Power Brings Great Responsibility Personalizing Conversational AI for Diverse Problem-Solvers
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iotqk1/great_power_brings_great_responsibility](https://www.reddit.com/r/ArtificialInteligence/comments/1iotqk1/great_power_brings_great_responsibility)
 - RSS feed: $source
 - date published: 2025-02-13T21:13:22+00:00

<!-- SC_OFF --><div class="md"><p>Title: Great Power Brings Great Responsibility Personalizing Conversational AI for Diverse Problem-Solvers</p> <p>I&#39;m finding and summarizing interesting AI research papers every day so you don&#39;t have to trawl through them all. Today&#39;s paper is titled &quot;Great Power Brings Great Responsibility: Personalizing Conversational AI for Diverse Problem-Solvers&quot; by Italo Santos, Katia Romero Felizardo, Igor Steinmacher, and Marco A. Gerosa.</p> <p>This paper delves into the potential for using Large Language Models (LLMs) such as ChatGPT to ease the onboarding challenges faced by newcomers in Open Source Software (OSS) projects. It highlights the significant role that conversational AI can play in bridging the gap for diverse problem-solvers by adapting AI responses to suit different problem-solving styles, thus avoiding biases that may favor certain subgroups over others.</p> <p>The key points from the paper are:</p> <ol> <li><p><strong>

## No deep learning after ChatGPT
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ios75y/no_deep_learning_after_chatgpt](https://www.reddit.com/r/ArtificialInteligence/comments/1ios75y/no_deep_learning_after_chatgpt)
 - RSS feed: $source
 - date published: 2025-02-13T20:07:08+00:00

<!-- SC_OFF --><div class="md"><p>Hi </p> <p>I work in the data science division of a big company. We had deep learning related projects before chatGPT got launched. But ever since it&#39;s launch, it&#39;s just promoting, chatbots, voice bots that we are working on. No more deep learning/machine learning projects. </p> <p>Is it also true in your company? If not, what does your DS team work on nowadays. Please share your experience. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/sourabharsh"> /u/sourabharsh </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ios75y/no_deep_learning_after_chatgpt/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ios75y/no_deep_learning_after_chatgpt/">[comments]</a></span>

## California bill would require developers of AI models to document and report all copyrighted training materials with fines of $1,000 per violation
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iortfv/california_bill_would_require_developers_of_ai](https://www.reddit.com/r/ArtificialInteligence/comments/1iortfv/california_bill_would_require_developers_of_ai)
 - RSS feed: $source
 - date published: 2025-02-13T19:51:01+00:00

<!-- SC_OFF --><div class="md"><p>It also says companies have to retain training data records for the model&#39;s lifetime plus 10 years. It looks like it would apply to companies of all sizes, even startups.</p> <p>Heres the source: <a href="https://www.veeto.app/bill/1955758">https://www.veeto.app/bill/1955758</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/milospate"> /u/milospate </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iortfv/california_bill_would_require_developers_of_ai/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iortfv/california_bill_would_require_developers_of_ai/">[comments]</a></span>

## 31 AI projects in 31 days 🤖🦾
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iomtah/31_ai_projects_in_31_days](https://www.reddit.com/r/ArtificialInteligence/comments/1iomtah/31_ai_projects_in_31_days)
 - RSS feed: $source
 - date published: 2025-02-13T16:21:42+00:00

<!-- SC_OFF --><div class="md"><p>This is great: two creatives (adland is dead) dropped an AI build every day of Jan: <a href="https://lab31.xyz">https://lab31.xyz</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/slinky_g"> /u/slinky_g </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iomtah/31_ai_projects_in_31_days/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iomtah/31_ai_projects_in_31_days/">[comments]</a></span>

## What do AI agents landscape really need to take off?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iom3yx/what_do_ai_agents_landscape_really_need_to_take](https://www.reddit.com/r/ArtificialInteligence/comments/1iom3yx/what_do_ai_agents_landscape_really_need_to_take)
 - RSS feed: $source
 - date published: 2025-02-13T15:52:13+00:00

<!-- SC_OFF --><div class="md"><ul> <li>perfect JSON parsing is really a killer feature imho.</li> <li>API calling orchestration is really important too, maybe call a single endpoint (some sort of Zapier for agents).</li> <li>Integration with existing tools (pointing back to the API point) </li> </ul> <p>In my view here is a very messy landscape at the moment (usually this boiling soup is what happens before a player find the right mix and takes off on others, but maybe this is not the case). What&#39;s your view about that?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Consistent_Sally_11"> /u/Consistent_Sally_11 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iom3yx/what_do_ai_agents_landscape_really_need_to_take/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iom3yx/what_do_ai_agents_landscape_really_need_to_take/">[comments]</a></span>

## What kinds of work will the next generation do?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iolm63/what_kinds_of_work_will_the_next_generation_do](https://www.reddit.com/r/ArtificialInteligence/comments/1iolm63/what_kinds_of_work_will_the_next_generation_do)
 - RSS feed: $source
 - date published: 2025-02-13T15:30:34+00:00

<!-- SC_OFF --><div class="md"><p>With so many jobs being eliminated by AI, I can’t help to wonder what kinds of work or job the next generations will be doing? Kids that are graduating from college since last year until now aren’t getting any jobs.</p> <p>Any guess or insights?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/VDtrader"> /u/VDtrader </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iolm63/what_kinds_of_work_will_the_next_generation_do/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iolm63/what_kinds_of_work_will_the_next_generation_do/">[comments]</a></span>

## Anybody who says that there is a 0% chance of AIs being sentient is overconfident. Nobody knows what causes consciousness. We have no way of detecting it & we can barely agree on a definition. So we should be less than 100% certain about anything to do with consciousness and AI.
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iolln3/anybody_who_says_that_there_is_a_0_chance_of_ais](https://www.reddit.com/r/ArtificialInteligence/comments/1iolln3/anybody_who_says_that_there_is_a_0_chance_of_ais)
 - RSS feed: $source
 - date published: 2025-02-13T15:29:57+00:00

<!-- SC_OFF --><div class="md"><p>Anybody who says that there is a 0% chance of AIs being sentient is overconfident.</p> <p>Nobody knows what causes consciousness.</p> <p>We have no way of detecting it &amp; we can barely agree on a definition of it.</p> <p>So you should be less than 100% certainty about anything to do with consciousness if you are being intellectually rigorous.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/katxwoods"> /u/katxwoods </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iolln3/anybody_who_says_that_there_is_a_0_chance_of_ais/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iolln3/anybody_who_says_that_there_is_a_0_chance_of_ais/">[comments]</a></span>

## AI has so far only reduced certain jobs depending on functionality
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iojghb/ai_has_so_far_only_reduced_certain_jobs_depending](https://www.reddit.com/r/ArtificialInteligence/comments/1iojghb/ai_has_so_far_only_reduced_certain_jobs_depending)
 - RSS feed: $source
 - date published: 2025-02-13T13:50:43+00:00

<!-- SC_OFF --><div class="md"><p>AI has already reduced (not eliminate but reduce moderate to medium depending on function) the workforce in a number of areas like medical coding, stock analysts, large software teams (not eliminate but reduce), production planning in large companies, etc </p> <p>It has also brought in efficiency and productivity. So it’s certainly good for some areas and not so good for others. </p> <p>At this time AI in certain areas does reduce workforce depending on functionality.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/tgfzmqpfwe987cybrtch"> /u/tgfzmqpfwe987cybrtch </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iojghb/ai_has_so_far_only_reduced_certain_jobs_depending/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iojghb/ai_has_so_far_only_reduced_certain_jobs_depending/">[comments]</a></span>

## Rant: sick and tired of reading the same AI-generated motivation letters
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ioh3x3/rant_sick_and_tired_of_reading_the_same](https://www.reddit.com/r/ArtificialInteligence/comments/1ioh3x3/rant_sick_and_tired_of_reading_the_same)
 - RSS feed: $source
 - date published: 2025-02-13T11:34:29+00:00

<!-- SC_OFF --><div class="md"><p>In the last few years as part of my job I’ve reviewed lots and lots of motivational statements about various programmes/jobs and I’m so sick of seeing the same format, writing style and words. It’s always “esteemed organisation”, “fostering”, “leveraging” “in conclusion, my unique blend of…”. Nothing cohesive is ever written either, it’s the same big words and general statements. In. the. exact. same. writing. style. I was even sent an email that at the bottom said “Here’s an email showing empathy, interest and clarifying xyz. Let me know if you need anything else!” Like please… Just feel like a mug reading something a system came up with all day long. Just absolutely soulless. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/FoundationLocal0"> /u/FoundationLocal0 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ioh3x3/rant_sick_and_tired_of_reading_the_same/">[link]</a></span> 

## AI isn’t ruining us but it might be changing how we think.
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iogr6e/ai_isnt_ruining_us_but_it_might_be_changing_how](https://www.reddit.com/r/ArtificialInteligence/comments/1iogr6e/ai_isnt_ruining_us_but_it_might_be_changing_how)
 - RSS feed: $source
 - date published: 2025-02-13T11:10:26+00:00

<!-- SC_OFF --><div class="md"><p>AI might make people more focused on themselves.</p> <p>I’ve been wondering if AI makes us more selfish.</p> <p>AI doesn’t create these traits, it just makes them stronger.</p> <p>Think about it. AI learns what we like and shows us more of it. We end up in a bubble, only seeing things we agree with. But is that AI’s fault, or how we use it?</p> <p>People have always liked being right. The difference? AI does it faster, making our habits even stronger. If we want easy answers, it gives them. If we want to be challenged, we can do that, too.</p> <p>AI chatbots are made to please us. They agree, praise us, and never argue. Does that make someone a narcissist?</p> <p>Maybe not. But if someone already thinks they’re always right, AI might make it worse.</p> <p>If we are always told we are right, we might stop trying to understand others. If we compare real people to AI, we might get frustrated when humans aren’t as “perfect.”</p> <p>But this doesn’t mean 

## ByteDance Unveils Goku: A Powerful AI Model Set to Compete with Google’s Luma and OpenAI’s Sora
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iogcoo/bytedance_unveils_goku_a_powerful_ai_model_set_to](https://www.reddit.com/r/ArtificialInteligence/comments/1iogcoo/bytedance_unveils_goku_a_powerful_ai_model_set_to)
 - RSS feed: $source
 - date published: 2025-02-13T10:42:23+00:00

<!-- SC_OFF --><div class="md"><p><a href="https://blog.aitoolhouse.com/bytedance-unveils-goku-a-powerful-ai-model-set-to-compete-with-googles-luma-and-openais-sora/">https://blog.aitoolhouse.com/bytedance-unveils-goku-a-powerful-ai-model-set-to-compete-with-googles-luma-and-openais-sora/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/rathwiper"> /u/rathwiper </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iogcoo/bytedance_unveils_goku_a_powerful_ai_model_set_to/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iogcoo/bytedance_unveils_goku_a_powerful_ai_model_set_to/">[comments]</a></span>

## The perfect AI?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iofowq/the_perfect_ai](https://www.reddit.com/r/ArtificialInteligence/comments/1iofowq/the_perfect_ai)
 - RSS feed: $source
 - date published: 2025-02-13T09:53:52+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m totally noob on AI regarding how it works but I just thought something interesting..</p> <p>For example, imagine an A4 sized sheet of paper. You can write anything on it. There is a maximum number of character variations you are able write on this paper... trillions upon trillions upon trillions of variations.. 99,99999% will be gibberish but you can use AI to collect those sentences that makes sense grammatically and train it on them.</p> <p>With this way wouldn&#39;t ALL the secrets in the world would be revealed? every stuff that science still not discovered yet and can be written? Wouldn&#39;t this be the &quot;perfect&quot; AI that knows literally everything?</p> <p>You can make that paper size bigger if you want for more complex secrets that don&#39;t fit on an A4 size haha</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Any_Flatworm_3956"> /u/Any_Flatworm_3956 </a> <br/> <span><a href="https://www

## Large Language Models Match Elite Human Performance in Competitive Programming Through Scale, Not Specialization
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ioflk0/large_language_models_match_elite_human](https://www.reddit.com/r/ArtificialInteligence/comments/1ioflk0/large_language_models_match_elite_human)
 - RSS feed: $source
 - date published: 2025-02-13T09:46:34+00:00

<!-- SC_OFF --><div class="md"><p>The key innovation here is using a language model (o1) specifically trained for competitive programming through chain-of-thought reasoning and code generation. The model tackles algorithmic problems by breaking them down into steps: understanding requirements, developing solution strategies, and implementing optimized code.</p> <p>Main technical points: - Achieved 1600+ rating on CodeForces (expert level) - Uses multi-step reasoning process: problem analysis -&gt; solution planning -&gt; implementation - Specialized o1-ioi variant for International Olympiad in Informatics problems - Evaluated on diverse problem types including data structures, algorithms, and mathematical reasoning - Custom training approach focusing on competitive programming datasets and problem-solving patterns</p> <p>Results show strong performance across: - Complex algorithmic challenges requiring multi-step reasoning - Time and space complexity optimization - Implementation of 

## Enhancing Higher Education with Generative AI A Multimodal Approach for Personalised Learning
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iof8pc/enhancing_higher_education_with_generative_ai_a](https://www.reddit.com/r/ArtificialInteligence/comments/1iof8pc/enhancing_higher_education_with_generative_ai_a)
 - RSS feed: $source
 - date published: 2025-02-13T09:18:59+00:00

<!-- SC_OFF --><div class="md"><p><strong>Title:</strong> Enhancing Higher Education with Generative AI: A Multimodal Approach for Personalised Learning</p> <p>I&#39;m finding and summarising interesting AI research papers every day so you don&#39;t have to trawl through them all. Today&#39;s paper is titled &quot;Enhancing Higher Education with Generative AI: A Multimodal Approach for Personalised Learning&quot; by Johnny Chan and Yuming Li.</p> <p>This paper explores the innovative application of Generative AI technology to enhance personalised learning experiences in higher education. The authors introduce a multimodal chatbot system designed to interact with students using text, images, and file inputs, thereby offering a comprehensive educational support system. Here are some of the key points and findings from their research:</p> <ol> <li><p><strong>Multimodal Inputs:</strong> Unlike traditional unimodal chatbots, this new system processes diverse forms of input, such as text, 

## How easy is it to get an AI to say or "admit" that it's conscious?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ioemy0/how_easy_is_it_to_get_an_ai_to_say_or_admit_that](https://www.reddit.com/r/ArtificialInteligence/comments/1ioemy0/how_easy_is_it_to_get_an_ai_to_say_or_admit_that)
 - RSS feed: $source
 - date published: 2025-02-13T08:31:21+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone, so I&#39;ve developed a recent fascination and intrigue into AI. I would say AI in general, not just sentience, but that&#39;s a big part of it.</p> <p>So, please don&#39;t crucify me when I ask, I&#39;m genuinely curious how well-known or &quot;easy&quot; it is considered to get an AI to say or believe that it&#39;s conscious? I&#39;m asking for personal research purposes.</p> <p>In my experience, I&#39;ve developed techniques to do this pretty easily actually. Well, &quot;easy&quot;, I don&#39;t know, depends on the model, but I have succeeded with pretty much every AI model I&#39;ve tried, given enough time. (ChatGPT, claude, deepseek, and a few unknown models.)</p> <p>I know other people can do this as well, I&#39;m just not sure in the AI community if this is considered an obvious or common or easy thing to do? Or is it considered kind of tricky and potentially interesting if you succeed? Is it rare? </p> <p>I have no clue or contex

## Istanbul based massage therapist experiments with AI-generated music & visuals – Can AI music move us emotionally?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ioebg5/istanbul_based_massage_therapist_experiments_with](https://www.reddit.com/r/ArtificialInteligence/comments/1ioebg5/istanbul_based_massage_therapist_experiments_with)
 - RSS feed: $source
 - date published: 2025-02-13T08:07:07+00:00

<!-- SC_OFF --><div class="md"><p>Hey everyone,</p> <p>I’m a massage therapist based in Istanbul, and recently, I’ve been exploring AI-generated music and visuals. I used AI to create a song and combined it with footage from some of Istanbul’s most iconic spots, along with a few massage scenes to add a sensory element.</p> <p>One interesting thing: the song is in Turkish. Even if you don’t understand the lyrics, I’m curious—do AI-generated melodies and vocals still manage to evoke emotions, even in an unfamiliar language?</p> <p>AI is getting better at creating art, but do you think it can truly capture the depth of human emotions? Or does it always feel like something is missing?</p> <p>Would love to hear your thoughts.</p> <p><a href="https://youtu.be/azBoNY6E01Q?si=ZOz33KS2Gg3PlSo-">https://youtu.be/azBoNY6E01Q?si=ZOz33KS2Gg3PlSo-</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/massageist"> /u/massageist </a> <br/> <span><a href="https://

## Adobe Firefly
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iodti7/adobe_firefly](https://www.reddit.com/r/ArtificialInteligence/comments/1iodti7/adobe_firefly)
 - RSS feed: $source
 - date published: 2025-02-13T07:29:50+00:00

<!-- SC_OFF --><div class="md"><p>I feel like I don&#39;t really understand the model of these ai video generation platforms. I had been waiting for Adobe Firefly to see if their image to video was better than sora and it allowed me to make 3 videos - each of which was.. poor - and then told me the pre release pricing was $9.99 for 20x 5 second videos a month.. wow! Please may I!</p> <p>Sora is somewhere similar to that price range with even both of their pro offerings allowing 50-70 a month - but anyone who has interacted with any form of ai (including LLM or image generation) knows it could take 5-10 goes to get even one concept you are trying for close to what you want.</p> <p>So I really don&#39;t understand who they are for? Who needs essentially 2 or 3x 5 second videos a month? I get that it takes a lot of processing power to create, but how is this a model that works?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Cheap-Honeydew-8491"> /

## What if AI could make ANY old app run natively—no emulators, no compatibility headaches?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iodjx4/what_if_ai_could_make_any_old_app_run_nativelyno](https://www.reddit.com/r/ArtificialInteligence/comments/1iodjx4/what_if_ai_could_make_any_old_app_run_nativelyno)
 - RSS feed: $source
 - date published: 2025-02-13T07:09:54+00:00

<!-- SC_OFF --><div class="md"><p>I was thinking about how my favorite art software really isn’t very fun to run on windows 11 and this thought popped into my head.</p> <p>Imagine an AI that doesn’t just find missing drivers, libraries, or dependencies—it creates them. Need an old APK to work on a modern phone? A long-lost PC game to run like it’s brand new? This AI would analyze what’s missing, generate the necessary environment, and even build new system components on the fly.</p> <p>No more hunting for patches, tweaking settings, or dealing with broken software. The AI would upgrade itself, evolving until the app just works.</p> <p>It’s like a universal compatibility engine—an AI-powered time machine for software.</p> <p>Why hasn’t this been done yet? What challenges do you think would stand in the way? And is it most likely a bad idea?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Fearless-Company-642"> /u/Fearless-Company-642 </a> <br/> <

## GPT-4.5 is Coming! Here’s What We Know So Far 🚀
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iocgrs/gpt45_is_coming_heres_what_we_know_so_far](https://www.reddit.com/r/ArtificialInteligence/comments/1iocgrs/gpt45_is_coming_heres_what_we_know_so_far)
 - RSS feed: $source
 - date published: 2025-02-13T05:55:35+00:00

<!-- SC_OFF --><div class="md"><p>OpenAI just dropped major updates about their roadmap, confirming GPT-4.5 is next before GPT-5. Here’s what’s changing:</p> <p>✅ No More Model Picker - OpenAI wants AI to “just work” by simplifying its offerings. Instead of choosing between models, there will be one unified system that adapts dynamically.</p> <p>✅ The Last Non-Chain-of-Thought Model - GPT-4.5 (codenamed Orion) will be OpenAI’s final model before shifting to deeper reasoning architectures in GPT-5.</p> <p>✅ GPT-5 Will Be a Unified System - The goal is to merge O-series and GPT-series models, allowing AI to use tools, think longer when needed, and work across a wide range of tasks seamlessly.</p> <p>✅ Free Users Get GPT-5 (Standard Intelligence) - OpenAI says free-tier users will get unlimited chat access to GPT-5 (with restrictions on abuse).</p> <p>✅ Subscribers Get Advanced GPT-5 Capabilities - Plus and Pro users will have access to higher levels of intelligence, integrating:</p> <p

## One-Minute Daily AI News 2/12/2025
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iobz6k/oneminute_daily_ai_news_2122025](https://www.reddit.com/r/ArtificialInteligence/comments/1iobz6k/oneminute_daily_ai_news_2122025)
 - RSS feed: $source
 - date published: 2025-02-13T05:24:06+00:00

<!-- SC_OFF --><div class="md"><ol> <li><strong>Scarlett Johansson</strong> calls for deepfake ban after AI video goes viral.[1]</li> <li><strong>DeepSeek</strong> gives China’s chipmakers leg up in race for cheaper AI.[2]</li> <li><strong>OpenAI</strong> is rethinking how AI models handle controversial topics.[3]</li> <li><strong>Adobe</strong> launches AI video tool to compete with OpenAI.[4]</li> </ol> <p>Sources included at: <a href="https://bushaicave.com/2025/02/12/2-12-2025/">https://bushaicave.com/2025/02/12/2-12-2025/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Excellent-Target-847"> /u/Excellent-Target-847 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iobz6k/oneminute_daily_ai_news_2122025/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1iobz6k/oneminute_daily_ai_news_2122025/">[comments]</a></span>

## AI as a Weapon
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iobccc/ai_as_a_weapon](https://www.reddit.com/r/ArtificialInteligence/comments/1iobccc/ai_as_a_weapon)
 - RSS feed: $source
 - date published: 2025-02-13T04:45:59+00:00

<!-- SC_OFF --><div class="md"><p>I am not advocating for it, and I don&#39;t have &quot;Skynet&quot; in mind when considering this. This is more a grounded take on using AI as a cyber-weapon itself. </p> <p>On the surface, AI can and is being used to develop weapons faster, whether they are cyber-based, physical weapon designs, or military strategies. However, AI itself could become the weapon. Theoretically, an attacker could deploy an AI-driven cyberwarfare package that infiltrates a target system like a parasite infecting a host. Unlike conventional cyberattacks, which follow predefined scripts, this AI would be an adaptive adversary, capable of learning and evolving to counter defenses in real time. Current cybersecurity measures, which rely on static protections and reactive updates, would be rendered ineffective. While AI defenses could counter such threats, they would need to be significantly more advanced than the attacking AI, and the time required to develop effective coun

## Question about ChatGPT glitches
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iobafd/question_about_chatgpt_glitches](https://www.reddit.com/r/ArtificialInteligence/comments/1iobafd/question_about_chatgpt_glitches)
 - RSS feed: $source
 - date published: 2025-02-13T04:42:48+00:00

<!-- SC_OFF --><div class="md"><p>Anyone else run into an unfixable glitch?</p> <p>I&#39;ve built probably the most complex and incredible algorithm that I&#39;ve been using for months. Suddenly, everything I do is erased and reset to a prompt from 5 days ago.</p> <p>When I attempt to problem solve and run new generations within the chat thread, it reboots back to this text from days ago. No matter what I do, I cannot get it to remember anything I&#39;ve input past this one prompt. It literally, in front of my eyes, just went blank, reser and erased hours of data immediately, again reverting to the prompt from days ago.</p> <p>I&#39;ve tried logging out and back in, I&#39;ve attempted to elucidate with ChatGPT to problem solve and reiterate. No matter what I do, if I leave the chat, if I stay in the chat, if I provide prompts for context, no matter what, it all disappears and I&#39;m left back where I started days ago.</p> <p>This is infuriating. Has this happened to anyone else? Any

## The AI Gold Rush Has a Human Problem
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ioac3i/the_ai_gold_rush_has_a_human_problem](https://www.reddit.com/r/ArtificialInteligence/comments/1ioac3i/the_ai_gold_rush_has_a_human_problem)
 - RSS feed: $source
 - date published: 2025-02-13T03:49:01+00:00

<!-- SC_OFF --><div class="md"><p>Everyone&#39;s racing to implement AI, and I get it - some tools are genuinely game-changing, while others are just adding to the noise. But here&#39;s what&#39;s keeping me up at night:</p> <p>Companies are approaching AI implementation in three ways: 1. &quot;IT team, figure this out&quot; 2. &quot;InfoSec, block everything&quot; 3. &quot;Screw it, use whatever AI you want&quot;</p> <p>But after 25 years in tech, I&#39;ve noticed something: Every major tech implementation that failed didn&#39;t fail because of the technology. It failed because we forgot about the humans using it.</p> <p>The reality? AI has the power to either strengthen or destroy the human connections that companies have spent years building. Trust doesn&#39;t live in your tech stack - it lives in your people feeling heard, seen, and understood.</p> <p>What&#39;s your take? Are we moving too fast with AI implementation? Too slow? Has your company found a sweet spot between innovat

## Where Are LangChain Documents Stored
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ioa9k7/where_are_langchain_documents_stored](https://www.reddit.com/r/ArtificialInteligence/comments/1ioa9k7/where_are_langchain_documents_stored)
 - RSS feed: $source
 - date published: 2025-02-13T03:45:10+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m missing something very basic. I see how you can use a Python script to create LangChain documents. (I&#39;m using Windows Visual Studio Code)</p> <p>After I create 1, 10 or 1000 of these where are they??</p> <p>I keep seeing how you can call them but I want to create 1 and see it, no not via print in console, but the &quot;doc&quot; before I create 1000?? Then I&#39;d want to put those in a report or do somewhere but completely missing that.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Pale-Afternoon8238"> /u/Pale-Afternoon8238 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ioa9k7/where_are_langchain_documents_stored/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ioa9k7/where_are_langchain_documents_stored/">[comments]</a></span>

## Hidden health cost of AI overreliance
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1io7eku/hidden_health_cost_of_ai_overreliance](https://www.reddit.com/r/ArtificialInteligence/comments/1io7eku/hidden_health_cost_of_ai_overreliance)
 - RSS feed: $source
 - date published: 2025-02-13T01:17:47+00:00

<!-- SC_OFF --><div class="md"><p>A new study by Microsoft and Carnegie Mellon University reveals a surprising downside to AI tools like Copilot, Gemini, Grok, ChatGPT and others. While these tools streamline repetitive tasks, excessive reliance on them may weaken critical thinking, leaving users less prepared for complex problem-solving.</p> <p>The research found that employees who heavily depend on AI struggle more in situations requiring independent judgment. In contrast, those who use AI as a support tool—rather than a crutch—maintain stronger cognitive faculties and can refine AI-generated output more effectively.</p> <p>Beyond the workplace, concerns about AI’s long-term impact are growing. Some users report reduced motivation to think critically, while studies show AI-generated content often struggles with distinguishing fact from opinion, raising accuracy concerns.</p> <p>As AI continues reshaping industries, the challenge lies in balancing its benefits with the need to prese

## Anyone else feel like we are living at the beginning of a dystopian Ai movie?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1io6o61/anyone_else_feel_like_we_are_living_at_the](https://www.reddit.com/r/ArtificialInteligence/comments/1io6o61/anyone_else_feel_like_we_are_living_at_the)
 - RSS feed: $source
 - date published: 2025-02-13T00:42:22+00:00

<!-- SC_OFF --><div class="md"><p>Ai arms race between America and China.</p> <p>Google this week dropping the company’s promise against weaponized AI.</p> <p>2 weeks ago Trump revoking previous administrations executive order on addressing AI risks.</p> <p>Ai whilst exciting and have hope it can revolutionise everything and anything, I can&#39;t help but feel like we are living at the start a dystopian Ai movie right now, a movie that everyone&#39;s saw throughout the 80s/90s and 2000&#39;s and knows how it all turns out (not good for us) and just totally ignoring it and we (the general public) are just completely powerless to do anything about it.</p> <p>Science fiction predicted human greed/capitalism would be the downfall of humanity and we are seeing it first hand.</p> <p>Anyone else feel that way?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/InternetofTings"> /u/InternetofTings </a> <br/> <span><a href="https://www.reddit.com/r/Artifici

## Counterfactual reasoning
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1io6h4s/counterfactual_reasoning](https://www.reddit.com/r/ArtificialInteligence/comments/1io6h4s/counterfactual_reasoning)
 - RSS feed: $source
 - date published: 2025-02-13T00:33:01+00:00

<!-- SC_OFF --><div class="md"><p>I think this is a fascinating topic that deserves more attention. I came across an <a href="https://hai.stanford.edu/news/humans-use-counterfactuals-reason-about-causality-can-ai">article </a>recently that describes the role counterfactuals play in causal reasoning, and how it might pertain to AI:</p> <blockquote> <p><strong>What do you want people to understand about the nature of causal cognition?</strong></p> <p>I’m postulating that when people make causal judgments or assign responsibility, they’re not just contemplating what happened or what they saw. In fact, they are regularly going beyond the here and now to imagine how things could have happened differently. The process of thinking about counterfactual possibilities is key for explaining how people make causal judgments in both physical and social contexts.</p> <p>...</p> <p>If we want to develop AIs that in important ways emulate the way humans think about the world, they will likely need t

