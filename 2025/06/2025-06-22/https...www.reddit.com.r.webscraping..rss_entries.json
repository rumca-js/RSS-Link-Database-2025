[
    {
        "age": null,
        "album": "",
        "author": "/u/anonymous222d",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-22T20:55:05.173953+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-22T20:24:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My script first download the alphanumeric captcha image and send it to cnn model for predicting the captcha. Then enter the captcha and hit enter that opens the data_screen. Then scrap the data from the data_screen and return to previous screen and do this for 80k iterations. How do i optimise it? Currently, the average time per iteration is 2.4 second that i would like to reduce around 1.5-1.7 seconds.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/anonymous222d\"> /u/anonymous222d </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lhxowm/how_to_optimise_selenium_script_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lhxowm/how_to_optimise_selenium_script_for/\">[comments]</a></span>",
        "id": 2993437,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lhxowm/how_to_optimise_selenium_script_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to optimise selenium script for scraping?(Making 80000 requests)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/rootbeerjayhawk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-22T20:55:05.337852+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-22T20:22:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am looking for stats on college basketball players, and am not having a ton of luck. I did find one website,<br/> <a href=\"https://barttorvik.com/playerstat.php?link=y&amp;minGP=1&amp;year=2025&amp;start=20250101&amp;end=20250110\">https://barttorvik.com/playerstat.php?link=y&amp;minGP=1&amp;year=2025&amp;start=20250101&amp;end=20250110</a><br/> that has the exact format and amount of player data that I want. However, I am not having much success scraping the data off of the website with selenium, as the contents of the table goes away when the webpage is loaded in selenium. I don&#39;t know if the website itself is hiding the contents of the table from selenium or what, but is there another way for me to get the data from this table? Thanks in advance for the help, I really appreciate it!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/rootbeerjayhawk\"> /u/rootbeerjayhawk </a> <br/> <span><a href=\"https://www.r",
        "id": 2993438,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lhxmol/alternative_web_scraping_methods",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Alternative Web Scraping Methods",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lucasliftslight",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-22T19:50:21.056380+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-22T19:04:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to scrape crunchbase and only extract companies which align with the VC thesis. I am trying to create an AI agent to do so through n8n. I have only done webscraping through Python in the past. How should I approach this? Are there free Crunchbase APIs that I can use (or not very expensive ones)? Or should i manually extract from the website?</p> <p>Thanks for your help!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lucasliftslight\"> /u/lucasliftslight </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lhvscj/webscraping_crunchbase/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lhvscj/webscraping_crunchbase/\">[comments]</a></span>",
        "id": 2992465,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lhvscj/webscraping_crunchbase",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WebScraping Crunchbase",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Mysterious-Ad4636",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-22T19:50:21.221040+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-22T18:39:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Complete beginner</p> <p>I&#39;m looking for a way to collect approximately 100 text samples from freely accessible newspaper articles. The data will be used to create a linguistic corpus for students. A possible scraping application would only need to search for 3 - 4 phrases and collect the full text. About 4 - 5 online journals would be sufficient for this. How much effort do estimate? Is it worth it if its just for some German lessons? Or any easier ways to get it done?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Mysterious-Ad4636\"> /u/Mysterious-Ad4636 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lhv6m6/web_scraping_for_text_examples/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lhv6m6/web_scraping_for_text_examples/\">[comments]</a></span>",
        "id": 2992466,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lhv6m6/web_scraping_for_text_examples",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Web Scraping for text examples",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/weluuu",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-22T19:50:21.551802+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-22T14:14:20+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey team, I am here with a lot of questions with my new side project : I want to gather news on a monthly basis and tbh doesn\u2019t make sense to purchase hundred of license api. Is it legal to crawl news pages If I am not using any personal data or getting money out of the project ? What is the best way to do that for js generated pages ? What is the easiest way for that ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/weluuu\"> /u/weluuu </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lhovzy/scraping_news_pages_questions/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lhovzy/scraping_news_pages_questions/\">[comments]</a></span>",
        "id": 2992468,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lhovzy/scraping_news_pages_questions",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping news pages questions",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/pulokjk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-22T19:50:21.385773+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-22T10:31:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I\u2019m working remotely for a small service-based company that builds travel agency software, like hotel booking, flight systems, etc., using .NET technologies.</p> <p>Now I\u2019m trying to find new remote job opportunities in similar companies, specially those working in the OTA (Online Travel Agency) space and possibly using GDS systems like Galileo or Sabre. Ideally, I want to focus on companies in first-world countries that offer remote positions.</p> <p>I\u2019ve been thinking of scraping job listings using relevant keywords like .NET, remote, OTA, ERP, Sabre, Galileo, etc. From those listings, I\u2019d like to extract useful info like the company name, contact email so I can reach out directly for potential job opportunities.</p> <p>What I\u2019m looking for is:</p> <ul> <li>Any free tools, platforms, or libraries that can help me scrape a large number of job posts </li> <li>Something that does not need too much time to build</li> <li>Other smart",
        "id": 2992467,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lhkss7/scraping_job_listings_to_find_remote_net_travel",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping Job Listings to Find Remote .NET Travel Tech Companies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/isa-programmer",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-22T10:27:52.239081+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-22T07:45:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,<br/> I wrote a small and lightweight python library that pulls data from YouTube such as search results, video title, description, and view count etc.</p> <p>Github: <a href=\"https://github.com/isa-programmer/yt_api_wrapper/\">https://github.com/isa-programmer/yt_api_wrapper/</a><br/> PyPI: <a href=\"https://pypi.org/project/yt-api-wrapper/\">https://pypi.org/project/yt-api-wrapper/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/isa-programmer\"> /u/isa-programmer </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lhiers/i_made_a_youtube_scraper_library_with_python/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lhiers/i_made_a_youtube_scraper_library_with_python/\">[comments]</a></span>",
        "id": 2991004,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lhiers/i_made_a_youtube_scraper_library_with_python",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I made a YouTube scraper library with Python",
        "vote": 0
    }
]