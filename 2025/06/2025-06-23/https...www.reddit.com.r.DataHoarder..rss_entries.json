[
    {
        "age": null,
        "album": "",
        "author": "/u/prototype073",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T23:10:37.211021+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T23:08:35+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1livfvf/wd_sn850x_8tb_nvme_ssd_worth_for_a_nas/\"> <img src=\"https://preview.redd.it/0dbvtnl7dr8f1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6667c2f2e4fbd2bd04a2d1acd45b5ff760652098\" alt=\"WD SN850X 8TB NVMe SSD worth for a NAS?\" title=\"WD SN850X 8TB NVMe SSD worth for a NAS?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>So I can get two Western Digital SN850X 8TB NVMe SSDs for 770 euros. New. If I bought them from a retailer they&#39;d be 1260 euros. I know that the speeds would be limited on my UGREEN DXP2800, but the second-hand price is great and I cannot really find any slower, and thus cheaper drives with the same capacity. And if they last a long time.... I want to max out the NAS. Worth it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/prototype073\"> /u/prototype073 </a> <br/> <span><a href=\"https://i.redd.it/0dbvtnl7dr8f1.jpeg\">[link]</a></span> &#32; ",
        "id": 3002345,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1livfvf/wd_sn850x_8tb_nvme_ssd_worth_for_a_nas",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/0dbvtnl7dr8f1.jpeg?width=640&crop=smart&auto=webp&s=6667c2f2e4fbd2bd04a2d1acd45b5ff760652098",
        "title": "WD SN850X 8TB NVMe SSD worth for a NAS?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/lunar-lullabies",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T23:10:37.411257+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T23:06:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m working on a storage setup, and preserving the original Date Created (not just Date Modified) is really important to me. I\u2019m trying to confirm whether pCloud actually preserves the \u201cDate Created\u201d metadata when adding files to the pCloud Drive on macOS.</p> <p>Right now I\u2019m running macOS off a temporary recovery SSD until I can get my laptop repaired, so I can\u2019t fully test this until I\u2019m back on my regular setup. But in my current setup, when I add files to the pCloud Drive, either by dragging and dropping, using <code>cp -p</code> in Terminal, or uploading through the desktop application, the &quot;Date Created&quot; gets changed to match Date Modified or the current date.</p> <p>Support has been very specific that Date Created should be preserved, and they\u2019ve tested it on their end as well. They said it should be retained whether uploading through the desktop application, copying manual, or through Terminal. They&#39;re investing the logs but",
        "id": 3002346,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1livdvv/does_pcloud_preserve_date_created_when_adding",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does pCloud preserve \u201cDate Created\u201d when adding files to pCloud Drive?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/nilgiri",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T23:10:37.607904+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T22:48:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Usage is a bunch of HDDs for Plex library with a HP Pro mini G9 mini PC. The Terramaster is almost double the cost of Orico ($230 vs. $115 pre tax). Which one should I pick??</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nilgiri\"> /u/nilgiri </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1liuywk/terramaster_d6320_or_orico_5_bay_usb_31/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1liuywk/terramaster_d6320_or_orico_5_bay_usb_31/\">[comments]</a></span>",
        "id": 3002347,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1liuywk/terramaster_d6320_or_orico_5_bay_usb_31",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Terramaster D6-320 or Orico 5 Bay USB 3.1",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/and-yet-it-grooves",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T23:10:37.804127+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T22:42:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently bought my first pair of 12TB HDDs (WD Red Plus) for my home server, and while I was researching what drives to buy I noticed that consistently every recommendation for quieter drives topped out around 12TB or 14TB regardless of brand.</p> <p>Is there a reason for that? Is there some technical boundary around that point of data, or is it more economic like larger drives are geared towards the enterprise market where noise isn&#39;t as much of a concern?</p> <p>Otherwise it seems unclear to me why, for example, a 7200RPM 14TB WD Red Plus could be relatively quiet but bumping that to a 16TB WD Red Pro at the same RPM sees the volume become much more pronounced.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/and-yet-it-grooves\"> /u/and-yet-it-grooves </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1liutwl/why_do_hdds_get_noticeably_louder_after_1214tb/\">[link]</a></span> &#32; <spa",
        "id": 3002348,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1liutwl/why_do_hdds_get_noticeably_louder_after_1214tb",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Why do HDDs get noticeably louder after 12-14TB?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/yougotgamesonphone",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T22:05:08.056900+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T21:38:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been trying to rip a 3d model and have been struggling to find .gltf/.glb In the network tab what am I supposed to do?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/yougotgamesonphone\"> /u/yougotgamesonphone </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lit9n7/rip_3d_model/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lit9n7/rip_3d_model/\">[comments]</a></span>",
        "id": 3001920,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lit9n7/rip_3d_model",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Rip 3d model?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/TimberTheDog",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T20:59:09.113941+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T20:51:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I think it would serve the public interest if the videos of masked ICE agents were being stored somewhere, along with location. Anything like that happening? If not, any idea what the best way to do this would be?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TimberTheDog\"> /u/TimberTheDog </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lis32d/is_there_anyone_or_site_collecting_and_storing/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lis32d/is_there_anyone_or_site_collecting_and_storing/\">[comments]</a></span>",
        "id": 3001445,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lis32d/is_there_anyone_or_site_collecting_and_storing",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there anyone or site collecting and storing vids of ICE agents?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/hd805",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T20:59:09.313855+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T19:56:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Would that make for a much more cost effective Networked attached storage? Any thoughts on potential trade offs in terms of lag and such applications include hosting video locally on LAN without transcoding? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hd805\"> /u/hd805 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1liqn7w/combining_disk_attached_storage_usb_with/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1liqn7w/combining_disk_attached_storage_usb_with/\">[comments]</a></span>",
        "id": 3001446,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1liqn7w/combining_disk_attached_storage_usb_with",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Combining Disk Attached Storage USB with Raspberry PI5 for NAS",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/stilljustacatinacage",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T19:52:49.021229+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T19:21:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I finally built myself a backup box. I&#39;m working on backing everything up now but as these files are flying past, I&#39;m realizing how many of them I still have left to rename and sort properly.</p> <p>Right now I&#39;m just using a basic rsync to pull from my Windows machine onto Ubuntu Server. Once it&#39;s done, I plan to migrate the Windows machine to TrueNAS and move the data back. Fine, groovy, I&#39;m confident (mostly) in this part.</p> <p>My question is, once everything&#39;s set up again and I get back to renaming files and folders... How do I then send those back to the Ubuntu Server without creating mountains of duplicates? I could obviously just manually keep track of renames and duplicates, but I was wondering if there was any more elegant way to go about doing this.</p> <p>Any leads would be appreciated. Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/stilljustacatinacage\"> /u/still",
        "id": 3001083,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lipr46/im_still_in_the_process_of_tidying_my_collection",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I'm still in the process of 'tidying' my collection: Renaming files, moving things around. How can I periodically sync these files to an offline backup without creating duplicates? Final setup will probably be TrueNAS to Ubuntu Server, ZFS - but I am very new to both.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/-1D-",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T19:52:48.673850+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T18:57:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So you all probably already know that youtube around 2 years ago now introduced 1080p 24/30 fps premium formats, those where encoded in vp9 and usually 10 to 15% higher in bitrate then avc1/h264 encodes, which where previous highest bitrate encodes. </p> <p>Now youtube is introducing 1080p 50/60fps premium formats that where encoded in av1 and most of the times not even higher then regular h264/avc1, though hard to comform exactly by how much due to format still being in A/B test meaning only some accounts see it and have access to it, and even those accounts that have it need premium cus ios client way to download premium formats doesn&#39;t work when passing coockies (i explain this beforehand in details in multiple times on youtubedl sub) , making avc1/h264 encodes very often better looking then premium formats </p> <p>Now youtube is even switching to av1 for 1080p 24/30fps videos <a href=\"https://www.reddit.com/r/AV1/s/Hon3UX4Mto\">proof</a> </p> <",
        "id": 3001082,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lip4jp/youtube_is_abusing_av1_to_lower_bitrates_to_abyss",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "YouTube is abusing AV1 to lower bitrates to abyss and ruin videos forever",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/LxFx",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T19:52:49.330035+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T18:57:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://pcpartpicker.com/list/rdqfcx\">PCPartPicker Part List</a></p> <table><thead> <tr> <th align=\"left\">Type</th> <th align=\"left\">Item</th> <th align=\"left\">Price</th> </tr> </thead><tbody> <tr> <td align=\"left\"><strong>CPU</strong></td> <td align=\"left\"><a href=\"https://pcpartpicker.com/product/QqyH99/amd-ryzen-5-8600g-43-ghz-6-core-processor-100-100001237box\">AMD Ryzen 5 8600G 4.3 GHz 6-Core Processor</a></td> <td align=\"left\">$180.00 @ Newegg</td> </tr> <tr> <td align=\"left\"><strong>CPU Cooler</strong></td> <td align=\"left\">Included AMD cooler</td> <td align=\"left\"></td> </tr> <tr> <td align=\"left\"><strong>Motherboard</strong></td> <td align=\"left\"><a href=\"https://pcpartpicker.com/product/rVfxFT/asrock-b650i-lightning-wifi-mini-itx-am5-motherboard-b650i-lightning-wifi\">ASRock B650I Lightning Wifi Mini ITX AM5 Motherboard</a></td> <td align=\"left\">$199.99 @ Amazon</td> </tr> <tr> <td align=\"left\"><strong>ECC Memory</strong></td> <td ali",
        "id": 3001084,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lip48o/building_a_compact_offsite_backup_for_my_home",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Building a compact offsite backup for my home server. Feedback welcome",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Kayect",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T17:43:48.498647+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T17:11:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a large quantity (about to be 4000) of MP3 song files that can be found on Spotify, and I have backups on a PC, laptop, phone, USB stick, and HDD drive. I would also like to backup to OneDrive as a cloud based backup because I have hundreds of GB free there, and all the music is currently under 50gb. I understand this may be a gray area because of OneDrive&#39;s ToS with copyrighted content, but the purpose of the OneDrive backup would not be to distribute, share, or sell any content wrongly. It&#39;s solely just a personal backup for myself. I&#39;ve heard that Microsoft regularly scans content for copyrighted material, and I don&#39;t want to deal with losing account access or other data I store on OneDrive.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kayect\"> /u/Kayect </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1limaym/can_i_store_music_mp3s_on_onedrive_for_personal/\">[l",
        "id": 2999939,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1limaym/can_i_store_music_mp3s_on_onedrive_for_personal",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can I Store Music MP3s on OneDrive for Personal Use?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/WorriedHelicopter764",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T17:43:48.699363+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T16:57:35+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/WorriedHelicopter764\"> /u/WorriedHelicopter764 </a> <br/> <span><a href=\"/r/CasualUK/comments/1libg3o/did_you_know_the_uk_dvla_offers_an_api_where_you/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lilxjd/did_you_know_the_uk_dvla_offers_an_api_where_you/\">[comments]</a></span>",
        "id": 2999940,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lilxjd/did_you_know_the_uk_dvla_offers_an_api_where_you",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Did you know the UK DVLA offers an API where you can download the entire MOT history of every vehicle in 1 .zip file?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/SwingDingeling",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T16:38:48.205988+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T16:22:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I tested this so many times:</p> <p>A UHD (aka 4K, but UHD is the correct term) gets released. I download it and get let&#39;s say a 18k bitrate vp9 video. </p> <p>I then download the video about a day later, get supposedly the exact same version, but the bitrate is at 25k now. At first I thought they replace the OG vp9 version with a better one. I then compared the quality many times and always got the same shocking result: OG version is better.</p> <p>YouTube replaces the best version you can get (av1 is more efficient, but quality is about the same as vp9 version 2) with a file that&#39;s up to 30% bigger, yet has 10% worse quality.</p> <p>How can we get them to fix this? Why are they doing this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SwingDingeling\"> /u/SwingDingeling </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lil04z/youtube_replaces_the_vp9_uhd_version_with_a/\">[link]</",
        "id": 2999418,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lil04z/youtube_replaces_the_vp9_uhd_version_with_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "YouTube replaces the vp9 UHD version with a higher bitrate, LOWER quality version \ud83e\udd26\u200d\u2640\ufe0f",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/BioHyena",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T16:38:48.482486+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T16:21:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello all,</p> <p>I have one that I&#39;m looking at and wanted to get some thoughts on it. I want an external device that can load a bunch of movies and shows for when the Wi-Fi is acting up or non-existent, and can be used with Android/Windows devices. I was looking at the <a href=\"https://www.amazon.com/Western-Digital-Elements-External-external/dp/B07D5V2ZXD/ref=sr_1_1?crid=2HXY6AAG1UPOO&amp;dib=eyJ2IjoiMSJ9.N5V4C9eV0oijGRtFpdzkHwwO1KvwPZzdzMBLJBhiq2w7yOx_l0QCiJaOplHj1GG0fdnMV3_7GehYD5NNIMKr5J0Nd9D37dfykCBMAP9Cbyz0ZQH1jrTkywquzVUVuyJg1cURnH2vTMLFyVm9QraoJGY8ofnCv7gcWo5KYZmBlz8epsUYgGhy-CVBpHNQRwRyUXy0PBRzTZ9_pA1EDrDiv0Vt2MeWuAG3zMK_N3ygI94.0PzTWgvFd4LzEUB1Asy02ggq7i6z-Sk-VKZnmRTS4v8&amp;dib_tag=se&amp;keywords=external%2Bhard%2Bdrive&amp;qid=1750694461&amp;refinements=p_n_feature_forty-six_browse-bin%3A5446816011&amp;rnid=562234011&amp;sprefix=External%2Caps%2C211&amp;sr=8-1&amp;th=1\">WD Elements #TB Desktop</a> since it falls within the range I w",
        "id": 2999419,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1likzxd/request_for_recommended_external_hdds_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Request for Recommended External HDDs for Shows/Movies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/The_Faceless1",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T15:33:48.629489+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T15:31:23+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1lijnpt/anyone_familiar_with_this_cdr_brand_is_it_good/\"> <img src=\"https://preview.redd.it/lk3sj4xp3p8f1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=68c404ef837590f85a093848afd5f9e5e602a2eb\" alt=\"Anyone familiar with this CDR brand? is it good?\" title=\"Anyone familiar with this CDR brand? is it good?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I want to burn some of my music from video games and old video games i loved into Disc, bought this one, the 10 pack is really cheap, verbatim is like 3X the price and the jewel case on D-MAX is far better than verbatim ones.</p> <p>But im unsure about the quality or the durability of the disc itself, tested burn a CD, and its normal, but unsure how it will be 5 years 10 years in the future.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/The_Faceless1\"> /u/The_Faceless1 </a> <br/> <span><a href=\"https://i.redd.it/lk3sj4",
        "id": 2998775,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lijnpt/anyone_familiar_with_this_cdr_brand_is_it_good",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/lk3sj4xp3p8f1.jpeg?width=640&crop=smart&auto=webp&s=68c404ef837590f85a093848afd5f9e5e602a2eb",
        "title": "Anyone familiar with this CDR brand? is it good?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/calcium",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T15:33:48.828334+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T15:29:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Was just looking at picking up some factory recertified drives through either SPD or GoHardDrive and was looking at the data sheets of the various drives when I noticed that the Seagate Factory Recertified Drive&#39;s data sheet had terrible metrics when compared to their newer drives.</p> <p>Here&#39;s a comparison between the Seagate Exos X16, Exos X22, and Factory Recertified drives...</p> <table><thead> <tr> <th align=\"left\">Type</th> <th align=\"left\">X16</th> <th align=\"left\">X22</th> <th align=\"left\">Factory Recertified</th> </tr> </thead><tbody> <tr> <td align=\"left\">Limited Warranty</td> <td align=\"left\">5 years</td> <td align=\"left\">5 years</td> <td align=\"left\">6 months</td> </tr> <tr> <td align=\"left\">Nonrecoverable Read Errors per Bits Read</td> <td align=\"left\">1 sector per 10E15</td> <td align=\"left\">1 sector per 10E15</td> <td align=\"left\">1 sector per 10E14</td> </tr> <tr> <td align=\"left\">Power-On Hours per Year (24\u00d77)</td> <td align=",
        "id": 2998776,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lijljv/seagates_factory_recertified_exos_hdds_have_much",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Seagate's Factory Recertified Exos HDDs have much looser tolerances compared to their various Exos X* lines. Are they a safe buy?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CastorTroy45",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T15:33:48.320271+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T14:54:58+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1liipdd/my_unraid_server/\"> <img src=\"https://preview.redd.it/ifvy0ygexo8f1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b7a50a9e7d0c9ab14421bb687613de7ce334cd8\" alt=\"My Unraid server\" title=\"My Unraid server\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CastorTroy45\"> /u/CastorTroy45 </a> <br/> <span><a href=\"https://i.redd.it/ifvy0ygexo8f1.jpeg\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1liipdd/my_unraid_server/\">[comments]</a></span> </td></tr></table>",
        "id": 2998774,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1liipdd/my_unraid_server",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/ifvy0ygexo8f1.jpeg?width=640&crop=smart&auto=webp&s=9b7a50a9e7d0c9ab14421bb687613de7ce334cd8",
        "title": "My Unraid server",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Stereogravy",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T15:33:48.117060+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T14:37:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m new to setting up this type of solution and would appreciate any help.</p> <p>I planned to buy a NAS, but I had parts to build a second PC and heard building would be cheaper.</p> <p>I\u2019ve built the PC using space parts:</p> <p>\u2022 \u20609950X CPU (I sent in an old CPU to AMD under warranty and they sent me back this one)</p> <p>\u2022 \u2060RTX 2080</p> <p>\u2022 \u206064GB DDR5 RAM</p> <p>\u2022 \u2060512GB NVMe SSD</p> <p>I\u2019m undecided about the NAS OS, but I\u2019m considering UnRAID or TrueNAS, any other options I\u2019m open to.</p> <p>I\u2019m thinking of buying manufacturer-refurbished drives from Severpartdeals.com, based on positive reviews.</p> <p>For my HDD bay, I\u2019m considering the QNAP TL-D800C 8-Bay Desktop JBOD Storage Enclosure with USB 3.2 Gen 2 Type-C Connectivity.</p> <p><a href=\"https://a.co/d/iy6yxfE\">https://a.co/d/iy6yxfE</a></p> <p>My goal is to have 25-45 terabytes of workable data, assuming each project takes about 300-500GB.</p> <p>I need fast and redundant RAID.</p> <p>Id",
        "id": 2998773,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lii9ox/building_a_video_editing_nas_am_i_missing_anything",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Building a video editing NAS, am I missing anything?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Marf321",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T13:24:05.550454+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T12:22:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone, I&#39;m starting my own engineering/architectual firm and well lets say ill make 10-15 projects a year each one using 400-800 MB. I&#39;m searching the web and trying to find an external HDD from 6-10 TB in a price range from 200-350\u20ac. Any tips for a good quality drive? </p> <p>Thanks in advance! :) </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Marf321\"> /u/Marf321 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lif6ek/need_help_in_choosing_the_external_hdd_for_work/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lif6ek/need_help_in_choosing_the_external_hdd_for_work/\">[comments]</a></span>",
        "id": 2997128,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lif6ek/need_help_in_choosing_the_external_hdd_for_work",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help in choosing the external HDD for work",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dazzng",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T13:24:05.784220+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T11:59:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I am looking to find if there is a directory for a book that I would like to download. It is a book on law (corporate law to be more precise). Right now, the latest edition of the book is not available on MAM or Libgen or Anna&#39;s so maybe I thought if there is another directory for this. </p> <p>Would you have any recommendations</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dazzng\"> /u/dazzng </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1liepy6/how_to_find_books_related_to_professions_legal/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1liepy6/how_to_find_books_related_to_professions_legal/\">[comments]</a></span>",
        "id": 2997129,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1liepy6/how_to_find_books_related_to_professions_legal",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to find books related to professions (legal)?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/real_yashji",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T13:24:06.251248+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T11:27:12+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/DataHoarder/comments/1lie4c3/i_want_to_have_a_collection_of_ipl_replays/\"> <img src=\"https://preview.redd.it/4i2wikw4wn8f1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8e6fd8aca77170c2ed76b4900b49d524f6eed6fd\" alt=\"I want to have a collection Of IPL - replays\" title=\"I want to have a collection Of IPL - replays\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><em>&quot;I\u2019m trying to build a collection of IPL match replays (preferably full matches, not just highlights). Does anyone know of:</em></p> <ul> <li><em>Official/unofficial sources where I can download past IPL matches?</em></li> <li><em>Private trackers/Telegram groups that specialize in cricket archives?</em></li> <li><em>Any existing data hoarders who\u2019ve archived IPL seasons?</em></li> </ul> <p><em>I have cheaked all the official sources no Luck</em></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/real_yashji\"> /u/real_yashji <",
        "id": 2997131,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lie4c3/i_want_to_have_a_collection_of_ipl_replays",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/4i2wikw4wn8f1.jpeg?width=640&crop=smart&auto=webp&s=8e6fd8aca77170c2ed76b4900b49d524f6eed6fd",
        "title": "I want to have a collection Of IPL - replays",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/ggekko999",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T10:37:53.471689+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T09:48:51+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ggekko999\"> /u/ggekko999 </a> <br/> <span><a href=\"https://v.redd.it/ibl6dmsuvh8f1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1lich36/reminds_me_of_when_i_asked_about_sata_connectors/\">[comments]</a></span>",
        "id": 2996576,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1lich36/reminds_me_of_when_i_asked_about_sata_connectors",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Reminds me of when I asked about SATA connectors a few weeks back",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Connect_Nerve_6499",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T09:32:53.386078+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T08:36:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I\u2019m looking for a <strong>4\u20138 bay DAS</strong> with <strong>RAID support</strong> (RAID 1, 5, or 10). It&#39;ll be used mostly for <strong>long-term HDD storage</strong> and backups \u2014 connected only when working with data. <strong>Speed isn\u2019t a priority</strong>, HDD speeds are fine. I\u2019ve seen models from <strong>ORICO, TerraMaster, Renkforce</strong>, but unsure about their <strong>build quality and RAID reliability</strong>.</p> <p>Any recommendations or current setup experiences ? </p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Connect_Nerve_6499\"> /u/Connect_Nerve_6499 </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1libdkn/looking_for_a_multibay_das_with_raid_eu/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1libdkn/looking_for_a_multibay_das_with_raid_eu/\">[comments]</a></span>",
        "id": 2996214,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1libdkn/looking_for_a_multibay_das_with_raid_eu",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a Multi-Bay DAS with RAID (EU availability)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/twofoursixohdang",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T07:22:58.380738+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T02:52:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been trying to clean up this scan of an obscure book of sheet music for a while now, and it&#39;s been driving me nuts.</p> <p>The initial scan was made (somewhat hastily) with one of those overhead book-cameras. The main problems are that some of the images are lightly distorted due to the curve of the page, and the colors aren&#39;t right - every page is black-on-grey.</p> <p>I&#39;ve Googled around and found ScanTailor Advanced, but from the looks of things, while it can fix the distortion, it has to be manually, laboriously applied to each individual page. I guess I can just live with it.</p> <p>The colors are what frustrate me. Messing about with Irfanview, I&#39;ve tried to find combinations of successively adjusting the colors and shifting the contrast to bring back the original look of the page, and while I&#39;ve had some success, some of the pages are just a little darker than others and still turn out looking grey while other pages",
        "id": 2995659,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1li5sem/is_there_no_quickandeasy_way_to_clean_up",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there no quick-and-easy way to clean up color/distortions in a book scan?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/xrepair",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T07:22:58.550836+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T02:42:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>Just wanted to share a small program I wrote that writes and verifies data on a raw disk device. It&#39;s designed to stress-test hard drives and SSDs by dividing the disk into sections, writing data in parallel using multiple worker threads, and verifying the written content for integrity.</p> <p>I use it regularly to test brand-new disks before adding them to a production NAS \u2014 and it has already helped me catch a few defective drives. </p> <p>Hope you find it useful too! The link to the project: <a href=\"https://github.com/favoritelotus/testdisk.git\">https://github.com/favoritelotus/testdisk.git</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/xrepair\"> /u/xrepair </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1li5lf9/a_program_to_test_hdd_and_ssd_drives/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1li5lf9/a_program_to",
        "id": 2995660,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1li5lf9/a_program_to_test_hdd_and_ssd_drives",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "a program to test HDD and SSD drives",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/CrushedSodaCan_",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-23T00:52:52.336103+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-23T00:02:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Ive been beating my head against my computer trying to make this work.</p> <p>I have data that I want to be redundant/cloned/mirrored. I need to be able to swap this device between computers that are NOT on the same network.</p> <p>I figured I would get a USB DAS with raid 1 but I can&#39;t seem to make that work for hot swapping from a kvm. </p> <p>Any suggestions? Hardware raid enclosure? Some other backup method?</p> <p>I currently have (2) m2 drives that I&#39;m hoping would be the basis of the system or ive got some big Amazon refunds to do \ud83d\ude05</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CrushedSodaCan_\"> /u/CrushedSodaCan_ </a> <br/> <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1li2inz/redundant_raid_1driveenclosuredas_that_can_be/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/DataHoarder/comments/1li2inz/redundant_raid_1driveenclosuredas_that_can_be/\">[comments]</a></sp",
        "id": 2994348,
        "language": null,
        "link": "https://www.reddit.com/r/DataHoarder/comments/1li2inz/redundant_raid_1driveenclosuredas_that_can_be",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 596,
        "source_url": "https://www.reddit.com/r/DataHoarder/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Redundant (raid 1?)drive/enclosure(das?) that can be swapped between PCs multiple times a day.",
        "vote": 0
    }
]