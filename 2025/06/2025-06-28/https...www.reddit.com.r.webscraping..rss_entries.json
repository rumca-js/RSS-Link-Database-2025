[
    {
        "age": null,
        "album": "",
        "author": "/u/DueDirection897",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-28T16:25:02.846692+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-28T15:46:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Not sure if this sub is the right choice but not having luck elsewhere.</p> <p>I\u2019m working on a project to automate mappng all shopping centers and their tenants within a couple of counties through Google Maps. and extracting the data to an SQL database.</p> <p>I had Claude build me an app that finds the shopping centers but it doesn\u2019t have any idea how to pull the tenant data via the GMaps API.</p> <p>Any suggestions?</p> <p>I</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DueDirection897\"> /u/DueDirection897 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lmpy82/trying_to_extract_tenant_data_from_shopping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lmpy82/trying_to_extract_tenant_data_from_shopping/\">[comments]</a></span>",
        "id": 3042716,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lmpy82/trying_to_extract_tenant_data_from_shopping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to Extract Tenant Data From Shopping Centers in Google Maps",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Firstboy11",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-28T04:29:58.823886+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-28T03:46:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, </p> <p>I have an interesting case here. I am scraping <a href=\"http://Metro.ca\">Metro.ca</a> and initially to test my script used a URL where the page contains local products. I believe the webpage is SSR, so I am using requests-html to scrape over requests and beautifulsoup.</p> <p>My first URL is <a href=\"https://www.metro.ca/en/online-grocery/themed-baskets/local-products\">https://www.metro.ca/en/online-grocery/themed-baskets/local-products</a> which works fine with my test script. Now, I tested my second URL <a href=\"https://www.metro.ca/en/online-grocery/aisles/fruits-vegetables\">https://www.metro.ca/en/online-grocery/aisles/fruits-vegetables</a> which returned an empty list and upon closer inspection, it was blocked by Cloudflare captcha. </p> <p>I looked around online and many suggested to use curl_cffi. I used curl_cffi and was still blocked by curl_cffi. Now, an interest case is <strong>the first URL is also blocked using curl_cffi</s",
        "id": 3039672,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lmdb8e/same_website_but_one_url_is_blocked_but_the_other",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Same website, but one URL is blocked but the other works",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cannabizpro420",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-28T04:29:59.019765+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-28T03:34:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Need advice: n8n AI agent vs. Playwright-based crawler for tracking a state-agency site &amp; monthly meeting videos</p> <p>Context:</p> <ol> <li><p>Monthly Crawl two levels deep on a site for new/updated PDFs, HTML, etc. </p></li> <li><p>Retrieve the board meeting agenda PDF and the YouTube livestream, and pull captions. </p></li> </ol> <p>I already have a spreadsheet of seed URLs (main portal sections and YouTube channels); I want to put them all into a vector database for an LLM to access. </p> <p>After the initial data scrape, I will need to monitor the meetings for updates. Beyond that, I really won&#39;t need to crawl it more than once a month. If needed, I can retrieve the monthly meeting PDF and the new meeting videos. </p> <p>A developer has quoted me to build one, but I&#39;m concerned that it will require ongoing maintenance, so I wonder if a commercial product is a better option, or if I even need one after the data dump?</p> <p>What do ex",
        "id": 3039673,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lmd3fl/n8n_ai_agent_vs_playwrightbased_crawler",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "n8n AI agent vs. Playwright-based crawler",
        "vote": 0
    }
]