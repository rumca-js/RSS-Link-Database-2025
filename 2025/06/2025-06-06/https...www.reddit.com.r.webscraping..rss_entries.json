[
    {
        "age": null,
        "album": "",
        "author": "/u/Swimming_Tangelo8423",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-06T22:27:49.701442+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-06T22:05:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>If you had to tell a newbie something you wish you had known since the beginning what would you tell them? </p> <p>E.g how to bypass detectors etc.</p> <p>Thank you so much!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Swimming_Tangelo8423\"> /u/Swimming_Tangelo8423 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l54uri/advice_to_a_web_scraping_beginner/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l54uri/advice_to_a_web_scraping_beginner/\">[comments]</a></span>",
        "id": 2869564,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l54uri/advice_to_a_web_scraping_beginner",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Advice to a web scraping beginner",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/dracariz",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-06T23:31:16.388209+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-06T21:50:18+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1l54iee/camoufox_playwright_automatic_captcha_solving/\"> <img src=\"https://external-preview.redd.it/dXhzcHBqZ3JtZDVmMfZojCnESs3ZVq6Hh5J6EU5wAH6HdlwkDSK5BxmFKloP.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a32386c0479a89191b88993112a705b203c8c88b\" alt=\"Camoufox (Playwright) automatic captcha solving (Cloudflare)\" title=\"Camoufox (Playwright) automatic captcha solving (Cloudflare)\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Built a Python library that extends <a href=\"http://github.com/daijro/camoufox\">camoufox</a> (playwright-based anti-detect browser) to automatically solve captchas (currently only Cloudflare: interstitial pages and turnstile widgets).<br/> Camoufox makes it possible to bypass closed Shadow DOM with strict CORS, which allows clicking Cloudflare\u2019s checkbox. More technical details on GitHub.</p> <p>Even with a dirty IP, challenges are solved automatically via clicks thanks to Camoufox&",
        "id": 2870064,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l54iee/camoufox_playwright_automatic_captcha_solving",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/dXhzcHBqZ3JtZDVmMfZojCnESs3ZVq6Hh5J6EU5wAH6HdlwkDSK5BxmFKloP.png?width=640&crop=smart&auto=webp&s=a32386c0479a89191b88993112a705b203c8c88b",
        "title": "Camoufox (Playwright) automatic captcha solving (Cloudflare)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/DanFlack",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-06T21:21:08.665151+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-06T21:01:18+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, I am looking for some advice and help (I hope I am in the correct place). I am trying to build a tool that can read a list of external links to apparel products, and tell me if said product is out of stock - or not. My main focus is just getting the info from one store at the moment, and this website is END Clothing. Is there a way of doing this free? I have attempted multiple methods utilising Chat GPT (I am beyond a beginner), however we came to the same block (apart from ScrapierAPI, where it worked but with a 95% success rate). Any ideas if this is possible? And help, ideas, or just advice would be greatly appreciated. Apologies if I\u2019m asking in the wrong place. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DanFlack\"> /u/DanFlack </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l53ddi/outofstockchecker/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/we",
        "id": 2869169,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l53ddi/outofstockchecker",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Out-Of-Stock-Checker",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/passtheknife",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-06T20:15:43.948241+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-06T19:45:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m a beginner with webscraping and one thing I want to do is scrape legal statutes to create a database across several US states. Has anyone done something like that and hoe difficult was it? Or is that just asking for a brain hemorrhaging level of effort? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/passtheknife\"> /u/passtheknife </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l51l9v/is_it_possible_to_scrape_legal_codes_to_create_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l51l9v/is_it_possible_to_scrape_legal_codes_to_create_a/\">[comments]</a></span>",
        "id": 2868717,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l51l9v/is_it_possible_to_scrape_legal_codes_to_create_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is it possible to scrape legal codes to create a database?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/suudoe",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-06T18:05:59.940808+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-06T17:54:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve finished scraping all the data I need for my project. Now I need to set up a database and import the data into it. I want to do this the right way, not just get it working, but follow a professional, maintainable process.</p> <p>What\u2019s the correct sequence of steps? Should I design the schema first? Are there standard practices for going from raw data to a structured, production-ready database?</p> <p>Sample Python dict from the cleaned data:</p> <p><code>{34731041: {&#39;Listing Code&#39;: &#39;KOEN55&#39;, &#39;Brand&#39;: &#39;Rolex&#39;, &#39;Model&#39;: &#39;Datejust 31&#39;, &#39;Year Of Production&#39;: &#39;2024&#39;, &#39;Condition&#39;: &#39;The item shows no signs of wear such as scratches or dents, and it has not been worn. The item has not been polished.&#39;, &#39;Location&#39;: &#39;United States of America, New York, New York City&#39;, &#39;Price&#39;: 25995.0}}</code></p> <p>The first key is a universally unique model ID.</p> <p",
        "id": 2867824,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l4ywq8/best_approach_for_moving_scraped_data_into_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best approach for moving scraped data into a database?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/keyayem",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-06T19:10:28.311174+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-06T14:18:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hii! I&#39;m working on my thesis and part of it involves scraping posts and comments from a specific subreddit. I&#39;m focusing on a certain topic, so I need to filter by keywords and ideally get both the main post and all the comments over a span of two years.</p> <p>I&#39;ve tried a few things already:</p> <ul> <li>PRAW - but it only gives me recent posts</li> <li>Pushshift - seems like it&#39;s no longer working?</li> </ul> <p>I&#39;m not sure what other tools or workarounds are thereee but, if anyone has suggestions or has done something similar before, I&#39;d seriously appreciate the help! Thank youuuuu</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/keyayem\"> /u/keyayem </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l4tlcc/struggling_with_web_scraping_reddit_data_need/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l4tlcc/struggling_with_w",
        "id": 2868236,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l4tlcc/struggling_with_web_scraping_reddit_data_need",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "struggling with web scraping reddit data - need advice \ud83d\ude4f",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/aaronboy22",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-06T14:50:27.504483+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-06T13:59:23+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey Reddit \ud83d\udc4b I&#39;m the founder of Chat4Data. We built a simple Chrome extension that lets you chat directly with any website to grab public data\u2014no coding required.</p> <p>Just install the extension, enter any URL, and chat naturally about the data you want (in any language!). Chat4Data instantly understands your request, extracts the data, and saves it straight to your computer as an Excel file. Our goal is to make web scraping painless for non-coders, founders, researchers, and builders.</p> <p>Today we\u2019re live on Product Hunt\ud83c\udf89 Try it now and get 1M tokens free to start! We&#39;re still in the early stages, so we\u2019d love feedback, questions, feature ideas, or just your hot takes. AMA! I&#39;ll be around all day! Check us out: <a href=\"https://www.chat4data.ai/\">https://www.chat4data.ai/</a> or find us in the Chrome Web Store. Proof: <a href=\"https://postimg.cc/62bcjSvj\">https://postimg.cc/62bcjSvj</a></p> </div><!-- SC_ON --> &#32; submitted by &#3",
        "id": 2866131,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l4t4dl/we_built_a_chatgptstyle_web_scraping_tool_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "We built a ChatGPT-style web scraping tool for non-coders. AMA\uff01",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/rockweller",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-06T10:30:27.829638+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-06T10:23:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking to get a database of Insta-gram and Tik-Tok usernames (All, or as comprehensive as possible) - bonus if it includes follower count or creation date.</p> <p>This is for a research/market analysis project, but I&#39;m hitting a wall. I&#39;d love to hear from anyone whos:</p> <p>- Has or Bought access to this kind of data</p> <p>- Built a scraper or paid a freelancer to do it</p> <p>How much does it cost? Is it feasible to do solo?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/rockweller\"> /u/rockweller </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l4oz22/anyone_ever_bought_or_built_a_social_media/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l4oz22/anyone_ever_bought_or_built_a_social_media/\">[comments]</a></span>",
        "id": 2864124,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l4oz22/anyone_ever_bought_or_built_a_social_media",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Anyone Ever Bought or Built a Social Media Username Database?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Tall-Lengthiness-472",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-06T13:45:27.877812+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-06T08:18:55+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I am new in this scraping world, I had a code for scraping prices in a website that was working around a year using curl_cffi to scrape the hidden api directly.</p> <p>But now 1 month ago is not working, I was thinking that this was due to a IPs ban from cloudflare but testing with a vpn installed in my vps that is hosted my code, I am able to scrape locally (windows 11) but not in my vps (ubuntu server), shows the message of &quot;Just a moment&quot;.</p> <p>Taking on acount that I test the code locally with the same IP from my VPS I am assuming that the problem is not related to my IP. It could be a problem with curl_cffi on linux?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tall-Lengthiness-472\"> /u/Tall-Lengthiness-472 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l4n6a1/curl_cffi_working_on_windows_but_not_linux/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.co",
        "id": 2865570,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l4n6a1/curl_cffi_working_on_windows_but_not_linux",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Curl_cffi working on windows but not linux",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Ok-Birthday5397",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-06T07:17:26.796190+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-06T07:02:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i&#39;ve made 2 scripts first a selenium which saves whole containers in html like laptop0.html then the other one reads them. now i&#39;ve asked AI for help hundreds of times but its not good i changed my script too but nothing is happening its just N/A for most prices (im new so explain with basics please)</p> <pre><code>from bs4 import BeautifulSoup import os folder = &quot;data&quot; for file in os.listdir(folder): if file.endswith(&quot;.html&quot;): with open(os.path.join(folder, file), &quot;r&quot;, encoding=&quot;utf-8&quot;) as f: soup = BeautifulSoup(f.read(), &quot;html.parser&quot;) title_tag = soup.find(&quot;h2&quot;) title = title_tag.get_text(strip=True) if title_tag else &quot;N/A&quot; prices_found = [] for price_container in soup.find_all(&#39;span&#39;, class_=&#39;a-price&#39;): price_span = price_container.find(&#39;span&#39;, class_=&#39;a-offscreen&#39;) if price_span: prices_found.append(price_span.text.strip()) if prices_fou",
        "id": 2863147,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l4m2t4/i_cant_get_prices_from_amazon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "i can't get prices from amazon",
        "vote": 0
    }
]