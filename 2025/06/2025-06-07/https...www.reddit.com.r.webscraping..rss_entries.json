[
    {
        "age": null,
        "album": "",
        "author": "/u/MtSnowden",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-07T21:13:23.025565+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-07T20:10:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anyone figured out a way to scrape the content off CWS extension pages? I was doing it until a few weeks ago, now I can&#39;t.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MtSnowden\"> /u/MtSnowden </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l5tzm6/scraping_the_chrome_web_store_extension_pages/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l5tzm6/scraping_the_chrome_web_store_extension_pages/\">[comments]</a></span>",
        "id": 2875794,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l5tzm6/scraping_the_chrome_web_store_extension_pages",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping the Chrome Web Store extension pages?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/StockOrganization874",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-07T20:08:22.173946+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-07T17:52:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I&#39;m trying to scrape data from the Cargoboard site: <a href=\"https://my.cargoboard.com/en-de\">https://my.cargoboard.com/en-de</a>. The process involves clicking the &quot;calculate&quot; button, which under the hood triggers an API call to:</p> <pre><code>bashCopyEdithttps://my.cargoboard.com/app/api/v1/acquisition </code></pre> <p>However, this API requires a valid Cloudflare Turnstile captcha token (<code>x-captcha-token</code>) in the headers. I&#39;ve tried using <strong>2Captcha</strong> to solve the captcha, but the response token always results in a <strong>403 Forbidden</strong> error when I use it in the API request.</p> <p>Here\u2019s a snippet of the request I&#39;m trying to send using Python <code>requests</code>:</p> <pre><code>pythonCopyEditimport requests, json url = &quot;https://my.cargoboard.com/app/api/v1/acquisition&quot; payload = json.dumps({...}) # redacted for brevity headers = { ... &#39;x-captcha-token&#39",
        "id": 2875518,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l5qua6/how_to_bypass_cloudflare_turnstile_captcha_when",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to Bypass Cloudflare Turnstile Captcha When Scraping Cargoboard?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Critical_Molasses844",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-07T20:08:22.371876+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-07T16:57:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have this code that I&#39;m using to try and fetch thousands of video urls from a specific website, why I am intercepting network with headless is because it requires JS and the video player is VideoJS so the website uses some kind of injection to src when it finds JS else the video url is hidden with simple html scraping</p> <pre><code>const puppeteer = require(&#39;puppeteer&#39;); const fetch = require(&#39;node-fetch&#39;); const cheerio = require(&#39;cheerio&#39;); const fs = require(&#39;fs&#39;); const { URL } = require(&#39;url&#39;); // === CONFIG === const BASE_URL = &quot;https://www.w.com&quot;; const VIDEO_LIST_URL = `${BASE_URL}/videos?o=mr&amp;type=public`; const DELAY = 1000; const MAX_RETRIES_PER_VIDEO = 10; const USE_EXISTING_LINKS_FILE = true; const VIDEO_LINKS_FILE = &#39;video_links.json&#39;; const USE_BROWSER_CONCURRENCY = true; const BROWSERS_COUNT = 3; const PAGES_PER_BROWSER = 3; // === UTILS === const delay = (ms) =&gt; n",
        "id": 2875519,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l5pj15/issues_with_puppeteer_concurrent_browsers_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Issues with puppeteer concurrent browsers and intercepting network",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/carlmango11",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-07T11:26:09.393925+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-07T11:13:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Anyone know where I could get a reliable source of residential IP addresses in Malaysia that use genuine residential ISPs? All the ones I&#39;ve found so far tend to give you addresses for things like web hosting companies or shady Eastern European ISPs that don&#39;t look authentic.</p> <p>If I use the true residential pools the IPs are changing every few hours even if configured to stay as sticky as possible.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/carlmango11\"> /u/carlmango11 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l5ie28/static_residential_malaysian_proxies/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l5ie28/static_residential_malaysian_proxies/\">[comments]</a></span>",
        "id": 2872840,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l5ie28/static_residential_malaysian_proxies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Static residential Malaysian proxies",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/GoingGeek",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-07T06:02:28.210458+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-07T05:03:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So I want to sell scraped datas, what kinda data should I target and how can I get buyers for them? would be really helpful.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GoingGeek\"> /u/GoingGeek </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l5cw3k/scraped_data_sell/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l5cw3k/scraped_data_sell/\">[comments]</a></span>",
        "id": 2871562,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l5cw3k/scraped_data_sell",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraped Data Sell",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/This_Cardiologist242",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-07T02:46:05.014067+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-07T01:43:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I haven\u2019t scraped Google or Bing for a few months - used my normal setup yesterday and low / behold I\u2019m getting bot checked.</p> <p>How accessible / adopted / recent are y\u2019all seeing different data sources go Captcha?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/This_Cardiologist242\"> /u/This_Cardiologist242 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l59ck6/what_websites_did_you_scrape_last_year_that_you/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1l59ck6/what_websites_did_you_scrape_last_year_that_you/\">[comments]</a></span>",
        "id": 2870973,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1l59ck6/what_websites_did_you_scrape_last_year_that_you",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "What websites did you scrape last year that you can\u2019t this year?",
        "vote": 0
    }
]