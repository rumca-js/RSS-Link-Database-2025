[
    {
        "age": null,
        "album": "",
        "author": "/u/brokecolleg3",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-19T23:54:49.188706+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-19T22:48:19+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Been struggling to create a web scraper in ChatGPT to scrape through sunbiz.org to find entity owners and address under authorized persons or officers. Does anyone know of an easier way to have it scraped outside of code? Or a better alternative than using ChatGPT and copy pasting back and forth. I\u2019m using an excel sheet with entity names. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/brokecolleg3\"> /u/brokecolleg3 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lfoeit/scraper_to_find_entity_owners/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lfoeit/scraper_to_find_entity_owners/\">[comments]</a></span>",
        "id": 2974636,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lfoeit/scraper_to_find_entity_owners",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraper to find entity owners",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/eranbeard",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-19T22:50:48.615441+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-19T22:46:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need to create an exhaustive (or as close as possible) database of running shoes and don&#39;t know where to start. A google search for &#39;every running shoe&#39; returns the main shoe review websites, so I&#39;m assuming I need to start looking there, but unsure what tools to use and how to go about it. Any help appreciated. Happy to pay for tools/services.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/eranbeard\"> /u/eranbeard </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lfocwi/database_of_running_shoes/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lfocwi/database_of_running_shoes/\">[comments]</a></span>",
        "id": 2974289,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lfocwi/database_of_running_shoes",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Database of running shoes",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Jazzlike_Middle2757",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-19T22:50:48.787694+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-19T21:59:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>The company I work at wants to use our data engineering stack, Dagster for scheduling and running of code, docker to containerize our dagster instance which is running on an EC2 instance to run web scraping and automation scripts probably using selenium. </p> <p>I am not worried about the ethical/legal aspect of this since the websites we plan on interacting with have allowed us to do this. </p> <p>I am more concerned about if this skill is valuable in the field since I don&#39;t see anyone mentioning web scraping in job listings for roles like data engineer which is what I do now. </p> <p>Should I look to move to another part of the company I work at like in full-stack development? I enjoy the work I do but I worry that this skill is extremely niche, and not valued. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Jazzlike_Middle2757\"> /u/Jazzlike_Middle2757 </a> <br/> <span><a href=\"https://www.reddit.com/r/web",
        "id": 2974290,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lfnaqc/are_companies_looking_for_people_with_web",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are companies looking for people with web scraping skills",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Tottalynotmrlean",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-19T16:18:04.117310+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-19T15:28:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I\u2019m trying to scrape match and player data from HLTV for a personal Counter Strike stats project. However, I keep running into Cloudflare\u2019s anti-bot protections that block all my requests.</p> <p>So far, I\u2019ve tried:</p> <ul> <li>Puppeteer </li> <li>Using different user agents and proxy rotation</li> <li>Waiting for the Cloudflare challenge to pass automatically in Puppeteer</li> <li>Other scraping libraries like requests-html and Selenium</li> </ul> <p>But I\u2019m still getting blocked or getting the \u201cAttention Required\u201d page from Cloudflare, and I\u2019m not sure how to bypass it reliably. I don\u2019t want to resort to manual data scraping, and I\u2019d like a programmatic way to get HLTV data.</p> <p>Has anyone successfully scraped HLTV behind Cloudflare recently? What methods or tools did you use? Any tips on getting around Cloudflare\u2019s JavaScript challenges?</p> <p>Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"ht",
        "id": 2971915,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lfdogz/struggling_to_scrape_hltv_data_because_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Struggling to scrape HLTV data because of Cloudflare",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Old-Machine8134",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-19T20:38:33.299442+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-19T11:32:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I\u2019m developing a new web scraping solution and I\u2019d love to stress-test it against dedicated \u201cbot test\u201d pages or sandbox environments. My two main goals are:</p> <p>Bot detection</p> <p>Ensure my scraper isn\u2019t flagged or blocked by anti-bot test sites (CAPTCHAs, rate limits, honeypots, fingerprinting, and so on)</p> <p>Complex data extraction</p> <p>Verify it can navigate and scrape dynamic pages (JS rendering, infinite scroll), multi-step forms, and nested data structures (nested tables, embedded JSON and so on)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Old-Machine8134\"> /u/Old-Machine8134 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lf8hig/looking_for_test_sites_or_to_validate_bot_and/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lf8hig/looking_for_test_sites_or_to_validate_bot_and/\">[comments]</a></span>",
        "id": 2973680,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lf8hig/looking_for_test_sites_or_to_validate_bot_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for test sites or to validate bot and data extraction",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/New_Needleworker7830",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-19T10:42:30.666257+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-19T09:41:01+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1lf6ol3/ispiderui/\"> <img src=\"https://b.thumbs.redditmedia.com/TVeg7r-tvF91Ynx_HmLyKHwab9l6znfW56diOqeZRas.jpg\" alt=\"iSpiderUI\" title=\"iSpiderUI\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>From my iSpider, I created a server version, and a fastAPI interface for control<br/> (<br/> it&#39;s on server 3 branch <a href=\"https://github.com/danruggi/ispider/tree/server3\">https://github.com/danruggi/ispider/tree/server3</a><br/> not yet documented but callable as<br/> <code>ispider api</code><br/> or<br/> <code>ISpider(domains=[], stage=&quot;unified&quot;, **config_overrides).run()</code><br/> ) </p> <p>I&#39;m creating a swift app, that will manage it. I didn&#39;t know swift since last week.<br/> Swift is great! Powerful and strict. </p> <p><a href=\"https://preview.redd.it/2iu9bk4ztu7f1.png?width=1912&amp;format=png&amp;auto=webp&amp;s=ac267b892eb507e024dfe7b47524f2427afe22a3\">https://preview.redd.it/2iu9bk",
        "id": 2969468,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lf6ol3/ispiderui",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/TVeg7r-tvF91Ynx_HmLyKHwab9l6znfW56diOqeZRas.jpg",
        "title": "iSpiderUI",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/Swaptionsb",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-19T00:52:56.809454+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-19T00:36:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Apologize if a basic question. Searched for answer, but did not find any results.</p> <p>I have a program to scrape fangraphs, to get a variety of statistics from different tables. It has been running for about 2 years successfully. Over the past couple of days, it has been breaking with an error code like : </p> <p>HTTPConnectionPool: Max retries exceeded, Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it&#39;))</p> <p>It is intermittent. It runs over a loop of roughly 25 urls or so. Sometimes it breaks on the 2nd url in the list, sometimes in the 10th. </p> <p>What causes this error? Has the site set up anti-scraping defenses? Is the most recent updated to chrome not good? </p> <p>I scrape other pages as well, but those run in their own codes, individual page scraped per script. This is the only one I have in a loop. </p> <p>Is there an easy way to fix this? I am startin",
        "id": 2967097,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lexbyv/python_selenium_errors_and_questions",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Python Selenium errors and questions",
        "vote": 0
    }
]