[
    {
        "age": null,
        "album": "",
        "author": "/u/SnarkBadger",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-20T21:35:19.061729+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-20T21:04:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi.</p> <p>So, I&#39;m Canadian, and the Premier (Governor equivalent for the US people! Hi!) of Ontario is planning on destroying records of Inspections for Long Term Care homes. I want to help some people preserve these files, as it&#39;s massively important, especially since it outlines which ones broke governmental rules and regulations, and if they complied with legal orders to fix dangerous issues. It&#39;s also useful to those who are fighting for justice for those harmed in those places and for those trying to find a safe one for their loved ones.</p> <p>This is the website in question - <a href=\"https://publicreporting.ltchomes.net/en-ca/Default.aspx\">https://publicreporting.ltchomes.net/en-ca/Default.aspx</a></p> <p>Thing is... I have zero idea how to do it. </p> <p>I need help. Even a tutorial for dummies would help. I don&#39;t know which places are credible for information on how to do this - there&#39;s so much garbage online, fake websi",
        "id": 2982368,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lgf1zg/newbie_question_scraping_1000s_of_pdfs_from_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Newbie Question - Scraping 1000s of PDFs from a website",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/carlmango11",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-20T14:00:25.565297+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-20T13:45:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>There&#39;s a project I&#39;m working on where I need a proxy that is truly residential but where my IP won&#39;t be changing every few hours.</p> <p>I&#39;m not looking for sources as I can do my own research, but I&#39;m just wondering if this product is even available publicly? It seems most resi providers just have a constantly shifting pool and the best they can do is try to keep you pinned to a particular IP but in reality it gets rotated very regularly (multiple times per day).</p> <p>Am I looking for something that doesn&#39;t exist?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/carlmango11\"> /u/carlmango11 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lg4dgz/does_this_product_exist/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lg4dgz/does_this_product_exist/\">[comments]</a></span>",
        "id": 2978742,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lg4dgz/does_this_product_exist",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Does this product exist?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": "/u/cabinetk",
        "bookmarked": false,
        "comments": [],
        "date_created": "2025-06-20T08:34:52.902505+00:00",
        "date_dead_since": null,
        "date_published": "2025-06-20T08:26:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello people,</p> <p>I am trying to get the contact urls for websites that contain a specific phrase.</p> <p>Tried google with advanced search and it does the job, but it limits the results. We also did some vpn rotation and it works to get some other results, but I am looking for a faster solution.</p> <p>Any ideas about how to improve this?</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cabinetk\"> /u/cabinetk </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lfyrso/how_to_scrape_contact_page_urls_for_websites_that/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1lfyrso/how_to_scrape_contact_page_urls_for_websites_that/\">[comments]</a></span>",
        "id": 2976558,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1lfyrso/how_to_scrape_contact_page_urls_for_websites_that",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape contact page urls for websites that contain a phrase",
        "vote": 0
    }
]