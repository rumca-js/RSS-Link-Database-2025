[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-05T23:13:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to scrap data from market website after searching for a specific brand, how to automate this process and scrap the data from the API directly? If any one can help please describe the process step by step. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DoublePistons\"> /u/DoublePistons </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hukbus/how_to_scrap_data_using_api_from_website/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hukbus/how_to_scrap_data_using_api_from_website/\">[comments]</a></span>",
        "id": 1839970,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hukbus/how_to_scrap_data_using_api_from_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrap data using API from website?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-05T21:34:03+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone, </p> <p>I am working on a project where I need to scrape data of a particular movie from a ticketing website (in this case fandang o). Images to scrape data of all the list of theatres with its links to a json. </p> <p>Now the actual problem comes from here, the ticketing url for each row is in a subdomain called tickets. fandango. com and each show generates a seat map and I need the response json to get seat availability and pricing data. And the seatmap fetch url is dynamic(it takes the click date and time with milliseconds and generates url) and that website have a pretty strong bot detection like Google captcha and all and I am new to this</p> <p>Requests and other libraries aren&#39;t working, so I proceeded with playwright with the headless mode but I am not getting the response, it only works with headless as False. It&#39;s fine for 50 or 100 URLs but I need to automate this for a minimum of 2000 URLs and it is taking me 12 h",
        "id": 1839723,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1huhz7g/need_help_scraping_data_from_a_website_for_2000",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need Help scraping data from a website for 2000+ URLs efficiently",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-05T19:20:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve learned Python and have dabbled a bit in Machine Learning, but I soon realized that most of the Machine Learning projects on freelancing platforms are given to people with more experience. As a self-taught programmer with no full-time work experience in an organization, I was looking for something I could dive into. That&#39;s when I discovered web scraping. I noticed that there are plenty of opportunities in this field on freelancing websites, so I decided to focus on it. I even landed my first web scraping job on Upwork and successfully completed it. Now, I&#39;m curious to understand the earning potential of web scraping on freelancing platforms like Upwork and how far I can go in this field</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/WalkCompetitive216\"> /u/WalkCompetitive216 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1huerz3/how_to_make_money_as_a_web_scraping_freel",
        "id": 1839220,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1huerz3/how_to_make_money_as_a_web_scraping_freelancer",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to make money as a Web Scraping freelancer?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-05T10:41:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>There is one site, this site has copyright and it is a dynamic website and I can log in to this site with a login. There are 3200 sublinks on this site and I want to scrape these sublinks under one heading and the texts written under each heading as a cell. I get the copyright warning as follows. After clicking on 10 or more links, my access to other links is blocked.</p> <p>How do you think I scrape this site?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Correct_Matter_2833\"> /u/Correct_Matter_2833 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hu4ae6/webscraping_from_copyrighted_and_dynamic_website/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hu4ae6/webscraping_from_copyrighted_and_dynamic_website/\">[comments]</a></span>",
        "id": 1837354,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hu4ae6/webscraping_from_copyrighted_and_dynamic_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "WebScraping from copyrighted and dynamic website",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-05T07:33:12+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Good every one I&#39;m new here Please I&#39;m trying to scrape home details from a real estate site(realtor.com) and there is the road block CAPTCHA press and hold Does anyone know how i can solve it in my script I&#39;m using playwright Please any work around over it</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Appropriate_Nose7257\"> /u/Appropriate_Nose7257 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hu0prl/trying_to_by_pass_press_and_hold_captcha/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hu0prl/trying_to_by_pass_press_and_hold_captcha/\">[comments]</a></span>",
        "id": 1836942,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hu0prl/trying_to_by_pass_press_and_hold_captcha",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Trying to by pass press and hold captcha",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-05T02:30:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all, </p> <p>I\u2018m doing my first web scraping project that arised out of a private need: scraping car listings from the popular mobile.de. The page is very limited when it comes to filtering (i.e. only 3 model/brand exclusion filters) and it\u2018s a pain to browse it with alle the ads and looking at countless listings.</p> <p>My code to scrape it actually runs very well and I had to overcome challenges like botdetection with playwright and scraping by parsing the URL (and also continuing to scrape data from pages abover 50 even though the website doesn\u2018t allow you to display listings after page 50 except for manually changing the URL!) </p> <p>So far it has been a very nice personal project and I want to finish it off by creating a simple (very simple!) web app using FastAPI, SQLite3 and htmx. </p> <p>However I have no knowledge of designing APIs, I have only ever used them. And I don\u2018t even know what exactly I want to ask here, and ChatGPT doesn\u2018t he",
        "id": 1835858,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1htvd4a/creating_a_web_app_to_interact_with_scraped_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Creating a (web) app to interact with scraped data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-05T00:49:32+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1httbi2/i_made_a_javassript_bookmarklet_that_automates/\"> <img src=\"https://external-preview.redd.it/X-jGFj7vmHLOh0-Db47fVvENWN6yCfUfbq0F055xuso.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d0650dded8cc6c8df5ccd7a3d2030e4b54cd924b\" alt=\"I made a JavasSript bookmarklet that automates blocking spam accounts\" title=\"I made a JavasSript bookmarklet that automates blocking spam accounts\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/readwithai\"> /u/readwithai </a> <br/> <span><a href=\"https://readwithai.substack.com/p/install-report-users-on-x-using-a\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1httbi2/i_made_a_javassript_bookmarklet_that_automates/\">[comments]</a></span> </td></tr></table>",
        "id": 1835731,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1httbi2/i_made_a_javassript_bookmarklet_that_automates",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/X-jGFj7vmHLOh0-Db47fVvENWN6yCfUfbq0F055xuso.jpg?width=320&crop=smart&auto=webp&s=d0650dded8cc6c8df5ccd7a3d2030e4b54cd924b",
        "title": "I made a JavasSript bookmarklet that automates blocking spam accounts",
        "vote": 0
    }
]