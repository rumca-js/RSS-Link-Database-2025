[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-02T22:55:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve been trying to scrape ChatGPT site with different tools (Selenium, Puppeteer, PlayWright) and setups (using proxies, scraping browsers like the one provided by Zenrows) and I always face the same issue, the page says &quot;Just a moment...&quot; and the UI won&#39;t load.</p> <p>Anyone has been able to scrape ChatGPT website recently? The reason I&#39;m trying to accomplish this is because using OpenAI API won&#39;t give me sources/citations of websites used to generate the response like the browser app does, and I&#39;m trying to monitor how often my company website gets mentioned by ChatGPT on certain queries.</p> <p>I&#39;d love any inputs on this or if there are better ways to achieve the same result with ChatGPT, since their support team did not give me much information on if/when the sources/citations would be available in the API.</p> <p>Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.c",
        "id": 1823901,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hs7333/scraping_chatcom_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping chat.com website",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-02T19:09:53+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1hs1ld9/can_someone_let_me_know_how_to_get_the_data_on/\"> <img src=\"https://preview.redd.it/0fwujpwcqmae1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d919d244ed72a8698d328437a9ae7dc8080096ad\" alt=\"Can someone let me know how to get the data on the left ? When I select a country and click search there is no api in the networks tab fetch/xhr which is giving out this data.\" title=\"Can someone let me know how to get the data on the left ? When I select a country and click search there is no api in the networks tab fetch/xhr which is giving out this data.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TalhaOnReddit\"> /u/TalhaOnReddit </a> <br/> <span><a href=\"https://i.redd.it/0fwujpwcqmae1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hs1ld9/can_someone_let_me_know_how_to_get_the_data_on/\">[comments]</a></span> </td></tr></table>",
        "id": 1823902,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hs1ld9/can_someone_let_me_know_how_to_get_the_data_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/0fwujpwcqmae1.png?width=640&crop=smart&auto=webp&s=d919d244ed72a8698d328437a9ae7dc8080096ad",
        "title": "Can someone let me know how to get the data on the left ? When I select a country and click search there is no api in the networks tab fetch/xhr which is giving out this data.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-02T17:25:20+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1hrz0jo/help_on_best_approach_to_scrapping_to_a_google/\"> <img src=\"https://b.thumbs.redditmedia.com/8hwXklPSaOXGAK-SQkaY9q_iXVBFuzql9n862-vYSfk.jpg\" alt=\"Help on best approach to Scrapping to a Google Sheet\" title=\"Help on best approach to Scrapping to a Google Sheet\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi, this might sound really dumb but I&#39;m trying to catalogue all the Lego pieces I have. </p> <p>The most efficient way I have found is by going to a page like this:</p> <p><a href=\"https://preview.redd.it/xy819ft77mae1.png?width=1889&amp;format=png&amp;auto=webp&amp;s=5ad3936d7f615ba10cb489026d2e5d1cd23c52ae\">Example Piece page</a></p> <p>Then opening a new tab for each piece and manually copying the information I want from it to a Google Sheet.</p> <p><a href=\"https://preview.redd.it/lafae5hi7mae1.png?width=762&amp;format=png&amp;auto=webp&amp;s=771f6cb50e4847808dd098274137a3504268a365\">Exam",
        "id": 1821974,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hrz0jo/help_on_best_approach_to_scrapping_to_a_google",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/8hwXklPSaOXGAK-SQkaY9q_iXVBFuzql9n862-vYSfk.jpg",
        "title": "Help on best approach to Scrapping to a Google Sheet",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-02T16:21:26+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1hrxggv/what_do_employers_expect_from_an_ethical_scraper/\"> <img src=\"https://b.thumbs.redditmedia.com/lZWDahsLi5KOUfSQIcSpJcm8HZqOmgcZ3JH74rpL_fE.jpg\" alt=\"What do employers expect from an &quot;ethical scraper&quot;?\" title=\"What do employers expect from an &quot;ethical scraper&quot;?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I&#39;ve always wondered what companies expect from you when you apply to a job posting like this, and the topic of &quot;ethical scraping&quot; comes up. Like in this random example (underlined), they&#39;re looking for a scraper to get data off ThatJobSite, who can also &quot;ensure compliance with website terms of service&quot;. ThatJobSite&#39;s terms of service clearly and explicitly forbids all kinds of automated data scraping and copying of any site data. Soooo... what exactly are they expecting? Is it just a formality? If I applied to a job like this, and they asked me ",
        "id": 1821593,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hrxggv/what_do_employers_expect_from_an_ethical_scraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/lZWDahsLi5KOUfSQIcSpJcm8HZqOmgcZ3JH74rpL_fE.jpg",
        "title": "What do employers expect from an \"ethical scraper\"?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-02T16:19:35+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/beam123\"> /u/beam123 </a> <br/> <span><a href=\"https://onequery.app/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hrxet0/has_anyone_tried_ai_web_scrapers_i_found_this_one/\">[comments]</a></span>",
        "id": 1821594,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hrxet0/has_anyone_tried_ai_web_scrapers_i_found_this_one",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Has anyone tried AI web scrapers? I found this one on another sub but I don't get how it works",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-02T15:22:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi folks! </p> <p>I&#39;m scraping hundreds of thousands of SKU reviews from various marketplaces and so far did not find any use for them.</p> <p>My idea is to run a couple of AI agents to filter and summarize them, but dedicated servers I use are non-GPU ones and agents like ollama one are insanely slow, even with 1B models.</p> <p>There are enough offerings on the market with SaaS and GPU enabled servers to rent, but I&#39;d really wanna go cheap and test it first without spending $$$$. </p> <p>Have you tried running production agents on cheap dedis? Like hetzner auctions have GTX1080 servers for ~$120, shall it be able to run 3.2:7b models fast enough? </p> <p>Have you got experience to share? </p> <p>P.S. Please do not post SaaS suggestions, that&#39;s not interesting at scale</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/danila_bodrov\"> /u/danila_bodrov </a> <br/> <span><a href=\"https://www.reddit.com/r/",
        "id": 1821191,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hrw2r7/ai_agent_hardware",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "AI agent hardware",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-02T14:33:07+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi again. My 2nd post today. I hope it&#39;s not too much.</p> <p>Question: Is it possible to scrape Youtube video links with titles, and possibly associated channel links? </p> <p>I know I can use Link Gopher to get a big list of video urls, but I can&#39;t get the video titles with that.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dandyweb\"> /u/dandyweb </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hruzsj/extract_youtube/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hruzsj/extract_youtube/\">[comments]</a></span>",
        "id": 1823903,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hruzsj/extract_youtube",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Extract YouTube",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-02T09:55:12+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1hrqdog/scrape_web_page_elements_fast_with_python_selenium/\"> <img src=\"https://external-preview.redd.it/T0MztKmCtPPLe8Eq5G1KnbKQWIhavTny3uBZ6thkNBY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c942a7bbbf4fbe022c173bf837a840ff9cb8928e\" alt=\"Scrape Web Page Elements FAST with Python Selenium!\" title=\"Scrape Web Page Elements FAST with Python Selenium!\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Capable-Post-5674\"> /u/Capable-Post-5674 </a> <br/> <span><a href=\"https://youtube.com/watch?v=U6RTD3poRlA&amp;si=y5k4GTJM7bKiIVjn\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hrqdog/scrape_web_page_elements_fast_with_python_selenium/\">[comments]</a></span> </td></tr></table>",
        "id": 1819380,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hrqdog/scrape_web_page_elements_fast_with_python_selenium",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/T0MztKmCtPPLe8Eq5G1KnbKQWIhavTny3uBZ6thkNBY.jpg?width=320&crop=smart&auto=webp&s=c942a7bbbf4fbe022c173bf837a840ff9cb8928e",
        "title": "Scrape Web Page Elements FAST with Python Selenium!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-02T05:57:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys might you know how to navigate the following </p> <p>DevTools listening on ws://127.0.0.1:59337/devtools/browser/91da8b9c-df06-4332-bf31-6e9c2fb14fdd Created TensorFlow Lite XNNPACK delegate for CPU.</p> <p>This occurs when it tries to navigate to the next page. It can scrape the first page successfully but the moment it navigates to the next pages, it either shows the above or just move to the subsequent pages without grabbing any details.</p> <p>I&#39;ve tried adding chrome options (--log-level) still no juice</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Kali_Linux_Rasta\"> /u/Kali_Linux_Rasta </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hrn2ty/selenium_using_chrome_driver/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hrn2ty/selenium_using_chrome_driver/\">[comments]</a></span>",
        "id": 1818632,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hrn2ty/selenium_using_chrome_driver",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Selenium using chrome driver",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-02T05:28:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I am trying to scrape data from: <a href=\"https://www.autotrader.ca/\">https://www.autotrader.ca/</a></p> <p>I am using a scrapy crawler to extract all the urls from the search results pages. I can do this successfully.</p> <p>My issue is when I go an extract the data from the details pages like this below:<br/> - <a href=\"https://www.autotrader.ca/a/lexus/rx%20450h%2B/toronto/ontario/5_64448219_on20090209112810199\">https://www.autotrader.ca/a/lexus/rx%20450h%2B/toronto/ontario/5_64448219_on20090209112810199</a></p> <p>There is a hidden api so I can&#39;t use an api to get this data, there is JS rendering so scrapy can&#39;t extract the data on its own. I am using scrapy-selenium to get around this. I am able to get 1 page done but when i try to do 4-5 different pages, after the first page i keep getting errors.</p> <p>I am not sure what I am doing wrong, I am right now just trying to get this to scale across multiple pages but keep getting errors",
        "id": 1818633,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hrmm25/getting_error_results_from_scrapyselenium",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Getting error results from scrapy-selenium",
        "vote": 0
    }
]