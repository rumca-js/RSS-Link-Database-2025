# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Difference between CSE and Custom Search API call
 - [https://www.reddit.com/r/webscraping/comments/1hxpcpi/difference_between_cse_and_custom_search_api_call](https://www.reddit.com/r/webscraping/comments/1hxpcpi/difference_between_cse_and_custom_search_api_call)
 - RSS feed: $source
 - date published: 2025-01-09T22:37:18+00:00

<!-- SC_OFF --><div class="md"><p>I created a google custom search engine, and when I use it manually from the dashboard, the results are quite relevant. When I search via an api call though, on that same exact search engine cx, the results are very very different. Whats weird is when I put the same url of the get request I use in my code into my browser, the search results are good again... </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/The_Drakon"> /u/The_Drakon </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hxpcpi/difference_between_cse_and_custom_search_api_call/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hxpcpi/difference_between_cse_and_custom_search_api_call/">[comments]</a></span>

## What scraper should I use to make a site similar to DekuDeals.com?
 - [https://www.reddit.com/r/webscraping/comments/1hxjwpr/what_scraper_should_i_use_to_make_a_site_similar](https://www.reddit.com/r/webscraping/comments/1hxjwpr/what_scraper_should_i_use_to_make_a_site_similar)
 - RSS feed: $source
 - date published: 2025-01-09T18:44:38+00:00

<!-- SC_OFF --><div class="md"><p>I am looking to start a website similar to <a href="http://DekuDeals.com">DekuDeals.com</a> but instead sells ukuleles.</p> <p>Features:</p> <ul> <li>tracks historical price</li> <li>notifies you of sales</li> <li>gets me affiliate sales</li> </ul> <p>I think I need to webscrape because there are no public API offerings for some of the sites: <a href="http://GuitarCenter.com">GuitarCenter.com</a>, <a href="http://Sweetwater.com">Sweetwater.com</a>, <a href="http://Reverb.com">Reverb.com</a>, <a href="http://alohacityukes.com">alohacityukes.com</a></p> <p>Any and all tips appreciated. I am new to this and have little coding experience but have a bit of experience using AI to help me code.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/YouDontTellMe"> /u/YouDontTellMe </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hxjwpr/what_scraper_should_i_use_to_make_a_site_similar/">[link]</a></span

## Most companies' website have a legal (ToS) prohibiting scraping.
 - [https://www.reddit.com/r/webscraping/comments/1hxfqyq/most_companies_website_have_a_legal_tos](https://www.reddit.com/r/webscraping/comments/1hxfqyq/most_companies_website_have_a_legal_tos)
 - RSS feed: $source
 - date published: 2025-01-09T15:49:55+00:00

<!-- SC_OFF --><div class="md"><p>If every company&#39;s website has a &quot;legally binding&quot; (Terms of service) prohibiting scraping, then how is it possible to build any business around it without getting sued &amp; lose in court?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/PhaseOk_1"> /u/PhaseOk_1 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hxfqyq/most_companies_website_have_a_legal_tos/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hxfqyq/most_companies_website_have_a_legal_tos/">[comments]</a></span>

## Looking to scrape emails off of FB post comments
 - [https://www.reddit.com/r/webscraping/comments/1hxdjm8/looking_to_scrape_emails_off_of_fb_post_comments](https://www.reddit.com/r/webscraping/comments/1hxdjm8/looking_to_scrape_emails_off_of_fb_post_comments)
 - RSS feed: $source
 - date published: 2025-01-09T14:07:40+00:00

<!-- SC_OFF --><div class="md"><p>I recently made a post in an FB group that got a ton of comments with their emails asking to learn more. Looking to scrape the emails and names of those who commented for easy and efficient sending. Any tools you recommend? Currently using the email extractor chrome extension but it doesn&#39;t grab the names. Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/RenaTodd9817"> /u/RenaTodd9817 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hxdjm8/looking_to_scrape_emails_off_of_fb_post_comments/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hxdjm8/looking_to_scrape_emails_off_of_fb_post_comments/">[comments]</a></span>

## ntscraper shut down due to regulations, do you know any alternatives?
 - [https://www.reddit.com/r/webscraping/comments/1hxb8cl/ntscraper_shut_down_due_to_regulations_do_you](https://www.reddit.com/r/webscraping/comments/1hxb8cl/ntscraper_shut_down_due_to_regulations_do_you)
 - RSS feed: $source
 - date published: 2025-01-09T11:59:25+00:00

<!-- SC_OFF --><div class="md"><p>I was trying to do som <a href="http://X.com">X.com</a> data scraping and found out that ntscraper is shut down, do you know of any other library for efficiently scraping? If posible an efficient one as I&#39;d like to retrieve quite some data. Any help is welcome, I&#39;m a bit new to this</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/jsandi99"> /u/jsandi99 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hxb8cl/ntscraper_shut_down_due_to_regulations_do_you/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hxb8cl/ntscraper_shut_down_due_to_regulations_do_you/">[comments]</a></span>

## Faster scraping (Fundus, CC_NEWS dataset)
 - [https://www.reddit.com/r/webscraping/comments/1hx4h66/faster_scraping_fundus_cc_news_dataset](https://www.reddit.com/r/webscraping/comments/1hx4h66/faster_scraping_fundus_cc_news_dataset)
 - RSS feed: $source
 - date published: 2025-01-09T04:13:08+00:00

<!-- SC_OFF --><div class="md"><p>Hey! I have been trying to scrape a lot of newspaper articles using fundus library and cc_news dataset. So far i have been able to scrape around 40k in around 10 hours. Which is very slow for my goal. 1) Scraping is done on CPU, would there be any benefit for me to google colab that shit and use a A100. (Chat gpt said it wouldnt help) 2) the library documentation says the code automatically uses all available cores, how can I check if it is true. Task manager shows my cpu usage isnt that high 3) can I run multiple scripts at the same time, I assume if the limitation is something else than cpu power this could help 4) if i walk to class closing the lid (idk how to call it) would the script stop working (i guess the computer would go to sleep and i would have no internet access) If you know that can make this process faster pls lmk!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/guywiththemonocle"> /u/guywiththem

## Looking for contributors!
 - [https://www.reddit.com/r/webscraping/comments/1hx3lie/looking_for_contributors](https://www.reddit.com/r/webscraping/comments/1hx3lie/looking_for_contributors)
 - RSS feed: $source
 - date published: 2025-01-09T03:29:47+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone! I&#39;m building an open-source, free, and lightweight tool to streamline the discovery of API documentation, policies. Here&#39;s the repo: <a href="https://github.com/UpdAPI/updAPI">https://github.com/UpdAPI/updAPI</a></p> <p>I&#39;m looking for contributors to help verify API doc&#39;s URLs and add new entries. This is a great project for <strong>first-time</strong> contributors or even non-coders!</p> <p>P.S&gt; It&#39;s my first time managing an open-source project, so I&#39;m learning as I go. If you have tips on inviting contributors or growing and managing a community, I’d love to hear them too!</p> <p>Thanks for reading, and I hope you’ll join the project!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Downtown-Law-2381"> /u/Downtown-Law-2381 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hx3lie/looking_for_contributors/">[link]</a></span> &#32; <span><a href="htt

## best way to access meta and google text and image data for research
 - [https://www.reddit.com/r/webscraping/comments/1hx1qnu/best_way_to_access_meta_and_google_text_and_image](https://www.reddit.com/r/webscraping/comments/1hx1qnu/best_way_to_access_meta_and_google_text_and_image)
 - RSS feed: $source
 - date published: 2025-01-09T02:03:52+00:00

<!-- SC_OFF --><div class="md"><h1>I need to access text and image data from meta platforms (fb, insta) and google to conduct research on political communication. What is the best and convenient way to access their data? Help a beginner. Thanks.</h1> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Own-Bodybuilder4821"> /u/Own-Bodybuilder4821 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hx1qnu/best_way_to_access_meta_and_google_text_and_image/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hx1qnu/best_way_to_access_meta_and_google_text_and_image/">[comments]</a></span>

## Impersonate JA4/H2 fingerprint of the latest browsers (Chrome, FF)
 - [https://www.reddit.com/r/webscraping/comments/1hwzt7o/impersonate_ja4h2_fingerprint_of_the_latest](https://www.reddit.com/r/webscraping/comments/1hwzt7o/impersonate_ja4h2_fingerprint_of_the_latest)
 - RSS feed: $source
 - date published: 2025-01-09T00:29:45+00:00

<!-- SC_OFF --><div class="md"><p>Hello,</p> <p><a href="https://www.fluxzy.io/resources/blogs/impersonate-network-fingerprint">We’ve shipped a network impersonation feature</a> for the latest browsers in the latest release of <a href="https://github.com/haga-rak/fluxzy.core">Fluxzy</a>, a Man-in-the-Middle (MITM) library.</p> <p>We thought you folks in <a href="/r/webscraping">r/webscraping</a> might find this feature useful.</p> <p>It currently supports the fingerprints of Chrome 131 (Windows and Android), Firefox 133 (Windows), and Edge 131 (Windows), running with the Hybrid Agreement X25519-MLKEM768.</p> <p><strong>Main differences from other tools:</strong></p> <ul> <li>Can be a standalone proxy, so you can keep using your favorite HTTP client.</li> <li>Runs on Docker, Windows, Linux, and macOS.</li> <li>Offers fingerprint customization via configuration, as long as the required TLS settings are supported.</li> </ul> <p>We’d love to hear your feedback, especially since browser s

