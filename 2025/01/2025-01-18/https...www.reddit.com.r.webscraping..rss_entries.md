# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Scraping a legacy site with mixed code
 - [https://www.reddit.com/r/webscraping/comments/1i4ihjw/scraping_a_legacy_site_with_mixed_code](https://www.reddit.com/r/webscraping/comments/1i4ihjw/scraping_a_legacy_site_with_mixed_code)
 - RSS feed: $source
 - date published: 2025-01-18T21:55:34+00:00

<!-- SC_OFF --><div class="md"><p>I have inherited a legacy website when my father passed away. He built it over years using available tools whilst he was learning - he was in his seventies when he died. Consequently there are 80000 pages built using MS Frontpage (yes, seriously!) right through to MS Visual Studio and everything in between.</p> <p>I would like to find the best way to port the site to Wordpress. What is the best way to do this? What tools are currently available? Is there an AI tool that can take in a url and create a page? </p> <p>An example of the issues is a heading that should be an H1 tag turns out to be formatted text. And there are groups of pages using different schema and CSS.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/darrylxxx"> /u/darrylxxx </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i4ihjw/scraping_a_legacy_site_with_mixed_code/">[link]</a></span> &#32; <span><a href="https://www.red

## Scraping Truth Social
 - [https://www.reddit.com/r/webscraping/comments/1i4fsif/scraping_truth_social](https://www.reddit.com/r/webscraping/comments/1i4fsif/scraping_truth_social)
 - RSS feed: $source
 - date published: 2025-01-18T19:52:32+00:00

<!-- SC_OFF --><div class="md"><p>Hey everybody, I&#39;m trying to scrape a certain individual&#39;s truth social account to do an analysis on rhetoric for a paper I&#39;m doing. I found TruthBrush, but it gets blocked by cloudflare. I&#39;m new to scraping, so talk to me like I&#39;m 5 years old. Is there any way to do this? The timeframe I&#39;m looking at is about 10,000 posts total, so doing the 50 or so and waiting to do more isn&#39;t very viable.</p> <p>I also found TrumpsTruths, a website that gathers all his posts. I&#39;d rather not go through them all one by one. Would it be easier to somehow scrape from there, rather than the actual Truth social site/app?</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Meizas"> /u/Meizas </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i4fsif/scraping_truth_social/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i4fsif/scra

## So is hCaptcha now essentially impenetrable to automated solving?
 - [https://www.reddit.com/r/webscraping/comments/1i47z9d/so_is_hcaptcha_now_essentially_impenetrable_to](https://www.reddit.com/r/webscraping/comments/1i47z9d/so_is_hcaptcha_now_essentially_impenetrable_to)
 - RSS feed: $source
 - date published: 2025-01-18T13:53:11+00:00

<!-- SC_OFF --><div class="md"><p>There are too many puzzle types and they are also seemingly getting increasingly complex as well. They have also sent out cease and desists to all the solver platforms. For fun I tried making my own solver for one puzzle type (the one where you have icons with a pair of different animals ie tiger and frog scattered on the background and you need to click on the one that isn&#39;t of the same 2 animals as the rest). I managed to get to about an 80% solve rate using opencv to get the bounding boxes and then sending it to GPT vision. But it&#39;s a moot point since there are another 50 fucking types of puzzles.</p> <p>From what I can tell vision LLMs are not there when it comes to solving it either. For my solution I cropped all the icons, line them up in a row and mark them with numbers and ask the LLM to find the different pair. In other words I passed the easiest possible version of the problem to the LLM and it still fails 20% of the time. </p> <p>I

## Webscraping strategy
 - [https://www.reddit.com/r/webscraping/comments/1i46fbb/webscraping_strategy](https://www.reddit.com/r/webscraping/comments/1i46fbb/webscraping_strategy)
 - RSS feed: $source
 - date published: 2025-01-18T12:21:31+00:00

<!-- SC_OFF --><div class="md"><p>Hi! </p> <p>I cannot seem to find any high-level strategies on approaching a new web-scraping project. Everywhere I go, people talk about setting up the anti-block mechanisms such as proxies, implementing wait times before requests etc.. </p> <p>Whilst all that is great, I do not want to invest in all those mechanisms pre-maturely. What If the target website has 0 defense against bots? Then it is a waste of time.</p> <p>Basically what I am asking is :</p> <p><strong>Should I start fast and without taking into consideration the anti-bot measures and get my IP address potentially blocked very soon and then slowly become more careful, or should I start extra careful and increase aggression if there have been no issues? What has been your experience?</strong> </p> <p>Additionally, maybe there are some legitimate ways to evaluate the anti-bot measures implemented in the website?</p> <p>Your inputs are highly appreciated. </p> </div><!-- SC_ON --> &#32; su

## Finding local news sources based on city name
 - [https://www.reddit.com/r/webscraping/comments/1i465hh/finding_local_news_sources_based_on_city_name](https://www.reddit.com/r/webscraping/comments/1i465hh/finding_local_news_sources_based_on_city_name)
 - RSS feed: $source
 - date published: 2025-01-18T12:03:51+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone,</p> <p>I am trying to automatically identify local news sources based on a specific city name. Currently, I am using google API to google &quot;news {city} {country}&quot; in the local language with the local language and country as the parameters of search and I consider the links of the websites of the first page (results) as the local news sources of that city. However, these links could also be of government websites, organizations, global news websites, or other websites, that are not local news sources. What I want instead is to only identify the local news sources. I tried to exclude terms but it is still not working the way i want it to be. There are many other exceptions that make this approach unreliable.</p> <p>I am not sure if this is the right approach to achieve my goal. It seems not consistent and ineffective. Do you have any suggestions for other alternative approaches and experience in this regard. </p> <p>Thank you in a

## Scrapping for product images
 - [https://www.reddit.com/r/webscraping/comments/1i3y177/scrapping_for_product_images](https://www.reddit.com/r/webscraping/comments/1i3y177/scrapping_for_product_images)
 - RSS feed: $source
 - date published: 2025-01-18T02:57:07+00:00

<!-- SC_OFF --><div class="md"><p>I am helping a distributor clean their data and manually collecting products is difficult when you have 1000s of products.</p> <p>If I have an excel sheet with part numbers, upc and manufacture names is there a tool that will help me scrape images?</p> <p>Any tools you can point me to and some basic guidance?</p> <p>Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/twiggs462"> /u/twiggs462 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i3y177/scrapping_for_product_images/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i3y177/scrapping_for_product_images/">[comments]</a></span>

## Need Help Finding API Data for Player Info on FUTBIN
 - [https://www.reddit.com/r/webscraping/comments/1i3xckx/need_help_finding_api_data_for_player_info_on](https://www.reddit.com/r/webscraping/comments/1i3xckx/need_help_finding_api_data_for_player_info_on)
 - RSS feed: $source
 - date published: 2025-01-18T02:20:04+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone!</p> <p>I’m working on a project to analyze football player data, and I’m trying to scrape specific data from FUTBIN. However, I’m struggling to locate the API endpoint using Chrome Developer Tools.</p> <p>Here’s what I need help with: • Website URL: <a href="https://www.futbin.com/players">https://www.futbin.com/players</a></p> <p>Data Points I’m Looking For: • Player name • Rating • Card type • Image • Price</p> <p>What I’ve Tried So Far:</p> <p>I’ve been using Chrome Developer Tools to look for API calls in the Network &gt; XHR tab, but I haven’t been able to pinpoint the request that contains this data. I’ve gone through individual requests but might be missing something.</p> <p>Goal:</p> <p>I want to extract this data to build a market analysis model for football player cards, focusing on trends and pricing.</p> <p>If anyone has experience with scraping from finding hidden API endpoints, I’d really appreciate your guidance. Any tips 

## Defeated by the captcha
 - [https://www.reddit.com/r/webscraping/comments/1i3wf1o/defeated_by_the_captcha](https://www.reddit.com/r/webscraping/comments/1i3wf1o/defeated_by_the_captcha)
 - RSS feed: $source
 - date published: 2025-01-18T01:31:18+00:00

<!-- SC_OFF --><div class="md"><p>In a scraper I had, they suddenly implemented a captcha. I thought this wasn&#39;t going to be a problem since I have several scrapers that I easily bypass, but this one is being a horror.<br/> I use a paid service to solve captchas, I get a response token and insert it into the hidden field called g-recaptcha-response, but when the front end calls the back end it always returns false. I found this code of the logic of how the front end works. Could I get some help?</p> <pre><code>var your_site_key = &#39;6Lcw5eUZAAAAABHOOZZ7Os6r5_Frva3okd7pixMw&#39; var renderRecaptcha = function () { grecaptcha.render(&#39;ReCaptchContainer&#39;, { &#39;sitekey&#39;: your_site_key, &#39;callback&#39;: reCaptchaCallback, theme: &#39;light&#39;, //light or dark type: &#39;image&#39;,// image or audio size: &#39;normal&#39;//normal or compact }); }; var reCaptchaCallback = function (response) { if (response !== &#39;&#39;) { $(&#39;#lblMessage&#39;).css(&#39;color&#39

