# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## In need of a web scraping tool to extract product info - $
 - [https://www.reddit.com/r/webscraping/comments/1i29c5l/in_need_of_a_web_scraping_tool_to_extract_product](https://www.reddit.com/r/webscraping/comments/1i29c5l/in_need_of_a_web_scraping_tool_to_extract_product)
 - RSS feed: $source
 - date published: 2025-01-15T22:12:48+00:00

<!-- SC_OFF --><div class="md"><p>Hi,</p> <p>I am seeking a web scraping tool that will allow me to log into my vendors website (several different ones) and have the tool scrape the product information i specify into an excel compatible file.</p> <p>Would need things like this scraped:</p> <ol> <li><p>SKU</p></li> <li><p>Cost</p></li> <li><p>UPC</p></li> </ol> <p>.... etc</p> <p>willing to pay for guidance or product or whatever. need this done asap</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Helpful_Hippo1103"> /u/Helpful_Hippo1103 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i29c5l/in_need_of_a_web_scraping_tool_to_extract_product/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i29c5l/in_need_of_a_web_scraping_tool_to_extract_product/">[comments]</a></span>

## Simple crawling server - looking for feedback
 - [https://www.reddit.com/r/webscraping/comments/1i28r7k/simple_crawling_server_looking_for_feedback](https://www.reddit.com/r/webscraping/comments/1i28r7k/simple_crawling_server_looking_for_feedback)
 - RSS feed: $source
 - date published: 2025-01-15T21:47:55+00:00

<!-- SC_OFF --><div class="md"><p>I’ve built a crawling server that you can use to crawl urls</p> <p>It:</p> <p>- Accepts requests via <strong>GET</strong> and responds with <strong>JSON</strong> data, including page contents, properties, headers, and more.</p> <p>- Supports multiple crawling methods—use <strong>requests</strong>, <strong>Selenium</strong>, <strong>Crawlee</strong>, and more. Just specify the method by name!</p> <p>- Perfect for developers who need a versatile and customizable solution for simple web scraping and crawling tasks</p> <p>- Can read information about youtube links using yt-dlp</p> <p>Check it out on GitHub <a href="https://github.com/rumca-js/crawler-buddy">https://github.com/rumca-js/crawler-buddy</a></p> <p>There is also a docker image.</p> <p>I&#39;d love your feedback</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/renegat0x0"> /u/renegat0x0 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments

## Are there any JAVA libraries beside Selenium and Playwright?
 - [https://www.reddit.com/r/webscraping/comments/1i28ayp/are_there_any_java_libraries_beside_selenium_and](https://www.reddit.com/r/webscraping/comments/1i28ayp/are_there_any_java_libraries_beside_selenium_and)
 - RSS feed: $source
 - date published: 2025-01-15T21:28:00+00:00

<!-- SC_OFF --><div class="md"><p>I know, that basically everyone is using Python now, but I have really large application built in java and not really won&#39;t to move it to other environment.</p> <p>The main problem is that I am stuck using selenium&lt;4.0, because after selenium 4.0, CDP get detected by antibot system and I could not find way to make it undetectable. But using selenium&lt;4.0 I am stuck with older chrome and chromium versions.</p> <p>I would probably move to use of Playwright, if I can be sure that CDP won&#39;t be detectable using latest chrome. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/OkTry9715"> /u/OkTry9715 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i28ayp/are_there_any_java_libraries_beside_selenium_and/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i28ayp/are_there_any_java_libraries_beside_selenium_and/">[comments]</a></span>

## Personal data for healthcare clinicians
 - [https://www.reddit.com/r/webscraping/comments/1i26j16/personal_data_for_healthcare_clinicians](https://www.reddit.com/r/webscraping/comments/1i26j16/personal_data_for_healthcare_clinicians)
 - RSS feed: $source
 - date published: 2025-01-15T20:10:28+00:00

<!-- SC_OFF --><div class="md"><p>Hi, I&#39;m recruiting healthcare providers and wondering if there is a good database of their personal info (email + cell phone). Focused on the US. I get their professional data from the NPI registry. Please let me know what tools you use for their personal contact info. Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/projomni"> /u/projomni </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i26j16/personal_data_for_healthcare_clinicians/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i26j16/personal_data_for_healthcare_clinicians/">[comments]</a></span>

## Looking for Browser Automation service (Not Scraping)
 - [https://www.reddit.com/r/webscraping/comments/1i1y4ts/looking_for_browser_automation_service_not](https://www.reddit.com/r/webscraping/comments/1i1y4ts/looking_for_browser_automation_service_not)
 - RSS feed: $source
 - date published: 2025-01-15T14:07:14+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m currently using XXXX service for browser automation tasks, connecting via WebSocket like this:</p> <pre><code>var connectOptions = new ConnectOptions() { BrowserWSEndpoint = &quot;wss://chrome.XXXX.io?token=YOUR_TOKEN&quot; }; </code></pre> <p>However, I&#39;m looking for alternatives. Most of the services I come across are focused solely on scraping, but I need a solution for <strong>full browser automation</strong>.</p> <p>My requirements are:</p> <ul> <li><strong>WebSocket connection support</strong> (similar to the example above).</li> <li>Capable of handling tasks beyond scraping, like automating user interactions, file uploads/downloads, etc.</li> <li><strong>Support for residential proxies</strong>, as some of my automation tasks require them to avoid blocks.</li> </ul> <p>If anyone has experience with a similar service that supports WebSocket-based browser automation and integrates well with residential proxies, I’d really appreciate 

## residential proxies with login
 - [https://www.reddit.com/r/webscraping/comments/1i1y1hr/residential_proxies_with_login](https://www.reddit.com/r/webscraping/comments/1i1y1hr/residential_proxies_with_login)
 - RSS feed: $source
 - date published: 2025-01-15T14:02:43+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1i1y1hr/residential_proxies_with_login/"> <img src="https://b.thumbs.redditmedia.com/MzfoK8aPVG3fj8fY2_u0wjJIA1jme3juwpCzBjjc6qY.jpg" alt="residential proxies with login" title="residential proxies with login" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>i am currently using (some service) to get like 50 residential proxies, and using them to automate a login that has a cloudflare captcha (trunstile),</p> <p>when i automate the login process and i click &quot;Log in&quot; it shows a trunstile captcha that can&#39;t be solved (like that photo), i normally use a captcha solver api but does this mean my residential proxy is blocked or its just something wrong with my browser args (using playwright btw) </p> <p><a href="https://preview.redd.it/hj4h4rn5z5de1.png?width=782&amp;format=png&amp;auto=webp&amp;s=e8c28f8f3f73570b2118ea89038eb5bb594c9fde">https://preview.redd.it/hj4h4rn5z5de1.png?width=782&amp;format=p

## Should I include an 'after-login' scraper on my intern-level resume?
 - [https://www.reddit.com/r/webscraping/comments/1i1q1vn/should_i_include_an_afterlogin_scraper_on_my](https://www.reddit.com/r/webscraping/comments/1i1q1vn/should_i_include_an_afterlogin_scraper_on_my)
 - RSS feed: $source
 - date published: 2025-01-15T04:58:22+00:00

<!-- SC_OFF --><div class="md"><p>I have developed several web scrapers that download content from popular course platforms.</p> <p>The script requires the user to have access to the platform and to have paid for the course.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Top-Stress5387"> /u/Top-Stress5387 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i1q1vn/should_i_include_an_afterlogin_scraper_on_my/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i1q1vn/should_i_include_an_afterlogin_scraper_on_my/">[comments]</a></span>

## How Web Scraping can be used to develop effective E-commerce strategy with sample Strategy
 - [https://www.reddit.com/r/webscraping/comments/1i1l8u4/how_web_scraping_can_be_used_to_develop_effective](https://www.reddit.com/r/webscraping/comments/1i1l8u4/how_web_scraping_can_be_used_to_develop_effective)
 - RSS feed: $source
 - date published: 2025-01-15T00:41:50+00:00

<!-- SC_OFF --><div class="md"><h1>Real-Life Use Case</h1> <p>James, the Ecommerce manager of a Clothing Brand, has a clear objective: <strong><em>To launch a new Men’s T-shirt line.</em></strong> </p> <p>Rather than relying on guesswork, James listens to what the market is saying.</p> <p><strong>His approach?</strong> </p> <p>James researches the top 3 fashion retailers (Amazon, eBay, Target) to identify trends in types, prices, and materials. </p> <p><strong>He automates data extraction, pulling detailed product info from best-selling t-shirts in CSV format.</strong></p> <p>It also adapts to country-specific versions of these platforms, enabling seamless data extraction from global and local markets.</p> <h1>Sample Ecommerce Growth Strategy</h1> <p>Raw data from web data extraction provides a solid starting point.</p> <p>With ChatGPT, the data is processed to generate insights and strategies for different Ecommerce strategy components.</p> <p><strong>Analyzing data from the top thr

