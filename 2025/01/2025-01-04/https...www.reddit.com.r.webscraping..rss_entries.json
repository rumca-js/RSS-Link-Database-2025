[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T20:16:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all,</p> <p>I\u2019m trying to scrape a site (WyScout) with Selenium.</p> <p>It appears that the site uses dynamic login URL\u2019s (different URL for every session) - I want to automate a login session for navigating into a database within the site but I\u2019m falling at the first Hurdle as I can\u2019t successfully automate a login due to a) the dynamic login above and b) the fact the login system initially needs a username, and then once submitted it takes me to another page.</p> <p>Where is the best place to start for resources in overcoming this?</p> <p>At the moment I\u2019m having to manually take the data, download it and analyse it using Python but I want to automate more of the process.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sea-Fly-8807\"> /u/Sea-Fly-8807 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1htnagi/dynamic_session_login_with_selenium/\">[link]</a></span> &#32; <spa",
        "id": 1834957,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1htnagi/dynamic_session_login_with_selenium",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Dynamic Session Login with Selenium",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T19:58:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I&#39;m not very familiar with scraping and all that, but I read a post on this server that said there are many bots or tools that perform the same function as spy.net or dis.cool (both of which have been taken down). I just want the feature that tells me which server someone is in. So, I was wondering if anyone has any tools they could share with me.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Cool_buntu\"> /u/Cool_buntu </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1htmvbn/discord_server_scraping_query/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1htmvbn/discord_server_scraping_query/\">[comments]</a></span>",
        "id": 1834703,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1htmvbn/discord_server_scraping_query",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Discord server scraping query",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T18:58:00+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><strong>Things to know:</strong></p> <ol> <li>The SEC rate limits you to 5 concurrent connections, a total of 5 requests / second, and about 30mb/s of egress. You can go to 10 requests / second, but you will be rate-limited within 15 minutes.</li> <li>Submissions to the SEC are uploaded in <a href=\"https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/0001193125-14-383437.txt\">SGML format</a>. One SGML file contains multiple files, for example a <a href=\"https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/d783162d10k.htm\">10-K</a> usually contains <a href=\"https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/aapl-20140927.xml\">XML</a>, <a href=\"https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/d783162dex1011.htm\">HTML</a>, and <a href=\"https://www.sec.gov/Archives/edgar/data/320193/000119312514383437/g783162g12_97.jpg\">GRAPHIC </a>files. This means, if you have a SGML parser, you can download eve",
        "id": 1834409,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1htlh0v/how_to_scrape_the_sec_in_2024_opensource",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape the SEC in 2024 [Open-Source]",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T18:11:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>im trying to scrape amazon reviews. i have been using selenium to scrape the prices of products with no issues but when i try to scrape reviews it asks to login and i dont know how to approach this. i tried to automate the login but it somehow doesnt work as it gets stuck without submitting the password. any ideas how to navigate through this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Parking_Bluebird826\"> /u/Parking_Bluebird826 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1htkeeg/loggin_in_amazon/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1htkeeg/loggin_in_amazon/\">[comments]</a></span>",
        "id": 1834410,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1htkeeg/loggin_in_amazon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "loggin in amazon",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T14:25:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi there,</p> <p>I&#39;m wondering about the best way to proceed. We have a fairly outdated site for a scientific journal that holds all the journal&#39;s archive and want to transfer this database to a new WP site, maintaining page and link structure if possible:<br/> Archive &gt; Edition page &gt; separate .pdfs for each article of that edition</p> <p><a href=\"https://www.ekphrasisjournal.ro/index.php?p=arch&amp;id=169\">https://www.ekphrasisjournal.ro/index.php?p=arch&amp;id=169</a></p> <p>I presume this could be done with scrapping and then uploading it to the WP site (unsure how to recreate the db structure without doing it painstakingly by hand), but I have no experience with this. </p> <p>I would very much appreciate if you confirm/refute this and point me towards some examples/resources.</p> <p>Cheers!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/scrjlt\"> /u/scrjlt </a> <br/> <span><a href=\"https://www",
        "id": 1833317,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1htffgp/help_scrape_journal_pdfs_and_then_import_to_wp",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help! Scrape journal .pdfs and then import to WP",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T12:14:04+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1htd68s/how_to_combine_pdfs_to_excel_excel_powerquery/\"> <img src=\"https://external-preview.redd.it/Gmpkc7BX83UGfZU1os2TkDUmbWdK-9XgJJqHN1s_k40.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=02e7320c4c37e55d88ee3a71b6350937e5c7b6b1\" alt=\"How to Combine PDFs to Excel #excel #powerquery #powerbi\" title=\"How to Combine PDFs to Excel #excel #powerquery #powerbi\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Capable-Post-5674\"> /u/Capable-Post-5674 </a> <br/> <span><a href=\"https://youtu.be/EV-7CUzppQA?si=PYPhxBNG8GZSMTl0\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1htd68s/how_to_combine_pdfs_to_excel_excel_powerquery/\">[comments]</a></span> </td></tr></table>",
        "id": 1832861,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1htd68s/how_to_combine_pdfs_to_excel_excel_powerquery",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/Gmpkc7BX83UGfZU1os2TkDUmbWdK-9XgJJqHN1s_k40.jpg?width=320&crop=smart&auto=webp&s=02e7320c4c37e55d88ee3a71b6350937e5c7b6b1",
        "title": "How to Combine PDFs to Excel #excel #powerquery #powerbi",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T12:11:52+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1htd532/web_scraping_in_excel_a_simple_guide_to_using/\"> <img src=\"https://external-preview.redd.it/qtNYVerX3x2G5tJTGW1_I3o5zw-FcXqK4_EXNIrtc6c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=774ef7a51aa638d10faf1eccfdb28bbc7d4f1b22\" alt=\"Web Scraping in Excel: A Simple Guide to Using Power Query\" title=\"Web Scraping in Excel: A Simple Guide to Using Power Query\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Capable-Post-5674\"> /u/Capable-Post-5674 </a> <br/> <span><a href=\"https://youtu.be/AbMq8r7OWfU?si=lYOkYT-JdjBZ4bfV\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1htd532/web_scraping_in_excel_a_simple_guide_to_using/\">[comments]</a></span> </td></tr></table>",
        "id": 1832862,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1htd532/web_scraping_in_excel_a_simple_guide_to_using",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/qtNYVerX3x2G5tJTGW1_I3o5zw-FcXqK4_EXNIrtc6c.jpg?width=320&crop=smart&auto=webp&s=774ef7a51aa638d10faf1eccfdb28bbc7d4f1b22",
        "title": "Web Scraping in Excel: A Simple Guide to Using Power Query",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T11:07:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I have limited knowledge of web scraping and a little experience with LLMs, and I\u2019m looking to build a tool for the following task:</p> <ol> <li>I have a list of company websites (in a .txt or .csv file) and want to automate the process of navigating to their career pages.</li> <li>The list is long, so manual navigation isn\u2019t feasible.</li> <li>Some career pages don\u2019t directly show job listings, so the tool may need to traverse further based on the webpage\u2019s content.</li> <li>Once on the job listings page, I need to scrape the full list of jobs (which may require scrolling) or filter jobs based on titles if possible.</li> <li>After scraping, I want to send the data to an LLM for advanced filtering.</li> </ol> <p>Is there any free or open-source tool/library you\u2019d recommend for this use case? I\u2019d appreciate any guidance or suggestions to get started.</p> <p>Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a hre",
        "id": 1832587,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1htc8dc/help_needed_tool_for_scraping_job_listings_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "[Help Needed] Tool for Scraping Job Listings from Multiple Websites",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T09:40:36+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Okay so how exactly do I access the network or other tabs in the dev tools if the website keeps redirecting back to homepage everything?</p> <p>Pausing the site while it&#39;s loading doesn&#39;t help as the content hasn&#39;t loaded. Also disabling javascript won&#39;t help either.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/RyuzakiSempai\"> /u/RyuzakiSempai </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1htb185/website_redirects_to_its_web_page_upon_opening/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1htb185/website_redirects_to_its_web_page_upon_opening/\">[comments]</a></span>",
        "id": 1833318,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1htb185/website_redirects_to_its_web_page_upon_opening",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Website redirects to its Web page upon opening Dev Tools",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T04:37:11+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1ht6ii8/whats_everyones_review_of_this_website/\"> <img src=\"https://external-preview.redd.it/tmbfrLApYm2htWFv578XLYks3hLK7jEmrkT-sC5L8mc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eb9354a9923f34c52cd37e2a4fc993071ef47638\" alt=\"Whats everyones review of this website ?\" title=\"Whats everyones review of this website ?\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Carpet-Western\"> /u/Carpet-Western </a> <br/> <span><a href=\"https://www.gumloop.com/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ht6ii8/whats_everyones_review_of_this_website/\">[comments]</a></span> </td></tr></table>",
        "id": 1831554,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ht6ii8/whats_everyones_review_of_this_website",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/tmbfrLApYm2htWFv578XLYks3hLK7jEmrkT-sC5L8mc.jpg?width=640&crop=smart&auto=webp&s=eb9354a9923f34c52cd37e2a4fc993071ef47638",
        "title": "Whats everyones review of this website ?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T03:19:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Can someone help me to scrape the level, platinum, gold, silver, bronze, trophies per day, ranks &amp; country.</p> <p>I tried doing it myself but I just don&#39;t have the experience to do so, preferably in different columns.</p> <p>My profile as example: <a href=\"https://psnprofiles.com/LexLexxis\">https://psnprofiles.com/LexLexxis</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LexLexxis\"> /u/LexLexxis </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ht536k/tried_to_scrape_some_data_cant_make_it_happen/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ht536k/tried_to_scrape_some_data_cant_make_it_happen/\">[comments]</a></span>",
        "id": 1831402,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ht536k/tried_to_scrape_some_data_cant_make_it_happen",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tried to scrape some data, can't make it happen.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-04T01:17:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"http://www.memoryexpress.com\">www.memoryexpress.com</a> for the life of me I cannot even get past the initial 403 error. Please help. I tried headers and proxies and selenium but I could be doing them all wrong.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PlasmaRevolt\"> /u/PlasmaRevolt </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ht2psn/at_wits_end_trying_to_scrape_this_site/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ht2psn/at_wits_end_trying_to_scrape_this_site/\">[comments]</a></span>",
        "id": 1831112,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ht2psn/at_wits_end_trying_to_scrape_this_site",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "At wits end trying to scrape this site",
        "vote": 0
    }
]