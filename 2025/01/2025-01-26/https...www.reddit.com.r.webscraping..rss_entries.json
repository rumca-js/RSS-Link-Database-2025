[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-26T23:37:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I just made a StockX Scraper API with Flask. It runs on a waitress server hosted using render. Y&#39;all can check it out on github: <a href=\"https://github.com/aidanmcintosh07/StockXScraper\">https://github.com/aidanmcintosh07/StockXScraper</a></p> <p>Any advice is greatly appreciated!!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/D4ring\"> /u/D4ring </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iaty56/stockx_scraper_api_with_flask/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iaty56/stockx_scraper_api_with_flask/\">[comments]</a></span>",
        "id": 1983773,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iaty56/stockx_scraper_api_with_flask",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "StockX Scraper API with Flask!!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-26T23:08:51+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>Could someone please help me with scraping these 2 HD images, I&#39;ve tried De-Zoomify with no success and the obvious inspect element doesn&#39;t work either. It&#39;s the kind of photos where it gives a small preview but when clicked on, allows you to zoom into a high resolution image but only in sections. Any ideas?</p> <p><a href=\"https://www.artsy.net/artwork/peter-hince-freddie-mercury-crown\">https://www.artsy.net/artwork/peter-hince-freddie-mercury-crown</a></p> <p><a href=\"https://www.artsy.net/artwork/peter-hince-freddie-mercury-sound-check-puebla-mexico\">https://www.artsy.net/artwork/peter-hince-freddie-mercury-sound-check-puebla-mexico</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Chinwonder2\"> /u/Chinwonder2 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iatbvf/downloading_zooming_image/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.co",
        "id": 1983774,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iatbvf/downloading_zooming_image",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Downloading Zooming Image",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-26T20:27:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So, today I was attempting to programmatically log-in in ChatGPT and ask about restaurant recommendations in my area. The objective is to set up a schedule that runs this every day in the morning and then extract the cited sources to a csv so I can track how often my own restaurant is recommended.</p> <p>I managed to do it using a headless browser + proxy IPs, and worked fine. The problem is that after a few runs (I was testing so maybe did like 4-5 runs in 30 mins), ChatGPT stopped using browser and would just reply without access to internet.</p> <p>When explicitly asked to browse the internet (Search option was already toggled), it keeps saying it does not have access to internet.</p> <p>Is this something that happened to anyone before? And any way to bypass or alternative other than using the OpenAI API (It does not give you access to internet).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SeriousMr\"> /u/",
        "id": 1983776,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iapcl7/chatgpt_shadowban_after_scrapping_its_ui",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "ChatGPT Shadowban after scrapping it's UI",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-26T20:26:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey <a href=\"/r/webscraping\">r/webscraping</a>! </p> <p>If you\u2019re tired of getting IP-banned or waiting ages for proxy validation, I\u2019ve got news for you: I just released <strong>v2.0.0</strong> of my Python library, <strong><a href=\"https://github.com/sachin-sankar/swiftshadow\">swiftshadow</a></strong>, and it\u2019s now <strong>15x faster</strong> thanks to async magic! \ud83d\ude80 </p> <h3><strong>What\u2019s New?</strong></h3> <p>\u26a1 <strong>15x Speed Boost</strong>: Rewrote proxy validation with <code>aiohttp</code> \u2013 dropped from <strong>~160s</strong> to <strong>~10s</strong> for 100 proxies.<br/> \ud83c\udf10 <strong>8 New Providers</strong>: Added sources like <em>KangProxy</em>, <em>GoodProxy</em>, and <em>Anonym0usWork1221</em> for more reliable IPs.<br/> \ud83d\udce6 <strong>Proxy Class</strong>: Use <code>Proxy.as_requests_dict()</code> to plug directly into <code>requests</code> or <code>httpx</code>.<br/> \ud83d\uddc4\ufe0f <strong>Faster Caching</strong>: Switched to <code>pickle</code> \u2013 no mo",
        "id": 1983771,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iapbff/i_made_my_python_proxy_library_15x_faster_perfect",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I Made My Python Proxy Library 15x Faster \u2013 Perfect for Web Scraping!",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-26T17:45:24+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I&#39;m proud to share to you my first scraping project. <a href=\"http://Doctolib.fr\">Doctolib.fr</a> is a french website to book doctors appointments. I wanted to gather the informations of all the doctors in my area to compare them easily.</p> <p>The code is entirely made of python code, and uses playwright to bypass the website&#39;s securities.</p> <p>Come take a look and tell me what you think :)</p> <p><a href=\"https://github.com/gagota/doctolib-scrapper/tree/main\">https://github.com/gagota/doctolib-scrapper/tree/main</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Key_Bluejay4726\"> /u/Key_Bluejay4726 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iakxm4/doctolibfr_scraper_my_first_scraping_project/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iakxm4/doctolibfr_scraper_my_first_scraping_project/\">[comments]</a></spa",
        "id": 1983775,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iakxm4/doctolibfr_scraper_my_first_scraping_project",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "doctolib.fr scraper, my first scraping project !",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-26T14:36:17+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1iag1yw/finally_found_something_worth_using_on_google_maps/\"> <img src=\"https://b.thumbs.redditmedia.com/REqifAwgZ9TyVGbcmmSJahG6LKPcas9kEgEKAIaKrnM.jpg\" alt=\"Finally found something worth using on google maps\" title=\"Finally found something worth using on google maps\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://preview.redd.it/v7476u5bncfe1.png?width=1909&amp;format=png&amp;auto=webp&amp;s=49f065b367d51d2966f6fbec704f3367b95a2754\">https://preview.redd.it/v7476u5bncfe1.png?width=1909&amp;format=png&amp;auto=webp&amp;s=49f065b367d51d2966f6fbec704f3367b95a2754</a></p> <p>and yes, all you need is location and keyword. gotta say, it&#39;s better than using Google dorks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Emtyspaces\"> /u/Emtyspaces </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iag1yw/finally_found_something_worth_usi",
        "id": 1981211,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iag1yw/finally_found_something_worth_using_on_google_maps",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://b.thumbs.redditmedia.com/REqifAwgZ9TyVGbcmmSJahG6LKPcas9kEgEKAIaKrnM.jpg",
        "title": "Finally found something worth using on google maps",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-26T13:40:40+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>NextDoor the neighborhood app has so many businesses that are either just starting out and have no online presence or just literally have nothing at all besides NextDoor.</p> <p>The thing about NextDoor tho is you need to be logged in to see businesses AND you are only allowed to search for businesses in a 15 miles radius.</p> <p>That doesnt matter though, so many businesses can be found in my 15 mile radius.</p> <p>Thus I ask, anyone have a data scraper for Nextdoor or know how to make one. Would love your insights!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CoolYeetKiddo\"> /u/CoolYeetKiddo </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iaesmq/need_your_help_finding_a_nextdoor_data_scraper/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1iaesmq/need_your_help_finding_a_nextdoor_data_scraper/\">[comments]</a></span>",
        "id": 1981210,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1iaesmq/need_your_help_finding_a_nextdoor_data_scraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need your help finding a Nextdoor Data Scraper (YES YOU!)",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-26T08:12:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>As the title says what is the recommended amount of time to rotate?<br/> For context the scraping is on social media sites.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Intrepid-Bicycle3438\"> /u/Intrepid-Bicycle3438 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ia97j6/residential_proxies_rotation_time_best_practice/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ia97j6/residential_proxies_rotation_time_best_practice/\">[comments]</a></span>",
        "id": 1983777,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ia97j6/residential_proxies_rotation_time_best_practice",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Residential Proxies rotation time best practice",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-26T07:19:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m looking for a cheap hosting solution for web scraping. I will be scraping 10,000 pages every day and store the results. Will use either Python or NodeJS with proxies. What would be the cheapest way to host this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/vroemboem\"> /u/vroemboem </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ia8ht1/cheap_web_scraping_hosting/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ia8ht1/cheap_web_scraping_hosting/\">[comments]</a></span>",
        "id": 1981209,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ia8ht1/cheap_web_scraping_hosting",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Cheap web scraping hosting",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-26T04:13:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve built a script that replicates calls from the app to different public API endpoints. (TikTok)</p> <p>I&#39;ve been using it for hashtag pages, to scrape profile/video data (public).<br/> So far i&#39;ve been capped at 5000 videos (cursor 5000) and my script returns no more data after that.</p> <p>Here&#39;s a snippet of the raw server json response at that cursor:</p> <p>&quot;cursor&quot;: 5040,</p> <p>&quot;extra&quot;: {</p> <p>&quot;fatal_item_ids&quot;: [],</p> <p>&quot;logid&quot;: &quot;2025012602325350792C1EA84EA3696629&quot;,</p> <p>&quot;now&quot;: 1737858773000</p> <p>},</p> <p>&quot;has_more&quot;: 0,</p> <p>&quot;log_pb&quot;: {</p> <p>&quot;impr_id&quot;: &quot;2025012602325350792C1EA84EA3696629&quot;</p> <p>},</p> <p>&quot;status_code&quot;: 0,</p> <p>&quot;status_msg&quot;: &quot;&quot;</p> <p>As you can see, the has_more value is set to 0. Now I have valid tokens/parems/headers in my script, but not the time sensitive ones. ",
        "id": 1983778,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ia5lsz/app_api_scraping_cursor_limit",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "App API Scraping - Cursor Limit??",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-26T01:13:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Im trying to parse some data from a polish gov website (link) through requests but I get blocked. The website is buggy so puppeteer/selenium is problematic. Apparently, there are some TSPD requests I need to handle first, but I can&#39;t manage to do it.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Amanhaalim0\"> /u/Amanhaalim0 </a> <br/> <span><a href=\"https://przegladarka-ekw.ms.gov.pl/eukw_prz/KsiegiWieczyste/wyszukiwanieKW\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ia2ahm/need_help_getting_cookies/\">[comments]</a></span>",
        "id": 1981212,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1ia2ahm/need_help_getting_cookies",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help Getting Cookies",
        "vote": 0
    }
]