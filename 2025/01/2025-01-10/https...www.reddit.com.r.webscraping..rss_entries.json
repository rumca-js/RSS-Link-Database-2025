[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-10T22:38:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is it possible to scrap Google reviews for a service-based business? </p> <p>Does the scraping work automatically as a new review comes in or like a snapshot in every few hours? </p> <p>I am learning about scraping for the first time so my apologies if I am not making sense, please ask me a follow-up question and I can expand further. </p> <p>Thanks! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/hiIaNotSam\"> /u/hiIaNotSam </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hyh2q9/is_this_possible/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hyh2q9/is_this_possible/\">[comments]</a></span>",
        "id": 1879669,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hyh2q9/is_this_possible",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is this possible?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-10T19:37:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello webscraping community of reddit, I have an idea for a smallish project that I believe will require me to do a decent amount of web scraping. To be honest I&#39;m not even sure it is the right approach for this project but wanted to see what people here think. </p> <p><strong>Would it be possible to scrape podcast platforms or RSS feeds to obtain a list of sponsorships and sponsorship transcripts from as many pods/episodes as possible?</strong> Basically I want to create a huge list of every company advertising on podcasts. </p> <p>Really appreciate any thoughts and ideas on the viability of this!!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/jyustones1\"> /u/jyustones1 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hycuu9/i_have_0_experience_web_scraping_is_this_possible/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hycuu9/i_have_0_exper",
        "id": 1878959,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hycuu9/i_have_0_experience_web_scraping_is_this_possible",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I have 0 experience web scraping, is this possible?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-10T16:36:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m coming back to a project which I successfully operate about 6 months ago, I am scraping data that is only update about once or twice a year, hence me not using it for a while.</p> <p>My basic setup was a docker container that ran chrome and chrome-driver, and then another container that executed my custom scraping application.</p> <p>My problem is now that my chrome container no longer seems to work as before, I cannot connect via chrome driver. The ports are correct, and chrome driver will print out logs if I try to access it incorrectly, for example at <code>http://0.0.0.0:4444</code>, instead of <code>http://localhost:4444</code>.</p> <p>If i enter into the container, and run <code>google-chrome</code>, this is the response that I receive, afterwhich the application quits</p> <pre><code>[1851:1877:0110/164408.436541:ERROR:bus.cc(407)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or dir",
        "id": 1877040,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hy8h9d/chrome_and_chromedriver_in_docker_container",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Chrome and chrome-driver in Docker container",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-10T15:15:09+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I need to scrape posts from a relatively small number of social media accounts on different social media platforms (which of course all make scraping as hard as possible). </p> <p>The use case is journalists researching what politicians have said on a particular topic on their social accounts. Right now this is a very manual, sometimes prohibitively time-consuming process.</p> <p>I\u2019m picturing a browser plugin that when enabled can capture screenshots as you browse and ideally crop/stitch them together at least somewhat intelligently for an LLM to OCR, parse and tag into searchable text (the ability of some LLMs to not only OCR but get date/attribution for text based on a screenshot has been amazing to me in my tests. That way it would work for any platform you could view in your browser without playing whack-a-mole with anti-scraping technical measures from platforms. I understand this requires a human user who can access the pages manually so it wo",
        "id": 1877039,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hy6lsa/browser_plugin_for_small_scale_scraping_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Browser plugin for small scale scraping of difficult sites",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-10T12:45:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>It&#39;s actually my first time a client asks me to scrape real estate websites (I have done bunch of them and on big sites like <a href=\"http://zillow.com\">zillow.com</a> ) but on my own &amp; for practice only.</p> <p>So my question is how much do people estimate its cost? is it for example 5$ / items scraped or so?</p> <p>Also one more thing, Do we give the client the script or just the scraped data or ask them about their preference? if the script, does it cost my hourly rate * hours I worked?</p> <p>Sorry if it seems trivial to some people but consider being put in the situation for 1st time :)</p> <p>Thanks in advance</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Potential-Gur-5748\"> /u/Potential-Gur-5748 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hy3m84/how_to_estimate_scraping_real_estate_cost/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/co",
        "id": 1875342,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hy3m84/how_to_estimate_scraping_real_estate_cost",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to estimate scraping real estate cost?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-10T10:43:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I am currently buying proxies at 7$/gb but read somewhere Torgaurd offers unlimited bandwidth, has anyone tried it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Healthy-Educator-289\"> /u/Healthy-Educator-289 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hy1pns/has_anyone_tried_torgaurd/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hy1pns/has_anyone_tried_torgaurd/\">[comments]</a></span>",
        "id": 1874420,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hy1pns/has_anyone_tried_torgaurd",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Has anyone tried Torgaurd?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-10T10:11:14+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, I wanted to provide a brief update on the progress of eventHive. If you&#39;re interested, you can find my previous post here <a href=\"https://www.reddit.com/r/webscraping/comments/1gyl0dx/a_little_project_of_mine/\">link</a></p> <p>I&#39;ve been quite busy, but I&#39;ve finally found some time to write. I&#39;ve got a few questions because I feel a bit lost.</p> <ul> <li>Does anyone have good blog samples on the topic of web scraping that they can share? I\u2019m looking for something popular in terms of views and that is well-written. </li> <li>I also want to share my own blog, and I&#39;ve noticed there&#39;s a monthly self-promotion thread. Would sharing research in that thread be appropriate? </li> </ul> <p>Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ready-Ninja-1272\"> /u/Ready-Ninja-1272 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hy1a5v/a_small_update/\">[",
        "id": 1874884,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hy1a5v/a_small_update",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "A small update",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-10T02:17:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I currently writing a Python script using Beautiful Soup and was wondering what the best practices were (if any) for assigning the web data to variables. Right now my variables look like:</p> <p>Var1 = soup.find(&quot;table&quot;).find(&quot;i&quot;).get_text().split()</p> <p>It seems pretty messy, and before I go digging and better ways to scrape what I want, is this normal to have variables look like this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/McKearnyPlum\"> /u/McKearnyPlum </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hxtxvc/beautiful_soup_variable_best_practices/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hxtxvc/beautiful_soup_variable_best_practices/\">[comments]</a></span>",
        "id": 1872606,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hxtxvc/beautiful_soup_variable_best_practices",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Beautiful Soup Variable Best Practices",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-10T01:35:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><h1>I tried to scrape all the reviews of an app using <a href=\"https://pypi.org/project/google-play-scraper/\">google-play-scraper \u00b7 PyPI</a>. However, I&#39;m not able to scrape all the reviews. For example,an app has 160M reviews but I&#39;m not able to scrape all of it. How can I scrape all the reviews? Please help!</h1> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Impressive-Rain-9948\"> /u/Impressive-Rain-9948 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hxt490/how_to_scrape_all_the_reviews_in_google_play_store/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hxt490/how_to_scrape_all_the_reviews_in_google_play_store/\">[comments]</a></span>",
        "id": 1872607,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hxt490/how_to_scrape_all_the_reviews_in_google_play_store",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape 'All' the reviews in Google Play store?",
        "vote": 0
    }
]