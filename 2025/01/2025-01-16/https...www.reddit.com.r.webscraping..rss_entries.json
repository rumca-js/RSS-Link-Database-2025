[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-16T17:55:17+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>my sample project to scrape simple craigslist data - <a href=\"https://www.youtube.com/watch?v=iGJoTAMNZpg\">https://www.youtube.com/watch?v=iGJoTAMNZpg</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Goodragonfruit\"> /u/Goodragonfruit </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2uv41/my_sample_project_to_scrape_simple_craigslist_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2uv41/my_sample_project_to_scrape_simple_craigslist_data/\">[comments]</a></span>",
        "id": 1918971,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1i2uv41/my_sample_project_to_scrape_simple_craigslist_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "My sample project to scrape simple craigslist data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-16T14:05:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey, I have a python code that checks a http site I browse to using selinum. I use webdriver.Chrome and browse to a site using driver.get with a http url. For some reason it opens the chrome browser but changes the url to https, when I change the url in the search bar to http it works well but why can&#39;t selinum open the http site? Is there a work around to force it to use http?</p> <p>Note: for some http sites I check it is not happening and they work open with http.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/IsraeliBoy69\"> /u/IsraeliBoy69 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2pn4c/python_selenium_issue/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2pn4c/python_selenium_issue/\">[comments]</a></span>",
        "id": 1920967,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1i2pn4c/python_selenium_issue",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Python selenium issue",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-16T13:22:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have 200K ASINs that I need the price and ranking from Amazon. What is the fastest way?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/misterno123\"> /u/misterno123 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2os0u/how_to_get_price_and_rank_only_from_amazon/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2os0u/how_to_get_price_and_rank_only_from_amazon/\">[comments]</a></span>",
        "id": 1916944,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1i2os0u/how_to_get_price_and_rank_only_from_amazon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to get price and rank only from Amazon?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-16T10:10:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I\u2019m looking for guests for my podcast that\u2019s all about business analytics and using data extraction to make better decisions. It\u2019ll be live on Spotify, and I\u2019m hoping to find people who can share their experiences or insights about working with data.</p> <p>If you\u2019re into things like web scraping, data analytics, or just have some cool stories about how businesses can use data smarter, I\u2019d love to chat with you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/imflameable\"> /u/imflameable </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2lryf/can_i_find_podcast_guests_here/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2lryf/can_i_find_podcast_guests_here/\">[comments]</a></span>",
        "id": 1915665,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1i2lryf/can_i_find_podcast_guests_here",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Can I find podcast guests here?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-16T07:32:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys, I am trying to use twikit python lib to webscrape X (formerly known as twitter).</p> <p>I am doing great so far but I want a validation with the auth_token saved in my cookies.json. I want to validate if it is expired, and if it is, then relogin, or load the saved cookies from the past. </p> <p>I have been trying to use PyJwt Python lib to decode the auth_token and fetch the &#39;exp&#39; attribute, but it needs a secret_key. This is where I am stuck right now. How do I get the secret_key? I am unable to figure out where to get it. I mean, I am using twikit, so I am not actively storing any secret key and using requests to perform any API calls. </p> <p>Here is the code snippet for your reference:</p> <pre><code>from twikit import Client, TooManyRequests import time from datetime import datetime import json import csv from configparser import ConfigParser from random import randint import asyncio import tracemalloc import os import jwt impo",
        "id": 1920968,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1i2jphc/using_twikit_python_lib_how_to_validate_if_auth",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Using twikit python lib, how to validate if auth_token expired?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-16T06:41:13+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>1. Extract the following fields for all restaurants listed on Talabat (<a href=\"https://www.talabat.com/uae\">https://www.talabat.com/uae</a>) in the UAE:</p> <p>\u00b7 Restaurant Name</p> <p>\u00b7 Cuisine Type(s)</p> <p>\u00b7 Location/Area</p> <p>\u00b7 Ratings (if available)</p> <p>\u00b7 Delivery Time (if available)</p> <p>\u00b7 Average Cost/Price Range (if available)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Great_Painter_9501\"> /u/Great_Painter_9501 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2j02k/webscrapping_talabt_uae/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2j02k/webscrapping_talabt_uae/\">[comments]</a></span>",
        "id": 1915186,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1i2j02k/webscrapping_talabt_uae",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "webscrapping talabt uae",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-16T02:20:01+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have 200K ASINs that I need the price and ranking from Amazon, Currently I use Keepa but it only gives me 20K a day. I can get more but it gets expensive. </p> <p>Is there a faster way to do this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/misterno123\"> /u/misterno123 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2ei5w/how_to_get_price_and_rank_only_from_amazon/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2ei5w/how_to_get_price_and_rank_only_from_amazon/\">[comments]</a></span>",
        "id": 1914134,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1i2ei5w/how_to_get_price_and_rank_only_from_amazon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to get price and rank only from Amazon?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2025-01-16T00:21:59+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I try to use puppeteer and scrape website , generally I just enter classname or id and scrape it. However few websites (many actually) use tailwind so even idk what to enter in classname or to target \ud83c\udfaf</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Better_Function146\"> /u/Better_Function146 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2c522/how_to_scrape_website_if_it_uses_tailwind/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1i2c522/how_to_scrape_website_if_it_uses_tailwind/\">[comments]</a></span>",
        "id": 1913645,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1i2c522/how_to_scrape_website_if_it_uses_tailwind",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to scrape website if it uses tailwind",
        "vote": 0
    }
]