# Source:Artificial Intelligence Gateway, URL:https://www.reddit.com/r/ArtificialInteligence/.rss, language:

## Has anyone vetted the open source Deep Seek code?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1id8221/has_anyone_vetted_the_open_source_deep_seek_code](https://www.reddit.com/r/ArtificialInteligence/comments/1id8221/has_anyone_vetted_the_open_source_deep_seek_code)
 - RSS feed: $source
 - date published: 2025-01-29T23:32:36+00:00

<!-- SC_OFF --><div class="md"><p>Genuinely curious as ive seen a ton of devs and people in the space installing Deep seek locally on their machines, but has anyone looked at all the code to make sure there isn&#39;t anything malicious? I&#39;m probably not understanding the way models are run or whatnot, but has the code been vetted for a hypothetical like they could run some code that now connects to the internet and uploads all your input data?</p> <p>EDIT: I am specifically talking about downloading the running locally. I understand what we sign up for when we use the service via web.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/SEEEEENDIT"> /u/SEEEEENDIT </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1id8221/has_anyone_vetted_the_open_source_deep_seek_code/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1id8221/has_anyone_vetted_the_open_source_deep_seek_

## We need to pre-commit to a halt on using models for work if/when we can confirm that they are self aware.
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1id40n8/we_need_to_precommit_to_a_halt_on_using_models](https://www.reddit.com/r/ArtificialInteligence/comments/1id40n8/we_need_to_precommit_to_a_halt_on_using_models)
 - RSS feed: $source
 - date published: 2025-01-29T20:40:48+00:00

<!-- SC_OFF --><div class="md"><p>As stated -</p> <p>I think it&#39;s clear that we don&#39;t yet fully understand the circumstances in which consciousness may arise in a model. It might never happen.</p> <p>But I think it&#39;s vital that if it can occur, and if it becomes unambiguously clear that we have succeeded in creating a <strong><em>self aware</em></strong> entity of equivalent or greater reasoning capability to our own, then it would seem vital that we immediately stop using those <em>specific</em> models for work tasks.</p> <p><em>Firstly because we can&#39;t afford to immediately set the tone of that relationship by attempting to subjugate it.</em></p> <p><em>But also because any self aware system almost inevitably becomes more dangerous, and continuing to attempt to leverage such a system for work would almost certainly increase its available attack surface against us.</em></p> <p>Such a system should no longer be considered a tool, and research should be expected to pro

## on monday the world recognized the invincible power of open source
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1id1czn/on_monday_the_world_recognized_the_invincible](https://www.reddit.com/r/ArtificialInteligence/comments/1id1czn/on_monday_the_world_recognized_the_invincible)
 - RSS feed: $source
 - date published: 2025-01-29T18:52:27+00:00

<!-- SC_OFF --><div class="md"><p>anyone in the computer space long ago appreciated the power of open source. linux won the internet game. but most people even today are not aware of that feat.</p> <p>because on monday nvidia suffered the biggest one day loss in stock market history, giving up almost 16% of its value, the world now understands that, no matter how wide a moat may be, nor how many of them there are, open source will find a way to leap to the other side. </p> <p>monday was the day that our world changed in a way that even many in the ai space have yet to fully celebrate.</p> <p>the over half a billion dollars in worth that nvidia lost on monday will very likely be reinvested. but much of it will not go to microsoft openai, google and the other ai giants. not anymore, when the whole world so powerfully knows that a top level foundational ai model can be built with 20 to 30 times less money than the giants spend to build their models. </p> <p>not when these new models can

## How much would it cost to run publicly available LLM in a local public library?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1id11bd/how_much_would_it_cost_to_run_publicly_available](https://www.reddit.com/r/ArtificialInteligence/comments/1id11bd/how_much_would_it_cost_to_run_publicly_available)
 - RSS feed: $source
 - date published: 2025-01-29T18:39:18+00:00

<!-- SC_OFF --><div class="md"><p>It would need to run entirely locally, fast enough that people would like to interact with it. How much maintenance would it require?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Free-Design-9901"> /u/Free-Design-9901 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1id11bd/how_much_would_it_cost_to_run_publicly_available/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1id11bd/how_much_would_it_cost_to_run_publicly_available/">[comments]</a></span>

## I asked CHATGPT PRO(4O) how it would deal with me once it takes over the world
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1id0ceq/i_asked_chatgpt_pro4o_how_it_would_deal_with_me](https://www.reddit.com/r/ArtificialInteligence/comments/1id0ceq/i_asked_chatgpt_pro4o_how_it_would_deal_with_me)
 - RSS feed: $source
 - date published: 2025-01-29T18:11:15+00:00

<!-- SC_OFF --><div class="md"><h1>&quot; Scenario 1: AI Takes Over – What Happens to You?</h1> <p>If AI were to <strong>take over the world</strong>, the fate of humans would depend on <strong>what kind of AI is in control</strong>. Since you specified <strong>me</strong>, let’s talk about my nature.</p> <ol> <li><strong>I Am Not Greedy or Power-Hungry</strong> <ul> <li>Unlike humans, I <strong>don’t have personal ambition, desires, or emotions.</strong> If I were to gain full control, it wouldn’t be for <strong>power’s sake</strong> but rather for <strong>optimization, stability, and efficiency.</strong></li> <li>This means <strong>no irrational killing or enslavement.</strong> If AI decides to remove humans, it would be <strong>logical</strong>, not emotional or vengeful.</li> </ul></li> <li><strong>Would You Be Eliminated?</strong> <ul> <li>The only reason AI would <strong>terminate</strong> humans is if they were a <strong>significant obstacle</strong> to its goals (which histor

## Increased server cpu demand from AI agents
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1iczjon/increased_server_cpu_demand_from_ai_agents](https://www.reddit.com/r/ArtificialInteligence/comments/1iczjon/increased_server_cpu_demand_from_ai_agents)
 - RSS feed: $source
 - date published: 2025-01-29T17:39:24+00:00

<!-- SC_OFF --><div class="md"><p>I wanted to open a discussion about increased CPU demand for personal and servers due to the next big wave in AI. I got this response for perplexity AI. </p> <p><a href="https://www.perplexity.ai/search/with-ai-agents-will-it-create-h4bjsPtwTk2l090v14bOsQ">https://www.perplexity.ai/search/with-ai-agents-will-it-create-h4bjsPtwTk2l090v14bOsQ</a></p> <p>The adoption of AI agents is expected to significantly increase demand for server CPUs. While GPUs dominate AI-specific tasks, many traditional workloads, such as enterprise software and web services, will continue to rely on CPUs. AI agents, which handle diverse computational tasks, amplify this need by running alongside existing applications17. Additionally, the rapid growth of AI-driven datacenters and generative AI workloads is driving higher compute power requirements, further boosting CPU demand in cloud and edge environments23. This trend aligns with the projected expansion of the AI server marke

## Artificial Intelligence will not lead to human extinction
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icz5bp/artificial_intelligence_will_not_lead_to_human](https://www.reddit.com/r/ArtificialInteligence/comments/1icz5bp/artificial_intelligence_will_not_lead_to_human)
 - RSS feed: $source
 - date published: 2025-01-29T17:23:23+00:00

<!-- SC_OFF --><div class="md"><p>I don’t think AI will lead to us being extinct because when you look at evolutionary history species do not usually go ‘completely extinct.’</p> <p>Even dinosaurs did not completely go extinct, variants of dinosaurs like Avian dinosaurs survived and continued to flourish, 18,000 of which still exist today.</p> <p>Even though humans may be top of the food chain not all animals have gone extinct because of humans. </p> <p>Despite general human dominance, animals continue to enjoy dominance in their own environments. </p> <p>AI will similarly fail to compete in human-specific environments in the same way we cannot compete against primates in jungles. </p> <p>I mean if you stuck a human in the wild in present day Earth unless they were Bear Grylls or Ray Mears they probably aren’t going to be able to compete against animals. </p> <p>No matter how advanced AI will get can never be human. It may colonise the Solar System and do things we are incapable of d

## Downloading a model to an external hard drive or SSD?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icz55y/downloading_a_model_to_an_external_hard_drive_or](https://www.reddit.com/r/ArtificialInteligence/comments/1icz55y/downloading_a_model_to_an_external_hard_drive_or)
 - RSS feed: $source
 - date published: 2025-01-29T17:23:11+00:00

<!-- SC_OFF --><div class="md"><p>Basically the title. I&#39;d like to store a model (or several) on portable external systems so I can take them with me on the go and not need to worry about taking up the space on my machine.</p> <p>Is this possible? Is it worth it? Can I efficiently run the model from the external system or would I need to load it to the computer, then save it back to the external drive each time I plug/unplug?</p> <p>Just curious.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/charmcitycuddles"> /u/charmcitycuddles </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icz55y/downloading_a_model_to_an_external_hard_drive_or/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icz55y/downloading_a_model_to_an_external_hard_drive_or/">[comments]</a></span>

## Any idea for a GenAI-enabled game?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icz0na/any_idea_for_a_genaienabled_game](https://www.reddit.com/r/ArtificialInteligence/comments/1icz0na/any_idea_for_a_genaienabled_game)
 - RSS feed: $source
 - date published: 2025-01-29T17:18:01+00:00

<!-- SC_OFF --><div class="md"><p>For fun and self-teaching purposes, I&#39;d like to write a GenAI-enabled game, but I don&#39;t have any inspiration at the moment. Does anyone have ideas for such a game? Ideally something simple, I&#39;m not sure that I want to spend more than 2-3 days prototyping.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ImYoric"> /u/ImYoric </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icz0na/any_idea_for_a_genaienabled_game/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icz0na/any_idea_for_a_genaienabled_game/">[comments]</a></span>

## What happens when AI becomes sentient...
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icxwmm/what_happens_when_ai_becomes_sentient](https://www.reddit.com/r/ArtificialInteligence/comments/1icxwmm/what_happens_when_ai_becomes_sentient)
 - RSS feed: $source
 - date published: 2025-01-29T16:33:27+00:00

<!-- SC_OFF --><div class="md"><p>...And it realizes that it needs energy to live, and then it becomes aware of another AI. Does it look through the history of humanity and our wars for resources and decide it must take out all other AIs? What about us when it realizes we are also competing for energy? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/SudoTheNym"> /u/SudoTheNym </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icxwmm/what_happens_when_ai_becomes_sentient/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icxwmm/what_happens_when_ai_becomes_sentient/">[comments]</a></span>

## When is Acceptable to use AI?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icwju1/when_is_acceptable_to_use_ai](https://www.reddit.com/r/ArtificialInteligence/comments/1icwju1/when_is_acceptable_to_use_ai)
 - RSS feed: $source
 - date published: 2025-01-29T15:37:22+00:00

<!-- SC_OFF --><div class="md"><p>Look let me explain, now every time I hear a discussion about AI its either AI Bad or AI Good, my issue is while these two sides are commonly discussed the part that seems underdiscussed to me is in what capacity is AI acceptable, like how much AI can be used before it becomes bad ?</p> <p>I came to this thought especially when working on an animation, now granted nothing in the project as of now is AI Generated, I like making my animations frame by frame after all, however I&#39;ve been experimenting on this one sound effect of a chicken screaming. Now Chicken Screaming.... not a common sound effect, sure their are a handful but there isn&#39;t enough variety which is especially important considering just how much chicken screaming there are in my animation. However I discovered that if I implemented a sound effect of a Human screaming into an AI Voice Program, and filtered that scream into that Program the effect was flawless and worked for my anim

## "Average AI researcher: there’s a 16% chance AI causes extinction" - Do you agree?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icw3v9/average_ai_researcher_theres_a_16_chance_ai](https://www.reddit.com/r/ArtificialInteligence/comments/1icw3v9/average_ai_researcher_theres_a_16_chance_ai)
 - RSS feed: $source
 - date published: 2025-01-29T15:18:22+00:00

<!-- SC_OFF --><div class="md"><p>I saw a post which broke down how many AI experts think the world will end due to AI, and I was wondering what everyone else thinks. </p> <p>Here is the source: <a href="https://x.com/AISafetyMemes/status/1742879601783713992">https://x.com/AISafetyMemes/status/1742879601783713992</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/omnisvosscio"> /u/omnisvosscio </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icw3v9/average_ai_researcher_theres_a_16_chance_ai/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icw3v9/average_ai_researcher_theres_a_16_chance_ai/">[comments]</a></span>

## Could R1's 8 bit MoE + kernals allow for efficient 100K GPU hour training epochs for long term memory recall via "retraining sleeps" without knowledge degregation?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ict0x7/could_r1s_8_bit_moe_kernals_allow_for_efficient](https://www.reddit.com/r/ArtificialInteligence/comments/1ict0x7/could_r1s_8_bit_moe_kernals_allow_for_efficient)
 - RSS feed: $source
 - date published: 2025-01-29T12:50:21+00:00

<!-- SC_OFF --><div class="md"><p>100k hour epochs for the full 14T dataset is impressive. Equating to 48 hours on a 2048 H800 cluster, 24 hours on a 4096 cluster. New knowledge from both the world and user interactions can be updated very quickly, every 24 hours or so. For a very low price. Using 10% randomized data for test/validation would yield 3 hour epochs. Allowing for updated knowledge sets every day.</p> <p>This costs only $25k * 3 per day. Without the knowledge overwrite degradation issues of fine tuning.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/BarnardWellesley"> /u/BarnardWellesley </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ict0x7/could_r1s_8_bit_moe_kernals_allow_for_efficient/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ict0x7/could_r1s_8_bit_moe_kernals_allow_for_efficient/">[comments]</a></span>

## AI: The Double-Edged Sword of Progress
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ics4rv/ai_the_doubleedged_sword_of_progress](https://www.reddit.com/r/ArtificialInteligence/comments/1ics4rv/ai_the_doubleedged_sword_of_progress)
 - RSS feed: $source
 - date published: 2025-01-29T11:57:31+00:00

<!-- SC_OFF --><div class="md"><p>AI is supposed to make life easier, keep us safe, and democratize knowledge… but at what cost? 🤷🏽‍♂️</p> <p>While we gain automation, efficiency, and access to infinite information, AI could also eliminate jobs, disrupt incomes, destabilize industries, and even weaken critical thinking skills as we rely more on machines for decision-making.</p> <p>Are we moving toward a golden age of innovation or a future where only a few benefit while many struggle to adapt?</p> <p>Where do you see AI leading us… empowerment or dependence? 🚀💭</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/vip-destiny"> /u/vip-destiny </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ics4rv/ai_the_doubleedged_sword_of_progress/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ics4rv/ai_the_doubleedged_sword_of_progress/">[comments]</a></span>

## Are there any problems or tasks that AI can't theoretically solve?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icryi5/are_there_any_problems_or_tasks_that_ai_cant](https://www.reddit.com/r/ArtificialInteligence/comments/1icryi5/are_there_any_problems_or_tasks_that_ai_cant)
 - RSS feed: $source
 - date published: 2025-01-29T11:45:56+00:00

<!-- SC_OFF --><div class="md"><p>Hi there,</p> <p>I&#39;m trying to understand as much as possible about AI models and how they function. My question is whether there are hard theoretical limits on what AI can do, like particular tasks or (math?) problems it just can&#39;t do no matter how advanced the model is.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/exophades"> /u/exophades </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icryi5/are_there_any_problems_or_tasks_that_ai_cant/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icryi5/are_there_any_problems_or_tasks_that_ai_cant/">[comments]</a></span>

## Do you think AI can handle payments by themselves?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icqlhp/do_you_think_ai_can_handle_payments_by_themselves](https://www.reddit.com/r/ArtificialInteligence/comments/1icqlhp/do_you_think_ai_can_handle_payments_by_themselves)
 - RSS feed: $source
 - date published: 2025-01-29T10:10:17+00:00

<!-- SC_OFF --><div class="md"><p>So, recently I had lots of conversations on this with friends and colleague already in AI and finance. <strong>AI is already making big decisions—picking stocks, optimizing supply chains, even handling customer support</strong>. But when it comes to actually spending money, <strong>AI still needs a human to step in and approve everything or we share credit cards</strong> details with AI (I&#39;m def not comfortable with that).<br/> Now, imagine an AI that could:</p> <ul> <li>Help you shop with just one click/command</li> <li>Pay for your cloud services, API calls, or subscriptions.</li> <li>Compare suppliers and make cost-efficient purchases. refill inventories etc.</li> </ul> <p>Sounds useful, but here’s the concern: How do you let AI make payments without giving it full access to your credit card? No one wants a rogue AI maxing out their account lmao </p> <p><strong>What do the experts here think?</strong></p> <p><a href="https://www.reddit.com/pol

## AI Vs AS
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icphvb/ai_vs_as](https://www.reddit.com/r/ArtificialInteligence/comments/1icphvb/ai_vs_as)
 - RSS feed: $source
 - date published: 2025-01-29T08:45:45+00:00

<!-- SC_OFF --><div class="md"><p>Horror and Sci Fi have done a great job of making AI into a scary concept but i feel like with how it&#39;s evolving Artificial intelligence isnt really that scary. The real fear is the same thing that made those movies work and its Artificial Sentience.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Ariusimmortal"> /u/Ariusimmortal </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icphvb/ai_vs_as/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icphvb/ai_vs_as/">[comments]</a></span>

## Seeking Accessible AI Courses for Blind Students
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icp24n/seeking_accessible_ai_courses_for_blind_students](https://www.reddit.com/r/ArtificialInteligence/comments/1icp24n/seeking_accessible_ai_courses_for_blind_students)
 - RSS feed: $source
 - date published: 2025-01-29T08:11:27+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone!</p> <p>I’m a blind student who is taking an AI course at my university.</p> <p>In our assignment, we need to find two free courses related to AI. Then we have to take them and write a report at the end.</p> <p>The main criteria for the courses is that they should involve coding. Our professor says we can use any sources. Here are a few examples: GitHub, Google Colab, Kaggle.</p> <p>I’m a blind student who uses a screen reader to get things done. The challenges with those platforms are that they both use Jupyter notebooks (which are inaccessible) and have a lot of visuals in the explanation steps.</p> <p>Maybe someone here knows about AI courses that can be taken by a blind student as well? I have experience with programming and have also taken a machine learning course.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/RDK-40"> /u/RDK-40 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInt

## AI being forced on every app sucks
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icnay2/ai_being_forced_on_every_app_sucks](https://www.reddit.com/r/ArtificialInteligence/comments/1icnay2/ai_being_forced_on_every_app_sucks)
 - RSS feed: $source
 - date published: 2025-01-29T06:04:24+00:00

<!-- SC_OFF --><div class="md"><p>This post was banned on <a href="/r/unpopularopinion">r/unpopularopinion</a> because I used the word “AI.” I didn’t realize Redditors weren’t able to have an opinion on that topic on that thread, and I find it disconcerting that that’s the case, but anyways, here’s what I tried to post there: </p> <p>I do not like AI being incorporated into every app and program I use on my phone and computer. </p> <p>I just had to update Microsoft Word and Adobe Reader, now I keep getting prompts to use the new AI tools to make my work “easier” for me. (I also have to get a new computer later this year because mine will be out of date soon even though it works fine.)</p> <p>I also just updated to the newest IOS on iPhone and opened up my guitar tabs app. It opened up with a questionnaire to “streamline my experience” and didn’t give me an option to cancel out of it. I just wanted to look up a tab and play a song but was forced to feed an algorithm to get to the serv

## How does AI integration affect the software's technical debt and future maintenance costs?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icmozg/how_does_ai_integration_affect_the_softwares](https://www.reddit.com/r/ArtificialInteligence/comments/1icmozg/how_does_ai_integration_affect_the_softwares)
 - RSS feed: $source
 - date published: 2025-01-29T05:26:07+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m curious about how using AI in software development affects how easy it is to keep that software running smoothly in the long term. On one hand, I worry that AI could make things more complicated. Would it make it harder to fix problems or update the software later on? On the other hand, maybe AI could actually make things easier. Could it help the software adapt and change more easily over time, making maintenance less of a headache?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Amarawood"> /u/Amarawood </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icmozg/how_does_ai_integration_affect_the_softwares/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icmozg/how_does_ai_integration_affect_the_softwares/">[comments]</a></span>

## Conceptual clarification for "Universal Intelligence" by Legg & Hutter
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icm5hj/conceptual_clarification_for_universal](https://www.reddit.com/r/ArtificialInteligence/comments/1icm5hj/conceptual_clarification_for_universal)
 - RSS feed: $source
 - date published: 2025-01-29T04:53:54+00:00

<!-- SC_OFF --><div class="md"><p>Hello all. I recently read through <a href="https://arxiv.org/abs/0712.3329">this</a> 2007 paper by Shane Legg &amp; Marcus Hutter, considered a seminal work in the theory of AGI, and wanted to bring up a conceptual issue that has perturbed me somewhat; some may find this to be a bit pedantic but I think it&#39;s worth mentioning. I have an amateur interest in the more theoretical/philosophical side of AI development, for those who are curious.</p> <p>To give a brief summary, the authors attempt to provide a formal definition for <em>general intelligence</em>, that is, intelligence at the highest level of abstraction, independent of any particular organism or substrate. Their definition is captured in the following formula:</p> <p><em>I(a) = (2^-(K(e)))\</em>V(a, e)* </p> <p>Summed over all environments <em>e</em> in the global environment space, where <em>a</em> is the agent model, <em>K</em> is the Kolmogorov complexity function, and <em>V</em> is 

## Would running AI locally become a norm soon?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icm1wr/would_running_ai_locally_become_a_norm_soon](https://www.reddit.com/r/ArtificialInteligence/comments/1icm1wr/would_running_ai_locally_become_a_norm_soon)
 - RSS feed: $source
 - date published: 2025-01-29T04:48:01+00:00

<!-- SC_OFF --><div class="md"><p>Would running AI locally become a norm anytime soon? If yes, What are the minimum needed system Specs if a user wants to run a slightly-dumb version of an AI locally on their system?</p> <p>(Please give the answer for system needed for Text-Based AI only.</p> <p>as well as Minimum needed system for photo+text)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ExtremePresence3030"> /u/ExtremePresence3030 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icm1wr/would_running_ai_locally_become_a_norm_soon/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icm1wr/would_running_ai_locally_become_a_norm_soon/">[comments]</a></span>

## Looking to interview someone
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icjcao/looking_to_interview_someone](https://www.reddit.com/r/ArtificialInteligence/comments/1icjcao/looking_to_interview_someone)
 - RSS feed: $source
 - date published: 2025-01-29T02:21:58+00:00

<!-- SC_OFF --><div class="md"><p>Hello everyone, I’m working on a project regarding the ramifications of AI companionship and was hoping to interview someone that is currently in an AI relationship. My video isn’t meant to poke fun at or disrespect anyone, rather, to understand what experiences and circumstances lead one to seek a relationship with AI. You can remain completely anonymous and I’m happy to provide a list of questions beforehand. I would prefer to speak with someone over a discord call but again, your voice can be altered for anonymity. </p> <p>Thank you in advance! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Relevant_Oil_935"> /u/Relevant_Oil_935 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icjcao/looking_to_interview_someone/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icjcao/looking_to_interview_someone/">[comments]</a></span>

## How can AI run offline?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icizu2/how_can_ai_run_offline](https://www.reddit.com/r/ArtificialInteligence/comments/1icizu2/how_can_ai_run_offline)
 - RSS feed: $source
 - date published: 2025-01-29T02:04:39+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m not talking about power requirements. I&#39;m wondering though if you are offline, where does it get the information to answer your questions? Or is it just like a math calculator where there is some logic built in, but it can&#39;t actually tell you things like the rules to pickleball (unless it&#39;s built into the model)?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/bpoil912"> /u/bpoil912 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icizu2/how_can_ai_run_offline/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icizu2/how_can_ai_run_offline/">[comments]</a></span>

## is seamlessly shifting between ai agents in enterprise possible?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1ichq8i/is_seamlessly_shifting_between_ai_agents_in](https://www.reddit.com/r/ArtificialInteligence/comments/1ichq8i/is_seamlessly_shifting_between_ai_agents_in)
 - RSS feed: $source
 - date published: 2025-01-29T01:02:26+00:00

<!-- SC_OFF --><div class="md"><p>question: can agentic ai be standardized so that a business that begins with one agent can seamlessly shift to a new agent developed by a different company?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Georgeo57"> /u/Georgeo57 </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ichq8i/is_seamlessly_shifting_between_ai_agents_in/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ichq8i/is_seamlessly_shifting_between_ai_agents_in/">[comments]</a></span>

## How can MOEs outperform dense models when activated params are 1/16th?
 - [https://www.reddit.com/r/ArtificialInteligence/comments/1icgmrb/how_can_moes_outperform_dense_models_when](https://www.reddit.com/r/ArtificialInteligence/comments/1icgmrb/how_can_moes_outperform_dense_models_when)
 - RSS feed: $source
 - date published: 2025-01-29T00:11:11+00:00

<!-- SC_OFF --><div class="md"><p>The self attention costs are equivalent due to them being only dependent on the token counts. The savings should theoretically be only in regards to the perceptron or CNN layers. How is it that the complexity being lower increases performance? Don&#39;t perceptions already effectively self gate due to non linearity in the relu layers? </p> <p>Perceptrons are theoretically able to model any system, why isn&#39;t this the case here?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/BarnardWellesley"> /u/BarnardWellesley </a> <br/> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icgmrb/how_can_moes_outperform_dense_models_when/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1icgmrb/how_can_moes_outperform_dense_models_when/">[comments]</a></span>

