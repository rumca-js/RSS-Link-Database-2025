# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Finding businessID to find founding date
 - [https://www.reddit.com/r/webscraping/comments/1i3pkeq/finding_businessid_to_find_founding_date](https://www.reddit.com/r/webscraping/comments/1i3pkeq/finding_businessid_to_find_founding_date)
 - RSS feed: $source
 - date published: 2025-01-17T20:13:23+00:00

<!-- SC_OFF --><div class="md"><p><a href="https://ccfs.sos.wa.gov/#/AdvancedSearch">https://ccfs.sos.wa.gov/#/AdvancedSearch</a></p> <p>Hello, I have been trying to get the founding dates of the companies that are active but had no success so far. I believe that I need to find the businessID so that I can use this API to get additional data for each one <a href="https://ccfs-api.prod.sos.wa.gov/api/BusinessSearch/BusinessInformation?businessID=596185">https://ccfs-api.prod.sos.wa.gov/api/BusinessSearch/BusinessInformation?businessID=596185</a> </p> <p>Any advise is appreciated, thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/HouseFlyOutreach"> /u/HouseFlyOutreach </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i3pkeq/finding_businessid_to_find_founding_date/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i3pkeq/finding_businessid_to_find_founding_date/">[comments]</a></spa

## Help me estimate the cost and time needed for scraping this website
 - [https://www.reddit.com/r/webscraping/comments/1i3pgeh/help_me_estimate_the_cost_and_time_needed_for](https://www.reddit.com/r/webscraping/comments/1i3pgeh/help_me_estimate_the_cost_and_time_needed_for)
 - RSS feed: $source
 - date published: 2025-01-17T20:08:31+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m a complete beginner to webscraping with basic computer programming skill. I am trying to build my own app scraping data from collecting data from a specific website. I really tried looking for some APIs but there aren&#39;t any available. Idk where to start and how to start, could someone guide me on how to scrape this <a href="https://incidecoder.com/">website</a>. I really can&#39;t afford a freelancer since I have already spent 90% of my savings. Can someone help me out?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/BornInstruction298"> /u/BornInstruction298 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i3pgeh/help_me_estimate_the_cost_and_time_needed_for/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i3pgeh/help_me_estimate_the_cost_and_time_needed_for/">[comments]</a></span>

## Puppeteer hangs when I launch headless with request interception
 - [https://www.reddit.com/r/webscraping/comments/1i3p61m/puppeteer_hangs_when_i_launch_headless_with](https://www.reddit.com/r/webscraping/comments/1i3p61m/puppeteer_hangs_when_i_launch_headless_with)
 - RSS feed: $source
 - date published: 2025-01-17T19:56:39+00:00

<!-- SC_OFF --><div class="md"><p>I can not for the life of me figure this out. I have a number of scripts that use request interception to capture some API http requests. This works fine most of the time but whenever I am building a new script and I turn on request interception the browser hangs on startup. So I go and launch the browser in non headless display mode and by simply changing that one flag in the browser launch command and no hanging. I have other scripts that use the exact same code in headless with request interception and they run fine. The error is something like network protocol timeout. Any ideas? Seriously I’m going crazy over here. Also this only happens in the production environment, it never happens in my home dev environment.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/LoveThemMegaSeeds"> /u/LoveThemMegaSeeds </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i3p61m/puppeteer_hangs_when_i_launch

## Command line tools for webscrapping
 - [https://www.reddit.com/r/webscraping/comments/1i3oqpf/command_line_tools_for_webscrapping](https://www.reddit.com/r/webscraping/comments/1i3oqpf/command_line_tools_for_webscrapping)
 - RSS feed: $source
 - date published: 2025-01-17T19:38:15+00:00

<!-- SC_OFF --><div class="md"><p>Any command line tools to do webscrapping. Something like this:</p> <p>crawl --url &quot;somestore.com&quot; --query &quot;find prices for shoes on this website&quot;</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Tiberius_Gladiator"> /u/Tiberius_Gladiator </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i3oqpf/command_line_tools_for_webscrapping/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i3oqpf/command_line_tools_for_webscrapping/">[comments]</a></span>

## WAIT Less in Python Selenium with CUSTOM Strategies!
 - [https://www.reddit.com/r/webscraping/comments/1i3n9d6/wait_less_in_python_selenium_with_custom](https://www.reddit.com/r/webscraping/comments/1i3n9d6/wait_less_in_python_selenium_with_custom)
 - RSS feed: $source
 - date published: 2025-01-17T18:34:39+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1i3n9d6/wait_less_in_python_selenium_with_custom/"> <img src="https://external-preview.redd.it/QTxRPIPYmE4SvdOPl6O66OhNtdIMyXvflr_lR5Q_M7s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0c359ba1dd23a881b91d4f38c08114e79d164398" alt="WAIT Less in Python Selenium with CUSTOM Strategies!" title="WAIT Less in Python Selenium with CUSTOM Strategies!" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Capable-Post-5674"> /u/Capable-Post-5674 </a> <br/> <span><a href="https://youtube.com/watch?v=L5ISCK_fuEk&amp;si=etX2VAww0x3Wu19V">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i3n9d6/wait_less_in_python_selenium_with_custom/">[comments]</a></span> </td></tr></table>

## ¿VPS or AWS Lambda?
 - [https://www.reddit.com/r/webscraping/comments/1i3kvpu/vps_or_aws_lambda](https://www.reddit.com/r/webscraping/comments/1i3kvpu/vps_or_aws_lambda)
 - RSS feed: $source
 - date published: 2025-01-17T16:54:56+00:00

<!-- SC_OFF --><div class="md"><p>Considering these two options: VPS or AWS Lambda, which option do you think is better for hosting your web scrapers? Taking into account speed, manageability, and other factors of your architecture.</p> <p>I have a project with more than 30 scrappers, with a concurrency of approximately 100 requests per minute. I am in this dilemma since I have worked with Lambda and Step Functions but I don&#39;t know if it is the most convenient. </p> <p>I am leaning more towards a Kubernetes-oriented architecture and a VPS, but I want to know. What do you think? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Stondarko"> /u/Stondarko </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i3kvpu/vps_or_aws_lambda/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i3kvpu/vps_or_aws_lambda/">[comments]</a></span>

## How to force chrome to get allocated with all ram for webscraping?
 - [https://www.reddit.com/r/webscraping/comments/1i3fhun/how_to_force_chrome_to_get_allocated_with_all_ram](https://www.reddit.com/r/webscraping/comments/1i3fhun/how_to_force_chrome_to_get_allocated_with_all_ram)
 - RSS feed: $source
 - date published: 2025-01-17T12:42:18+00:00

<!-- SC_OFF --><div class="md"><p>My goal is to scrape a list from webull to do stock market analysis. I have found a good webscraping plugin and it have been working well. However, the data is like more than 20K posts, and my chrome went out of memory after scraping 7K posts. My PC&#39;s ram is 16GB and I have tried using my colleague whose position is video editing and his pc has 64GB of ram. Both of our chromes crashed when we got 7K posts. So I think this was because chrome weren&#39;t distributed that much ram. How to give all ram of my pc to chrome?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/That-Eagle8010"> /u/That-Eagle8010 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i3fhun/how_to_force_chrome_to_get_allocated_with_all_ram/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i3fhun/how_to_force_chrome_to_get_allocated_with_all_ram/">[comments]</a></span>

## Generating a list of SaaS pulling 20k+$ MRR
 - [https://www.reddit.com/r/webscraping/comments/1i3bk7p/generating_a_list_of_saas_pulling_20k_mrr](https://www.reddit.com/r/webscraping/comments/1i3bk7p/generating_a_list_of_saas_pulling_20k_mrr)
 - RSS feed: $source
 - date published: 2025-01-17T08:02:25+00:00

<!-- SC_OFF --><div class="md"><p>Hello everyone , I have been contracted to a project for scraping CrunchBase and few other sites to pull all software companies that are pulling more than 20k per month.</p> <p>Before starting wanted to ask if datacentre proxies might be a good fit for CrunchBase or should I just go for residential proxies ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/True_Masterpiece224"> /u/True_Masterpiece224 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i3bk7p/generating_a_list_of_saas_pulling_20k_mrr/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i3bk7p/generating_a_list_of_saas_pulling_20k_mrr/">[comments]</a></span>

## Python EOF error after some time
 - [https://www.reddit.com/r/webscraping/comments/1i39awo/python_eof_error_after_some_time](https://www.reddit.com/r/webscraping/comments/1i39awo/python_eof_error_after_some_time)
 - RSS feed: $source
 - date published: 2025-01-17T05:22:58+00:00

<!-- SC_OFF --><div class="md"><p>Hey all,</p> <p>I have a function running on Google Cloud that doing calls to some API using <a href="https://github.com/VeNoMouS/cloudscraper">cloudscraper</a>, it works well by bypass 403 error from cloudflare.</p> <p>I am doing iteration of 250 calls with delay between them, it works fine till I get to a point where I get this error:</p> <p><em>An error occurred: HTTPSConnectionPool(host=&#39;SOME_URL&#39;, port=443): Max retries exceeded with url: SOME_URL(Caused by SSLError(SSLEOFError(8, &#39;[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)&#39;)))</em> </p> <p>I tried to look online but I couldn&#39;t find anything related, I thought I might hit some rate limiter but I am not sure.</p> <p>Does someone knows how to fix it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/eilatc"> /u/eilatc </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i39awo/

## Logging into new york times programmatically with a valid account
 - [https://www.reddit.com/r/webscraping/comments/1i363mj/logging_into_new_york_times_programmatically_with](https://www.reddit.com/r/webscraping/comments/1i363mj/logging_into_new_york_times_programmatically_with)
 - RSS feed: $source
 - date published: 2025-01-17T02:24:06+00:00

<!-- SC_OFF --><div class="md"><p>Has anyone had success logging into <a href="http://nytimes.com">nytimes.com</a> with a valid account through a browser-based script? I&#39;ve tried the code below but keep getting thrown a captcha at the bottom of this script. Even after correctly solving it (manually), I still get an automated blocked message (bot detected).</p> <p>Would love to see if anyone has been able to get around this. thanks</p> <p>--</p> <pre><code>import time import undetected_chromedriver as uc from selenium_stealth import stealth from selenium.webdriver.common.by import By # 1. Set up Chrome options chrome_options = uc.ChromeOptions() chrome_options.add_argument(&quot;--no-sandbox&quot;) chrome_options.add_argument(&quot;--disable-blink-features=AutomationControlled&quot;) chrome_options.add_argument(&quot;--disable-infobars&quot;) chrome_options.add_argument(&quot;--disable-gpu&quot;) chrome_options.add_argument(&quot;--disable-dev-shm-usage&quot;) # chrome_options.add

## How to scrape a website when the request is stopped or not received?
 - [https://www.reddit.com/r/webscraping/comments/1i34ll3/how_to_scrape_a_website_when_the_request_is](https://www.reddit.com/r/webscraping/comments/1i34ll3/how_to_scrape_a_website_when_the_request_is)
 - RSS feed: $source
 - date published: 2025-01-17T01:07:38+00:00

<!-- SC_OFF --><div class="md"><p>For now , I&#39;m using Requests/BeautifulSoup as a start. This website is of a well known store in my country. I have tried scraping the data directly from the site and via API with the same results. User-agents are in use. In the http header, I have even put the cookies and still no success. Anyone else had this issue?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/decisively-undecided"> /u/decisively-undecided </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i34ll3/how_to_scrape_a_website_when_the_request_is/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i34ll3/how_to_scrape_a_website_when_the_request_is/">[comments]</a></span>

## How can I scrape reddit without limit?
 - [https://www.reddit.com/r/webscraping/comments/1i33zps/how_can_i_scrape_reddit_without_limit](https://www.reddit.com/r/webscraping/comments/1i33zps/how_can_i_scrape_reddit_without_limit)
 - RSS feed: $source
 - date published: 2025-01-17T00:37:47+00:00

<!-- SC_OFF --><div class="md"><p>I want to crawl askreddit&#39;s posts and comments from the order of the most popular.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Odd_Pianist_4521"> /u/Odd_Pianist_4521 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1i33zps/how_can_i_scrape_reddit_without_limit/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1i33zps/how_can_i_scrape_reddit_without_limit/">[comments]</a></span>

